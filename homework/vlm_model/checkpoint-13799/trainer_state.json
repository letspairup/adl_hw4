{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 13799,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 7.247164546871037e-05,
      "grad_norm": 32.82517623901367,
      "learning_rate": 0.0002,
      "loss": 8.0028,
      "step": 1
    },
    {
      "epoch": 0.00014494329093742075,
      "grad_norm": 13.751426696777344,
      "learning_rate": 0.00019998550619610117,
      "loss": 6.1253,
      "step": 2
    },
    {
      "epoch": 0.0002174149364061311,
      "grad_norm": 14.133289337158203,
      "learning_rate": 0.00019997101239220235,
      "loss": 5.4673,
      "step": 3
    },
    {
      "epoch": 0.0002898865818748415,
      "grad_norm": 24.54303741455078,
      "learning_rate": 0.0001999565185883035,
      "loss": 3.5187,
      "step": 4
    },
    {
      "epoch": 0.0003623582273435518,
      "grad_norm": 12.790197372436523,
      "learning_rate": 0.00019994202478440466,
      "loss": 3.8077,
      "step": 5
    },
    {
      "epoch": 0.0004348298728122622,
      "grad_norm": 8.515637397766113,
      "learning_rate": 0.00019992753098050585,
      "loss": 2.0776,
      "step": 6
    },
    {
      "epoch": 0.0005073015182809725,
      "grad_norm": 8.254708290100098,
      "learning_rate": 0.000199913037176607,
      "loss": 1.9575,
      "step": 7
    },
    {
      "epoch": 0.000579773163749683,
      "grad_norm": 8.83700180053711,
      "learning_rate": 0.00019989854337270816,
      "loss": 2.7332,
      "step": 8
    },
    {
      "epoch": 0.0006522448092183933,
      "grad_norm": 7.532907009124756,
      "learning_rate": 0.00019988404956880934,
      "loss": 2.9012,
      "step": 9
    },
    {
      "epoch": 0.0007247164546871036,
      "grad_norm": 7.752445697784424,
      "learning_rate": 0.0001998695557649105,
      "loss": 1.7375,
      "step": 10
    },
    {
      "epoch": 0.0007971881001558141,
      "grad_norm": 5.768640518188477,
      "learning_rate": 0.00019985506196101166,
      "loss": 2.0899,
      "step": 11
    },
    {
      "epoch": 0.0008696597456245244,
      "grad_norm": 7.863707065582275,
      "learning_rate": 0.00019984056815711284,
      "loss": 2.1908,
      "step": 12
    },
    {
      "epoch": 0.0009421313910932348,
      "grad_norm": 7.244498252868652,
      "learning_rate": 0.00019982607435321402,
      "loss": 1.8135,
      "step": 13
    },
    {
      "epoch": 0.001014603036561945,
      "grad_norm": 9.885364532470703,
      "learning_rate": 0.00019981158054931518,
      "loss": 2.0291,
      "step": 14
    },
    {
      "epoch": 0.0010870746820306554,
      "grad_norm": 7.200526237487793,
      "learning_rate": 0.00019979708674541636,
      "loss": 1.6355,
      "step": 15
    },
    {
      "epoch": 0.001159546327499366,
      "grad_norm": 10.748762130737305,
      "learning_rate": 0.00019978259294151752,
      "loss": 2.0657,
      "step": 16
    },
    {
      "epoch": 0.0012320179729680763,
      "grad_norm": 8.342181205749512,
      "learning_rate": 0.00019976809913761868,
      "loss": 1.498,
      "step": 17
    },
    {
      "epoch": 0.0013044896184367866,
      "grad_norm": 6.396667003631592,
      "learning_rate": 0.00019975360533371986,
      "loss": 1.4007,
      "step": 18
    },
    {
      "epoch": 0.001376961263905497,
      "grad_norm": 4.989565372467041,
      "learning_rate": 0.00019973911152982102,
      "loss": 1.0098,
      "step": 19
    },
    {
      "epoch": 0.0014494329093742073,
      "grad_norm": 4.431452751159668,
      "learning_rate": 0.00019972461772592217,
      "loss": 1.0526,
      "step": 20
    },
    {
      "epoch": 0.0015219045548429176,
      "grad_norm": 8.05736255645752,
      "learning_rate": 0.00019971012392202336,
      "loss": 1.7729,
      "step": 21
    },
    {
      "epoch": 0.0015943762003116282,
      "grad_norm": 8.098490715026855,
      "learning_rate": 0.0001996956301181245,
      "loss": 1.6817,
      "step": 22
    },
    {
      "epoch": 0.0016668478457803385,
      "grad_norm": 6.804064750671387,
      "learning_rate": 0.00019968113631422567,
      "loss": 1.149,
      "step": 23
    },
    {
      "epoch": 0.0017393194912490488,
      "grad_norm": 6.384942054748535,
      "learning_rate": 0.00019966664251032685,
      "loss": 1.153,
      "step": 24
    },
    {
      "epoch": 0.0018117911367177592,
      "grad_norm": 5.533908367156982,
      "learning_rate": 0.000199652148706428,
      "loss": 1.3038,
      "step": 25
    },
    {
      "epoch": 0.0018842627821864695,
      "grad_norm": 4.227537155151367,
      "learning_rate": 0.00019963765490252917,
      "loss": 1.0133,
      "step": 26
    },
    {
      "epoch": 0.00195673442765518,
      "grad_norm": 5.150226593017578,
      "learning_rate": 0.00019962316109863035,
      "loss": 1.5827,
      "step": 27
    },
    {
      "epoch": 0.00202920607312389,
      "grad_norm": 9.661989212036133,
      "learning_rate": 0.0001996086672947315,
      "loss": 1.0842,
      "step": 28
    },
    {
      "epoch": 0.0021016777185926005,
      "grad_norm": 4.530704498291016,
      "learning_rate": 0.00019959417349083266,
      "loss": 1.1954,
      "step": 29
    },
    {
      "epoch": 0.002174149364061311,
      "grad_norm": 5.478062152862549,
      "learning_rate": 0.00019957967968693385,
      "loss": 1.0336,
      "step": 30
    },
    {
      "epoch": 0.002246621009530021,
      "grad_norm": 5.515416622161865,
      "learning_rate": 0.000199565185883035,
      "loss": 1.4633,
      "step": 31
    },
    {
      "epoch": 0.002319092654998732,
      "grad_norm": 5.303169250488281,
      "learning_rate": 0.00019955069207913616,
      "loss": 1.6647,
      "step": 32
    },
    {
      "epoch": 0.0023915643004674423,
      "grad_norm": 3.8489646911621094,
      "learning_rate": 0.00019953619827523734,
      "loss": 1.1508,
      "step": 33
    },
    {
      "epoch": 0.0024640359459361526,
      "grad_norm": 4.680717945098877,
      "learning_rate": 0.0001995217044713385,
      "loss": 0.7428,
      "step": 34
    },
    {
      "epoch": 0.002536507591404863,
      "grad_norm": 5.458600044250488,
      "learning_rate": 0.00019950721066743968,
      "loss": 1.243,
      "step": 35
    },
    {
      "epoch": 0.0026089792368735733,
      "grad_norm": 6.301918029785156,
      "learning_rate": 0.00019949271686354084,
      "loss": 1.2733,
      "step": 36
    },
    {
      "epoch": 0.0026814508823422836,
      "grad_norm": 4.826423645019531,
      "learning_rate": 0.00019947822305964202,
      "loss": 0.8502,
      "step": 37
    },
    {
      "epoch": 0.002753922527810994,
      "grad_norm": 4.16141939163208,
      "learning_rate": 0.00019946372925574318,
      "loss": 0.7852,
      "step": 38
    },
    {
      "epoch": 0.0028263941732797043,
      "grad_norm": 6.128273010253906,
      "learning_rate": 0.00019944923545184436,
      "loss": 1.3416,
      "step": 39
    },
    {
      "epoch": 0.0028988658187484146,
      "grad_norm": 5.773983001708984,
      "learning_rate": 0.00019943474164794552,
      "loss": 0.618,
      "step": 40
    },
    {
      "epoch": 0.002971337464217125,
      "grad_norm": 5.044294834136963,
      "learning_rate": 0.00019942024784404668,
      "loss": 0.6186,
      "step": 41
    },
    {
      "epoch": 0.0030438091096858353,
      "grad_norm": 6.132046699523926,
      "learning_rate": 0.00019940575404014786,
      "loss": 0.8226,
      "step": 42
    },
    {
      "epoch": 0.0031162807551545456,
      "grad_norm": 4.692368984222412,
      "learning_rate": 0.00019939126023624902,
      "loss": 0.8403,
      "step": 43
    },
    {
      "epoch": 0.0031887524006232564,
      "grad_norm": 5.0464863777160645,
      "learning_rate": 0.00019937676643235017,
      "loss": 0.7575,
      "step": 44
    },
    {
      "epoch": 0.0032612240460919667,
      "grad_norm": 6.399755954742432,
      "learning_rate": 0.00019936227262845136,
      "loss": 0.9401,
      "step": 45
    },
    {
      "epoch": 0.003333695691560677,
      "grad_norm": 3.252681016921997,
      "learning_rate": 0.0001993477788245525,
      "loss": 0.3884,
      "step": 46
    },
    {
      "epoch": 0.0034061673370293873,
      "grad_norm": 6.800271511077881,
      "learning_rate": 0.00019933328502065367,
      "loss": 0.7423,
      "step": 47
    },
    {
      "epoch": 0.0034786389824980977,
      "grad_norm": 7.276630401611328,
      "learning_rate": 0.00019931879121675485,
      "loss": 0.5416,
      "step": 48
    },
    {
      "epoch": 0.003551110627966808,
      "grad_norm": 5.243659973144531,
      "learning_rate": 0.000199304297412856,
      "loss": 0.6212,
      "step": 49
    },
    {
      "epoch": 0.0036235822734355183,
      "grad_norm": 5.018394947052002,
      "learning_rate": 0.00019928980360895717,
      "loss": 0.673,
      "step": 50
    },
    {
      "epoch": 0.0036960539189042287,
      "grad_norm": 5.024820804595947,
      "learning_rate": 0.00019927530980505835,
      "loss": 0.8722,
      "step": 51
    },
    {
      "epoch": 0.003768525564372939,
      "grad_norm": 5.4828081130981445,
      "learning_rate": 0.0001992608160011595,
      "loss": 0.8104,
      "step": 52
    },
    {
      "epoch": 0.0038409972098416493,
      "grad_norm": 4.463771820068359,
      "learning_rate": 0.00019924632219726066,
      "loss": 0.5169,
      "step": 53
    },
    {
      "epoch": 0.00391346885531036,
      "grad_norm": 4.386903285980225,
      "learning_rate": 0.00019923182839336185,
      "loss": 0.6402,
      "step": 54
    },
    {
      "epoch": 0.0039859405007790704,
      "grad_norm": 3.9272453784942627,
      "learning_rate": 0.000199217334589463,
      "loss": 0.536,
      "step": 55
    },
    {
      "epoch": 0.00405841214624778,
      "grad_norm": 5.485404968261719,
      "learning_rate": 0.00019920284078556416,
      "loss": 0.7837,
      "step": 56
    },
    {
      "epoch": 0.004130883791716491,
      "grad_norm": 3.1748251914978027,
      "learning_rate": 0.00019918834698166534,
      "loss": 0.6495,
      "step": 57
    },
    {
      "epoch": 0.004203355437185201,
      "grad_norm": 4.823156356811523,
      "learning_rate": 0.0001991738531777665,
      "loss": 0.5835,
      "step": 58
    },
    {
      "epoch": 0.004275827082653912,
      "grad_norm": 6.02276611328125,
      "learning_rate": 0.00019915935937386768,
      "loss": 0.4708,
      "step": 59
    },
    {
      "epoch": 0.004348298728122622,
      "grad_norm": 4.714724063873291,
      "learning_rate": 0.00019914486556996887,
      "loss": 0.4357,
      "step": 60
    },
    {
      "epoch": 0.004420770373591332,
      "grad_norm": 5.93076229095459,
      "learning_rate": 0.00019913037176607002,
      "loss": 0.7438,
      "step": 61
    },
    {
      "epoch": 0.004493242019060042,
      "grad_norm": 4.582098960876465,
      "learning_rate": 0.00019911587796217118,
      "loss": 0.4227,
      "step": 62
    },
    {
      "epoch": 0.004565713664528753,
      "grad_norm": 5.72915506362915,
      "learning_rate": 0.00019910138415827236,
      "loss": 0.7791,
      "step": 63
    },
    {
      "epoch": 0.004638185309997464,
      "grad_norm": 8.21886920928955,
      "learning_rate": 0.00019908689035437352,
      "loss": 0.6766,
      "step": 64
    },
    {
      "epoch": 0.004710656955466174,
      "grad_norm": 4.489808082580566,
      "learning_rate": 0.00019907239655047468,
      "loss": 0.6186,
      "step": 65
    },
    {
      "epoch": 0.0047831286009348845,
      "grad_norm": 7.150038719177246,
      "learning_rate": 0.00019905790274657586,
      "loss": 0.5907,
      "step": 66
    },
    {
      "epoch": 0.004855600246403594,
      "grad_norm": 4.490682601928711,
      "learning_rate": 0.00019904340894267702,
      "loss": 0.4133,
      "step": 67
    },
    {
      "epoch": 0.004928071891872305,
      "grad_norm": 4.496176719665527,
      "learning_rate": 0.00019902891513877817,
      "loss": 0.7125,
      "step": 68
    },
    {
      "epoch": 0.005000543537341015,
      "grad_norm": 4.732399940490723,
      "learning_rate": 0.00019901442133487936,
      "loss": 0.5509,
      "step": 69
    },
    {
      "epoch": 0.005073015182809726,
      "grad_norm": 5.343934535980225,
      "learning_rate": 0.0001989999275309805,
      "loss": 0.8268,
      "step": 70
    },
    {
      "epoch": 0.005145486828278436,
      "grad_norm": 3.33333158493042,
      "learning_rate": 0.00019898543372708167,
      "loss": 0.5422,
      "step": 71
    },
    {
      "epoch": 0.0052179584737471465,
      "grad_norm": 5.150930881500244,
      "learning_rate": 0.00019897093992318285,
      "loss": 0.4324,
      "step": 72
    },
    {
      "epoch": 0.005290430119215856,
      "grad_norm": 4.430136680603027,
      "learning_rate": 0.000198956446119284,
      "loss": 0.5609,
      "step": 73
    },
    {
      "epoch": 0.005362901764684567,
      "grad_norm": 3.46382212638855,
      "learning_rate": 0.00019894195231538516,
      "loss": 0.5617,
      "step": 74
    },
    {
      "epoch": 0.005435373410153278,
      "grad_norm": 3.7377429008483887,
      "learning_rate": 0.00019892745851148635,
      "loss": 0.5142,
      "step": 75
    },
    {
      "epoch": 0.005507845055621988,
      "grad_norm": 2.9223837852478027,
      "learning_rate": 0.0001989129647075875,
      "loss": 0.4183,
      "step": 76
    },
    {
      "epoch": 0.005580316701090699,
      "grad_norm": 2.785234212875366,
      "learning_rate": 0.00019889847090368866,
      "loss": 0.3781,
      "step": 77
    },
    {
      "epoch": 0.0056527883465594085,
      "grad_norm": 4.711000442504883,
      "learning_rate": 0.00019888397709978984,
      "loss": 0.4644,
      "step": 78
    },
    {
      "epoch": 0.005725259992028119,
      "grad_norm": 3.4837427139282227,
      "learning_rate": 0.000198869483295891,
      "loss": 0.4009,
      "step": 79
    },
    {
      "epoch": 0.005797731637496829,
      "grad_norm": 4.037106990814209,
      "learning_rate": 0.00019885498949199219,
      "loss": 0.509,
      "step": 80
    },
    {
      "epoch": 0.00587020328296554,
      "grad_norm": 5.035923480987549,
      "learning_rate": 0.00019884049568809334,
      "loss": 0.5114,
      "step": 81
    },
    {
      "epoch": 0.00594267492843425,
      "grad_norm": 3.250305652618408,
      "learning_rate": 0.00019882600188419453,
      "loss": 0.3287,
      "step": 82
    },
    {
      "epoch": 0.006015146573902961,
      "grad_norm": 3.7741265296936035,
      "learning_rate": 0.00019881150808029568,
      "loss": 0.438,
      "step": 83
    },
    {
      "epoch": 0.0060876182193716705,
      "grad_norm": 5.663719177246094,
      "learning_rate": 0.00019879701427639687,
      "loss": 0.6791,
      "step": 84
    },
    {
      "epoch": 0.006160089864840381,
      "grad_norm": 6.3947577476501465,
      "learning_rate": 0.00019878252047249802,
      "loss": 0.6017,
      "step": 85
    },
    {
      "epoch": 0.006232561510309091,
      "grad_norm": 3.622791051864624,
      "learning_rate": 0.0001987680266685992,
      "loss": 0.4462,
      "step": 86
    },
    {
      "epoch": 0.006305033155777802,
      "grad_norm": 2.863682985305786,
      "learning_rate": 0.00019875353286470036,
      "loss": 0.2842,
      "step": 87
    },
    {
      "epoch": 0.006377504801246513,
      "grad_norm": 4.069246292114258,
      "learning_rate": 0.00019873903906080152,
      "loss": 0.3889,
      "step": 88
    },
    {
      "epoch": 0.006449976446715223,
      "grad_norm": 2.840047597885132,
      "learning_rate": 0.0001987245452569027,
      "loss": 0.4434,
      "step": 89
    },
    {
      "epoch": 0.006522448092183933,
      "grad_norm": 5.524693965911865,
      "learning_rate": 0.00019871005145300386,
      "loss": 0.4941,
      "step": 90
    },
    {
      "epoch": 0.006594919737652643,
      "grad_norm": 2.60980224609375,
      "learning_rate": 0.00019869555764910501,
      "loss": 0.4287,
      "step": 91
    },
    {
      "epoch": 0.006667391383121354,
      "grad_norm": 2.8558876514434814,
      "learning_rate": 0.0001986810638452062,
      "loss": 0.4143,
      "step": 92
    },
    {
      "epoch": 0.006739863028590064,
      "grad_norm": 3.998286008834839,
      "learning_rate": 0.00019866657004130735,
      "loss": 0.3973,
      "step": 93
    },
    {
      "epoch": 0.006812334674058775,
      "grad_norm": 4.7724809646606445,
      "learning_rate": 0.0001986520762374085,
      "loss": 0.3999,
      "step": 94
    },
    {
      "epoch": 0.006884806319527485,
      "grad_norm": 3.4140377044677734,
      "learning_rate": 0.0001986375824335097,
      "loss": 0.559,
      "step": 95
    },
    {
      "epoch": 0.006957277964996195,
      "grad_norm": 3.2648046016693115,
      "learning_rate": 0.00019862308862961085,
      "loss": 0.4508,
      "step": 96
    },
    {
      "epoch": 0.007029749610464905,
      "grad_norm": 5.531752109527588,
      "learning_rate": 0.000198608594825712,
      "loss": 0.3644,
      "step": 97
    },
    {
      "epoch": 0.007102221255933616,
      "grad_norm": 3.2332346439361572,
      "learning_rate": 0.0001985941010218132,
      "loss": 0.3711,
      "step": 98
    },
    {
      "epoch": 0.007174692901402326,
      "grad_norm": 3.8544483184814453,
      "learning_rate": 0.00019857960721791435,
      "loss": 0.4168,
      "step": 99
    },
    {
      "epoch": 0.007247164546871037,
      "grad_norm": 3.0698800086975098,
      "learning_rate": 0.0001985651134140155,
      "loss": 0.4603,
      "step": 100
    },
    {
      "epoch": 0.0073196361923397475,
      "grad_norm": 5.853153705596924,
      "learning_rate": 0.0001985506196101167,
      "loss": 0.3992,
      "step": 101
    },
    {
      "epoch": 0.007392107837808457,
      "grad_norm": 3.9541985988616943,
      "learning_rate": 0.00019853612580621784,
      "loss": 0.3789,
      "step": 102
    },
    {
      "epoch": 0.007464579483277168,
      "grad_norm": 4.69758939743042,
      "learning_rate": 0.000198521632002319,
      "loss": 0.4569,
      "step": 103
    },
    {
      "epoch": 0.007537051128745878,
      "grad_norm": 2.4720449447631836,
      "learning_rate": 0.00019850713819842018,
      "loss": 0.5727,
      "step": 104
    },
    {
      "epoch": 0.007609522774214589,
      "grad_norm": 4.017034530639648,
      "learning_rate": 0.00019849264439452134,
      "loss": 0.3641,
      "step": 105
    },
    {
      "epoch": 0.007681994419683299,
      "grad_norm": 2.7158162593841553,
      "learning_rate": 0.00019847815059062252,
      "loss": 0.3666,
      "step": 106
    },
    {
      "epoch": 0.0077544660651520094,
      "grad_norm": 4.104364395141602,
      "learning_rate": 0.0001984636567867237,
      "loss": 0.2777,
      "step": 107
    },
    {
      "epoch": 0.00782693771062072,
      "grad_norm": 3.5055878162384033,
      "learning_rate": 0.00019844916298282486,
      "loss": 0.3111,
      "step": 108
    },
    {
      "epoch": 0.00789940935608943,
      "grad_norm": 3.998511791229248,
      "learning_rate": 0.00019843466917892602,
      "loss": 0.3453,
      "step": 109
    },
    {
      "epoch": 0.007971881001558141,
      "grad_norm": 1.544499397277832,
      "learning_rate": 0.0001984201753750272,
      "loss": 0.2598,
      "step": 110
    },
    {
      "epoch": 0.00804435264702685,
      "grad_norm": 3.9483277797698975,
      "learning_rate": 0.00019840568157112836,
      "loss": 0.4322,
      "step": 111
    },
    {
      "epoch": 0.00811682429249556,
      "grad_norm": 3.5381219387054443,
      "learning_rate": 0.00019839118776722952,
      "loss": 0.2338,
      "step": 112
    },
    {
      "epoch": 0.008189295937964271,
      "grad_norm": 3.8422434329986572,
      "learning_rate": 0.0001983766939633307,
      "loss": 0.5918,
      "step": 113
    },
    {
      "epoch": 0.008261767583432982,
      "grad_norm": 4.423384666442871,
      "learning_rate": 0.00019836220015943186,
      "loss": 0.5256,
      "step": 114
    },
    {
      "epoch": 0.008334239228901693,
      "grad_norm": 3.017224073410034,
      "learning_rate": 0.00019834770635553301,
      "loss": 0.4432,
      "step": 115
    },
    {
      "epoch": 0.008406710874370402,
      "grad_norm": 3.109156608581543,
      "learning_rate": 0.0001983332125516342,
      "loss": 0.4883,
      "step": 116
    },
    {
      "epoch": 0.008479182519839113,
      "grad_norm": 3.4161343574523926,
      "learning_rate": 0.00019831871874773535,
      "loss": 0.281,
      "step": 117
    },
    {
      "epoch": 0.008551654165307824,
      "grad_norm": 4.5082244873046875,
      "learning_rate": 0.0001983042249438365,
      "loss": 0.5144,
      "step": 118
    },
    {
      "epoch": 0.008624125810776534,
      "grad_norm": 2.521669864654541,
      "learning_rate": 0.0001982897311399377,
      "loss": 0.3253,
      "step": 119
    },
    {
      "epoch": 0.008696597456245243,
      "grad_norm": 4.04524564743042,
      "learning_rate": 0.00019827523733603885,
      "loss": 0.3545,
      "step": 120
    },
    {
      "epoch": 0.008769069101713954,
      "grad_norm": 3.348539113998413,
      "learning_rate": 0.00019826074353214,
      "loss": 0.3186,
      "step": 121
    },
    {
      "epoch": 0.008841540747182665,
      "grad_norm": 4.419942855834961,
      "learning_rate": 0.0001982462497282412,
      "loss": 0.3693,
      "step": 122
    },
    {
      "epoch": 0.008914012392651376,
      "grad_norm": 4.888516902923584,
      "learning_rate": 0.00019823175592434235,
      "loss": 0.4006,
      "step": 123
    },
    {
      "epoch": 0.008986484038120085,
      "grad_norm": 2.6353673934936523,
      "learning_rate": 0.0001982172621204435,
      "loss": 0.3324,
      "step": 124
    },
    {
      "epoch": 0.009058955683588795,
      "grad_norm": 3.75895094871521,
      "learning_rate": 0.0001982027683165447,
      "loss": 0.3317,
      "step": 125
    },
    {
      "epoch": 0.009131427329057506,
      "grad_norm": 3.9959139823913574,
      "learning_rate": 0.00019818827451264584,
      "loss": 0.2037,
      "step": 126
    },
    {
      "epoch": 0.009203898974526217,
      "grad_norm": 3.390291452407837,
      "learning_rate": 0.00019817378070874703,
      "loss": 0.3774,
      "step": 127
    },
    {
      "epoch": 0.009276370619994928,
      "grad_norm": 4.3436384201049805,
      "learning_rate": 0.00019815928690484818,
      "loss": 0.4045,
      "step": 128
    },
    {
      "epoch": 0.009348842265463637,
      "grad_norm": 3.94071364402771,
      "learning_rate": 0.00019814479310094937,
      "loss": 0.3543,
      "step": 129
    },
    {
      "epoch": 0.009421313910932348,
      "grad_norm": 4.009245872497559,
      "learning_rate": 0.00019813029929705052,
      "loss": 0.4827,
      "step": 130
    },
    {
      "epoch": 0.009493785556401058,
      "grad_norm": 5.317011833190918,
      "learning_rate": 0.0001981158054931517,
      "loss": 0.4954,
      "step": 131
    },
    {
      "epoch": 0.009566257201869769,
      "grad_norm": 3.3852128982543945,
      "learning_rate": 0.00019810131168925286,
      "loss": 0.484,
      "step": 132
    },
    {
      "epoch": 0.009638728847338478,
      "grad_norm": 2.4086737632751465,
      "learning_rate": 0.00019808681788535402,
      "loss": 0.3024,
      "step": 133
    },
    {
      "epoch": 0.009711200492807189,
      "grad_norm": 3.2945661544799805,
      "learning_rate": 0.0001980723240814552,
      "loss": 0.2962,
      "step": 134
    },
    {
      "epoch": 0.0097836721382759,
      "grad_norm": 6.291089057922363,
      "learning_rate": 0.00019805783027755636,
      "loss": 0.3119,
      "step": 135
    },
    {
      "epoch": 0.00985614378374461,
      "grad_norm": 2.8558835983276367,
      "learning_rate": 0.00019804333647365752,
      "loss": 0.3813,
      "step": 136
    },
    {
      "epoch": 0.009928615429213321,
      "grad_norm": 5.297901630401611,
      "learning_rate": 0.0001980288426697587,
      "loss": 0.2772,
      "step": 137
    },
    {
      "epoch": 0.01000108707468203,
      "grad_norm": 4.139895439147949,
      "learning_rate": 0.00019801434886585986,
      "loss": 0.4814,
      "step": 138
    },
    {
      "epoch": 0.010073558720150741,
      "grad_norm": 6.12175178527832,
      "learning_rate": 0.00019799985506196101,
      "loss": 0.3974,
      "step": 139
    },
    {
      "epoch": 0.010146030365619452,
      "grad_norm": 2.7197229862213135,
      "learning_rate": 0.0001979853612580622,
      "loss": 0.3249,
      "step": 140
    },
    {
      "epoch": 0.010218502011088162,
      "grad_norm": 3.9191317558288574,
      "learning_rate": 0.00019797086745416335,
      "loss": 0.3976,
      "step": 141
    },
    {
      "epoch": 0.010290973656556872,
      "grad_norm": 2.9159128665924072,
      "learning_rate": 0.0001979563736502645,
      "loss": 0.3875,
      "step": 142
    },
    {
      "epoch": 0.010363445302025582,
      "grad_norm": 3.0490529537200928,
      "learning_rate": 0.0001979418798463657,
      "loss": 0.286,
      "step": 143
    },
    {
      "epoch": 0.010435916947494293,
      "grad_norm": 2.508580446243286,
      "learning_rate": 0.00019792738604246685,
      "loss": 0.3623,
      "step": 144
    },
    {
      "epoch": 0.010508388592963004,
      "grad_norm": 3.621939182281494,
      "learning_rate": 0.000197912892238568,
      "loss": 0.4099,
      "step": 145
    },
    {
      "epoch": 0.010580860238431713,
      "grad_norm": 5.018901824951172,
      "learning_rate": 0.0001978983984346692,
      "loss": 0.3492,
      "step": 146
    },
    {
      "epoch": 0.010653331883900424,
      "grad_norm": 4.262439250946045,
      "learning_rate": 0.00019788390463077035,
      "loss": 0.4468,
      "step": 147
    },
    {
      "epoch": 0.010725803529369134,
      "grad_norm": 4.667287349700928,
      "learning_rate": 0.0001978694108268715,
      "loss": 0.4485,
      "step": 148
    },
    {
      "epoch": 0.010798275174837845,
      "grad_norm": 3.3430750370025635,
      "learning_rate": 0.0001978549170229727,
      "loss": 0.3582,
      "step": 149
    },
    {
      "epoch": 0.010870746820306556,
      "grad_norm": 4.638391017913818,
      "learning_rate": 0.00019784042321907384,
      "loss": 0.415,
      "step": 150
    },
    {
      "epoch": 0.010943218465775265,
      "grad_norm": 5.266053199768066,
      "learning_rate": 0.00019782592941517503,
      "loss": 0.4199,
      "step": 151
    },
    {
      "epoch": 0.011015690111243976,
      "grad_norm": 4.042882442474365,
      "learning_rate": 0.00019781143561127618,
      "loss": 0.2696,
      "step": 152
    },
    {
      "epoch": 0.011088161756712686,
      "grad_norm": 6.197966575622559,
      "learning_rate": 0.00019779694180737737,
      "loss": 0.5147,
      "step": 153
    },
    {
      "epoch": 0.011160633402181397,
      "grad_norm": 3.0372626781463623,
      "learning_rate": 0.00019778244800347852,
      "loss": 0.5077,
      "step": 154
    },
    {
      "epoch": 0.011233105047650106,
      "grad_norm": 3.529334783554077,
      "learning_rate": 0.0001977679541995797,
      "loss": 0.3284,
      "step": 155
    },
    {
      "epoch": 0.011305576693118817,
      "grad_norm": 3.986116409301758,
      "learning_rate": 0.00019775346039568086,
      "loss": 0.3261,
      "step": 156
    },
    {
      "epoch": 0.011378048338587528,
      "grad_norm": 4.902033805847168,
      "learning_rate": 0.00019773896659178202,
      "loss": 0.4317,
      "step": 157
    },
    {
      "epoch": 0.011450519984056239,
      "grad_norm": 3.4858264923095703,
      "learning_rate": 0.0001977244727878832,
      "loss": 0.4401,
      "step": 158
    },
    {
      "epoch": 0.011522991629524948,
      "grad_norm": 3.1565020084381104,
      "learning_rate": 0.00019770997898398436,
      "loss": 0.2912,
      "step": 159
    },
    {
      "epoch": 0.011595463274993658,
      "grad_norm": 1.8375978469848633,
      "learning_rate": 0.00019769548518008552,
      "loss": 0.2366,
      "step": 160
    },
    {
      "epoch": 0.011667934920462369,
      "grad_norm": 2.5450501441955566,
      "learning_rate": 0.0001976809913761867,
      "loss": 0.3885,
      "step": 161
    },
    {
      "epoch": 0.01174040656593108,
      "grad_norm": 2.5844197273254395,
      "learning_rate": 0.00019766649757228786,
      "loss": 0.3109,
      "step": 162
    },
    {
      "epoch": 0.01181287821139979,
      "grad_norm": 2.2119638919830322,
      "learning_rate": 0.00019765200376838901,
      "loss": 0.3204,
      "step": 163
    },
    {
      "epoch": 0.0118853498568685,
      "grad_norm": 2.6795144081115723,
      "learning_rate": 0.0001976375099644902,
      "loss": 0.2943,
      "step": 164
    },
    {
      "epoch": 0.01195782150233721,
      "grad_norm": 3.5443849563598633,
      "learning_rate": 0.00019762301616059135,
      "loss": 0.4329,
      "step": 165
    },
    {
      "epoch": 0.012030293147805921,
      "grad_norm": 5.071197986602783,
      "learning_rate": 0.0001976085223566925,
      "loss": 0.4448,
      "step": 166
    },
    {
      "epoch": 0.012102764793274632,
      "grad_norm": 8.847149848937988,
      "learning_rate": 0.0001975940285527937,
      "loss": 0.4604,
      "step": 167
    },
    {
      "epoch": 0.012175236438743341,
      "grad_norm": 4.811280727386475,
      "learning_rate": 0.00019757953474889485,
      "loss": 0.1952,
      "step": 168
    },
    {
      "epoch": 0.012247708084212052,
      "grad_norm": 3.64437198638916,
      "learning_rate": 0.000197565040944996,
      "loss": 0.343,
      "step": 169
    },
    {
      "epoch": 0.012320179729680763,
      "grad_norm": 5.015792369842529,
      "learning_rate": 0.0001975505471410972,
      "loss": 0.2876,
      "step": 170
    },
    {
      "epoch": 0.012392651375149473,
      "grad_norm": 2.8389651775360107,
      "learning_rate": 0.00019753605333719835,
      "loss": 0.3027,
      "step": 171
    },
    {
      "epoch": 0.012465123020618182,
      "grad_norm": 3.0030617713928223,
      "learning_rate": 0.0001975215595332995,
      "loss": 0.242,
      "step": 172
    },
    {
      "epoch": 0.012537594666086893,
      "grad_norm": 2.470028877258301,
      "learning_rate": 0.0001975070657294007,
      "loss": 0.3411,
      "step": 173
    },
    {
      "epoch": 0.012610066311555604,
      "grad_norm": 2.8104312419891357,
      "learning_rate": 0.00019749257192550187,
      "loss": 0.3759,
      "step": 174
    },
    {
      "epoch": 0.012682537957024315,
      "grad_norm": 3.0643107891082764,
      "learning_rate": 0.00019747807812160303,
      "loss": 0.244,
      "step": 175
    },
    {
      "epoch": 0.012755009602493025,
      "grad_norm": 2.9294333457946777,
      "learning_rate": 0.0001974635843177042,
      "loss": 0.3418,
      "step": 176
    },
    {
      "epoch": 0.012827481247961734,
      "grad_norm": 4.922103404998779,
      "learning_rate": 0.00019744909051380537,
      "loss": 0.3396,
      "step": 177
    },
    {
      "epoch": 0.012899952893430445,
      "grad_norm": 2.4805192947387695,
      "learning_rate": 0.00019743459670990652,
      "loss": 0.3508,
      "step": 178
    },
    {
      "epoch": 0.012972424538899156,
      "grad_norm": 5.7794270515441895,
      "learning_rate": 0.0001974201029060077,
      "loss": 0.5085,
      "step": 179
    },
    {
      "epoch": 0.013044896184367867,
      "grad_norm": 4.8747334480285645,
      "learning_rate": 0.00019740560910210886,
      "loss": 0.3204,
      "step": 180
    },
    {
      "epoch": 0.013117367829836576,
      "grad_norm": 2.555893659591675,
      "learning_rate": 0.00019739111529821002,
      "loss": 0.2822,
      "step": 181
    },
    {
      "epoch": 0.013189839475305287,
      "grad_norm": 3.163451910018921,
      "learning_rate": 0.0001973766214943112,
      "loss": 0.3409,
      "step": 182
    },
    {
      "epoch": 0.013262311120773997,
      "grad_norm": 2.4634950160980225,
      "learning_rate": 0.00019736212769041236,
      "loss": 0.2267,
      "step": 183
    },
    {
      "epoch": 0.013334782766242708,
      "grad_norm": 5.119697570800781,
      "learning_rate": 0.00019734763388651352,
      "loss": 0.3011,
      "step": 184
    },
    {
      "epoch": 0.013407254411711417,
      "grad_norm": 9.783884048461914,
      "learning_rate": 0.0001973331400826147,
      "loss": 0.2859,
      "step": 185
    },
    {
      "epoch": 0.013479726057180128,
      "grad_norm": 2.752135992050171,
      "learning_rate": 0.00019731864627871586,
      "loss": 0.3043,
      "step": 186
    },
    {
      "epoch": 0.013552197702648839,
      "grad_norm": 5.4893083572387695,
      "learning_rate": 0.000197304152474817,
      "loss": 0.4084,
      "step": 187
    },
    {
      "epoch": 0.01362466934811755,
      "grad_norm": 2.1325771808624268,
      "learning_rate": 0.0001972896586709182,
      "loss": 0.2781,
      "step": 188
    },
    {
      "epoch": 0.01369714099358626,
      "grad_norm": 4.277859687805176,
      "learning_rate": 0.00019727516486701935,
      "loss": 0.3065,
      "step": 189
    },
    {
      "epoch": 0.01376961263905497,
      "grad_norm": 7.959438800811768,
      "learning_rate": 0.0001972606710631205,
      "loss": 0.4419,
      "step": 190
    },
    {
      "epoch": 0.01384208428452368,
      "grad_norm": 4.526352882385254,
      "learning_rate": 0.0001972461772592217,
      "loss": 0.3898,
      "step": 191
    },
    {
      "epoch": 0.01391455592999239,
      "grad_norm": 2.7749133110046387,
      "learning_rate": 0.00019723168345532285,
      "loss": 0.2917,
      "step": 192
    },
    {
      "epoch": 0.013987027575461101,
      "grad_norm": 4.4321393966674805,
      "learning_rate": 0.000197217189651424,
      "loss": 0.2049,
      "step": 193
    },
    {
      "epoch": 0.01405949922092981,
      "grad_norm": 3.6072981357574463,
      "learning_rate": 0.0001972026958475252,
      "loss": 0.2701,
      "step": 194
    },
    {
      "epoch": 0.014131970866398521,
      "grad_norm": 2.081425189971924,
      "learning_rate": 0.00019718820204362635,
      "loss": 0.2536,
      "step": 195
    },
    {
      "epoch": 0.014204442511867232,
      "grad_norm": 3.7528438568115234,
      "learning_rate": 0.00019717370823972753,
      "loss": 0.2437,
      "step": 196
    },
    {
      "epoch": 0.014276914157335943,
      "grad_norm": 4.987689971923828,
      "learning_rate": 0.0001971592144358287,
      "loss": 0.3276,
      "step": 197
    },
    {
      "epoch": 0.014349385802804652,
      "grad_norm": 7.713738441467285,
      "learning_rate": 0.00019714472063192987,
      "loss": 0.3234,
      "step": 198
    },
    {
      "epoch": 0.014421857448273363,
      "grad_norm": 2.2684154510498047,
      "learning_rate": 0.00019713022682803103,
      "loss": 0.2271,
      "step": 199
    },
    {
      "epoch": 0.014494329093742073,
      "grad_norm": 5.2152910232543945,
      "learning_rate": 0.0001971157330241322,
      "loss": 0.3451,
      "step": 200
    },
    {
      "epoch": 0.014566800739210784,
      "grad_norm": 4.418097496032715,
      "learning_rate": 0.00019710123922023337,
      "loss": 0.1982,
      "step": 201
    },
    {
      "epoch": 0.014639272384679495,
      "grad_norm": 3.797797679901123,
      "learning_rate": 0.00019708674541633452,
      "loss": 0.3413,
      "step": 202
    },
    {
      "epoch": 0.014711744030148204,
      "grad_norm": 2.3954274654388428,
      "learning_rate": 0.0001970722516124357,
      "loss": 0.2527,
      "step": 203
    },
    {
      "epoch": 0.014784215675616915,
      "grad_norm": 3.051564931869507,
      "learning_rate": 0.00019705775780853686,
      "loss": 0.2012,
      "step": 204
    },
    {
      "epoch": 0.014856687321085625,
      "grad_norm": 4.151638031005859,
      "learning_rate": 0.00019704326400463802,
      "loss": 0.5341,
      "step": 205
    },
    {
      "epoch": 0.014929158966554336,
      "grad_norm": 2.5971357822418213,
      "learning_rate": 0.0001970287702007392,
      "loss": 0.3317,
      "step": 206
    },
    {
      "epoch": 0.015001630612023045,
      "grad_norm": 3.10927152633667,
      "learning_rate": 0.00019701427639684036,
      "loss": 0.2699,
      "step": 207
    },
    {
      "epoch": 0.015074102257491756,
      "grad_norm": 3.1568846702575684,
      "learning_rate": 0.00019699978259294152,
      "loss": 0.2629,
      "step": 208
    },
    {
      "epoch": 0.015146573902960467,
      "grad_norm": 2.6979658603668213,
      "learning_rate": 0.0001969852887890427,
      "loss": 0.1422,
      "step": 209
    },
    {
      "epoch": 0.015219045548429178,
      "grad_norm": 8.273125648498535,
      "learning_rate": 0.00019697079498514386,
      "loss": 0.3525,
      "step": 210
    },
    {
      "epoch": 0.015291517193897887,
      "grad_norm": 1.9848196506500244,
      "learning_rate": 0.000196956301181245,
      "loss": 0.3201,
      "step": 211
    },
    {
      "epoch": 0.015363988839366597,
      "grad_norm": 4.041369915008545,
      "learning_rate": 0.0001969418073773462,
      "loss": 0.3369,
      "step": 212
    },
    {
      "epoch": 0.015436460484835308,
      "grad_norm": 7.130441188812256,
      "learning_rate": 0.00019692731357344735,
      "loss": 0.6701,
      "step": 213
    },
    {
      "epoch": 0.015508932130304019,
      "grad_norm": 3.290893316268921,
      "learning_rate": 0.0001969128197695485,
      "loss": 0.3592,
      "step": 214
    },
    {
      "epoch": 0.01558140377577273,
      "grad_norm": 7.0384955406188965,
      "learning_rate": 0.0001968983259656497,
      "loss": 0.4698,
      "step": 215
    },
    {
      "epoch": 0.01565387542124144,
      "grad_norm": 3.674384832382202,
      "learning_rate": 0.00019688383216175085,
      "loss": 0.2863,
      "step": 216
    },
    {
      "epoch": 0.01572634706671015,
      "grad_norm": 4.840547561645508,
      "learning_rate": 0.000196869338357852,
      "loss": 0.2312,
      "step": 217
    },
    {
      "epoch": 0.01579881871217886,
      "grad_norm": 3.5574214458465576,
      "learning_rate": 0.0001968548445539532,
      "loss": 0.2296,
      "step": 218
    },
    {
      "epoch": 0.01587129035764757,
      "grad_norm": 12.225923538208008,
      "learning_rate": 0.00019684035075005435,
      "loss": 0.2748,
      "step": 219
    },
    {
      "epoch": 0.015943762003116282,
      "grad_norm": 3.658590078353882,
      "learning_rate": 0.00019682585694615553,
      "loss": 0.3333,
      "step": 220
    },
    {
      "epoch": 0.016016233648584993,
      "grad_norm": 10.845834732055664,
      "learning_rate": 0.00019681136314225669,
      "loss": 0.3411,
      "step": 221
    },
    {
      "epoch": 0.0160887052940537,
      "grad_norm": 4.776029109954834,
      "learning_rate": 0.00019679686933835787,
      "loss": 0.2303,
      "step": 222
    },
    {
      "epoch": 0.01616117693952241,
      "grad_norm": 3.440394401550293,
      "learning_rate": 0.00019678237553445903,
      "loss": 0.2714,
      "step": 223
    },
    {
      "epoch": 0.01623364858499112,
      "grad_norm": 7.823397159576416,
      "learning_rate": 0.0001967678817305602,
      "loss": 0.3813,
      "step": 224
    },
    {
      "epoch": 0.016306120230459832,
      "grad_norm": 3.098064661026001,
      "learning_rate": 0.00019675338792666137,
      "loss": 0.1826,
      "step": 225
    },
    {
      "epoch": 0.016378591875928543,
      "grad_norm": 4.242933750152588,
      "learning_rate": 0.00019673889412276252,
      "loss": 0.4077,
      "step": 226
    },
    {
      "epoch": 0.016451063521397254,
      "grad_norm": 2.6977665424346924,
      "learning_rate": 0.0001967244003188637,
      "loss": 0.2575,
      "step": 227
    },
    {
      "epoch": 0.016523535166865964,
      "grad_norm": 2.3794138431549072,
      "learning_rate": 0.00019670990651496486,
      "loss": 0.2789,
      "step": 228
    },
    {
      "epoch": 0.016596006812334675,
      "grad_norm": 4.841702938079834,
      "learning_rate": 0.00019669541271106602,
      "loss": 0.3011,
      "step": 229
    },
    {
      "epoch": 0.016668478457803386,
      "grad_norm": 2.5455844402313232,
      "learning_rate": 0.0001966809189071672,
      "loss": 0.2174,
      "step": 230
    },
    {
      "epoch": 0.016740950103272093,
      "grad_norm": 4.1006951332092285,
      "learning_rate": 0.00019666642510326836,
      "loss": 0.267,
      "step": 231
    },
    {
      "epoch": 0.016813421748740804,
      "grad_norm": 2.1716220378875732,
      "learning_rate": 0.00019665193129936952,
      "loss": 0.235,
      "step": 232
    },
    {
      "epoch": 0.016885893394209515,
      "grad_norm": 2.816972017288208,
      "learning_rate": 0.0001966374374954707,
      "loss": 0.3887,
      "step": 233
    },
    {
      "epoch": 0.016958365039678226,
      "grad_norm": 2.6037371158599854,
      "learning_rate": 0.00019662294369157186,
      "loss": 0.3172,
      "step": 234
    },
    {
      "epoch": 0.017030836685146936,
      "grad_norm": 4.178441047668457,
      "learning_rate": 0.000196608449887673,
      "loss": 0.4691,
      "step": 235
    },
    {
      "epoch": 0.017103308330615647,
      "grad_norm": 2.884533643722534,
      "learning_rate": 0.0001965939560837742,
      "loss": 0.4463,
      "step": 236
    },
    {
      "epoch": 0.017175779976084358,
      "grad_norm": 2.948887586593628,
      "learning_rate": 0.00019657946227987535,
      "loss": 0.4962,
      "step": 237
    },
    {
      "epoch": 0.01724825162155307,
      "grad_norm": 2.3218510150909424,
      "learning_rate": 0.0001965649684759765,
      "loss": 0.3227,
      "step": 238
    },
    {
      "epoch": 0.01732072326702178,
      "grad_norm": 2.9296743869781494,
      "learning_rate": 0.0001965504746720777,
      "loss": 0.2637,
      "step": 239
    },
    {
      "epoch": 0.017393194912490487,
      "grad_norm": 3.0073981285095215,
      "learning_rate": 0.00019653598086817885,
      "loss": 0.2934,
      "step": 240
    },
    {
      "epoch": 0.017465666557959197,
      "grad_norm": 4.648445129394531,
      "learning_rate": 0.00019652148706428,
      "loss": 0.3767,
      "step": 241
    },
    {
      "epoch": 0.017538138203427908,
      "grad_norm": 3.4295718669891357,
      "learning_rate": 0.0001965069932603812,
      "loss": 0.2084,
      "step": 242
    },
    {
      "epoch": 0.01761060984889662,
      "grad_norm": 3.630319356918335,
      "learning_rate": 0.00019649249945648237,
      "loss": 0.3927,
      "step": 243
    },
    {
      "epoch": 0.01768308149436533,
      "grad_norm": 2.5025994777679443,
      "learning_rate": 0.00019647800565258353,
      "loss": 0.3375,
      "step": 244
    },
    {
      "epoch": 0.01775555313983404,
      "grad_norm": 1.7454811334609985,
      "learning_rate": 0.0001964635118486847,
      "loss": 0.2042,
      "step": 245
    },
    {
      "epoch": 0.01782802478530275,
      "grad_norm": 2.629272937774658,
      "learning_rate": 0.00019644901804478587,
      "loss": 0.3781,
      "step": 246
    },
    {
      "epoch": 0.017900496430771462,
      "grad_norm": 4.3071746826171875,
      "learning_rate": 0.00019643452424088705,
      "loss": 0.3135,
      "step": 247
    },
    {
      "epoch": 0.01797296807624017,
      "grad_norm": 1.7970744371414185,
      "learning_rate": 0.0001964200304369882,
      "loss": 0.1916,
      "step": 248
    },
    {
      "epoch": 0.01804543972170888,
      "grad_norm": 2.912982225418091,
      "learning_rate": 0.00019640553663308937,
      "loss": 0.3209,
      "step": 249
    },
    {
      "epoch": 0.01811791136717759,
      "grad_norm": 5.568920612335205,
      "learning_rate": 0.00019639104282919055,
      "loss": 0.3876,
      "step": 250
    },
    {
      "epoch": 0.0181903830126463,
      "grad_norm": 3.3723807334899902,
      "learning_rate": 0.0001963765490252917,
      "loss": 0.3414,
      "step": 251
    },
    {
      "epoch": 0.018262854658115012,
      "grad_norm": 6.413697242736816,
      "learning_rate": 0.00019636205522139286,
      "loss": 0.3196,
      "step": 252
    },
    {
      "epoch": 0.018335326303583723,
      "grad_norm": 4.452652931213379,
      "learning_rate": 0.00019634756141749405,
      "loss": 0.3528,
      "step": 253
    },
    {
      "epoch": 0.018407797949052434,
      "grad_norm": 4.103387832641602,
      "learning_rate": 0.0001963330676135952,
      "loss": 0.3277,
      "step": 254
    },
    {
      "epoch": 0.018480269594521145,
      "grad_norm": 4.07114839553833,
      "learning_rate": 0.00019631857380969636,
      "loss": 0.2847,
      "step": 255
    },
    {
      "epoch": 0.018552741239989855,
      "grad_norm": 4.123919486999512,
      "learning_rate": 0.00019630408000579754,
      "loss": 0.2816,
      "step": 256
    },
    {
      "epoch": 0.018625212885458563,
      "grad_norm": 3.8156650066375732,
      "learning_rate": 0.0001962895862018987,
      "loss": 0.2938,
      "step": 257
    },
    {
      "epoch": 0.018697684530927274,
      "grad_norm": 5.593416690826416,
      "learning_rate": 0.00019627509239799986,
      "loss": 0.43,
      "step": 258
    },
    {
      "epoch": 0.018770156176395984,
      "grad_norm": 4.468898296356201,
      "learning_rate": 0.00019626059859410104,
      "loss": 0.3535,
      "step": 259
    },
    {
      "epoch": 0.018842627821864695,
      "grad_norm": 2.0154504776000977,
      "learning_rate": 0.0001962461047902022,
      "loss": 0.1606,
      "step": 260
    },
    {
      "epoch": 0.018915099467333406,
      "grad_norm": 4.464913845062256,
      "learning_rate": 0.00019623161098630335,
      "loss": 0.3497,
      "step": 261
    },
    {
      "epoch": 0.018987571112802117,
      "grad_norm": 2.085394859313965,
      "learning_rate": 0.00019621711718240454,
      "loss": 0.1915,
      "step": 262
    },
    {
      "epoch": 0.019060042758270827,
      "grad_norm": 4.591162204742432,
      "learning_rate": 0.0001962026233785057,
      "loss": 0.3142,
      "step": 263
    },
    {
      "epoch": 0.019132514403739538,
      "grad_norm": 4.605180740356445,
      "learning_rate": 0.00019618812957460685,
      "loss": 0.3559,
      "step": 264
    },
    {
      "epoch": 0.01920498604920825,
      "grad_norm": 3.6910958290100098,
      "learning_rate": 0.00019617363577070803,
      "loss": 0.2213,
      "step": 265
    },
    {
      "epoch": 0.019277457694676956,
      "grad_norm": 4.7443623542785645,
      "learning_rate": 0.0001961591419668092,
      "loss": 0.3212,
      "step": 266
    },
    {
      "epoch": 0.019349929340145667,
      "grad_norm": 4.0346245765686035,
      "learning_rate": 0.00019614464816291037,
      "loss": 0.2111,
      "step": 267
    },
    {
      "epoch": 0.019422400985614378,
      "grad_norm": 3.0024805068969727,
      "learning_rate": 0.00019613015435901153,
      "loss": 0.2563,
      "step": 268
    },
    {
      "epoch": 0.01949487263108309,
      "grad_norm": 5.3349151611328125,
      "learning_rate": 0.0001961156605551127,
      "loss": 0.2615,
      "step": 269
    },
    {
      "epoch": 0.0195673442765518,
      "grad_norm": 4.575125694274902,
      "learning_rate": 0.00019610116675121387,
      "loss": 0.3349,
      "step": 270
    },
    {
      "epoch": 0.01963981592202051,
      "grad_norm": 5.749612808227539,
      "learning_rate": 0.00019608667294731505,
      "loss": 0.2895,
      "step": 271
    },
    {
      "epoch": 0.01971228756748922,
      "grad_norm": 4.812177658081055,
      "learning_rate": 0.0001960721791434162,
      "loss": 0.3683,
      "step": 272
    },
    {
      "epoch": 0.01978475921295793,
      "grad_norm": 4.150739669799805,
      "learning_rate": 0.00019605768533951737,
      "loss": 0.2818,
      "step": 273
    },
    {
      "epoch": 0.019857230858426642,
      "grad_norm": 3.276224136352539,
      "learning_rate": 0.00019604319153561855,
      "loss": 0.3414,
      "step": 274
    },
    {
      "epoch": 0.01992970250389535,
      "grad_norm": 5.275392055511475,
      "learning_rate": 0.0001960286977317197,
      "loss": 0.3086,
      "step": 275
    },
    {
      "epoch": 0.02000217414936406,
      "grad_norm": 3.29239559173584,
      "learning_rate": 0.00019601420392782086,
      "loss": 0.1879,
      "step": 276
    },
    {
      "epoch": 0.02007464579483277,
      "grad_norm": 2.5999722480773926,
      "learning_rate": 0.00019599971012392205,
      "loss": 0.1991,
      "step": 277
    },
    {
      "epoch": 0.020147117440301482,
      "grad_norm": 2.368786096572876,
      "learning_rate": 0.0001959852163200232,
      "loss": 0.1962,
      "step": 278
    },
    {
      "epoch": 0.020219589085770193,
      "grad_norm": 3.933248519897461,
      "learning_rate": 0.00019597072251612436,
      "loss": 0.2701,
      "step": 279
    },
    {
      "epoch": 0.020292060731238903,
      "grad_norm": 4.368097305297852,
      "learning_rate": 0.00019595622871222554,
      "loss": 0.2628,
      "step": 280
    },
    {
      "epoch": 0.020364532376707614,
      "grad_norm": 3.147515058517456,
      "learning_rate": 0.0001959417349083267,
      "loss": 0.1268,
      "step": 281
    },
    {
      "epoch": 0.020437004022176325,
      "grad_norm": 4.047230243682861,
      "learning_rate": 0.00019592724110442786,
      "loss": 0.2128,
      "step": 282
    },
    {
      "epoch": 0.020509475667645032,
      "grad_norm": 2.3981809616088867,
      "learning_rate": 0.00019591274730052904,
      "loss": 0.1917,
      "step": 283
    },
    {
      "epoch": 0.020581947313113743,
      "grad_norm": 2.642139434814453,
      "learning_rate": 0.0001958982534966302,
      "loss": 0.2772,
      "step": 284
    },
    {
      "epoch": 0.020654418958582454,
      "grad_norm": 4.026312828063965,
      "learning_rate": 0.00019588375969273135,
      "loss": 0.4043,
      "step": 285
    },
    {
      "epoch": 0.020726890604051165,
      "grad_norm": 3.6249899864196777,
      "learning_rate": 0.00019586926588883254,
      "loss": 0.2096,
      "step": 286
    },
    {
      "epoch": 0.020799362249519875,
      "grad_norm": 2.0896034240722656,
      "learning_rate": 0.0001958547720849337,
      "loss": 0.1582,
      "step": 287
    },
    {
      "epoch": 0.020871833894988586,
      "grad_norm": 1.8792139291763306,
      "learning_rate": 0.00019584027828103485,
      "loss": 0.1148,
      "step": 288
    },
    {
      "epoch": 0.020944305540457297,
      "grad_norm": 4.634860038757324,
      "learning_rate": 0.00019582578447713603,
      "loss": 0.4097,
      "step": 289
    },
    {
      "epoch": 0.021016777185926008,
      "grad_norm": 4.833099365234375,
      "learning_rate": 0.00019581129067323722,
      "loss": 0.2422,
      "step": 290
    },
    {
      "epoch": 0.02108924883139472,
      "grad_norm": 4.030947685241699,
      "learning_rate": 0.00019579679686933837,
      "loss": 0.2088,
      "step": 291
    },
    {
      "epoch": 0.021161720476863426,
      "grad_norm": 4.193329334259033,
      "learning_rate": 0.00019578230306543956,
      "loss": 0.3265,
      "step": 292
    },
    {
      "epoch": 0.021234192122332136,
      "grad_norm": 5.119952201843262,
      "learning_rate": 0.0001957678092615407,
      "loss": 0.2918,
      "step": 293
    },
    {
      "epoch": 0.021306663767800847,
      "grad_norm": 5.509082794189453,
      "learning_rate": 0.00019575331545764187,
      "loss": 0.2918,
      "step": 294
    },
    {
      "epoch": 0.021379135413269558,
      "grad_norm": 4.706243991851807,
      "learning_rate": 0.00019573882165374305,
      "loss": 0.2301,
      "step": 295
    },
    {
      "epoch": 0.02145160705873827,
      "grad_norm": 5.164925575256348,
      "learning_rate": 0.0001957243278498442,
      "loss": 0.2697,
      "step": 296
    },
    {
      "epoch": 0.02152407870420698,
      "grad_norm": 7.693004608154297,
      "learning_rate": 0.00019570983404594536,
      "loss": 0.5539,
      "step": 297
    },
    {
      "epoch": 0.02159655034967569,
      "grad_norm": 6.028334617614746,
      "learning_rate": 0.00019569534024204655,
      "loss": 0.2717,
      "step": 298
    },
    {
      "epoch": 0.0216690219951444,
      "grad_norm": 7.145472049713135,
      "learning_rate": 0.0001956808464381477,
      "loss": 0.4119,
      "step": 299
    },
    {
      "epoch": 0.021741493640613112,
      "grad_norm": 3.421487808227539,
      "learning_rate": 0.00019566635263424886,
      "loss": 0.3639,
      "step": 300
    },
    {
      "epoch": 0.02181396528608182,
      "grad_norm": 5.192438125610352,
      "learning_rate": 0.00019565185883035005,
      "loss": 0.3293,
      "step": 301
    },
    {
      "epoch": 0.02188643693155053,
      "grad_norm": 5.223206520080566,
      "learning_rate": 0.0001956373650264512,
      "loss": 0.3257,
      "step": 302
    },
    {
      "epoch": 0.02195890857701924,
      "grad_norm": 2.9994595050811768,
      "learning_rate": 0.00019562287122255236,
      "loss": 0.3415,
      "step": 303
    },
    {
      "epoch": 0.02203138022248795,
      "grad_norm": 2.71809458732605,
      "learning_rate": 0.00019560837741865354,
      "loss": 0.2285,
      "step": 304
    },
    {
      "epoch": 0.022103851867956662,
      "grad_norm": 3.860969305038452,
      "learning_rate": 0.0001955938836147547,
      "loss": 0.3282,
      "step": 305
    },
    {
      "epoch": 0.022176323513425373,
      "grad_norm": 3.6127495765686035,
      "learning_rate": 0.00019557938981085585,
      "loss": 0.3163,
      "step": 306
    },
    {
      "epoch": 0.022248795158894084,
      "grad_norm": 2.7673544883728027,
      "learning_rate": 0.00019556489600695704,
      "loss": 0.1716,
      "step": 307
    },
    {
      "epoch": 0.022321266804362794,
      "grad_norm": 2.7297418117523193,
      "learning_rate": 0.0001955504022030582,
      "loss": 0.2205,
      "step": 308
    },
    {
      "epoch": 0.022393738449831502,
      "grad_norm": 1.8575656414031982,
      "learning_rate": 0.00019553590839915935,
      "loss": 0.2019,
      "step": 309
    },
    {
      "epoch": 0.022466210095300213,
      "grad_norm": 2.4847898483276367,
      "learning_rate": 0.00019552141459526053,
      "loss": 0.2368,
      "step": 310
    },
    {
      "epoch": 0.022538681740768923,
      "grad_norm": 1.6575987339019775,
      "learning_rate": 0.0001955069207913617,
      "loss": 0.1763,
      "step": 311
    },
    {
      "epoch": 0.022611153386237634,
      "grad_norm": 3.4849166870117188,
      "learning_rate": 0.00019549242698746287,
      "loss": 0.2099,
      "step": 312
    },
    {
      "epoch": 0.022683625031706345,
      "grad_norm": 3.5067036151885986,
      "learning_rate": 0.00019547793318356403,
      "loss": 0.2592,
      "step": 313
    },
    {
      "epoch": 0.022756096677175056,
      "grad_norm": 4.571642875671387,
      "learning_rate": 0.00019546343937966521,
      "loss": 0.241,
      "step": 314
    },
    {
      "epoch": 0.022828568322643766,
      "grad_norm": 3.194000720977783,
      "learning_rate": 0.00019544894557576637,
      "loss": 0.3547,
      "step": 315
    },
    {
      "epoch": 0.022901039968112477,
      "grad_norm": 3.8381407260894775,
      "learning_rate": 0.00019543445177186756,
      "loss": 0.2484,
      "step": 316
    },
    {
      "epoch": 0.022973511613581188,
      "grad_norm": 1.8047854900360107,
      "learning_rate": 0.0001954199579679687,
      "loss": 0.1147,
      "step": 317
    },
    {
      "epoch": 0.023045983259049895,
      "grad_norm": 2.714154005050659,
      "learning_rate": 0.00019540546416406987,
      "loss": 0.1643,
      "step": 318
    },
    {
      "epoch": 0.023118454904518606,
      "grad_norm": 1.4323477745056152,
      "learning_rate": 0.00019539097036017105,
      "loss": 0.137,
      "step": 319
    },
    {
      "epoch": 0.023190926549987317,
      "grad_norm": 2.776012897491455,
      "learning_rate": 0.0001953764765562722,
      "loss": 0.1766,
      "step": 320
    },
    {
      "epoch": 0.023263398195456027,
      "grad_norm": 2.927711009979248,
      "learning_rate": 0.00019536198275237336,
      "loss": 0.131,
      "step": 321
    },
    {
      "epoch": 0.023335869840924738,
      "grad_norm": 6.110067844390869,
      "learning_rate": 0.00019534748894847455,
      "loss": 0.2992,
      "step": 322
    },
    {
      "epoch": 0.02340834148639345,
      "grad_norm": 5.2081990242004395,
      "learning_rate": 0.0001953329951445757,
      "loss": 0.1937,
      "step": 323
    },
    {
      "epoch": 0.02348081313186216,
      "grad_norm": 4.194875240325928,
      "learning_rate": 0.00019531850134067686,
      "loss": 0.2857,
      "step": 324
    },
    {
      "epoch": 0.02355328477733087,
      "grad_norm": 4.333209037780762,
      "learning_rate": 0.00019530400753677804,
      "loss": 0.1715,
      "step": 325
    },
    {
      "epoch": 0.02362575642279958,
      "grad_norm": 2.6913909912109375,
      "learning_rate": 0.0001952895137328792,
      "loss": 0.2419,
      "step": 326
    },
    {
      "epoch": 0.02369822806826829,
      "grad_norm": 4.075470924377441,
      "learning_rate": 0.00019527501992898036,
      "loss": 0.2374,
      "step": 327
    },
    {
      "epoch": 0.023770699713737,
      "grad_norm": 6.128034591674805,
      "learning_rate": 0.00019526052612508154,
      "loss": 0.312,
      "step": 328
    },
    {
      "epoch": 0.02384317135920571,
      "grad_norm": 8.38286018371582,
      "learning_rate": 0.0001952460323211827,
      "loss": 0.2294,
      "step": 329
    },
    {
      "epoch": 0.02391564300467442,
      "grad_norm": 3.1836705207824707,
      "learning_rate": 0.00019523153851728385,
      "loss": 0.2972,
      "step": 330
    },
    {
      "epoch": 0.02398811465014313,
      "grad_norm": 1.3421000242233276,
      "learning_rate": 0.00019521704471338504,
      "loss": 0.1882,
      "step": 331
    },
    {
      "epoch": 0.024060586295611842,
      "grad_norm": 3.4214088916778564,
      "learning_rate": 0.0001952025509094862,
      "loss": 0.1147,
      "step": 332
    },
    {
      "epoch": 0.024133057941080553,
      "grad_norm": 3.6992223262786865,
      "learning_rate": 0.00019518805710558735,
      "loss": 0.3076,
      "step": 333
    },
    {
      "epoch": 0.024205529586549264,
      "grad_norm": 4.766624450683594,
      "learning_rate": 0.00019517356330168853,
      "loss": 0.2288,
      "step": 334
    },
    {
      "epoch": 0.02427800123201797,
      "grad_norm": 4.9907684326171875,
      "learning_rate": 0.0001951590694977897,
      "loss": 0.2571,
      "step": 335
    },
    {
      "epoch": 0.024350472877486682,
      "grad_norm": 2.8454480171203613,
      "learning_rate": 0.00019514457569389087,
      "loss": 0.2234,
      "step": 336
    },
    {
      "epoch": 0.024422944522955393,
      "grad_norm": 2.190854072570801,
      "learning_rate": 0.00019513008188999206,
      "loss": 0.2458,
      "step": 337
    },
    {
      "epoch": 0.024495416168424104,
      "grad_norm": 6.264859199523926,
      "learning_rate": 0.00019511558808609321,
      "loss": 0.3965,
      "step": 338
    },
    {
      "epoch": 0.024567887813892814,
      "grad_norm": 2.791973114013672,
      "learning_rate": 0.00019510109428219437,
      "loss": 0.2138,
      "step": 339
    },
    {
      "epoch": 0.024640359459361525,
      "grad_norm": 1.7721580266952515,
      "learning_rate": 0.00019508660047829555,
      "loss": 0.1435,
      "step": 340
    },
    {
      "epoch": 0.024712831104830236,
      "grad_norm": 3.884836435317993,
      "learning_rate": 0.0001950721066743967,
      "loss": 0.2056,
      "step": 341
    },
    {
      "epoch": 0.024785302750298947,
      "grad_norm": 2.0261151790618896,
      "learning_rate": 0.00019505761287049787,
      "loss": 0.2702,
      "step": 342
    },
    {
      "epoch": 0.024857774395767657,
      "grad_norm": 1.9725500345230103,
      "learning_rate": 0.00019504311906659905,
      "loss": 0.154,
      "step": 343
    },
    {
      "epoch": 0.024930246041236365,
      "grad_norm": 2.2804689407348633,
      "learning_rate": 0.0001950286252627002,
      "loss": 0.1552,
      "step": 344
    },
    {
      "epoch": 0.025002717686705075,
      "grad_norm": 3.280386447906494,
      "learning_rate": 0.00019501413145880136,
      "loss": 0.2578,
      "step": 345
    },
    {
      "epoch": 0.025075189332173786,
      "grad_norm": 5.011036396026611,
      "learning_rate": 0.00019499963765490255,
      "loss": 0.2599,
      "step": 346
    },
    {
      "epoch": 0.025147660977642497,
      "grad_norm": 5.757493019104004,
      "learning_rate": 0.0001949851438510037,
      "loss": 0.3702,
      "step": 347
    },
    {
      "epoch": 0.025220132623111208,
      "grad_norm": 7.235187530517578,
      "learning_rate": 0.00019497065004710486,
      "loss": 0.3553,
      "step": 348
    },
    {
      "epoch": 0.02529260426857992,
      "grad_norm": 3.223024606704712,
      "learning_rate": 0.00019495615624320604,
      "loss": 0.2708,
      "step": 349
    },
    {
      "epoch": 0.02536507591404863,
      "grad_norm": 4.240487575531006,
      "learning_rate": 0.0001949416624393072,
      "loss": 0.2516,
      "step": 350
    },
    {
      "epoch": 0.02543754755951734,
      "grad_norm": 3.34171199798584,
      "learning_rate": 0.00019492716863540836,
      "loss": 0.209,
      "step": 351
    },
    {
      "epoch": 0.02551001920498605,
      "grad_norm": 4.062716007232666,
      "learning_rate": 0.00019491267483150954,
      "loss": 0.3794,
      "step": 352
    },
    {
      "epoch": 0.025582490850454758,
      "grad_norm": 2.4946467876434326,
      "learning_rate": 0.0001948981810276107,
      "loss": 0.2143,
      "step": 353
    },
    {
      "epoch": 0.02565496249592347,
      "grad_norm": 3.701246976852417,
      "learning_rate": 0.00019488368722371185,
      "loss": 0.2574,
      "step": 354
    },
    {
      "epoch": 0.02572743414139218,
      "grad_norm": 2.8078932762145996,
      "learning_rate": 0.00019486919341981304,
      "loss": 0.1567,
      "step": 355
    },
    {
      "epoch": 0.02579990578686089,
      "grad_norm": 1.9752739667892456,
      "learning_rate": 0.0001948546996159142,
      "loss": 0.0951,
      "step": 356
    },
    {
      "epoch": 0.0258723774323296,
      "grad_norm": 3.818648338317871,
      "learning_rate": 0.00019484020581201535,
      "loss": 0.2053,
      "step": 357
    },
    {
      "epoch": 0.025944849077798312,
      "grad_norm": 1.0336302518844604,
      "learning_rate": 0.00019482571200811653,
      "loss": 0.0935,
      "step": 358
    },
    {
      "epoch": 0.026017320723267023,
      "grad_norm": 2.7856082916259766,
      "learning_rate": 0.00019481121820421772,
      "loss": 0.1753,
      "step": 359
    },
    {
      "epoch": 0.026089792368735733,
      "grad_norm": 5.045741081237793,
      "learning_rate": 0.00019479672440031887,
      "loss": 0.3229,
      "step": 360
    },
    {
      "epoch": 0.026162264014204444,
      "grad_norm": 3.051650285720825,
      "learning_rate": 0.00019478223059642006,
      "loss": 0.3104,
      "step": 361
    },
    {
      "epoch": 0.02623473565967315,
      "grad_norm": 2.4157679080963135,
      "learning_rate": 0.00019476773679252121,
      "loss": 0.3243,
      "step": 362
    },
    {
      "epoch": 0.026307207305141862,
      "grad_norm": 1.5736366510391235,
      "learning_rate": 0.00019475324298862237,
      "loss": 0.1895,
      "step": 363
    },
    {
      "epoch": 0.026379678950610573,
      "grad_norm": 3.769897937774658,
      "learning_rate": 0.00019473874918472355,
      "loss": 0.2636,
      "step": 364
    },
    {
      "epoch": 0.026452150596079284,
      "grad_norm": 2.959364175796509,
      "learning_rate": 0.0001947242553808247,
      "loss": 0.3071,
      "step": 365
    },
    {
      "epoch": 0.026524622241547995,
      "grad_norm": 1.2034403085708618,
      "learning_rate": 0.00019470976157692587,
      "loss": 0.094,
      "step": 366
    },
    {
      "epoch": 0.026597093887016705,
      "grad_norm": 3.473146915435791,
      "learning_rate": 0.00019469526777302705,
      "loss": 0.2888,
      "step": 367
    },
    {
      "epoch": 0.026669565532485416,
      "grad_norm": 3.0663723945617676,
      "learning_rate": 0.0001946807739691282,
      "loss": 0.1655,
      "step": 368
    },
    {
      "epoch": 0.026742037177954127,
      "grad_norm": 4.290977954864502,
      "learning_rate": 0.00019466628016522936,
      "loss": 0.2298,
      "step": 369
    },
    {
      "epoch": 0.026814508823422834,
      "grad_norm": 1.6487650871276855,
      "learning_rate": 0.00019465178636133055,
      "loss": 0.0969,
      "step": 370
    },
    {
      "epoch": 0.026886980468891545,
      "grad_norm": 3.2799625396728516,
      "learning_rate": 0.0001946372925574317,
      "loss": 0.1928,
      "step": 371
    },
    {
      "epoch": 0.026959452114360256,
      "grad_norm": 2.2513296604156494,
      "learning_rate": 0.00019462279875353286,
      "loss": 0.2122,
      "step": 372
    },
    {
      "epoch": 0.027031923759828966,
      "grad_norm": 4.895205497741699,
      "learning_rate": 0.00019460830494963404,
      "loss": 0.3147,
      "step": 373
    },
    {
      "epoch": 0.027104395405297677,
      "grad_norm": 4.899766445159912,
      "learning_rate": 0.0001945938111457352,
      "loss": 0.2854,
      "step": 374
    },
    {
      "epoch": 0.027176867050766388,
      "grad_norm": 4.500479698181152,
      "learning_rate": 0.00019457931734183636,
      "loss": 0.278,
      "step": 375
    },
    {
      "epoch": 0.0272493386962351,
      "grad_norm": 1.2425092458724976,
      "learning_rate": 0.00019456482353793754,
      "loss": 0.1593,
      "step": 376
    },
    {
      "epoch": 0.02732181034170381,
      "grad_norm": 1.8505297899246216,
      "learning_rate": 0.0001945503297340387,
      "loss": 0.1474,
      "step": 377
    },
    {
      "epoch": 0.02739428198717252,
      "grad_norm": 2.7776002883911133,
      "learning_rate": 0.00019453583593013985,
      "loss": 0.215,
      "step": 378
    },
    {
      "epoch": 0.027466753632641228,
      "grad_norm": 5.099863529205322,
      "learning_rate": 0.00019452134212624104,
      "loss": 0.2479,
      "step": 379
    },
    {
      "epoch": 0.02753922527810994,
      "grad_norm": 2.970496892929077,
      "learning_rate": 0.0001945068483223422,
      "loss": 0.236,
      "step": 380
    },
    {
      "epoch": 0.02761169692357865,
      "grad_norm": 4.02581787109375,
      "learning_rate": 0.00019449235451844338,
      "loss": 0.2377,
      "step": 381
    },
    {
      "epoch": 0.02768416856904736,
      "grad_norm": 2.277596950531006,
      "learning_rate": 0.00019447786071454453,
      "loss": 0.1678,
      "step": 382
    },
    {
      "epoch": 0.02775664021451607,
      "grad_norm": 5.028317451477051,
      "learning_rate": 0.00019446336691064572,
      "loss": 0.2757,
      "step": 383
    },
    {
      "epoch": 0.02782911185998478,
      "grad_norm": 3.713026523590088,
      "learning_rate": 0.00019444887310674687,
      "loss": 0.2269,
      "step": 384
    },
    {
      "epoch": 0.027901583505453492,
      "grad_norm": 5.049301624298096,
      "learning_rate": 0.00019443437930284806,
      "loss": 0.3846,
      "step": 385
    },
    {
      "epoch": 0.027974055150922203,
      "grad_norm": 4.439123153686523,
      "learning_rate": 0.00019441988549894921,
      "loss": 0.1967,
      "step": 386
    },
    {
      "epoch": 0.028046526796390914,
      "grad_norm": 5.396742820739746,
      "learning_rate": 0.00019440539169505037,
      "loss": 0.2691,
      "step": 387
    },
    {
      "epoch": 0.02811899844185962,
      "grad_norm": 3.0592567920684814,
      "learning_rate": 0.00019439089789115155,
      "loss": 0.2506,
      "step": 388
    },
    {
      "epoch": 0.028191470087328332,
      "grad_norm": 3.173748016357422,
      "learning_rate": 0.0001943764040872527,
      "loss": 0.1668,
      "step": 389
    },
    {
      "epoch": 0.028263941732797043,
      "grad_norm": 3.299771547317505,
      "learning_rate": 0.00019436191028335387,
      "loss": 0.2674,
      "step": 390
    },
    {
      "epoch": 0.028336413378265753,
      "grad_norm": 8.00860595703125,
      "learning_rate": 0.00019434741647945505,
      "loss": 0.3911,
      "step": 391
    },
    {
      "epoch": 0.028408885023734464,
      "grad_norm": 4.37769889831543,
      "learning_rate": 0.0001943329226755562,
      "loss": 0.2588,
      "step": 392
    },
    {
      "epoch": 0.028481356669203175,
      "grad_norm": 4.664649963378906,
      "learning_rate": 0.00019431842887165736,
      "loss": 0.2905,
      "step": 393
    },
    {
      "epoch": 0.028553828314671886,
      "grad_norm": 8.32708740234375,
      "learning_rate": 0.00019430393506775855,
      "loss": 0.3311,
      "step": 394
    },
    {
      "epoch": 0.028626299960140596,
      "grad_norm": 4.922857284545898,
      "learning_rate": 0.0001942894412638597,
      "loss": 0.1995,
      "step": 395
    },
    {
      "epoch": 0.028698771605609304,
      "grad_norm": 4.282852649688721,
      "learning_rate": 0.00019427494745996086,
      "loss": 0.2033,
      "step": 396
    },
    {
      "epoch": 0.028771243251078014,
      "grad_norm": 4.936960220336914,
      "learning_rate": 0.00019426045365606204,
      "loss": 0.3551,
      "step": 397
    },
    {
      "epoch": 0.028843714896546725,
      "grad_norm": 2.8717992305755615,
      "learning_rate": 0.0001942459598521632,
      "loss": 0.2368,
      "step": 398
    },
    {
      "epoch": 0.028916186542015436,
      "grad_norm": 8.280322074890137,
      "learning_rate": 0.00019423146604826436,
      "loss": 0.3413,
      "step": 399
    },
    {
      "epoch": 0.028988658187484147,
      "grad_norm": 2.0632734298706055,
      "learning_rate": 0.00019421697224436554,
      "loss": 0.2261,
      "step": 400
    },
    {
      "epoch": 0.029061129832952858,
      "grad_norm": 2.1691136360168457,
      "learning_rate": 0.0001942024784404667,
      "loss": 0.1965,
      "step": 401
    },
    {
      "epoch": 0.02913360147842157,
      "grad_norm": 3.9720914363861084,
      "learning_rate": 0.00019418798463656785,
      "loss": 0.2205,
      "step": 402
    },
    {
      "epoch": 0.02920607312389028,
      "grad_norm": 1.6174767017364502,
      "learning_rate": 0.00019417349083266904,
      "loss": 0.1956,
      "step": 403
    },
    {
      "epoch": 0.02927854476935899,
      "grad_norm": 1.2535133361816406,
      "learning_rate": 0.0001941589970287702,
      "loss": 0.1662,
      "step": 404
    },
    {
      "epoch": 0.029351016414827697,
      "grad_norm": 4.004153728485107,
      "learning_rate": 0.00019414450322487138,
      "loss": 0.229,
      "step": 405
    },
    {
      "epoch": 0.029423488060296408,
      "grad_norm": 5.876357078552246,
      "learning_rate": 0.00019413000942097256,
      "loss": 0.3469,
      "step": 406
    },
    {
      "epoch": 0.02949595970576512,
      "grad_norm": 3.0357885360717773,
      "learning_rate": 0.00019411551561707372,
      "loss": 0.2629,
      "step": 407
    },
    {
      "epoch": 0.02956843135123383,
      "grad_norm": 3.735060930252075,
      "learning_rate": 0.0001941010218131749,
      "loss": 0.3216,
      "step": 408
    },
    {
      "epoch": 0.02964090299670254,
      "grad_norm": 3.06268048286438,
      "learning_rate": 0.00019408652800927606,
      "loss": 0.3229,
      "step": 409
    },
    {
      "epoch": 0.02971337464217125,
      "grad_norm": 3.4311611652374268,
      "learning_rate": 0.0001940720342053772,
      "loss": 0.2515,
      "step": 410
    },
    {
      "epoch": 0.02978584628763996,
      "grad_norm": 3.008981466293335,
      "learning_rate": 0.0001940575404014784,
      "loss": 0.2153,
      "step": 411
    },
    {
      "epoch": 0.029858317933108672,
      "grad_norm": 3.197606325149536,
      "learning_rate": 0.00019404304659757955,
      "loss": 0.3478,
      "step": 412
    },
    {
      "epoch": 0.029930789578577383,
      "grad_norm": 3.058406114578247,
      "learning_rate": 0.0001940285527936807,
      "loss": 0.3627,
      "step": 413
    },
    {
      "epoch": 0.03000326122404609,
      "grad_norm": 3.013169050216675,
      "learning_rate": 0.0001940140589897819,
      "loss": 0.3443,
      "step": 414
    },
    {
      "epoch": 0.0300757328695148,
      "grad_norm": 4.889838695526123,
      "learning_rate": 0.00019399956518588305,
      "loss": 0.2946,
      "step": 415
    },
    {
      "epoch": 0.030148204514983512,
      "grad_norm": 2.4339756965637207,
      "learning_rate": 0.0001939850713819842,
      "loss": 0.3117,
      "step": 416
    },
    {
      "epoch": 0.030220676160452223,
      "grad_norm": 1.728698968887329,
      "learning_rate": 0.0001939705775780854,
      "loss": 0.1838,
      "step": 417
    },
    {
      "epoch": 0.030293147805920934,
      "grad_norm": 2.4170024394989014,
      "learning_rate": 0.00019395608377418655,
      "loss": 0.2829,
      "step": 418
    },
    {
      "epoch": 0.030365619451389644,
      "grad_norm": 2.698843002319336,
      "learning_rate": 0.0001939415899702877,
      "loss": 0.1216,
      "step": 419
    },
    {
      "epoch": 0.030438091096858355,
      "grad_norm": 6.177295207977295,
      "learning_rate": 0.0001939270961663889,
      "loss": 0.3368,
      "step": 420
    },
    {
      "epoch": 0.030510562742327066,
      "grad_norm": 3.5768868923187256,
      "learning_rate": 0.00019391260236249004,
      "loss": 0.2894,
      "step": 421
    },
    {
      "epoch": 0.030583034387795773,
      "grad_norm": 3.913494825363159,
      "learning_rate": 0.0001938981085585912,
      "loss": 0.202,
      "step": 422
    },
    {
      "epoch": 0.030655506033264484,
      "grad_norm": 7.068638324737549,
      "learning_rate": 0.00019388361475469238,
      "loss": 0.1779,
      "step": 423
    },
    {
      "epoch": 0.030727977678733195,
      "grad_norm": 2.8546247482299805,
      "learning_rate": 0.00019386912095079354,
      "loss": 0.2224,
      "step": 424
    },
    {
      "epoch": 0.030800449324201905,
      "grad_norm": 4.244112968444824,
      "learning_rate": 0.0001938546271468947,
      "loss": 0.2912,
      "step": 425
    },
    {
      "epoch": 0.030872920969670616,
      "grad_norm": 1.6389427185058594,
      "learning_rate": 0.00019384013334299588,
      "loss": 0.2477,
      "step": 426
    },
    {
      "epoch": 0.030945392615139327,
      "grad_norm": 3.0134527683258057,
      "learning_rate": 0.00019382563953909704,
      "loss": 0.2474,
      "step": 427
    },
    {
      "epoch": 0.031017864260608038,
      "grad_norm": 2.390261173248291,
      "learning_rate": 0.00019381114573519822,
      "loss": 0.1589,
      "step": 428
    },
    {
      "epoch": 0.03109033590607675,
      "grad_norm": 4.0655035972595215,
      "learning_rate": 0.00019379665193129938,
      "loss": 0.2895,
      "step": 429
    },
    {
      "epoch": 0.03116280755154546,
      "grad_norm": 2.259838819503784,
      "learning_rate": 0.00019378215812740056,
      "loss": 0.1461,
      "step": 430
    },
    {
      "epoch": 0.031235279197014167,
      "grad_norm": 2.0698039531707764,
      "learning_rate": 0.00019376766432350172,
      "loss": 0.1518,
      "step": 431
    },
    {
      "epoch": 0.03130775084248288,
      "grad_norm": 3.348065137863159,
      "learning_rate": 0.0001937531705196029,
      "loss": 0.2016,
      "step": 432
    },
    {
      "epoch": 0.03138022248795159,
      "grad_norm": 4.12445592880249,
      "learning_rate": 0.00019373867671570406,
      "loss": 0.2176,
      "step": 433
    },
    {
      "epoch": 0.0314526941334203,
      "grad_norm": 4.444520950317383,
      "learning_rate": 0.0001937241829118052,
      "loss": 0.1703,
      "step": 434
    },
    {
      "epoch": 0.03152516577888901,
      "grad_norm": 6.12798547744751,
      "learning_rate": 0.0001937096891079064,
      "loss": 0.3838,
      "step": 435
    },
    {
      "epoch": 0.03159763742435772,
      "grad_norm": 3.0638134479522705,
      "learning_rate": 0.00019369519530400755,
      "loss": 0.2479,
      "step": 436
    },
    {
      "epoch": 0.03167010906982643,
      "grad_norm": 2.9564707279205322,
      "learning_rate": 0.0001936807015001087,
      "loss": 0.1581,
      "step": 437
    },
    {
      "epoch": 0.03174258071529514,
      "grad_norm": 1.1422632932662964,
      "learning_rate": 0.0001936662076962099,
      "loss": 0.0795,
      "step": 438
    },
    {
      "epoch": 0.03181505236076385,
      "grad_norm": 1.780838966369629,
      "learning_rate": 0.00019365171389231105,
      "loss": 0.1187,
      "step": 439
    },
    {
      "epoch": 0.031887524006232564,
      "grad_norm": 4.338382720947266,
      "learning_rate": 0.0001936372200884122,
      "loss": 0.3486,
      "step": 440
    },
    {
      "epoch": 0.031959995651701274,
      "grad_norm": 5.681534767150879,
      "learning_rate": 0.0001936227262845134,
      "loss": 0.2818,
      "step": 441
    },
    {
      "epoch": 0.032032467297169985,
      "grad_norm": 3.2620363235473633,
      "learning_rate": 0.00019360823248061455,
      "loss": 0.2137,
      "step": 442
    },
    {
      "epoch": 0.032104938942638696,
      "grad_norm": 3.6416656970977783,
      "learning_rate": 0.0001935937386767157,
      "loss": 0.2859,
      "step": 443
    },
    {
      "epoch": 0.0321774105881074,
      "grad_norm": 3.3192989826202393,
      "learning_rate": 0.00019357924487281689,
      "loss": 0.2323,
      "step": 444
    },
    {
      "epoch": 0.03224988223357611,
      "grad_norm": 7.573617935180664,
      "learning_rate": 0.00019356475106891804,
      "loss": 0.276,
      "step": 445
    },
    {
      "epoch": 0.03232235387904482,
      "grad_norm": 2.744966506958008,
      "learning_rate": 0.0001935502572650192,
      "loss": 0.2176,
      "step": 446
    },
    {
      "epoch": 0.03239482552451353,
      "grad_norm": 3.2610342502593994,
      "learning_rate": 0.00019353576346112038,
      "loss": 0.24,
      "step": 447
    },
    {
      "epoch": 0.03246729716998224,
      "grad_norm": 1.9413212537765503,
      "learning_rate": 0.00019352126965722154,
      "loss": 0.1845,
      "step": 448
    },
    {
      "epoch": 0.03253976881545095,
      "grad_norm": 2.641496419906616,
      "learning_rate": 0.0001935067758533227,
      "loss": 0.2068,
      "step": 449
    },
    {
      "epoch": 0.032612240460919664,
      "grad_norm": 3.609315872192383,
      "learning_rate": 0.00019349228204942388,
      "loss": 0.2423,
      "step": 450
    },
    {
      "epoch": 0.032684712106388375,
      "grad_norm": 3.3667898178100586,
      "learning_rate": 0.00019347778824552504,
      "loss": 0.1762,
      "step": 451
    },
    {
      "epoch": 0.032757183751857086,
      "grad_norm": 5.780375003814697,
      "learning_rate": 0.00019346329444162622,
      "loss": 0.2179,
      "step": 452
    },
    {
      "epoch": 0.032829655397325797,
      "grad_norm": 7.474860668182373,
      "learning_rate": 0.0001934488006377274,
      "loss": 0.2989,
      "step": 453
    },
    {
      "epoch": 0.03290212704279451,
      "grad_norm": 3.4485301971435547,
      "learning_rate": 0.00019343430683382856,
      "loss": 0.1586,
      "step": 454
    },
    {
      "epoch": 0.03297459868826322,
      "grad_norm": 4.039953708648682,
      "learning_rate": 0.00019341981302992972,
      "loss": 0.2013,
      "step": 455
    },
    {
      "epoch": 0.03304707033373193,
      "grad_norm": 3.682819366455078,
      "learning_rate": 0.0001934053192260309,
      "loss": 0.2089,
      "step": 456
    },
    {
      "epoch": 0.03311954197920064,
      "grad_norm": 3.784708023071289,
      "learning_rate": 0.00019339082542213206,
      "loss": 0.1728,
      "step": 457
    },
    {
      "epoch": 0.03319201362466935,
      "grad_norm": 8.048515319824219,
      "learning_rate": 0.0001933763316182332,
      "loss": 0.4031,
      "step": 458
    },
    {
      "epoch": 0.03326448527013806,
      "grad_norm": 8.46398639678955,
      "learning_rate": 0.0001933618378143344,
      "loss": 0.3308,
      "step": 459
    },
    {
      "epoch": 0.03333695691560677,
      "grad_norm": 4.0249786376953125,
      "learning_rate": 0.00019334734401043555,
      "loss": 0.4264,
      "step": 460
    },
    {
      "epoch": 0.03340942856107548,
      "grad_norm": 2.1146509647369385,
      "learning_rate": 0.0001933328502065367,
      "loss": 0.1804,
      "step": 461
    },
    {
      "epoch": 0.033481900206544186,
      "grad_norm": 4.070371150970459,
      "learning_rate": 0.0001933183564026379,
      "loss": 0.1673,
      "step": 462
    },
    {
      "epoch": 0.0335543718520129,
      "grad_norm": 4.15492582321167,
      "learning_rate": 0.00019330386259873905,
      "loss": 0.2314,
      "step": 463
    },
    {
      "epoch": 0.03362684349748161,
      "grad_norm": 3.96238374710083,
      "learning_rate": 0.0001932893687948402,
      "loss": 0.2183,
      "step": 464
    },
    {
      "epoch": 0.03369931514295032,
      "grad_norm": 2.613029718399048,
      "learning_rate": 0.0001932748749909414,
      "loss": 0.1702,
      "step": 465
    },
    {
      "epoch": 0.03377178678841903,
      "grad_norm": 6.124260902404785,
      "learning_rate": 0.00019326038118704255,
      "loss": 0.2404,
      "step": 466
    },
    {
      "epoch": 0.03384425843388774,
      "grad_norm": 1.5826475620269775,
      "learning_rate": 0.0001932458873831437,
      "loss": 0.1118,
      "step": 467
    },
    {
      "epoch": 0.03391673007935645,
      "grad_norm": 1.789018154144287,
      "learning_rate": 0.00019323139357924489,
      "loss": 0.2086,
      "step": 468
    },
    {
      "epoch": 0.03398920172482516,
      "grad_norm": 2.601978063583374,
      "learning_rate": 0.00019321689977534604,
      "loss": 0.2785,
      "step": 469
    },
    {
      "epoch": 0.03406167337029387,
      "grad_norm": 2.4958460330963135,
      "learning_rate": 0.0001932024059714472,
      "loss": 0.1971,
      "step": 470
    },
    {
      "epoch": 0.03413414501576258,
      "grad_norm": 1.7711868286132812,
      "learning_rate": 0.00019318791216754838,
      "loss": 0.1673,
      "step": 471
    },
    {
      "epoch": 0.034206616661231294,
      "grad_norm": 2.11961030960083,
      "learning_rate": 0.00019317341836364954,
      "loss": 0.2363,
      "step": 472
    },
    {
      "epoch": 0.034279088306700005,
      "grad_norm": 4.912284851074219,
      "learning_rate": 0.00019315892455975072,
      "loss": 0.1678,
      "step": 473
    },
    {
      "epoch": 0.034351559952168716,
      "grad_norm": 1.946777582168579,
      "learning_rate": 0.00019314443075585188,
      "loss": 0.2752,
      "step": 474
    },
    {
      "epoch": 0.034424031597637426,
      "grad_norm": 5.304868698120117,
      "learning_rate": 0.00019312993695195306,
      "loss": 0.2667,
      "step": 475
    },
    {
      "epoch": 0.03449650324310614,
      "grad_norm": 4.494287967681885,
      "learning_rate": 0.00019311544314805422,
      "loss": 0.212,
      "step": 476
    },
    {
      "epoch": 0.03456897488857485,
      "grad_norm": 4.9939985275268555,
      "learning_rate": 0.0001931009493441554,
      "loss": 0.1435,
      "step": 477
    },
    {
      "epoch": 0.03464144653404356,
      "grad_norm": 1.608560562133789,
      "learning_rate": 0.00019308645554025656,
      "loss": 0.2019,
      "step": 478
    },
    {
      "epoch": 0.03471391817951226,
      "grad_norm": 2.0141851902008057,
      "learning_rate": 0.00019307196173635772,
      "loss": 0.1189,
      "step": 479
    },
    {
      "epoch": 0.03478638982498097,
      "grad_norm": 5.109893321990967,
      "learning_rate": 0.0001930574679324589,
      "loss": 0.3015,
      "step": 480
    },
    {
      "epoch": 0.034858861470449684,
      "grad_norm": 2.7802894115448,
      "learning_rate": 0.00019304297412856006,
      "loss": 0.1678,
      "step": 481
    },
    {
      "epoch": 0.034931333115918395,
      "grad_norm": 1.3826613426208496,
      "learning_rate": 0.0001930284803246612,
      "loss": 0.1022,
      "step": 482
    },
    {
      "epoch": 0.035003804761387106,
      "grad_norm": 4.406477451324463,
      "learning_rate": 0.0001930139865207624,
      "loss": 0.1748,
      "step": 483
    },
    {
      "epoch": 0.035076276406855816,
      "grad_norm": 3.0030834674835205,
      "learning_rate": 0.00019299949271686355,
      "loss": 0.2501,
      "step": 484
    },
    {
      "epoch": 0.03514874805232453,
      "grad_norm": 2.679426431655884,
      "learning_rate": 0.0001929849989129647,
      "loss": 0.2027,
      "step": 485
    },
    {
      "epoch": 0.03522121969779324,
      "grad_norm": 4.2860565185546875,
      "learning_rate": 0.0001929705051090659,
      "loss": 0.1223,
      "step": 486
    },
    {
      "epoch": 0.03529369134326195,
      "grad_norm": 7.627240180969238,
      "learning_rate": 0.00019295601130516705,
      "loss": 0.2854,
      "step": 487
    },
    {
      "epoch": 0.03536616298873066,
      "grad_norm": 3.4963409900665283,
      "learning_rate": 0.0001929415175012682,
      "loss": 0.2111,
      "step": 488
    },
    {
      "epoch": 0.03543863463419937,
      "grad_norm": 4.626083850860596,
      "learning_rate": 0.0001929270236973694,
      "loss": 0.1912,
      "step": 489
    },
    {
      "epoch": 0.03551110627966808,
      "grad_norm": 6.142614841461182,
      "learning_rate": 0.00019291252989347055,
      "loss": 0.2027,
      "step": 490
    },
    {
      "epoch": 0.03558357792513679,
      "grad_norm": 2.7702667713165283,
      "learning_rate": 0.0001928980360895717,
      "loss": 0.2282,
      "step": 491
    },
    {
      "epoch": 0.0356560495706055,
      "grad_norm": 7.111787796020508,
      "learning_rate": 0.00019288354228567289,
      "loss": 0.3024,
      "step": 492
    },
    {
      "epoch": 0.03572852121607421,
      "grad_norm": 4.47308874130249,
      "learning_rate": 0.00019286904848177404,
      "loss": 0.1337,
      "step": 493
    },
    {
      "epoch": 0.035800992861542924,
      "grad_norm": 5.726335525512695,
      "learning_rate": 0.0001928545546778752,
      "loss": 0.2715,
      "step": 494
    },
    {
      "epoch": 0.035873464507011635,
      "grad_norm": 5.640911102294922,
      "learning_rate": 0.00019284006087397638,
      "loss": 0.291,
      "step": 495
    },
    {
      "epoch": 0.03594593615248034,
      "grad_norm": 1.8255027532577515,
      "learning_rate": 0.00019282556707007754,
      "loss": 0.1673,
      "step": 496
    },
    {
      "epoch": 0.03601840779794905,
      "grad_norm": 4.295363903045654,
      "learning_rate": 0.00019281107326617872,
      "loss": 0.3064,
      "step": 497
    },
    {
      "epoch": 0.03609087944341776,
      "grad_norm": 5.55922794342041,
      "learning_rate": 0.00019279657946227988,
      "loss": 0.4197,
      "step": 498
    },
    {
      "epoch": 0.03616335108888647,
      "grad_norm": 3.9482266902923584,
      "learning_rate": 0.00019278208565838106,
      "loss": 0.1934,
      "step": 499
    },
    {
      "epoch": 0.03623582273435518,
      "grad_norm": 6.020792484283447,
      "learning_rate": 0.00019276759185448222,
      "loss": 0.2914,
      "step": 500
    },
    {
      "epoch": 0.03630829437982389,
      "grad_norm": 3.543458938598633,
      "learning_rate": 0.0001927530980505834,
      "loss": 0.2595,
      "step": 501
    },
    {
      "epoch": 0.0363807660252926,
      "grad_norm": 2.354828357696533,
      "learning_rate": 0.00019273860424668456,
      "loss": 0.1562,
      "step": 502
    },
    {
      "epoch": 0.036453237670761314,
      "grad_norm": 1.9209340810775757,
      "learning_rate": 0.00019272411044278572,
      "loss": 0.1644,
      "step": 503
    },
    {
      "epoch": 0.036525709316230025,
      "grad_norm": 1.3143086433410645,
      "learning_rate": 0.0001927096166388869,
      "loss": 0.1184,
      "step": 504
    },
    {
      "epoch": 0.036598180961698736,
      "grad_norm": 3.291680097579956,
      "learning_rate": 0.00019269512283498806,
      "loss": 0.1843,
      "step": 505
    },
    {
      "epoch": 0.036670652607167446,
      "grad_norm": 3.299243927001953,
      "learning_rate": 0.0001926806290310892,
      "loss": 0.2176,
      "step": 506
    },
    {
      "epoch": 0.03674312425263616,
      "grad_norm": 3.7439446449279785,
      "learning_rate": 0.0001926661352271904,
      "loss": 0.3001,
      "step": 507
    },
    {
      "epoch": 0.03681559589810487,
      "grad_norm": 3.000572443008423,
      "learning_rate": 0.00019265164142329155,
      "loss": 0.1818,
      "step": 508
    },
    {
      "epoch": 0.03688806754357358,
      "grad_norm": 2.9550821781158447,
      "learning_rate": 0.0001926371476193927,
      "loss": 0.197,
      "step": 509
    },
    {
      "epoch": 0.03696053918904229,
      "grad_norm": 3.8660974502563477,
      "learning_rate": 0.0001926226538154939,
      "loss": 0.3177,
      "step": 510
    },
    {
      "epoch": 0.037033010834511,
      "grad_norm": 3.244866371154785,
      "learning_rate": 0.00019260816001159505,
      "loss": 0.2724,
      "step": 511
    },
    {
      "epoch": 0.03710548247997971,
      "grad_norm": 3.314631462097168,
      "learning_rate": 0.0001925936662076962,
      "loss": 0.167,
      "step": 512
    },
    {
      "epoch": 0.03717795412544842,
      "grad_norm": 2.978289842605591,
      "learning_rate": 0.0001925791724037974,
      "loss": 0.1412,
      "step": 513
    },
    {
      "epoch": 0.037250425770917125,
      "grad_norm": 3.8942291736602783,
      "learning_rate": 0.00019256467859989854,
      "loss": 0.3247,
      "step": 514
    },
    {
      "epoch": 0.037322897416385836,
      "grad_norm": 5.082481384277344,
      "learning_rate": 0.0001925501847959997,
      "loss": 0.234,
      "step": 515
    },
    {
      "epoch": 0.03739536906185455,
      "grad_norm": 2.738847494125366,
      "learning_rate": 0.00019253569099210088,
      "loss": 0.2006,
      "step": 516
    },
    {
      "epoch": 0.03746784070732326,
      "grad_norm": 2.3201589584350586,
      "learning_rate": 0.00019252119718820204,
      "loss": 0.1209,
      "step": 517
    },
    {
      "epoch": 0.03754031235279197,
      "grad_norm": 2.59562349319458,
      "learning_rate": 0.0001925067033843032,
      "loss": 0.1833,
      "step": 518
    },
    {
      "epoch": 0.03761278399826068,
      "grad_norm": 5.3336076736450195,
      "learning_rate": 0.00019249220958040438,
      "loss": 0.3693,
      "step": 519
    },
    {
      "epoch": 0.03768525564372939,
      "grad_norm": 6.762752056121826,
      "learning_rate": 0.00019247771577650557,
      "loss": 0.2706,
      "step": 520
    },
    {
      "epoch": 0.0377577272891981,
      "grad_norm": 3.4351422786712646,
      "learning_rate": 0.00019246322197260672,
      "loss": 0.2306,
      "step": 521
    },
    {
      "epoch": 0.03783019893466681,
      "grad_norm": 2.570974588394165,
      "learning_rate": 0.0001924487281687079,
      "loss": 0.0819,
      "step": 522
    },
    {
      "epoch": 0.03790267058013552,
      "grad_norm": 1.884099006652832,
      "learning_rate": 0.00019243423436480906,
      "loss": 0.2055,
      "step": 523
    },
    {
      "epoch": 0.03797514222560423,
      "grad_norm": 1.9035625457763672,
      "learning_rate": 0.00019241974056091022,
      "loss": 0.1499,
      "step": 524
    },
    {
      "epoch": 0.038047613871072944,
      "grad_norm": 4.853801250457764,
      "learning_rate": 0.0001924052467570114,
      "loss": 0.1897,
      "step": 525
    },
    {
      "epoch": 0.038120085516541655,
      "grad_norm": 2.0647284984588623,
      "learning_rate": 0.00019239075295311256,
      "loss": 0.1462,
      "step": 526
    },
    {
      "epoch": 0.038192557162010365,
      "grad_norm": 3.503363847732544,
      "learning_rate": 0.00019237625914921371,
      "loss": 0.142,
      "step": 527
    },
    {
      "epoch": 0.038265028807479076,
      "grad_norm": 2.490161657333374,
      "learning_rate": 0.0001923617653453149,
      "loss": 0.157,
      "step": 528
    },
    {
      "epoch": 0.03833750045294779,
      "grad_norm": 4.0013933181762695,
      "learning_rate": 0.00019234727154141605,
      "loss": 0.2766,
      "step": 529
    },
    {
      "epoch": 0.0384099720984165,
      "grad_norm": 2.2231836318969727,
      "learning_rate": 0.0001923327777375172,
      "loss": 0.1544,
      "step": 530
    },
    {
      "epoch": 0.0384824437438852,
      "grad_norm": 1.4977245330810547,
      "learning_rate": 0.0001923182839336184,
      "loss": 0.1577,
      "step": 531
    },
    {
      "epoch": 0.03855491538935391,
      "grad_norm": 2.448106050491333,
      "learning_rate": 0.00019230379012971955,
      "loss": 0.2053,
      "step": 532
    },
    {
      "epoch": 0.03862738703482262,
      "grad_norm": 4.015122413635254,
      "learning_rate": 0.0001922892963258207,
      "loss": 0.3614,
      "step": 533
    },
    {
      "epoch": 0.038699858680291334,
      "grad_norm": 1.7921007871627808,
      "learning_rate": 0.0001922748025219219,
      "loss": 0.1147,
      "step": 534
    },
    {
      "epoch": 0.038772330325760045,
      "grad_norm": 1.8516478538513184,
      "learning_rate": 0.00019226030871802305,
      "loss": 0.1793,
      "step": 535
    },
    {
      "epoch": 0.038844801971228755,
      "grad_norm": 3.586024284362793,
      "learning_rate": 0.0001922458149141242,
      "loss": 0.2603,
      "step": 536
    },
    {
      "epoch": 0.038917273616697466,
      "grad_norm": 5.292022705078125,
      "learning_rate": 0.0001922313211102254,
      "loss": 0.2457,
      "step": 537
    },
    {
      "epoch": 0.03898974526216618,
      "grad_norm": 4.26436185836792,
      "learning_rate": 0.00019221682730632654,
      "loss": 0.3868,
      "step": 538
    },
    {
      "epoch": 0.03906221690763489,
      "grad_norm": 3.9134202003479004,
      "learning_rate": 0.0001922023335024277,
      "loss": 0.1793,
      "step": 539
    },
    {
      "epoch": 0.0391346885531036,
      "grad_norm": 5.027646064758301,
      "learning_rate": 0.00019218783969852888,
      "loss": 0.1863,
      "step": 540
    },
    {
      "epoch": 0.03920716019857231,
      "grad_norm": 2.955885410308838,
      "learning_rate": 0.00019217334589463004,
      "loss": 0.1947,
      "step": 541
    },
    {
      "epoch": 0.03927963184404102,
      "grad_norm": 3.657884120941162,
      "learning_rate": 0.00019215885209073122,
      "loss": 0.155,
      "step": 542
    },
    {
      "epoch": 0.03935210348950973,
      "grad_norm": 2.331782817840576,
      "learning_rate": 0.00019214435828683238,
      "loss": 0.1972,
      "step": 543
    },
    {
      "epoch": 0.03942457513497844,
      "grad_norm": 3.221334457397461,
      "learning_rate": 0.00019212986448293356,
      "loss": 0.2931,
      "step": 544
    },
    {
      "epoch": 0.03949704678044715,
      "grad_norm": 1.9825106859207153,
      "learning_rate": 0.00019211537067903472,
      "loss": 0.172,
      "step": 545
    },
    {
      "epoch": 0.03956951842591586,
      "grad_norm": 2.2364840507507324,
      "learning_rate": 0.0001921008768751359,
      "loss": 0.1584,
      "step": 546
    },
    {
      "epoch": 0.039641990071384574,
      "grad_norm": 2.071206569671631,
      "learning_rate": 0.00019208638307123706,
      "loss": 0.3505,
      "step": 547
    },
    {
      "epoch": 0.039714461716853285,
      "grad_norm": 2.8693132400512695,
      "learning_rate": 0.00019207188926733822,
      "loss": 0.2765,
      "step": 548
    },
    {
      "epoch": 0.03978693336232199,
      "grad_norm": 4.457656383514404,
      "learning_rate": 0.0001920573954634394,
      "loss": 0.2964,
      "step": 549
    },
    {
      "epoch": 0.0398594050077907,
      "grad_norm": 2.2207157611846924,
      "learning_rate": 0.00019204290165954056,
      "loss": 0.2158,
      "step": 550
    },
    {
      "epoch": 0.03993187665325941,
      "grad_norm": 2.1915175914764404,
      "learning_rate": 0.00019202840785564171,
      "loss": 0.3208,
      "step": 551
    },
    {
      "epoch": 0.04000434829872812,
      "grad_norm": 2.1206319332122803,
      "learning_rate": 0.0001920139140517429,
      "loss": 0.2267,
      "step": 552
    },
    {
      "epoch": 0.04007681994419683,
      "grad_norm": 3.123612880706787,
      "learning_rate": 0.00019199942024784405,
      "loss": 0.2556,
      "step": 553
    },
    {
      "epoch": 0.04014929158966554,
      "grad_norm": 4.183731555938721,
      "learning_rate": 0.0001919849264439452,
      "loss": 0.214,
      "step": 554
    },
    {
      "epoch": 0.04022176323513425,
      "grad_norm": 4.202247619628906,
      "learning_rate": 0.0001919704326400464,
      "loss": 0.2404,
      "step": 555
    },
    {
      "epoch": 0.040294234880602964,
      "grad_norm": 2.3820672035217285,
      "learning_rate": 0.00019195593883614755,
      "loss": 0.1859,
      "step": 556
    },
    {
      "epoch": 0.040366706526071675,
      "grad_norm": 2.995854616165161,
      "learning_rate": 0.0001919414450322487,
      "loss": 0.2349,
      "step": 557
    },
    {
      "epoch": 0.040439178171540385,
      "grad_norm": 2.4747653007507324,
      "learning_rate": 0.0001919269512283499,
      "loss": 0.1211,
      "step": 558
    },
    {
      "epoch": 0.040511649817009096,
      "grad_norm": 0.7709314823150635,
      "learning_rate": 0.00019191245742445105,
      "loss": 0.0916,
      "step": 559
    },
    {
      "epoch": 0.04058412146247781,
      "grad_norm": 1.6606762409210205,
      "learning_rate": 0.0001918979636205522,
      "loss": 0.175,
      "step": 560
    },
    {
      "epoch": 0.04065659310794652,
      "grad_norm": 4.02655029296875,
      "learning_rate": 0.0001918834698166534,
      "loss": 0.265,
      "step": 561
    },
    {
      "epoch": 0.04072906475341523,
      "grad_norm": 4.994272232055664,
      "learning_rate": 0.00019186897601275454,
      "loss": 0.2881,
      "step": 562
    },
    {
      "epoch": 0.04080153639888394,
      "grad_norm": 5.174117088317871,
      "learning_rate": 0.0001918544822088557,
      "loss": 0.3306,
      "step": 563
    },
    {
      "epoch": 0.04087400804435265,
      "grad_norm": 1.5559207201004028,
      "learning_rate": 0.00019183998840495688,
      "loss": 0.0914,
      "step": 564
    },
    {
      "epoch": 0.04094647968982136,
      "grad_norm": 2.597193479537964,
      "learning_rate": 0.00019182549460105804,
      "loss": 0.1417,
      "step": 565
    },
    {
      "epoch": 0.041018951335290064,
      "grad_norm": 2.1864097118377686,
      "learning_rate": 0.00019181100079715922,
      "loss": 0.1484,
      "step": 566
    },
    {
      "epoch": 0.041091422980758775,
      "grad_norm": 4.66980504989624,
      "learning_rate": 0.00019179650699326038,
      "loss": 0.2601,
      "step": 567
    },
    {
      "epoch": 0.041163894626227486,
      "grad_norm": 2.5110299587249756,
      "learning_rate": 0.00019178201318936156,
      "loss": 0.1364,
      "step": 568
    },
    {
      "epoch": 0.0412363662716962,
      "grad_norm": 2.1199862957000732,
      "learning_rate": 0.00019176751938546272,
      "loss": 0.1436,
      "step": 569
    },
    {
      "epoch": 0.04130883791716491,
      "grad_norm": 4.5853400230407715,
      "learning_rate": 0.0001917530255815639,
      "loss": 0.3297,
      "step": 570
    },
    {
      "epoch": 0.04138130956263362,
      "grad_norm": 2.3875808715820312,
      "learning_rate": 0.00019173853177766506,
      "loss": 0.0918,
      "step": 571
    },
    {
      "epoch": 0.04145378120810233,
      "grad_norm": 3.7372469902038574,
      "learning_rate": 0.00019172403797376624,
      "loss": 0.1431,
      "step": 572
    },
    {
      "epoch": 0.04152625285357104,
      "grad_norm": 2.2268786430358887,
      "learning_rate": 0.0001917095441698674,
      "loss": 0.2243,
      "step": 573
    },
    {
      "epoch": 0.04159872449903975,
      "grad_norm": 2.0847127437591553,
      "learning_rate": 0.00019169505036596856,
      "loss": 0.1125,
      "step": 574
    },
    {
      "epoch": 0.04167119614450846,
      "grad_norm": 3.6514947414398193,
      "learning_rate": 0.00019168055656206974,
      "loss": 0.1566,
      "step": 575
    },
    {
      "epoch": 0.04174366778997717,
      "grad_norm": 3.610445499420166,
      "learning_rate": 0.0001916660627581709,
      "loss": 0.1505,
      "step": 576
    },
    {
      "epoch": 0.04181613943544588,
      "grad_norm": 3.24998140335083,
      "learning_rate": 0.00019165156895427205,
      "loss": 0.2249,
      "step": 577
    },
    {
      "epoch": 0.041888611080914594,
      "grad_norm": 2.6510989665985107,
      "learning_rate": 0.00019163707515037324,
      "loss": 0.1807,
      "step": 578
    },
    {
      "epoch": 0.041961082726383304,
      "grad_norm": 3.0440633296966553,
      "learning_rate": 0.0001916225813464744,
      "loss": 0.2339,
      "step": 579
    },
    {
      "epoch": 0.042033554371852015,
      "grad_norm": 6.826251029968262,
      "learning_rate": 0.00019160808754257555,
      "loss": 0.2576,
      "step": 580
    },
    {
      "epoch": 0.042106026017320726,
      "grad_norm": 2.091294288635254,
      "learning_rate": 0.00019159359373867673,
      "loss": 0.184,
      "step": 581
    },
    {
      "epoch": 0.04217849766278944,
      "grad_norm": 3.9836652278900146,
      "learning_rate": 0.0001915790999347779,
      "loss": 0.3091,
      "step": 582
    },
    {
      "epoch": 0.04225096930825814,
      "grad_norm": 2.0822432041168213,
      "learning_rate": 0.00019156460613087905,
      "loss": 0.1532,
      "step": 583
    },
    {
      "epoch": 0.04232344095372685,
      "grad_norm": 2.3780038356781006,
      "learning_rate": 0.00019155011232698023,
      "loss": 0.1868,
      "step": 584
    },
    {
      "epoch": 0.04239591259919556,
      "grad_norm": 3.0834920406341553,
      "learning_rate": 0.0001915356185230814,
      "loss": 0.1848,
      "step": 585
    },
    {
      "epoch": 0.04246838424466427,
      "grad_norm": 1.7520004510879517,
      "learning_rate": 0.00019152112471918254,
      "loss": 0.1375,
      "step": 586
    },
    {
      "epoch": 0.042540855890132984,
      "grad_norm": 1.2774845361709595,
      "learning_rate": 0.00019150663091528373,
      "loss": 0.0906,
      "step": 587
    },
    {
      "epoch": 0.042613327535601694,
      "grad_norm": 1.908345341682434,
      "learning_rate": 0.00019149213711138488,
      "loss": 0.1337,
      "step": 588
    },
    {
      "epoch": 0.042685799181070405,
      "grad_norm": 2.247779369354248,
      "learning_rate": 0.00019147764330748607,
      "loss": 0.1495,
      "step": 589
    },
    {
      "epoch": 0.042758270826539116,
      "grad_norm": 3.558049440383911,
      "learning_rate": 0.00019146314950358722,
      "loss": 0.1001,
      "step": 590
    },
    {
      "epoch": 0.04283074247200783,
      "grad_norm": 5.477147579193115,
      "learning_rate": 0.0001914486556996884,
      "loss": 0.2342,
      "step": 591
    },
    {
      "epoch": 0.04290321411747654,
      "grad_norm": 6.227960586547852,
      "learning_rate": 0.00019143416189578956,
      "loss": 0.1842,
      "step": 592
    },
    {
      "epoch": 0.04297568576294525,
      "grad_norm": 5.928304672241211,
      "learning_rate": 0.00019141966809189075,
      "loss": 0.2377,
      "step": 593
    },
    {
      "epoch": 0.04304815740841396,
      "grad_norm": 4.362575054168701,
      "learning_rate": 0.0001914051742879919,
      "loss": 0.2029,
      "step": 594
    },
    {
      "epoch": 0.04312062905388267,
      "grad_norm": 8.579961776733398,
      "learning_rate": 0.00019139068048409306,
      "loss": 0.2746,
      "step": 595
    },
    {
      "epoch": 0.04319310069935138,
      "grad_norm": 4.117079734802246,
      "learning_rate": 0.00019137618668019424,
      "loss": 0.1477,
      "step": 596
    },
    {
      "epoch": 0.04326557234482009,
      "grad_norm": 6.27937126159668,
      "learning_rate": 0.0001913616928762954,
      "loss": 0.2553,
      "step": 597
    },
    {
      "epoch": 0.0433380439902888,
      "grad_norm": 5.743707180023193,
      "learning_rate": 0.00019134719907239656,
      "loss": 0.2537,
      "step": 598
    },
    {
      "epoch": 0.04341051563575751,
      "grad_norm": 7.903738498687744,
      "learning_rate": 0.00019133270526849774,
      "loss": 0.1262,
      "step": 599
    },
    {
      "epoch": 0.043482987281226224,
      "grad_norm": 3.353025436401367,
      "learning_rate": 0.0001913182114645989,
      "loss": 0.2242,
      "step": 600
    },
    {
      "epoch": 0.04355545892669493,
      "grad_norm": 6.631523609161377,
      "learning_rate": 0.00019130371766070005,
      "loss": 0.236,
      "step": 601
    },
    {
      "epoch": 0.04362793057216364,
      "grad_norm": 1.7193355560302734,
      "learning_rate": 0.00019128922385680124,
      "loss": 0.1029,
      "step": 602
    },
    {
      "epoch": 0.04370040221763235,
      "grad_norm": 5.281973361968994,
      "learning_rate": 0.0001912747300529024,
      "loss": 0.2114,
      "step": 603
    },
    {
      "epoch": 0.04377287386310106,
      "grad_norm": 1.9368126392364502,
      "learning_rate": 0.00019126023624900355,
      "loss": 0.1138,
      "step": 604
    },
    {
      "epoch": 0.04384534550856977,
      "grad_norm": 7.640048980712891,
      "learning_rate": 0.00019124574244510473,
      "loss": 0.3579,
      "step": 605
    },
    {
      "epoch": 0.04391781715403848,
      "grad_norm": 2.422905206680298,
      "learning_rate": 0.0001912312486412059,
      "loss": 0.0855,
      "step": 606
    },
    {
      "epoch": 0.04399028879950719,
      "grad_norm": 4.453970432281494,
      "learning_rate": 0.00019121675483730705,
      "loss": 0.149,
      "step": 607
    },
    {
      "epoch": 0.0440627604449759,
      "grad_norm": 2.434583902359009,
      "learning_rate": 0.00019120226103340823,
      "loss": 0.1978,
      "step": 608
    },
    {
      "epoch": 0.044135232090444614,
      "grad_norm": 5.228559494018555,
      "learning_rate": 0.0001911877672295094,
      "loss": 0.246,
      "step": 609
    },
    {
      "epoch": 0.044207703735913324,
      "grad_norm": 2.1690592765808105,
      "learning_rate": 0.00019117327342561054,
      "loss": 0.1213,
      "step": 610
    },
    {
      "epoch": 0.044280175381382035,
      "grad_norm": 3.351971387863159,
      "learning_rate": 0.00019115877962171173,
      "loss": 0.1711,
      "step": 611
    },
    {
      "epoch": 0.044352647026850746,
      "grad_norm": 2.9218642711639404,
      "learning_rate": 0.00019114428581781288,
      "loss": 0.1869,
      "step": 612
    },
    {
      "epoch": 0.04442511867231946,
      "grad_norm": 7.773674011230469,
      "learning_rate": 0.00019112979201391407,
      "loss": 0.3708,
      "step": 613
    },
    {
      "epoch": 0.04449759031778817,
      "grad_norm": 4.700551509857178,
      "learning_rate": 0.00019111529821001522,
      "loss": 0.2258,
      "step": 614
    },
    {
      "epoch": 0.04457006196325688,
      "grad_norm": 3.198110342025757,
      "learning_rate": 0.0001911008044061164,
      "loss": 0.1015,
      "step": 615
    },
    {
      "epoch": 0.04464253360872559,
      "grad_norm": 1.7624926567077637,
      "learning_rate": 0.00019108631060221756,
      "loss": 0.1545,
      "step": 616
    },
    {
      "epoch": 0.0447150052541943,
      "grad_norm": 4.011826515197754,
      "learning_rate": 0.00019107181679831875,
      "loss": 0.2636,
      "step": 617
    },
    {
      "epoch": 0.044787476899663003,
      "grad_norm": 3.0881450176239014,
      "learning_rate": 0.0001910573229944199,
      "loss": 0.178,
      "step": 618
    },
    {
      "epoch": 0.044859948545131714,
      "grad_norm": 6.403623580932617,
      "learning_rate": 0.00019104282919052106,
      "loss": 0.1661,
      "step": 619
    },
    {
      "epoch": 0.044932420190600425,
      "grad_norm": 1.9531797170639038,
      "learning_rate": 0.00019102833538662224,
      "loss": 0.1035,
      "step": 620
    },
    {
      "epoch": 0.045004891836069136,
      "grad_norm": 4.412101745605469,
      "learning_rate": 0.0001910138415827234,
      "loss": 0.1172,
      "step": 621
    },
    {
      "epoch": 0.04507736348153785,
      "grad_norm": 3.574711799621582,
      "learning_rate": 0.00019099934777882456,
      "loss": 0.1898,
      "step": 622
    },
    {
      "epoch": 0.04514983512700656,
      "grad_norm": 3.018728494644165,
      "learning_rate": 0.00019098485397492574,
      "loss": 0.1947,
      "step": 623
    },
    {
      "epoch": 0.04522230677247527,
      "grad_norm": 2.6668295860290527,
      "learning_rate": 0.0001909703601710269,
      "loss": 0.1972,
      "step": 624
    },
    {
      "epoch": 0.04529477841794398,
      "grad_norm": 1.7304831743240356,
      "learning_rate": 0.00019095586636712805,
      "loss": 0.1599,
      "step": 625
    },
    {
      "epoch": 0.04536725006341269,
      "grad_norm": 3.343357801437378,
      "learning_rate": 0.00019094137256322924,
      "loss": 0.2328,
      "step": 626
    },
    {
      "epoch": 0.0454397217088814,
      "grad_norm": 3.935495376586914,
      "learning_rate": 0.0001909268787593304,
      "loss": 0.2346,
      "step": 627
    },
    {
      "epoch": 0.04551219335435011,
      "grad_norm": 5.299684524536133,
      "learning_rate": 0.00019091238495543155,
      "loss": 0.2801,
      "step": 628
    },
    {
      "epoch": 0.04558466499981882,
      "grad_norm": 3.719783067703247,
      "learning_rate": 0.00019089789115153273,
      "loss": 0.2604,
      "step": 629
    },
    {
      "epoch": 0.04565713664528753,
      "grad_norm": 2.7118051052093506,
      "learning_rate": 0.0001908833973476339,
      "loss": 0.2538,
      "step": 630
    },
    {
      "epoch": 0.04572960829075624,
      "grad_norm": 2.9871039390563965,
      "learning_rate": 0.00019086890354373505,
      "loss": 0.2471,
      "step": 631
    },
    {
      "epoch": 0.045802079936224954,
      "grad_norm": 3.735710859298706,
      "learning_rate": 0.00019085440973983623,
      "loss": 0.197,
      "step": 632
    },
    {
      "epoch": 0.045874551581693665,
      "grad_norm": 4.458008766174316,
      "learning_rate": 0.00019083991593593739,
      "loss": 0.2236,
      "step": 633
    },
    {
      "epoch": 0.045947023227162376,
      "grad_norm": 2.357253074645996,
      "learning_rate": 0.00019082542213203854,
      "loss": 0.1143,
      "step": 634
    },
    {
      "epoch": 0.046019494872631087,
      "grad_norm": 1.7281723022460938,
      "learning_rate": 0.00019081092832813973,
      "loss": 0.1142,
      "step": 635
    },
    {
      "epoch": 0.04609196651809979,
      "grad_norm": 2.6175801753997803,
      "learning_rate": 0.0001907964345242409,
      "loss": 0.221,
      "step": 636
    },
    {
      "epoch": 0.0461644381635685,
      "grad_norm": 1.9703699350357056,
      "learning_rate": 0.00019078194072034207,
      "loss": 0.1685,
      "step": 637
    },
    {
      "epoch": 0.04623690980903721,
      "grad_norm": 2.273798942565918,
      "learning_rate": 0.00019076744691644325,
      "loss": 0.2181,
      "step": 638
    },
    {
      "epoch": 0.04630938145450592,
      "grad_norm": 1.4809362888336182,
      "learning_rate": 0.0001907529531125444,
      "loss": 0.1199,
      "step": 639
    },
    {
      "epoch": 0.04638185309997463,
      "grad_norm": 3.098112106323242,
      "learning_rate": 0.00019073845930864556,
      "loss": 0.203,
      "step": 640
    },
    {
      "epoch": 0.046454324745443344,
      "grad_norm": 4.7117204666137695,
      "learning_rate": 0.00019072396550474675,
      "loss": 0.2048,
      "step": 641
    },
    {
      "epoch": 0.046526796390912055,
      "grad_norm": 4.6327972412109375,
      "learning_rate": 0.0001907094717008479,
      "loss": 0.3209,
      "step": 642
    },
    {
      "epoch": 0.046599268036380766,
      "grad_norm": 4.264349460601807,
      "learning_rate": 0.00019069497789694906,
      "loss": 0.1312,
      "step": 643
    },
    {
      "epoch": 0.046671739681849476,
      "grad_norm": 2.5342962741851807,
      "learning_rate": 0.00019068048409305024,
      "loss": 0.1483,
      "step": 644
    },
    {
      "epoch": 0.04674421132731819,
      "grad_norm": 4.429774761199951,
      "learning_rate": 0.0001906659902891514,
      "loss": 0.1639,
      "step": 645
    },
    {
      "epoch": 0.0468166829727869,
      "grad_norm": 4.247372627258301,
      "learning_rate": 0.00019065149648525256,
      "loss": 0.2107,
      "step": 646
    },
    {
      "epoch": 0.04688915461825561,
      "grad_norm": 3.5211503505706787,
      "learning_rate": 0.00019063700268135374,
      "loss": 0.1783,
      "step": 647
    },
    {
      "epoch": 0.04696162626372432,
      "grad_norm": 3.454380989074707,
      "learning_rate": 0.0001906225088774549,
      "loss": 0.1691,
      "step": 648
    },
    {
      "epoch": 0.04703409790919303,
      "grad_norm": 2.5893406867980957,
      "learning_rate": 0.00019060801507355605,
      "loss": 0.096,
      "step": 649
    },
    {
      "epoch": 0.04710656955466174,
      "grad_norm": 4.38102912902832,
      "learning_rate": 0.00019059352126965724,
      "loss": 0.1906,
      "step": 650
    },
    {
      "epoch": 0.04717904120013045,
      "grad_norm": 3.27419376373291,
      "learning_rate": 0.0001905790274657584,
      "loss": 0.2007,
      "step": 651
    },
    {
      "epoch": 0.04725151284559916,
      "grad_norm": 2.575544834136963,
      "learning_rate": 0.00019056453366185955,
      "loss": 0.1434,
      "step": 652
    },
    {
      "epoch": 0.047323984491067866,
      "grad_norm": 2.687985897064209,
      "learning_rate": 0.00019055003985796073,
      "loss": 0.1567,
      "step": 653
    },
    {
      "epoch": 0.04739645613653658,
      "grad_norm": 4.48274040222168,
      "learning_rate": 0.0001905355460540619,
      "loss": 0.3066,
      "step": 654
    },
    {
      "epoch": 0.04746892778200529,
      "grad_norm": 7.199812412261963,
      "learning_rate": 0.00019052105225016305,
      "loss": 0.121,
      "step": 655
    },
    {
      "epoch": 0.047541399427474,
      "grad_norm": 3.7281689643859863,
      "learning_rate": 0.00019050655844626423,
      "loss": 0.2224,
      "step": 656
    },
    {
      "epoch": 0.04761387107294271,
      "grad_norm": 3.448843479156494,
      "learning_rate": 0.00019049206464236539,
      "loss": 0.2607,
      "step": 657
    },
    {
      "epoch": 0.04768634271841142,
      "grad_norm": 3.894212484359741,
      "learning_rate": 0.00019047757083846657,
      "loss": 0.1937,
      "step": 658
    },
    {
      "epoch": 0.04775881436388013,
      "grad_norm": 2.064671039581299,
      "learning_rate": 0.00019046307703456773,
      "loss": 0.1214,
      "step": 659
    },
    {
      "epoch": 0.04783128600934884,
      "grad_norm": 1.449366807937622,
      "learning_rate": 0.0001904485832306689,
      "loss": 0.1093,
      "step": 660
    },
    {
      "epoch": 0.04790375765481755,
      "grad_norm": 5.998257637023926,
      "learning_rate": 0.00019043408942677007,
      "loss": 0.0702,
      "step": 661
    },
    {
      "epoch": 0.04797622930028626,
      "grad_norm": 5.540225028991699,
      "learning_rate": 0.00019041959562287125,
      "loss": 0.1845,
      "step": 662
    },
    {
      "epoch": 0.048048700945754974,
      "grad_norm": 3.325348377227783,
      "learning_rate": 0.0001904051018189724,
      "loss": 0.1236,
      "step": 663
    },
    {
      "epoch": 0.048121172591223685,
      "grad_norm": 3.5856359004974365,
      "learning_rate": 0.00019039060801507356,
      "loss": 0.2067,
      "step": 664
    },
    {
      "epoch": 0.048193644236692396,
      "grad_norm": 4.5274152755737305,
      "learning_rate": 0.00019037611421117475,
      "loss": 0.2981,
      "step": 665
    },
    {
      "epoch": 0.048266115882161106,
      "grad_norm": 1.9811091423034668,
      "learning_rate": 0.0001903616204072759,
      "loss": 0.1698,
      "step": 666
    },
    {
      "epoch": 0.04833858752762982,
      "grad_norm": 1.9198403358459473,
      "learning_rate": 0.00019034712660337706,
      "loss": 0.1339,
      "step": 667
    },
    {
      "epoch": 0.04841105917309853,
      "grad_norm": 2.1083528995513916,
      "learning_rate": 0.00019033263279947824,
      "loss": 0.1496,
      "step": 668
    },
    {
      "epoch": 0.04848353081856724,
      "grad_norm": 4.620181560516357,
      "learning_rate": 0.0001903181389955794,
      "loss": 0.1391,
      "step": 669
    },
    {
      "epoch": 0.04855600246403594,
      "grad_norm": 5.733767986297607,
      "learning_rate": 0.00019030364519168056,
      "loss": 0.2351,
      "step": 670
    },
    {
      "epoch": 0.04862847410950465,
      "grad_norm": 8.02291488647461,
      "learning_rate": 0.00019028915138778174,
      "loss": 0.4373,
      "step": 671
    },
    {
      "epoch": 0.048700945754973364,
      "grad_norm": 3.478928565979004,
      "learning_rate": 0.0001902746575838829,
      "loss": 0.1833,
      "step": 672
    },
    {
      "epoch": 0.048773417400442075,
      "grad_norm": 4.472886085510254,
      "learning_rate": 0.00019026016377998405,
      "loss": 0.2182,
      "step": 673
    },
    {
      "epoch": 0.048845889045910786,
      "grad_norm": 4.344453811645508,
      "learning_rate": 0.00019024566997608524,
      "loss": 0.1623,
      "step": 674
    },
    {
      "epoch": 0.048918360691379496,
      "grad_norm": 2.081817388534546,
      "learning_rate": 0.0001902311761721864,
      "loss": 0.1054,
      "step": 675
    },
    {
      "epoch": 0.04899083233684821,
      "grad_norm": 2.323009729385376,
      "learning_rate": 0.00019021668236828755,
      "loss": 0.1563,
      "step": 676
    },
    {
      "epoch": 0.04906330398231692,
      "grad_norm": 2.6070775985717773,
      "learning_rate": 0.00019020218856438873,
      "loss": 0.1709,
      "step": 677
    },
    {
      "epoch": 0.04913577562778563,
      "grad_norm": 3.637556791305542,
      "learning_rate": 0.0001901876947604899,
      "loss": 0.2136,
      "step": 678
    },
    {
      "epoch": 0.04920824727325434,
      "grad_norm": 1.6405441761016846,
      "learning_rate": 0.00019017320095659105,
      "loss": 0.0935,
      "step": 679
    },
    {
      "epoch": 0.04928071891872305,
      "grad_norm": 6.781930446624756,
      "learning_rate": 0.00019015870715269223,
      "loss": 0.233,
      "step": 680
    },
    {
      "epoch": 0.04935319056419176,
      "grad_norm": 3.0077993869781494,
      "learning_rate": 0.00019014421334879339,
      "loss": 0.1785,
      "step": 681
    },
    {
      "epoch": 0.04942566220966047,
      "grad_norm": 6.829310417175293,
      "learning_rate": 0.00019012971954489457,
      "loss": 0.1492,
      "step": 682
    },
    {
      "epoch": 0.04949813385512918,
      "grad_norm": 1.5754172801971436,
      "learning_rate": 0.00019011522574099575,
      "loss": 0.147,
      "step": 683
    },
    {
      "epoch": 0.04957060550059789,
      "grad_norm": 4.290227890014648,
      "learning_rate": 0.0001901007319370969,
      "loss": 0.1338,
      "step": 684
    },
    {
      "epoch": 0.049643077146066604,
      "grad_norm": 1.4165990352630615,
      "learning_rate": 0.00019008623813319807,
      "loss": 0.1123,
      "step": 685
    },
    {
      "epoch": 0.049715548791535315,
      "grad_norm": 3.304142713546753,
      "learning_rate": 0.00019007174432929925,
      "loss": 0.1581,
      "step": 686
    },
    {
      "epoch": 0.049788020437004026,
      "grad_norm": 5.786080360412598,
      "learning_rate": 0.0001900572505254004,
      "loss": 0.2853,
      "step": 687
    },
    {
      "epoch": 0.04986049208247273,
      "grad_norm": 2.805396795272827,
      "learning_rate": 0.00019004275672150156,
      "loss": 0.1401,
      "step": 688
    },
    {
      "epoch": 0.04993296372794144,
      "grad_norm": 4.820836544036865,
      "learning_rate": 0.00019002826291760275,
      "loss": 0.2044,
      "step": 689
    },
    {
      "epoch": 0.05000543537341015,
      "grad_norm": 6.530010223388672,
      "learning_rate": 0.0001900137691137039,
      "loss": 0.3522,
      "step": 690
    },
    {
      "epoch": 0.05007790701887886,
      "grad_norm": 2.679697275161743,
      "learning_rate": 0.00018999927530980506,
      "loss": 0.0863,
      "step": 691
    },
    {
      "epoch": 0.05015037866434757,
      "grad_norm": 3.756121873855591,
      "learning_rate": 0.00018998478150590624,
      "loss": 0.197,
      "step": 692
    },
    {
      "epoch": 0.05022285030981628,
      "grad_norm": 3.8533008098602295,
      "learning_rate": 0.0001899702877020074,
      "loss": 0.3041,
      "step": 693
    },
    {
      "epoch": 0.050295321955284994,
      "grad_norm": 2.585317373275757,
      "learning_rate": 0.00018995579389810856,
      "loss": 0.1503,
      "step": 694
    },
    {
      "epoch": 0.050367793600753705,
      "grad_norm": 9.361197471618652,
      "learning_rate": 0.00018994130009420974,
      "loss": 0.1255,
      "step": 695
    },
    {
      "epoch": 0.050440265246222415,
      "grad_norm": 4.2610297203063965,
      "learning_rate": 0.0001899268062903109,
      "loss": 0.1681,
      "step": 696
    },
    {
      "epoch": 0.050512736891691126,
      "grad_norm": 3.1265599727630615,
      "learning_rate": 0.00018991231248641205,
      "loss": 0.1208,
      "step": 697
    },
    {
      "epoch": 0.05058520853715984,
      "grad_norm": 2.834740400314331,
      "learning_rate": 0.00018989781868251324,
      "loss": 0.2231,
      "step": 698
    },
    {
      "epoch": 0.05065768018262855,
      "grad_norm": 2.583683729171753,
      "learning_rate": 0.0001898833248786144,
      "loss": 0.1545,
      "step": 699
    },
    {
      "epoch": 0.05073015182809726,
      "grad_norm": 4.940825462341309,
      "learning_rate": 0.00018986883107471555,
      "loss": 0.1748,
      "step": 700
    },
    {
      "epoch": 0.05080262347356597,
      "grad_norm": 1.8950008153915405,
      "learning_rate": 0.00018985433727081673,
      "loss": 0.1484,
      "step": 701
    },
    {
      "epoch": 0.05087509511903468,
      "grad_norm": 9.23596477508545,
      "learning_rate": 0.0001898398434669179,
      "loss": 0.2931,
      "step": 702
    },
    {
      "epoch": 0.05094756676450339,
      "grad_norm": 3.6970534324645996,
      "learning_rate": 0.00018982534966301907,
      "loss": 0.2184,
      "step": 703
    },
    {
      "epoch": 0.0510200384099721,
      "grad_norm": 3.6332435607910156,
      "learning_rate": 0.00018981085585912023,
      "loss": 0.1403,
      "step": 704
    },
    {
      "epoch": 0.051092510055440805,
      "grad_norm": 3.5891129970550537,
      "learning_rate": 0.0001897963620552214,
      "loss": 0.2259,
      "step": 705
    },
    {
      "epoch": 0.051164981700909516,
      "grad_norm": 1.9987995624542236,
      "learning_rate": 0.00018978186825132257,
      "loss": 0.2986,
      "step": 706
    },
    {
      "epoch": 0.05123745334637823,
      "grad_norm": 4.371358871459961,
      "learning_rate": 0.00018976737444742375,
      "loss": 0.2638,
      "step": 707
    },
    {
      "epoch": 0.05130992499184694,
      "grad_norm": 1.568833589553833,
      "learning_rate": 0.0001897528806435249,
      "loss": 0.0863,
      "step": 708
    },
    {
      "epoch": 0.05138239663731565,
      "grad_norm": 2.0668790340423584,
      "learning_rate": 0.00018973838683962607,
      "loss": 0.1237,
      "step": 709
    },
    {
      "epoch": 0.05145486828278436,
      "grad_norm": 3.6653053760528564,
      "learning_rate": 0.00018972389303572725,
      "loss": 0.1888,
      "step": 710
    },
    {
      "epoch": 0.05152733992825307,
      "grad_norm": 2.9171879291534424,
      "learning_rate": 0.0001897093992318284,
      "loss": 0.1252,
      "step": 711
    },
    {
      "epoch": 0.05159981157372178,
      "grad_norm": 4.92797327041626,
      "learning_rate": 0.00018969490542792956,
      "loss": 0.284,
      "step": 712
    },
    {
      "epoch": 0.05167228321919049,
      "grad_norm": 1.6380997896194458,
      "learning_rate": 0.00018968041162403075,
      "loss": 0.1005,
      "step": 713
    },
    {
      "epoch": 0.0517447548646592,
      "grad_norm": 5.519720554351807,
      "learning_rate": 0.0001896659178201319,
      "loss": 0.2893,
      "step": 714
    },
    {
      "epoch": 0.05181722651012791,
      "grad_norm": 3.295764207839966,
      "learning_rate": 0.00018965142401623306,
      "loss": 0.2678,
      "step": 715
    },
    {
      "epoch": 0.051889698155596624,
      "grad_norm": 3.590482234954834,
      "learning_rate": 0.00018963693021233424,
      "loss": 0.1437,
      "step": 716
    },
    {
      "epoch": 0.051962169801065335,
      "grad_norm": 4.686641693115234,
      "learning_rate": 0.0001896224364084354,
      "loss": 0.163,
      "step": 717
    },
    {
      "epoch": 0.052034641446534045,
      "grad_norm": 3.9247851371765137,
      "learning_rate": 0.00018960794260453655,
      "loss": 0.1622,
      "step": 718
    },
    {
      "epoch": 0.052107113092002756,
      "grad_norm": 4.076961040496826,
      "learning_rate": 0.00018959344880063774,
      "loss": 0.2702,
      "step": 719
    },
    {
      "epoch": 0.05217958473747147,
      "grad_norm": 3.824920415878296,
      "learning_rate": 0.0001895789549967389,
      "loss": 0.2695,
      "step": 720
    },
    {
      "epoch": 0.05225205638294018,
      "grad_norm": 3.673698663711548,
      "learning_rate": 0.00018956446119284005,
      "loss": 0.1093,
      "step": 721
    },
    {
      "epoch": 0.05232452802840889,
      "grad_norm": 4.928550720214844,
      "learning_rate": 0.00018954996738894124,
      "loss": 0.1992,
      "step": 722
    },
    {
      "epoch": 0.05239699967387759,
      "grad_norm": 3.740969181060791,
      "learning_rate": 0.0001895354735850424,
      "loss": 0.1265,
      "step": 723
    },
    {
      "epoch": 0.0524694713193463,
      "grad_norm": 2.6771137714385986,
      "learning_rate": 0.00018952097978114355,
      "loss": 0.2332,
      "step": 724
    },
    {
      "epoch": 0.052541942964815014,
      "grad_norm": 1.9129799604415894,
      "learning_rate": 0.00018950648597724473,
      "loss": 0.1049,
      "step": 725
    },
    {
      "epoch": 0.052614414610283725,
      "grad_norm": 5.122498035430908,
      "learning_rate": 0.0001894919921733459,
      "loss": 0.3042,
      "step": 726
    },
    {
      "epoch": 0.052686886255752435,
      "grad_norm": 3.3857030868530273,
      "learning_rate": 0.00018947749836944707,
      "loss": 0.2337,
      "step": 727
    },
    {
      "epoch": 0.052759357901221146,
      "grad_norm": 2.539146900177002,
      "learning_rate": 0.00018946300456554823,
      "loss": 0.0713,
      "step": 728
    },
    {
      "epoch": 0.05283182954668986,
      "grad_norm": 5.73464298248291,
      "learning_rate": 0.0001894485107616494,
      "loss": 0.1533,
      "step": 729
    },
    {
      "epoch": 0.05290430119215857,
      "grad_norm": 3.3712775707244873,
      "learning_rate": 0.00018943401695775057,
      "loss": 0.259,
      "step": 730
    },
    {
      "epoch": 0.05297677283762728,
      "grad_norm": 3.044656991958618,
      "learning_rate": 0.00018941952315385175,
      "loss": 0.1407,
      "step": 731
    },
    {
      "epoch": 0.05304924448309599,
      "grad_norm": 2.7569756507873535,
      "learning_rate": 0.0001894050293499529,
      "loss": 0.1564,
      "step": 732
    },
    {
      "epoch": 0.0531217161285647,
      "grad_norm": 3.3818860054016113,
      "learning_rate": 0.0001893905355460541,
      "loss": 0.1398,
      "step": 733
    },
    {
      "epoch": 0.05319418777403341,
      "grad_norm": 5.183002948760986,
      "learning_rate": 0.00018937604174215525,
      "loss": 0.2558,
      "step": 734
    },
    {
      "epoch": 0.05326665941950212,
      "grad_norm": 2.021682024002075,
      "learning_rate": 0.0001893615479382564,
      "loss": 0.2128,
      "step": 735
    },
    {
      "epoch": 0.05333913106497083,
      "grad_norm": 3.2923851013183594,
      "learning_rate": 0.0001893470541343576,
      "loss": 0.2225,
      "step": 736
    },
    {
      "epoch": 0.05341160271043954,
      "grad_norm": 1.5885653495788574,
      "learning_rate": 0.00018933256033045875,
      "loss": 0.0518,
      "step": 737
    },
    {
      "epoch": 0.053484074355908254,
      "grad_norm": 2.2094829082489014,
      "learning_rate": 0.0001893180665265599,
      "loss": 0.1507,
      "step": 738
    },
    {
      "epoch": 0.053556546001376965,
      "grad_norm": 2.1505520343780518,
      "learning_rate": 0.00018930357272266109,
      "loss": 0.1132,
      "step": 739
    },
    {
      "epoch": 0.05362901764684567,
      "grad_norm": 1.627615213394165,
      "learning_rate": 0.00018928907891876224,
      "loss": 0.0687,
      "step": 740
    },
    {
      "epoch": 0.05370148929231438,
      "grad_norm": 3.2407236099243164,
      "learning_rate": 0.0001892745851148634,
      "loss": 0.2545,
      "step": 741
    },
    {
      "epoch": 0.05377396093778309,
      "grad_norm": 3.410968065261841,
      "learning_rate": 0.00018926009131096458,
      "loss": 0.1107,
      "step": 742
    },
    {
      "epoch": 0.0538464325832518,
      "grad_norm": 3.9843673706054688,
      "learning_rate": 0.00018924559750706574,
      "loss": 0.2643,
      "step": 743
    },
    {
      "epoch": 0.05391890422872051,
      "grad_norm": 1.3093098402023315,
      "learning_rate": 0.0001892311037031669,
      "loss": 0.1027,
      "step": 744
    },
    {
      "epoch": 0.05399137587418922,
      "grad_norm": 3.0959465503692627,
      "learning_rate": 0.00018921660989926808,
      "loss": 0.2536,
      "step": 745
    },
    {
      "epoch": 0.05406384751965793,
      "grad_norm": 4.386229038238525,
      "learning_rate": 0.00018920211609536923,
      "loss": 0.2395,
      "step": 746
    },
    {
      "epoch": 0.054136319165126644,
      "grad_norm": 2.058025360107422,
      "learning_rate": 0.0001891876222914704,
      "loss": 0.0544,
      "step": 747
    },
    {
      "epoch": 0.054208790810595354,
      "grad_norm": 2.1627955436706543,
      "learning_rate": 0.00018917312848757157,
      "loss": 0.0972,
      "step": 748
    },
    {
      "epoch": 0.054281262456064065,
      "grad_norm": 6.05682373046875,
      "learning_rate": 0.00018915863468367273,
      "loss": 0.233,
      "step": 749
    },
    {
      "epoch": 0.054353734101532776,
      "grad_norm": 5.054198265075684,
      "learning_rate": 0.0001891441408797739,
      "loss": 0.1619,
      "step": 750
    },
    {
      "epoch": 0.05442620574700149,
      "grad_norm": 2.0108418464660645,
      "learning_rate": 0.00018912964707587507,
      "loss": 0.2099,
      "step": 751
    },
    {
      "epoch": 0.0544986773924702,
      "grad_norm": 1.3255263566970825,
      "learning_rate": 0.00018911515327197625,
      "loss": 0.0827,
      "step": 752
    },
    {
      "epoch": 0.05457114903793891,
      "grad_norm": 2.5256474018096924,
      "learning_rate": 0.0001891006594680774,
      "loss": 0.1652,
      "step": 753
    },
    {
      "epoch": 0.05464362068340762,
      "grad_norm": 2.301745891571045,
      "learning_rate": 0.0001890861656641786,
      "loss": 0.2029,
      "step": 754
    },
    {
      "epoch": 0.05471609232887633,
      "grad_norm": 1.4479835033416748,
      "learning_rate": 0.00018907167186027975,
      "loss": 0.1078,
      "step": 755
    },
    {
      "epoch": 0.05478856397434504,
      "grad_norm": 3.677525520324707,
      "learning_rate": 0.0001890571780563809,
      "loss": 0.1991,
      "step": 756
    },
    {
      "epoch": 0.054861035619813744,
      "grad_norm": 5.003481388092041,
      "learning_rate": 0.0001890426842524821,
      "loss": 0.2318,
      "step": 757
    },
    {
      "epoch": 0.054933507265282455,
      "grad_norm": 6.543638706207275,
      "learning_rate": 0.00018902819044858325,
      "loss": 0.2587,
      "step": 758
    },
    {
      "epoch": 0.055005978910751166,
      "grad_norm": 3.2630774974823,
      "learning_rate": 0.0001890136966446844,
      "loss": 0.1898,
      "step": 759
    },
    {
      "epoch": 0.05507845055621988,
      "grad_norm": 2.4255192279815674,
      "learning_rate": 0.0001889992028407856,
      "loss": 0.2349,
      "step": 760
    },
    {
      "epoch": 0.05515092220168859,
      "grad_norm": 4.112110137939453,
      "learning_rate": 0.00018898470903688674,
      "loss": 0.2263,
      "step": 761
    },
    {
      "epoch": 0.0552233938471573,
      "grad_norm": 2.7041351795196533,
      "learning_rate": 0.0001889702152329879,
      "loss": 0.1634,
      "step": 762
    },
    {
      "epoch": 0.05529586549262601,
      "grad_norm": 5.58305025100708,
      "learning_rate": 0.00018895572142908908,
      "loss": 0.1902,
      "step": 763
    },
    {
      "epoch": 0.05536833713809472,
      "grad_norm": 1.460910677909851,
      "learning_rate": 0.00018894122762519024,
      "loss": 0.1003,
      "step": 764
    },
    {
      "epoch": 0.05544080878356343,
      "grad_norm": 2.6088006496429443,
      "learning_rate": 0.0001889267338212914,
      "loss": 0.1818,
      "step": 765
    },
    {
      "epoch": 0.05551328042903214,
      "grad_norm": 3.829477548599243,
      "learning_rate": 0.00018891224001739258,
      "loss": 0.1964,
      "step": 766
    },
    {
      "epoch": 0.05558575207450085,
      "grad_norm": 3.0901970863342285,
      "learning_rate": 0.00018889774621349374,
      "loss": 0.1561,
      "step": 767
    },
    {
      "epoch": 0.05565822371996956,
      "grad_norm": 4.976675033569336,
      "learning_rate": 0.0001888832524095949,
      "loss": 0.1308,
      "step": 768
    },
    {
      "epoch": 0.055730695365438274,
      "grad_norm": 3.926548719406128,
      "learning_rate": 0.00018886875860569608,
      "loss": 0.2135,
      "step": 769
    },
    {
      "epoch": 0.055803167010906984,
      "grad_norm": 2.000713348388672,
      "learning_rate": 0.00018885426480179723,
      "loss": 0.1374,
      "step": 770
    },
    {
      "epoch": 0.055875638656375695,
      "grad_norm": 3.205676555633545,
      "learning_rate": 0.0001888397709978984,
      "loss": 0.1825,
      "step": 771
    },
    {
      "epoch": 0.055948110301844406,
      "grad_norm": 3.086435079574585,
      "learning_rate": 0.00018882527719399957,
      "loss": 0.1087,
      "step": 772
    },
    {
      "epoch": 0.05602058194731312,
      "grad_norm": 2.9339523315429688,
      "learning_rate": 0.00018881078339010073,
      "loss": 0.1631,
      "step": 773
    },
    {
      "epoch": 0.05609305359278183,
      "grad_norm": 2.741710901260376,
      "learning_rate": 0.00018879628958620191,
      "loss": 0.1256,
      "step": 774
    },
    {
      "epoch": 0.05616552523825053,
      "grad_norm": 4.646028995513916,
      "learning_rate": 0.00018878179578230307,
      "loss": 0.1904,
      "step": 775
    },
    {
      "epoch": 0.05623799688371924,
      "grad_norm": 2.793654680252075,
      "learning_rate": 0.00018876730197840425,
      "loss": 0.0809,
      "step": 776
    },
    {
      "epoch": 0.05631046852918795,
      "grad_norm": 1.859696865081787,
      "learning_rate": 0.0001887528081745054,
      "loss": 0.126,
      "step": 777
    },
    {
      "epoch": 0.056382940174656664,
      "grad_norm": 2.2620742321014404,
      "learning_rate": 0.0001887383143706066,
      "loss": 0.1339,
      "step": 778
    },
    {
      "epoch": 0.056455411820125374,
      "grad_norm": 1.7980672121047974,
      "learning_rate": 0.00018872382056670775,
      "loss": 0.1248,
      "step": 779
    },
    {
      "epoch": 0.056527883465594085,
      "grad_norm": 6.00583553314209,
      "learning_rate": 0.0001887093267628089,
      "loss": 0.0826,
      "step": 780
    },
    {
      "epoch": 0.056600355111062796,
      "grad_norm": 4.200097560882568,
      "learning_rate": 0.0001886948329589101,
      "loss": 0.195,
      "step": 781
    },
    {
      "epoch": 0.05667282675653151,
      "grad_norm": 3.9426965713500977,
      "learning_rate": 0.00018868033915501125,
      "loss": 0.3836,
      "step": 782
    },
    {
      "epoch": 0.05674529840200022,
      "grad_norm": 4.433769226074219,
      "learning_rate": 0.0001886658453511124,
      "loss": 0.3398,
      "step": 783
    },
    {
      "epoch": 0.05681777004746893,
      "grad_norm": 1.785696029663086,
      "learning_rate": 0.0001886513515472136,
      "loss": 0.144,
      "step": 784
    },
    {
      "epoch": 0.05689024169293764,
      "grad_norm": 3.0494682788848877,
      "learning_rate": 0.00018863685774331474,
      "loss": 0.1546,
      "step": 785
    },
    {
      "epoch": 0.05696271333840635,
      "grad_norm": 2.6610031127929688,
      "learning_rate": 0.0001886223639394159,
      "loss": 0.1857,
      "step": 786
    },
    {
      "epoch": 0.05703518498387506,
      "grad_norm": 1.8941198587417603,
      "learning_rate": 0.00018860787013551708,
      "loss": 0.1833,
      "step": 787
    },
    {
      "epoch": 0.05710765662934377,
      "grad_norm": 1.3601562976837158,
      "learning_rate": 0.00018859337633161824,
      "loss": 0.0775,
      "step": 788
    },
    {
      "epoch": 0.05718012827481248,
      "grad_norm": 3.7783188819885254,
      "learning_rate": 0.0001885788825277194,
      "loss": 0.1653,
      "step": 789
    },
    {
      "epoch": 0.05725259992028119,
      "grad_norm": 4.776968479156494,
      "learning_rate": 0.00018856438872382058,
      "loss": 0.2117,
      "step": 790
    },
    {
      "epoch": 0.057325071565749904,
      "grad_norm": 1.6519519090652466,
      "learning_rate": 0.00018854989491992174,
      "loss": 0.1241,
      "step": 791
    },
    {
      "epoch": 0.05739754321121861,
      "grad_norm": 3.0893778800964355,
      "learning_rate": 0.0001885354011160229,
      "loss": 0.1874,
      "step": 792
    },
    {
      "epoch": 0.05747001485668732,
      "grad_norm": 4.73016357421875,
      "learning_rate": 0.00018852090731212408,
      "loss": 0.1942,
      "step": 793
    },
    {
      "epoch": 0.05754248650215603,
      "grad_norm": 2.1814322471618652,
      "learning_rate": 0.00018850641350822523,
      "loss": 0.1648,
      "step": 794
    },
    {
      "epoch": 0.05761495814762474,
      "grad_norm": 0.9060184955596924,
      "learning_rate": 0.0001884919197043264,
      "loss": 0.067,
      "step": 795
    },
    {
      "epoch": 0.05768742979309345,
      "grad_norm": 4.123115539550781,
      "learning_rate": 0.00018847742590042757,
      "loss": 0.1385,
      "step": 796
    },
    {
      "epoch": 0.05775990143856216,
      "grad_norm": 3.986825704574585,
      "learning_rate": 0.00018846293209652873,
      "loss": 0.1135,
      "step": 797
    },
    {
      "epoch": 0.05783237308403087,
      "grad_norm": 1.895351767539978,
      "learning_rate": 0.00018844843829262991,
      "loss": 0.1911,
      "step": 798
    },
    {
      "epoch": 0.05790484472949958,
      "grad_norm": 2.8339085578918457,
      "learning_rate": 0.0001884339444887311,
      "loss": 0.1539,
      "step": 799
    },
    {
      "epoch": 0.057977316374968293,
      "grad_norm": 2.7335362434387207,
      "learning_rate": 0.00018841945068483225,
      "loss": 0.0994,
      "step": 800
    },
    {
      "epoch": 0.058049788020437004,
      "grad_norm": 2.3717310428619385,
      "learning_rate": 0.0001884049568809334,
      "loss": 0.1899,
      "step": 801
    },
    {
      "epoch": 0.058122259665905715,
      "grad_norm": 1.9878867864608765,
      "learning_rate": 0.0001883904630770346,
      "loss": 0.1238,
      "step": 802
    },
    {
      "epoch": 0.058194731311374426,
      "grad_norm": 1.186885952949524,
      "learning_rate": 0.00018837596927313575,
      "loss": 0.0898,
      "step": 803
    },
    {
      "epoch": 0.05826720295684314,
      "grad_norm": 2.2832584381103516,
      "learning_rate": 0.0001883614754692369,
      "loss": 0.1574,
      "step": 804
    },
    {
      "epoch": 0.05833967460231185,
      "grad_norm": 6.973381519317627,
      "learning_rate": 0.0001883469816653381,
      "loss": 0.1582,
      "step": 805
    },
    {
      "epoch": 0.05841214624778056,
      "grad_norm": 2.3203954696655273,
      "learning_rate": 0.00018833248786143925,
      "loss": 0.2119,
      "step": 806
    },
    {
      "epoch": 0.05848461789324927,
      "grad_norm": 1.5873687267303467,
      "learning_rate": 0.0001883179940575404,
      "loss": 0.1431,
      "step": 807
    },
    {
      "epoch": 0.05855708953871798,
      "grad_norm": 4.390671253204346,
      "learning_rate": 0.0001883035002536416,
      "loss": 0.3462,
      "step": 808
    },
    {
      "epoch": 0.05862956118418669,
      "grad_norm": 3.739895820617676,
      "learning_rate": 0.00018828900644974274,
      "loss": 0.2078,
      "step": 809
    },
    {
      "epoch": 0.058702032829655394,
      "grad_norm": 3.3306946754455566,
      "learning_rate": 0.0001882745126458439,
      "loss": 0.1586,
      "step": 810
    },
    {
      "epoch": 0.058774504475124105,
      "grad_norm": 1.6486968994140625,
      "learning_rate": 0.00018826001884194508,
      "loss": 0.109,
      "step": 811
    },
    {
      "epoch": 0.058846976120592816,
      "grad_norm": 3.703101873397827,
      "learning_rate": 0.00018824552503804624,
      "loss": 0.2351,
      "step": 812
    },
    {
      "epoch": 0.058919447766061527,
      "grad_norm": 3.7940173149108887,
      "learning_rate": 0.0001882310312341474,
      "loss": 0.1865,
      "step": 813
    },
    {
      "epoch": 0.05899191941153024,
      "grad_norm": 8.106624603271484,
      "learning_rate": 0.00018821653743024858,
      "loss": 0.1938,
      "step": 814
    },
    {
      "epoch": 0.05906439105699895,
      "grad_norm": 2.9709928035736084,
      "learning_rate": 0.00018820204362634974,
      "loss": 0.1584,
      "step": 815
    },
    {
      "epoch": 0.05913686270246766,
      "grad_norm": 3.535311698913574,
      "learning_rate": 0.0001881875498224509,
      "loss": 0.1948,
      "step": 816
    },
    {
      "epoch": 0.05920933434793637,
      "grad_norm": 2.6540846824645996,
      "learning_rate": 0.00018817305601855208,
      "loss": 0.12,
      "step": 817
    },
    {
      "epoch": 0.05928180599340508,
      "grad_norm": 1.8195760250091553,
      "learning_rate": 0.00018815856221465323,
      "loss": 0.1314,
      "step": 818
    },
    {
      "epoch": 0.05935427763887379,
      "grad_norm": 2.101019859313965,
      "learning_rate": 0.00018814406841075442,
      "loss": 0.166,
      "step": 819
    },
    {
      "epoch": 0.0594267492843425,
      "grad_norm": 2.755511999130249,
      "learning_rate": 0.00018812957460685557,
      "loss": 0.1251,
      "step": 820
    },
    {
      "epoch": 0.05949922092981121,
      "grad_norm": 3.6245052814483643,
      "learning_rate": 0.00018811508080295676,
      "loss": 0.2281,
      "step": 821
    },
    {
      "epoch": 0.05957169257527992,
      "grad_norm": 1.2540842294692993,
      "learning_rate": 0.00018810058699905791,
      "loss": 0.104,
      "step": 822
    },
    {
      "epoch": 0.059644164220748634,
      "grad_norm": 2.5999503135681152,
      "learning_rate": 0.0001880860931951591,
      "loss": 0.1625,
      "step": 823
    },
    {
      "epoch": 0.059716635866217345,
      "grad_norm": 2.5344903469085693,
      "learning_rate": 0.00018807159939126025,
      "loss": 0.1405,
      "step": 824
    },
    {
      "epoch": 0.059789107511686056,
      "grad_norm": 4.091742992401123,
      "learning_rate": 0.0001880571055873614,
      "loss": 0.1813,
      "step": 825
    },
    {
      "epoch": 0.059861579157154766,
      "grad_norm": 3.441697120666504,
      "learning_rate": 0.0001880426117834626,
      "loss": 0.1365,
      "step": 826
    },
    {
      "epoch": 0.05993405080262347,
      "grad_norm": 3.990217685699463,
      "learning_rate": 0.00018802811797956375,
      "loss": 0.1831,
      "step": 827
    },
    {
      "epoch": 0.06000652244809218,
      "grad_norm": 2.7070024013519287,
      "learning_rate": 0.0001880136241756649,
      "loss": 0.1821,
      "step": 828
    },
    {
      "epoch": 0.06007899409356089,
      "grad_norm": 3.0797040462493896,
      "learning_rate": 0.0001879991303717661,
      "loss": 0.1998,
      "step": 829
    },
    {
      "epoch": 0.0601514657390296,
      "grad_norm": 2.7703678607940674,
      "learning_rate": 0.00018798463656786725,
      "loss": 0.2736,
      "step": 830
    },
    {
      "epoch": 0.06022393738449831,
      "grad_norm": 3.9276204109191895,
      "learning_rate": 0.0001879701427639684,
      "loss": 0.1916,
      "step": 831
    },
    {
      "epoch": 0.060296409029967024,
      "grad_norm": 3.378244638442993,
      "learning_rate": 0.0001879556489600696,
      "loss": 0.1845,
      "step": 832
    },
    {
      "epoch": 0.060368880675435735,
      "grad_norm": 1.8543407917022705,
      "learning_rate": 0.00018794115515617074,
      "loss": 0.0837,
      "step": 833
    },
    {
      "epoch": 0.060441352320904446,
      "grad_norm": 2.7660253047943115,
      "learning_rate": 0.0001879266613522719,
      "loss": 0.1794,
      "step": 834
    },
    {
      "epoch": 0.060513823966373156,
      "grad_norm": 1.8132364749908447,
      "learning_rate": 0.00018791216754837308,
      "loss": 0.1277,
      "step": 835
    },
    {
      "epoch": 0.06058629561184187,
      "grad_norm": 3.248715877532959,
      "learning_rate": 0.00018789767374447424,
      "loss": 0.11,
      "step": 836
    },
    {
      "epoch": 0.06065876725731058,
      "grad_norm": 2.0867435932159424,
      "learning_rate": 0.0001878831799405754,
      "loss": 0.1852,
      "step": 837
    },
    {
      "epoch": 0.06073123890277929,
      "grad_norm": 2.9290454387664795,
      "learning_rate": 0.00018786868613667658,
      "loss": 0.1767,
      "step": 838
    },
    {
      "epoch": 0.060803710548248,
      "grad_norm": 4.537161827087402,
      "learning_rate": 0.00018785419233277774,
      "loss": 0.1859,
      "step": 839
    },
    {
      "epoch": 0.06087618219371671,
      "grad_norm": 2.7619616985321045,
      "learning_rate": 0.0001878396985288789,
      "loss": 0.1781,
      "step": 840
    },
    {
      "epoch": 0.06094865383918542,
      "grad_norm": 6.440887928009033,
      "learning_rate": 0.00018782520472498008,
      "loss": 0.2267,
      "step": 841
    },
    {
      "epoch": 0.06102112548465413,
      "grad_norm": 5.441777229309082,
      "learning_rate": 0.00018781071092108123,
      "loss": 0.2431,
      "step": 842
    },
    {
      "epoch": 0.06109359713012284,
      "grad_norm": 2.7378149032592773,
      "learning_rate": 0.00018779621711718242,
      "loss": 0.0943,
      "step": 843
    },
    {
      "epoch": 0.061166068775591546,
      "grad_norm": 3.116684913635254,
      "learning_rate": 0.00018778172331328357,
      "loss": 0.1504,
      "step": 844
    },
    {
      "epoch": 0.06123854042106026,
      "grad_norm": 2.10593843460083,
      "learning_rate": 0.00018776722950938476,
      "loss": 0.1306,
      "step": 845
    },
    {
      "epoch": 0.06131101206652897,
      "grad_norm": 5.7411675453186035,
      "learning_rate": 0.0001877527357054859,
      "loss": 0.1699,
      "step": 846
    },
    {
      "epoch": 0.06138348371199768,
      "grad_norm": 4.996578216552734,
      "learning_rate": 0.0001877382419015871,
      "loss": 0.106,
      "step": 847
    },
    {
      "epoch": 0.06145595535746639,
      "grad_norm": 5.227558612823486,
      "learning_rate": 0.00018772374809768825,
      "loss": 0.1429,
      "step": 848
    },
    {
      "epoch": 0.0615284270029351,
      "grad_norm": 4.0057148933410645,
      "learning_rate": 0.0001877092542937894,
      "loss": 0.2086,
      "step": 849
    },
    {
      "epoch": 0.06160089864840381,
      "grad_norm": 5.161547660827637,
      "learning_rate": 0.0001876947604898906,
      "loss": 0.2175,
      "step": 850
    },
    {
      "epoch": 0.06167337029387252,
      "grad_norm": 4.352194309234619,
      "learning_rate": 0.00018768026668599175,
      "loss": 0.298,
      "step": 851
    },
    {
      "epoch": 0.06174584193934123,
      "grad_norm": 5.660325527191162,
      "learning_rate": 0.0001876657728820929,
      "loss": 0.2213,
      "step": 852
    },
    {
      "epoch": 0.06181831358480994,
      "grad_norm": 3.563662528991699,
      "learning_rate": 0.0001876512790781941,
      "loss": 0.2098,
      "step": 853
    },
    {
      "epoch": 0.061890785230278654,
      "grad_norm": 2.7005832195281982,
      "learning_rate": 0.00018763678527429525,
      "loss": 0.1233,
      "step": 854
    },
    {
      "epoch": 0.061963256875747365,
      "grad_norm": 4.253232955932617,
      "learning_rate": 0.0001876222914703964,
      "loss": 0.1543,
      "step": 855
    },
    {
      "epoch": 0.062035728521216076,
      "grad_norm": 6.883578300476074,
      "learning_rate": 0.0001876077976664976,
      "loss": 0.2254,
      "step": 856
    },
    {
      "epoch": 0.062108200166684786,
      "grad_norm": 2.2189552783966064,
      "learning_rate": 0.00018759330386259874,
      "loss": 0.1514,
      "step": 857
    },
    {
      "epoch": 0.0621806718121535,
      "grad_norm": 2.701692581176758,
      "learning_rate": 0.0001875788100586999,
      "loss": 0.1292,
      "step": 858
    },
    {
      "epoch": 0.06225314345762221,
      "grad_norm": 2.254528760910034,
      "learning_rate": 0.00018756431625480108,
      "loss": 0.1259,
      "step": 859
    },
    {
      "epoch": 0.06232561510309092,
      "grad_norm": 6.587276935577393,
      "learning_rate": 0.00018754982245090224,
      "loss": 0.1991,
      "step": 860
    },
    {
      "epoch": 0.06239808674855963,
      "grad_norm": 3.5896987915039062,
      "learning_rate": 0.0001875353286470034,
      "loss": 0.1395,
      "step": 861
    },
    {
      "epoch": 0.06247055839402833,
      "grad_norm": 2.430051565170288,
      "learning_rate": 0.00018752083484310458,
      "loss": 0.0684,
      "step": 862
    },
    {
      "epoch": 0.06254303003949704,
      "grad_norm": 1.6375652551651,
      "learning_rate": 0.00018750634103920574,
      "loss": 0.1389,
      "step": 863
    },
    {
      "epoch": 0.06261550168496575,
      "grad_norm": 8.089278221130371,
      "learning_rate": 0.0001874918472353069,
      "loss": 0.2892,
      "step": 864
    },
    {
      "epoch": 0.06268797333043447,
      "grad_norm": 4.555845737457275,
      "learning_rate": 0.00018747735343140808,
      "loss": 0.2966,
      "step": 865
    },
    {
      "epoch": 0.06276044497590318,
      "grad_norm": 5.0525102615356445,
      "learning_rate": 0.00018746285962750926,
      "loss": 0.2084,
      "step": 866
    },
    {
      "epoch": 0.06283291662137189,
      "grad_norm": 2.7399790287017822,
      "learning_rate": 0.00018744836582361042,
      "loss": 0.1215,
      "step": 867
    },
    {
      "epoch": 0.0629053882668406,
      "grad_norm": 3.62174391746521,
      "learning_rate": 0.0001874338720197116,
      "loss": 0.1271,
      "step": 868
    },
    {
      "epoch": 0.06297785991230931,
      "grad_norm": 4.627718448638916,
      "learning_rate": 0.00018741937821581276,
      "loss": 0.1194,
      "step": 869
    },
    {
      "epoch": 0.06305033155777802,
      "grad_norm": 5.509213447570801,
      "learning_rate": 0.0001874048844119139,
      "loss": 0.1694,
      "step": 870
    },
    {
      "epoch": 0.06312280320324673,
      "grad_norm": 1.2314709424972534,
      "learning_rate": 0.0001873903906080151,
      "loss": 0.0393,
      "step": 871
    },
    {
      "epoch": 0.06319527484871544,
      "grad_norm": 3.7982676029205322,
      "learning_rate": 0.00018737589680411625,
      "loss": 0.1687,
      "step": 872
    },
    {
      "epoch": 0.06326774649418415,
      "grad_norm": 3.5338497161865234,
      "learning_rate": 0.0001873614030002174,
      "loss": 0.1461,
      "step": 873
    },
    {
      "epoch": 0.06334021813965286,
      "grad_norm": 1.638290524482727,
      "learning_rate": 0.0001873469091963186,
      "loss": 0.1326,
      "step": 874
    },
    {
      "epoch": 0.06341268978512157,
      "grad_norm": 2.364128828048706,
      "learning_rate": 0.00018733241539241975,
      "loss": 0.149,
      "step": 875
    },
    {
      "epoch": 0.06348516143059028,
      "grad_norm": 2.1074280738830566,
      "learning_rate": 0.0001873179215885209,
      "loss": 0.0681,
      "step": 876
    },
    {
      "epoch": 0.063557633076059,
      "grad_norm": 6.762315273284912,
      "learning_rate": 0.0001873034277846221,
      "loss": 0.0686,
      "step": 877
    },
    {
      "epoch": 0.0636301047215277,
      "grad_norm": 2.729041576385498,
      "learning_rate": 0.00018728893398072325,
      "loss": 0.1405,
      "step": 878
    },
    {
      "epoch": 0.06370257636699642,
      "grad_norm": 3.435091972351074,
      "learning_rate": 0.0001872744401768244,
      "loss": 0.1367,
      "step": 879
    },
    {
      "epoch": 0.06377504801246513,
      "grad_norm": 1.4804537296295166,
      "learning_rate": 0.00018725994637292559,
      "loss": 0.0419,
      "step": 880
    },
    {
      "epoch": 0.06384751965793384,
      "grad_norm": 3.2735495567321777,
      "learning_rate": 0.00018724545256902674,
      "loss": 0.1518,
      "step": 881
    },
    {
      "epoch": 0.06391999130340255,
      "grad_norm": 3.321552276611328,
      "learning_rate": 0.0001872309587651279,
      "loss": 0.1851,
      "step": 882
    },
    {
      "epoch": 0.06399246294887126,
      "grad_norm": 3.4252593517303467,
      "learning_rate": 0.00018721646496122908,
      "loss": 0.1073,
      "step": 883
    },
    {
      "epoch": 0.06406493459433997,
      "grad_norm": 4.2642083168029785,
      "learning_rate": 0.00018720197115733024,
      "loss": 0.2789,
      "step": 884
    },
    {
      "epoch": 0.06413740623980868,
      "grad_norm": 2.318094253540039,
      "learning_rate": 0.0001871874773534314,
      "loss": 0.0929,
      "step": 885
    },
    {
      "epoch": 0.06420987788527739,
      "grad_norm": 3.5932066440582275,
      "learning_rate": 0.00018717298354953258,
      "loss": 0.1535,
      "step": 886
    },
    {
      "epoch": 0.0642823495307461,
      "grad_norm": 3.180101156234741,
      "learning_rate": 0.00018715848974563374,
      "loss": 0.1733,
      "step": 887
    },
    {
      "epoch": 0.0643548211762148,
      "grad_norm": 1.698413372039795,
      "learning_rate": 0.00018714399594173492,
      "loss": 0.1192,
      "step": 888
    },
    {
      "epoch": 0.06442729282168351,
      "grad_norm": 1.8165204524993896,
      "learning_rate": 0.00018712950213783608,
      "loss": 0.0408,
      "step": 889
    },
    {
      "epoch": 0.06449976446715222,
      "grad_norm": 2.872897148132324,
      "learning_rate": 0.00018711500833393726,
      "loss": 0.1729,
      "step": 890
    },
    {
      "epoch": 0.06457223611262093,
      "grad_norm": 3.4975216388702393,
      "learning_rate": 0.00018710051453003842,
      "loss": 0.154,
      "step": 891
    },
    {
      "epoch": 0.06464470775808964,
      "grad_norm": 3.42683744430542,
      "learning_rate": 0.0001870860207261396,
      "loss": 0.1646,
      "step": 892
    },
    {
      "epoch": 0.06471717940355835,
      "grad_norm": 5.2633819580078125,
      "learning_rate": 0.00018707152692224076,
      "loss": 0.2884,
      "step": 893
    },
    {
      "epoch": 0.06478965104902706,
      "grad_norm": 2.462218999862671,
      "learning_rate": 0.00018705703311834194,
      "loss": 0.1234,
      "step": 894
    },
    {
      "epoch": 0.06486212269449577,
      "grad_norm": 2.3173487186431885,
      "learning_rate": 0.0001870425393144431,
      "loss": 0.2308,
      "step": 895
    },
    {
      "epoch": 0.06493459433996449,
      "grad_norm": 2.4222500324249268,
      "learning_rate": 0.00018702804551054425,
      "loss": 0.1686,
      "step": 896
    },
    {
      "epoch": 0.0650070659854332,
      "grad_norm": 1.4813978672027588,
      "learning_rate": 0.00018701355170664544,
      "loss": 0.1014,
      "step": 897
    },
    {
      "epoch": 0.0650795376309019,
      "grad_norm": 5.342512130737305,
      "learning_rate": 0.0001869990579027466,
      "loss": 0.2512,
      "step": 898
    },
    {
      "epoch": 0.06515200927637062,
      "grad_norm": 2.292562484741211,
      "learning_rate": 0.00018698456409884775,
      "loss": 0.1228,
      "step": 899
    },
    {
      "epoch": 0.06522448092183933,
      "grad_norm": 2.9118926525115967,
      "learning_rate": 0.00018697007029494893,
      "loss": 0.1421,
      "step": 900
    },
    {
      "epoch": 0.06529695256730804,
      "grad_norm": 1.3126786947250366,
      "learning_rate": 0.0001869555764910501,
      "loss": 0.1,
      "step": 901
    },
    {
      "epoch": 0.06536942421277675,
      "grad_norm": 1.1224408149719238,
      "learning_rate": 0.00018694108268715125,
      "loss": 0.0471,
      "step": 902
    },
    {
      "epoch": 0.06544189585824546,
      "grad_norm": 1.7540401220321655,
      "learning_rate": 0.00018692658888325243,
      "loss": 0.1593,
      "step": 903
    },
    {
      "epoch": 0.06551436750371417,
      "grad_norm": 2.3721039295196533,
      "learning_rate": 0.00018691209507935359,
      "loss": 0.0819,
      "step": 904
    },
    {
      "epoch": 0.06558683914918288,
      "grad_norm": 1.774669885635376,
      "learning_rate": 0.00018689760127545474,
      "loss": 0.1902,
      "step": 905
    },
    {
      "epoch": 0.06565931079465159,
      "grad_norm": 3.159492015838623,
      "learning_rate": 0.00018688310747155593,
      "loss": 0.1804,
      "step": 906
    },
    {
      "epoch": 0.0657317824401203,
      "grad_norm": 5.281259059906006,
      "learning_rate": 0.00018686861366765708,
      "loss": 0.3544,
      "step": 907
    },
    {
      "epoch": 0.06580425408558901,
      "grad_norm": 1.960377812385559,
      "learning_rate": 0.00018685411986375824,
      "loss": 0.1419,
      "step": 908
    },
    {
      "epoch": 0.06587672573105773,
      "grad_norm": 3.0509753227233887,
      "learning_rate": 0.00018683962605985942,
      "loss": 0.1266,
      "step": 909
    },
    {
      "epoch": 0.06594919737652644,
      "grad_norm": 2.1046030521392822,
      "learning_rate": 0.00018682513225596058,
      "loss": 0.1293,
      "step": 910
    },
    {
      "epoch": 0.06602166902199515,
      "grad_norm": 4.22909688949585,
      "learning_rate": 0.00018681063845206174,
      "loss": 0.2581,
      "step": 911
    },
    {
      "epoch": 0.06609414066746386,
      "grad_norm": 2.1768553256988525,
      "learning_rate": 0.00018679614464816292,
      "loss": 0.1552,
      "step": 912
    },
    {
      "epoch": 0.06616661231293257,
      "grad_norm": 1.0812674760818481,
      "learning_rate": 0.00018678165084426408,
      "loss": 0.0716,
      "step": 913
    },
    {
      "epoch": 0.06623908395840128,
      "grad_norm": 3.6286327838897705,
      "learning_rate": 0.00018676715704036526,
      "loss": 0.1271,
      "step": 914
    },
    {
      "epoch": 0.06631155560386999,
      "grad_norm": 1.082779884338379,
      "learning_rate": 0.00018675266323646644,
      "loss": 0.095,
      "step": 915
    },
    {
      "epoch": 0.0663840272493387,
      "grad_norm": 4.016587734222412,
      "learning_rate": 0.0001867381694325676,
      "loss": 0.1133,
      "step": 916
    },
    {
      "epoch": 0.06645649889480741,
      "grad_norm": 5.667196273803711,
      "learning_rate": 0.00018672367562866876,
      "loss": 0.256,
      "step": 917
    },
    {
      "epoch": 0.06652897054027612,
      "grad_norm": 2.3152217864990234,
      "learning_rate": 0.00018670918182476994,
      "loss": 0.1028,
      "step": 918
    },
    {
      "epoch": 0.06660144218574483,
      "grad_norm": 3.5905864238739014,
      "learning_rate": 0.0001866946880208711,
      "loss": 0.1149,
      "step": 919
    },
    {
      "epoch": 0.06667391383121354,
      "grad_norm": 3.193871259689331,
      "learning_rate": 0.00018668019421697225,
      "loss": 0.2079,
      "step": 920
    },
    {
      "epoch": 0.06674638547668225,
      "grad_norm": 1.9751195907592773,
      "learning_rate": 0.00018666570041307344,
      "loss": 0.0747,
      "step": 921
    },
    {
      "epoch": 0.06681885712215097,
      "grad_norm": 1.9940903186798096,
      "learning_rate": 0.0001866512066091746,
      "loss": 0.1021,
      "step": 922
    },
    {
      "epoch": 0.06689132876761966,
      "grad_norm": 3.418292999267578,
      "learning_rate": 0.00018663671280527575,
      "loss": 0.117,
      "step": 923
    },
    {
      "epoch": 0.06696380041308837,
      "grad_norm": 9.058935165405273,
      "learning_rate": 0.00018662221900137693,
      "loss": 0.1892,
      "step": 924
    },
    {
      "epoch": 0.06703627205855708,
      "grad_norm": 3.8454225063323975,
      "learning_rate": 0.0001866077251974781,
      "loss": 0.1116,
      "step": 925
    },
    {
      "epoch": 0.0671087437040258,
      "grad_norm": 3.6359777450561523,
      "learning_rate": 0.00018659323139357925,
      "loss": 0.1487,
      "step": 926
    },
    {
      "epoch": 0.0671812153494945,
      "grad_norm": 6.2949538230896,
      "learning_rate": 0.00018657873758968043,
      "loss": 0.2402,
      "step": 927
    },
    {
      "epoch": 0.06725368699496322,
      "grad_norm": 3.5692522525787354,
      "learning_rate": 0.00018656424378578159,
      "loss": 0.2167,
      "step": 928
    },
    {
      "epoch": 0.06732615864043193,
      "grad_norm": 1.7043321132659912,
      "learning_rate": 0.00018654974998188274,
      "loss": 0.183,
      "step": 929
    },
    {
      "epoch": 0.06739863028590064,
      "grad_norm": 2.0820517539978027,
      "learning_rate": 0.00018653525617798393,
      "loss": 0.1214,
      "step": 930
    },
    {
      "epoch": 0.06747110193136935,
      "grad_norm": 3.3809866905212402,
      "learning_rate": 0.00018652076237408508,
      "loss": 0.0804,
      "step": 931
    },
    {
      "epoch": 0.06754357357683806,
      "grad_norm": 3.3141567707061768,
      "learning_rate": 0.00018650626857018624,
      "loss": 0.2744,
      "step": 932
    },
    {
      "epoch": 0.06761604522230677,
      "grad_norm": 3.806602954864502,
      "learning_rate": 0.00018649177476628742,
      "loss": 0.2112,
      "step": 933
    },
    {
      "epoch": 0.06768851686777548,
      "grad_norm": 2.567002773284912,
      "learning_rate": 0.00018647728096238858,
      "loss": 0.1331,
      "step": 934
    },
    {
      "epoch": 0.06776098851324419,
      "grad_norm": 2.408252716064453,
      "learning_rate": 0.00018646278715848976,
      "loss": 0.1633,
      "step": 935
    },
    {
      "epoch": 0.0678334601587129,
      "grad_norm": 3.0562949180603027,
      "learning_rate": 0.00018644829335459092,
      "loss": 0.0997,
      "step": 936
    },
    {
      "epoch": 0.06790593180418161,
      "grad_norm": 2.6029114723205566,
      "learning_rate": 0.0001864337995506921,
      "loss": 0.2352,
      "step": 937
    },
    {
      "epoch": 0.06797840344965032,
      "grad_norm": 1.8190642595291138,
      "learning_rate": 0.00018641930574679326,
      "loss": 0.0971,
      "step": 938
    },
    {
      "epoch": 0.06805087509511903,
      "grad_norm": 1.7211467027664185,
      "learning_rate": 0.00018640481194289444,
      "loss": 0.1075,
      "step": 939
    },
    {
      "epoch": 0.06812334674058775,
      "grad_norm": 1.969260334968567,
      "learning_rate": 0.0001863903181389956,
      "loss": 0.075,
      "step": 940
    },
    {
      "epoch": 0.06819581838605646,
      "grad_norm": 2.636140823364258,
      "learning_rate": 0.00018637582433509676,
      "loss": 0.2224,
      "step": 941
    },
    {
      "epoch": 0.06826829003152517,
      "grad_norm": 3.8010408878326416,
      "learning_rate": 0.00018636133053119794,
      "loss": 0.1382,
      "step": 942
    },
    {
      "epoch": 0.06834076167699388,
      "grad_norm": 4.468423843383789,
      "learning_rate": 0.0001863468367272991,
      "loss": 0.1992,
      "step": 943
    },
    {
      "epoch": 0.06841323332246259,
      "grad_norm": 2.6545896530151367,
      "learning_rate": 0.00018633234292340025,
      "loss": 0.1048,
      "step": 944
    },
    {
      "epoch": 0.0684857049679313,
      "grad_norm": 4.813048362731934,
      "learning_rate": 0.00018631784911950144,
      "loss": 0.2738,
      "step": 945
    },
    {
      "epoch": 0.06855817661340001,
      "grad_norm": 5.713874340057373,
      "learning_rate": 0.0001863033553156026,
      "loss": 0.2176,
      "step": 946
    },
    {
      "epoch": 0.06863064825886872,
      "grad_norm": 5.289563179016113,
      "learning_rate": 0.00018628886151170375,
      "loss": 0.1878,
      "step": 947
    },
    {
      "epoch": 0.06870311990433743,
      "grad_norm": 2.789217233657837,
      "learning_rate": 0.00018627436770780493,
      "loss": 0.1104,
      "step": 948
    },
    {
      "epoch": 0.06877559154980614,
      "grad_norm": 2.2667160034179688,
      "learning_rate": 0.0001862598739039061,
      "loss": 0.1878,
      "step": 949
    },
    {
      "epoch": 0.06884806319527485,
      "grad_norm": 1.6756187677383423,
      "learning_rate": 0.00018624538010000724,
      "loss": 0.082,
      "step": 950
    },
    {
      "epoch": 0.06892053484074356,
      "grad_norm": 3.886936902999878,
      "learning_rate": 0.00018623088629610843,
      "loss": 0.2738,
      "step": 951
    },
    {
      "epoch": 0.06899300648621227,
      "grad_norm": 1.383113980293274,
      "learning_rate": 0.00018621639249220958,
      "loss": 0.0778,
      "step": 952
    },
    {
      "epoch": 0.06906547813168099,
      "grad_norm": 3.1209816932678223,
      "learning_rate": 0.00018620189868831074,
      "loss": 0.1478,
      "step": 953
    },
    {
      "epoch": 0.0691379497771497,
      "grad_norm": 2.5931341648101807,
      "learning_rate": 0.00018618740488441192,
      "loss": 0.1485,
      "step": 954
    },
    {
      "epoch": 0.0692104214226184,
      "grad_norm": 1.6402004957199097,
      "learning_rate": 0.00018617291108051308,
      "loss": 0.1382,
      "step": 955
    },
    {
      "epoch": 0.06928289306808712,
      "grad_norm": 2.7255022525787354,
      "learning_rate": 0.00018615841727661424,
      "loss": 0.1954,
      "step": 956
    },
    {
      "epoch": 0.06935536471355583,
      "grad_norm": 1.9625399112701416,
      "learning_rate": 0.00018614392347271542,
      "loss": 0.1616,
      "step": 957
    },
    {
      "epoch": 0.06942783635902453,
      "grad_norm": 1.958098292350769,
      "learning_rate": 0.00018612942966881658,
      "loss": 0.1232,
      "step": 958
    },
    {
      "epoch": 0.06950030800449324,
      "grad_norm": 0.912196695804596,
      "learning_rate": 0.00018611493586491776,
      "loss": 0.0826,
      "step": 959
    },
    {
      "epoch": 0.06957277964996195,
      "grad_norm": 2.128507137298584,
      "learning_rate": 0.00018610044206101892,
      "loss": 0.1344,
      "step": 960
    },
    {
      "epoch": 0.06964525129543066,
      "grad_norm": 5.376148700714111,
      "learning_rate": 0.0001860859482571201,
      "loss": 0.2465,
      "step": 961
    },
    {
      "epoch": 0.06971772294089937,
      "grad_norm": 2.1780409812927246,
      "learning_rate": 0.00018607145445322126,
      "loss": 0.1493,
      "step": 962
    },
    {
      "epoch": 0.06979019458636808,
      "grad_norm": 5.6864519119262695,
      "learning_rate": 0.00018605696064932244,
      "loss": 0.175,
      "step": 963
    },
    {
      "epoch": 0.06986266623183679,
      "grad_norm": 2.5791234970092773,
      "learning_rate": 0.0001860424668454236,
      "loss": 0.0705,
      "step": 964
    },
    {
      "epoch": 0.0699351378773055,
      "grad_norm": 4.2215142250061035,
      "learning_rate": 0.00018602797304152475,
      "loss": 0.216,
      "step": 965
    },
    {
      "epoch": 0.07000760952277421,
      "grad_norm": 3.402616262435913,
      "learning_rate": 0.00018601347923762594,
      "loss": 0.135,
      "step": 966
    },
    {
      "epoch": 0.07008008116824292,
      "grad_norm": 2.9363276958465576,
      "learning_rate": 0.0001859989854337271,
      "loss": 0.191,
      "step": 967
    },
    {
      "epoch": 0.07015255281371163,
      "grad_norm": 1.217300534248352,
      "learning_rate": 0.00018598449162982825,
      "loss": 0.0734,
      "step": 968
    },
    {
      "epoch": 0.07022502445918034,
      "grad_norm": 2.9164648056030273,
      "learning_rate": 0.00018596999782592943,
      "loss": 0.1129,
      "step": 969
    },
    {
      "epoch": 0.07029749610464905,
      "grad_norm": 2.5338807106018066,
      "learning_rate": 0.0001859555040220306,
      "loss": 0.1838,
      "step": 970
    },
    {
      "epoch": 0.07036996775011777,
      "grad_norm": 3.367873191833496,
      "learning_rate": 0.00018594101021813175,
      "loss": 0.1586,
      "step": 971
    },
    {
      "epoch": 0.07044243939558648,
      "grad_norm": 3.5149500370025635,
      "learning_rate": 0.00018592651641423293,
      "loss": 0.1187,
      "step": 972
    },
    {
      "epoch": 0.07051491104105519,
      "grad_norm": 1.720495581626892,
      "learning_rate": 0.0001859120226103341,
      "loss": 0.1,
      "step": 973
    },
    {
      "epoch": 0.0705873826865239,
      "grad_norm": 1.348616123199463,
      "learning_rate": 0.00018589752880643524,
      "loss": 0.1291,
      "step": 974
    },
    {
      "epoch": 0.07065985433199261,
      "grad_norm": 1.7225927114486694,
      "learning_rate": 0.00018588303500253643,
      "loss": 0.0897,
      "step": 975
    },
    {
      "epoch": 0.07073232597746132,
      "grad_norm": 2.175830364227295,
      "learning_rate": 0.00018586854119863758,
      "loss": 0.0864,
      "step": 976
    },
    {
      "epoch": 0.07080479762293003,
      "grad_norm": 3.0561139583587646,
      "learning_rate": 0.00018585404739473874,
      "loss": 0.0737,
      "step": 977
    },
    {
      "epoch": 0.07087726926839874,
      "grad_norm": 4.52180290222168,
      "learning_rate": 0.00018583955359083992,
      "loss": 0.1991,
      "step": 978
    },
    {
      "epoch": 0.07094974091386745,
      "grad_norm": 1.4700541496276855,
      "learning_rate": 0.00018582505978694108,
      "loss": 0.1535,
      "step": 979
    },
    {
      "epoch": 0.07102221255933616,
      "grad_norm": 4.2761616706848145,
      "learning_rate": 0.00018581056598304224,
      "loss": 0.0954,
      "step": 980
    },
    {
      "epoch": 0.07109468420480487,
      "grad_norm": 5.780806541442871,
      "learning_rate": 0.00018579607217914342,
      "loss": 0.1501,
      "step": 981
    },
    {
      "epoch": 0.07116715585027358,
      "grad_norm": 4.076202869415283,
      "learning_rate": 0.0001857815783752446,
      "loss": 0.1921,
      "step": 982
    },
    {
      "epoch": 0.0712396274957423,
      "grad_norm": 1.7683805227279663,
      "learning_rate": 0.00018576708457134576,
      "loss": 0.0741,
      "step": 983
    },
    {
      "epoch": 0.071312099141211,
      "grad_norm": 2.261464834213257,
      "learning_rate": 0.00018575259076744694,
      "loss": 0.1787,
      "step": 984
    },
    {
      "epoch": 0.07138457078667972,
      "grad_norm": 1.8670473098754883,
      "learning_rate": 0.0001857380969635481,
      "loss": 0.1192,
      "step": 985
    },
    {
      "epoch": 0.07145704243214843,
      "grad_norm": 3.8794925212860107,
      "learning_rate": 0.00018572360315964926,
      "loss": 0.2675,
      "step": 986
    },
    {
      "epoch": 0.07152951407761714,
      "grad_norm": 6.864051818847656,
      "learning_rate": 0.00018570910935575044,
      "loss": 0.313,
      "step": 987
    },
    {
      "epoch": 0.07160198572308585,
      "grad_norm": 8.596863746643066,
      "learning_rate": 0.0001856946155518516,
      "loss": 0.2056,
      "step": 988
    },
    {
      "epoch": 0.07167445736855456,
      "grad_norm": 4.87698221206665,
      "learning_rate": 0.00018568012174795275,
      "loss": 0.1676,
      "step": 989
    },
    {
      "epoch": 0.07174692901402327,
      "grad_norm": 1.9275833368301392,
      "learning_rate": 0.00018566562794405394,
      "loss": 0.0957,
      "step": 990
    },
    {
      "epoch": 0.07181940065949198,
      "grad_norm": 2.0200328826904297,
      "learning_rate": 0.0001856511341401551,
      "loss": 0.0845,
      "step": 991
    },
    {
      "epoch": 0.07189187230496068,
      "grad_norm": 4.229365825653076,
      "learning_rate": 0.00018563664033625625,
      "loss": 0.1276,
      "step": 992
    },
    {
      "epoch": 0.07196434395042939,
      "grad_norm": 4.202759742736816,
      "learning_rate": 0.00018562214653235743,
      "loss": 0.1982,
      "step": 993
    },
    {
      "epoch": 0.0720368155958981,
      "grad_norm": 2.0685272216796875,
      "learning_rate": 0.0001856076527284586,
      "loss": 0.0925,
      "step": 994
    },
    {
      "epoch": 0.07210928724136681,
      "grad_norm": 2.8837900161743164,
      "learning_rate": 0.00018559315892455975,
      "loss": 0.2008,
      "step": 995
    },
    {
      "epoch": 0.07218175888683552,
      "grad_norm": 3.4814908504486084,
      "learning_rate": 0.00018557866512066093,
      "loss": 0.3359,
      "step": 996
    },
    {
      "epoch": 0.07225423053230423,
      "grad_norm": 5.430273532867432,
      "learning_rate": 0.0001855641713167621,
      "loss": 0.2696,
      "step": 997
    },
    {
      "epoch": 0.07232670217777294,
      "grad_norm": 2.295586347579956,
      "learning_rate": 0.00018554967751286324,
      "loss": 0.226,
      "step": 998
    },
    {
      "epoch": 0.07239917382324165,
      "grad_norm": 4.851906776428223,
      "learning_rate": 0.00018553518370896443,
      "loss": 0.0917,
      "step": 999
    },
    {
      "epoch": 0.07247164546871036,
      "grad_norm": 2.1130430698394775,
      "learning_rate": 0.00018552068990506558,
      "loss": 0.1378,
      "step": 1000
    },
    {
      "epoch": 0.07254411711417907,
      "grad_norm": 3.0105698108673096,
      "learning_rate": 0.00018550619610116674,
      "loss": 0.1599,
      "step": 1001
    },
    {
      "epoch": 0.07261658875964778,
      "grad_norm": 2.6104300022125244,
      "learning_rate": 0.00018549170229726792,
      "loss": 0.0798,
      "step": 1002
    },
    {
      "epoch": 0.0726890604051165,
      "grad_norm": 1.3892070055007935,
      "learning_rate": 0.00018547720849336908,
      "loss": 0.0862,
      "step": 1003
    },
    {
      "epoch": 0.0727615320505852,
      "grad_norm": 1.5012632608413696,
      "learning_rate": 0.00018546271468947026,
      "loss": 0.143,
      "step": 1004
    },
    {
      "epoch": 0.07283400369605392,
      "grad_norm": 3.7512660026550293,
      "learning_rate": 0.00018544822088557142,
      "loss": 0.1398,
      "step": 1005
    },
    {
      "epoch": 0.07290647534152263,
      "grad_norm": 1.6790419816970825,
      "learning_rate": 0.0001854337270816726,
      "loss": 0.1012,
      "step": 1006
    },
    {
      "epoch": 0.07297894698699134,
      "grad_norm": 2.1357476711273193,
      "learning_rate": 0.00018541923327777376,
      "loss": 0.1294,
      "step": 1007
    },
    {
      "epoch": 0.07305141863246005,
      "grad_norm": 4.620886325836182,
      "learning_rate": 0.00018540473947387494,
      "loss": 0.1138,
      "step": 1008
    },
    {
      "epoch": 0.07312389027792876,
      "grad_norm": 2.0640766620635986,
      "learning_rate": 0.0001853902456699761,
      "loss": 0.0726,
      "step": 1009
    },
    {
      "epoch": 0.07319636192339747,
      "grad_norm": 2.10082745552063,
      "learning_rate": 0.00018537575186607726,
      "loss": 0.1283,
      "step": 1010
    },
    {
      "epoch": 0.07326883356886618,
      "grad_norm": 2.50791072845459,
      "learning_rate": 0.00018536125806217844,
      "loss": 0.1565,
      "step": 1011
    },
    {
      "epoch": 0.07334130521433489,
      "grad_norm": 2.9436655044555664,
      "learning_rate": 0.0001853467642582796,
      "loss": 0.1994,
      "step": 1012
    },
    {
      "epoch": 0.0734137768598036,
      "grad_norm": 2.202342987060547,
      "learning_rate": 0.00018533227045438075,
      "loss": 0.1272,
      "step": 1013
    },
    {
      "epoch": 0.07348624850527231,
      "grad_norm": 2.9936530590057373,
      "learning_rate": 0.00018531777665048194,
      "loss": 0.2249,
      "step": 1014
    },
    {
      "epoch": 0.07355872015074102,
      "grad_norm": 3.4862799644470215,
      "learning_rate": 0.0001853032828465831,
      "loss": 0.102,
      "step": 1015
    },
    {
      "epoch": 0.07363119179620974,
      "grad_norm": 2.0892460346221924,
      "learning_rate": 0.00018528878904268425,
      "loss": 0.1513,
      "step": 1016
    },
    {
      "epoch": 0.07370366344167845,
      "grad_norm": 4.316091060638428,
      "learning_rate": 0.00018527429523878543,
      "loss": 0.125,
      "step": 1017
    },
    {
      "epoch": 0.07377613508714716,
      "grad_norm": 2.008920431137085,
      "learning_rate": 0.0001852598014348866,
      "loss": 0.1921,
      "step": 1018
    },
    {
      "epoch": 0.07384860673261587,
      "grad_norm": 3.139017343521118,
      "learning_rate": 0.00018524530763098775,
      "loss": 0.1844,
      "step": 1019
    },
    {
      "epoch": 0.07392107837808458,
      "grad_norm": 2.1915388107299805,
      "learning_rate": 0.00018523081382708893,
      "loss": 0.1258,
      "step": 1020
    },
    {
      "epoch": 0.07399355002355329,
      "grad_norm": 3.187626361846924,
      "learning_rate": 0.0001852163200231901,
      "loss": 0.1372,
      "step": 1021
    },
    {
      "epoch": 0.074066021669022,
      "grad_norm": 3.8529372215270996,
      "learning_rate": 0.00018520182621929124,
      "loss": 0.2251,
      "step": 1022
    },
    {
      "epoch": 0.07413849331449071,
      "grad_norm": 2.9976019859313965,
      "learning_rate": 0.00018518733241539243,
      "loss": 0.1151,
      "step": 1023
    },
    {
      "epoch": 0.07421096495995942,
      "grad_norm": 1.4454398155212402,
      "learning_rate": 0.00018517283861149358,
      "loss": 0.1595,
      "step": 1024
    },
    {
      "epoch": 0.07428343660542813,
      "grad_norm": 2.030745506286621,
      "learning_rate": 0.00018515834480759474,
      "loss": 0.1307,
      "step": 1025
    },
    {
      "epoch": 0.07435590825089684,
      "grad_norm": 1.63314950466156,
      "learning_rate": 0.00018514385100369592,
      "loss": 0.0612,
      "step": 1026
    },
    {
      "epoch": 0.07442837989636554,
      "grad_norm": 3.977020025253296,
      "learning_rate": 0.00018512935719979708,
      "loss": 0.1119,
      "step": 1027
    },
    {
      "epoch": 0.07450085154183425,
      "grad_norm": 2.5272371768951416,
      "learning_rate": 0.00018511486339589826,
      "loss": 0.2287,
      "step": 1028
    },
    {
      "epoch": 0.07457332318730296,
      "grad_norm": 4.649463653564453,
      "learning_rate": 0.00018510036959199945,
      "loss": 0.2081,
      "step": 1029
    },
    {
      "epoch": 0.07464579483277167,
      "grad_norm": 3.8729043006896973,
      "learning_rate": 0.0001850858757881006,
      "loss": 0.2004,
      "step": 1030
    },
    {
      "epoch": 0.07471826647824038,
      "grad_norm": 6.027731895446777,
      "learning_rate": 0.00018507138198420176,
      "loss": 0.3584,
      "step": 1031
    },
    {
      "epoch": 0.0747907381237091,
      "grad_norm": 3.9691014289855957,
      "learning_rate": 0.00018505688818030294,
      "loss": 0.3284,
      "step": 1032
    },
    {
      "epoch": 0.0748632097691778,
      "grad_norm": 3.1288018226623535,
      "learning_rate": 0.0001850423943764041,
      "loss": 0.1601,
      "step": 1033
    },
    {
      "epoch": 0.07493568141464652,
      "grad_norm": 2.3722681999206543,
      "learning_rate": 0.00018502790057250526,
      "loss": 0.1256,
      "step": 1034
    },
    {
      "epoch": 0.07500815306011523,
      "grad_norm": 2.367415189743042,
      "learning_rate": 0.00018501340676860644,
      "loss": 0.1672,
      "step": 1035
    },
    {
      "epoch": 0.07508062470558394,
      "grad_norm": 3.046142578125,
      "learning_rate": 0.0001849989129647076,
      "loss": 0.111,
      "step": 1036
    },
    {
      "epoch": 0.07515309635105265,
      "grad_norm": 3.0520734786987305,
      "learning_rate": 0.00018498441916080875,
      "loss": 0.2549,
      "step": 1037
    },
    {
      "epoch": 0.07522556799652136,
      "grad_norm": 2.8382527828216553,
      "learning_rate": 0.00018496992535690994,
      "loss": 0.1437,
      "step": 1038
    },
    {
      "epoch": 0.07529803964199007,
      "grad_norm": 0.8894267082214355,
      "learning_rate": 0.0001849554315530111,
      "loss": 0.0515,
      "step": 1039
    },
    {
      "epoch": 0.07537051128745878,
      "grad_norm": 3.68644642829895,
      "learning_rate": 0.00018494093774911225,
      "loss": 0.1684,
      "step": 1040
    },
    {
      "epoch": 0.07544298293292749,
      "grad_norm": 2.7919986248016357,
      "learning_rate": 0.00018492644394521343,
      "loss": 0.1211,
      "step": 1041
    },
    {
      "epoch": 0.0755154545783962,
      "grad_norm": 2.672964096069336,
      "learning_rate": 0.0001849119501413146,
      "loss": 0.0903,
      "step": 1042
    },
    {
      "epoch": 0.07558792622386491,
      "grad_norm": 2.6445729732513428,
      "learning_rate": 0.00018489745633741575,
      "loss": 0.2326,
      "step": 1043
    },
    {
      "epoch": 0.07566039786933362,
      "grad_norm": 5.692190647125244,
      "learning_rate": 0.00018488296253351693,
      "loss": 0.1385,
      "step": 1044
    },
    {
      "epoch": 0.07573286951480233,
      "grad_norm": 1.7777302265167236,
      "learning_rate": 0.0001848684687296181,
      "loss": 0.0835,
      "step": 1045
    },
    {
      "epoch": 0.07580534116027104,
      "grad_norm": 3.245624303817749,
      "learning_rate": 0.00018485397492571924,
      "loss": 0.1046,
      "step": 1046
    },
    {
      "epoch": 0.07587781280573976,
      "grad_norm": 6.184046745300293,
      "learning_rate": 0.00018483948112182043,
      "loss": 0.1663,
      "step": 1047
    },
    {
      "epoch": 0.07595028445120847,
      "grad_norm": 2.6441187858581543,
      "learning_rate": 0.00018482498731792158,
      "loss": 0.1458,
      "step": 1048
    },
    {
      "epoch": 0.07602275609667718,
      "grad_norm": 4.310268402099609,
      "learning_rate": 0.00018481049351402277,
      "loss": 0.2477,
      "step": 1049
    },
    {
      "epoch": 0.07609522774214589,
      "grad_norm": 1.6616460084915161,
      "learning_rate": 0.00018479599971012392,
      "loss": 0.0635,
      "step": 1050
    },
    {
      "epoch": 0.0761676993876146,
      "grad_norm": 1.5124245882034302,
      "learning_rate": 0.0001847815059062251,
      "loss": 0.1643,
      "step": 1051
    },
    {
      "epoch": 0.07624017103308331,
      "grad_norm": 2.774484395980835,
      "learning_rate": 0.00018476701210232626,
      "loss": 0.123,
      "step": 1052
    },
    {
      "epoch": 0.07631264267855202,
      "grad_norm": 2.9470701217651367,
      "learning_rate": 0.00018475251829842745,
      "loss": 0.054,
      "step": 1053
    },
    {
      "epoch": 0.07638511432402073,
      "grad_norm": 7.040788650512695,
      "learning_rate": 0.0001847380244945286,
      "loss": 0.2164,
      "step": 1054
    },
    {
      "epoch": 0.07645758596948944,
      "grad_norm": 4.094529151916504,
      "learning_rate": 0.00018472353069062976,
      "loss": 0.1828,
      "step": 1055
    },
    {
      "epoch": 0.07653005761495815,
      "grad_norm": 2.3084678649902344,
      "learning_rate": 0.00018470903688673094,
      "loss": 0.169,
      "step": 1056
    },
    {
      "epoch": 0.07660252926042686,
      "grad_norm": 4.341390132904053,
      "learning_rate": 0.0001846945430828321,
      "loss": 0.1494,
      "step": 1057
    },
    {
      "epoch": 0.07667500090589557,
      "grad_norm": 2.850435495376587,
      "learning_rate": 0.00018468004927893328,
      "loss": 0.1339,
      "step": 1058
    },
    {
      "epoch": 0.07674747255136428,
      "grad_norm": 4.04719352722168,
      "learning_rate": 0.00018466555547503444,
      "loss": 0.1982,
      "step": 1059
    },
    {
      "epoch": 0.076819944196833,
      "grad_norm": 2.72639799118042,
      "learning_rate": 0.0001846510616711356,
      "loss": 0.1257,
      "step": 1060
    },
    {
      "epoch": 0.0768924158423017,
      "grad_norm": 4.30183219909668,
      "learning_rate": 0.00018463656786723678,
      "loss": 0.3135,
      "step": 1061
    },
    {
      "epoch": 0.0769648874877704,
      "grad_norm": 5.664052963256836,
      "learning_rate": 0.00018462207406333794,
      "loss": 0.0519,
      "step": 1062
    },
    {
      "epoch": 0.07703735913323911,
      "grad_norm": 2.8566131591796875,
      "learning_rate": 0.0001846075802594391,
      "loss": 0.0941,
      "step": 1063
    },
    {
      "epoch": 0.07710983077870782,
      "grad_norm": 5.37624979019165,
      "learning_rate": 0.00018459308645554028,
      "loss": 0.0823,
      "step": 1064
    },
    {
      "epoch": 0.07718230242417654,
      "grad_norm": 6.405955791473389,
      "learning_rate": 0.00018457859265164143,
      "loss": 0.241,
      "step": 1065
    },
    {
      "epoch": 0.07725477406964525,
      "grad_norm": 2.367316961288452,
      "learning_rate": 0.0001845640988477426,
      "loss": 0.1381,
      "step": 1066
    },
    {
      "epoch": 0.07732724571511396,
      "grad_norm": 2.097479820251465,
      "learning_rate": 0.00018454960504384377,
      "loss": 0.1445,
      "step": 1067
    },
    {
      "epoch": 0.07739971736058267,
      "grad_norm": 0.9225329160690308,
      "learning_rate": 0.00018453511123994493,
      "loss": 0.0438,
      "step": 1068
    },
    {
      "epoch": 0.07747218900605138,
      "grad_norm": 2.11698579788208,
      "learning_rate": 0.00018452061743604609,
      "loss": 0.0628,
      "step": 1069
    },
    {
      "epoch": 0.07754466065152009,
      "grad_norm": 1.93531334400177,
      "learning_rate": 0.00018450612363214727,
      "loss": 0.104,
      "step": 1070
    },
    {
      "epoch": 0.0776171322969888,
      "grad_norm": 2.7783045768737793,
      "learning_rate": 0.00018449162982824843,
      "loss": 0.124,
      "step": 1071
    },
    {
      "epoch": 0.07768960394245751,
      "grad_norm": 5.678423881530762,
      "learning_rate": 0.00018447713602434958,
      "loss": 0.2969,
      "step": 1072
    },
    {
      "epoch": 0.07776207558792622,
      "grad_norm": 2.3396811485290527,
      "learning_rate": 0.00018446264222045077,
      "loss": 0.095,
      "step": 1073
    },
    {
      "epoch": 0.07783454723339493,
      "grad_norm": 1.4465172290802002,
      "learning_rate": 0.00018444814841655192,
      "loss": 0.0688,
      "step": 1074
    },
    {
      "epoch": 0.07790701887886364,
      "grad_norm": 3.462634325027466,
      "learning_rate": 0.0001844336546126531,
      "loss": 0.1684,
      "step": 1075
    },
    {
      "epoch": 0.07797949052433235,
      "grad_norm": 6.9836812019348145,
      "learning_rate": 0.0001844191608087543,
      "loss": 0.1913,
      "step": 1076
    },
    {
      "epoch": 0.07805196216980106,
      "grad_norm": 4.789581298828125,
      "learning_rate": 0.00018440466700485545,
      "loss": 0.3461,
      "step": 1077
    },
    {
      "epoch": 0.07812443381526978,
      "grad_norm": 4.376290798187256,
      "learning_rate": 0.0001843901732009566,
      "loss": 0.1414,
      "step": 1078
    },
    {
      "epoch": 0.07819690546073849,
      "grad_norm": 3.8219661712646484,
      "learning_rate": 0.0001843756793970578,
      "loss": 0.2165,
      "step": 1079
    },
    {
      "epoch": 0.0782693771062072,
      "grad_norm": 1.4484877586364746,
      "learning_rate": 0.00018436118559315894,
      "loss": 0.083,
      "step": 1080
    },
    {
      "epoch": 0.07834184875167591,
      "grad_norm": 2.4861013889312744,
      "learning_rate": 0.0001843466917892601,
      "loss": 0.1507,
      "step": 1081
    },
    {
      "epoch": 0.07841432039714462,
      "grad_norm": 4.428091049194336,
      "learning_rate": 0.00018433219798536128,
      "loss": 0.1762,
      "step": 1082
    },
    {
      "epoch": 0.07848679204261333,
      "grad_norm": 3.6809136867523193,
      "learning_rate": 0.00018431770418146244,
      "loss": 0.3014,
      "step": 1083
    },
    {
      "epoch": 0.07855926368808204,
      "grad_norm": 1.264884114265442,
      "learning_rate": 0.0001843032103775636,
      "loss": 0.083,
      "step": 1084
    },
    {
      "epoch": 0.07863173533355075,
      "grad_norm": 1.620019793510437,
      "learning_rate": 0.00018428871657366478,
      "loss": 0.1248,
      "step": 1085
    },
    {
      "epoch": 0.07870420697901946,
      "grad_norm": 6.2889180183410645,
      "learning_rate": 0.00018427422276976594,
      "loss": 0.1755,
      "step": 1086
    },
    {
      "epoch": 0.07877667862448817,
      "grad_norm": 2.5177927017211914,
      "learning_rate": 0.0001842597289658671,
      "loss": 0.1519,
      "step": 1087
    },
    {
      "epoch": 0.07884915026995688,
      "grad_norm": 1.7735546827316284,
      "learning_rate": 0.00018424523516196828,
      "loss": 0.1361,
      "step": 1088
    },
    {
      "epoch": 0.0789216219154256,
      "grad_norm": 1.8215469121932983,
      "learning_rate": 0.00018423074135806943,
      "loss": 0.1117,
      "step": 1089
    },
    {
      "epoch": 0.0789940935608943,
      "grad_norm": 4.29874849319458,
      "learning_rate": 0.0001842162475541706,
      "loss": 0.2124,
      "step": 1090
    },
    {
      "epoch": 0.07906656520636302,
      "grad_norm": 1.5907834768295288,
      "learning_rate": 0.00018420175375027177,
      "loss": 0.1604,
      "step": 1091
    },
    {
      "epoch": 0.07913903685183173,
      "grad_norm": 3.02394437789917,
      "learning_rate": 0.00018418725994637293,
      "loss": 0.1987,
      "step": 1092
    },
    {
      "epoch": 0.07921150849730044,
      "grad_norm": 2.7174479961395264,
      "learning_rate": 0.00018417276614247409,
      "loss": 0.1611,
      "step": 1093
    },
    {
      "epoch": 0.07928398014276915,
      "grad_norm": 2.137721300125122,
      "learning_rate": 0.00018415827233857527,
      "loss": 0.1284,
      "step": 1094
    },
    {
      "epoch": 0.07935645178823786,
      "grad_norm": 2.9907684326171875,
      "learning_rate": 0.00018414377853467643,
      "loss": 0.1753,
      "step": 1095
    },
    {
      "epoch": 0.07942892343370657,
      "grad_norm": 5.035921573638916,
      "learning_rate": 0.00018412928473077758,
      "loss": 0.0899,
      "step": 1096
    },
    {
      "epoch": 0.07950139507917527,
      "grad_norm": 3.1174070835113525,
      "learning_rate": 0.00018411479092687877,
      "loss": 0.1262,
      "step": 1097
    },
    {
      "epoch": 0.07957386672464398,
      "grad_norm": 1.3813657760620117,
      "learning_rate": 0.00018410029712297995,
      "loss": 0.1127,
      "step": 1098
    },
    {
      "epoch": 0.07964633837011269,
      "grad_norm": 2.9690325260162354,
      "learning_rate": 0.0001840858033190811,
      "loss": 0.096,
      "step": 1099
    },
    {
      "epoch": 0.0797188100155814,
      "grad_norm": 6.653005123138428,
      "learning_rate": 0.0001840713095151823,
      "loss": 0.149,
      "step": 1100
    },
    {
      "epoch": 0.07979128166105011,
      "grad_norm": 4.34695291519165,
      "learning_rate": 0.00018405681571128345,
      "loss": 0.4575,
      "step": 1101
    },
    {
      "epoch": 0.07986375330651882,
      "grad_norm": 4.660795211791992,
      "learning_rate": 0.0001840423219073846,
      "loss": 0.171,
      "step": 1102
    },
    {
      "epoch": 0.07993622495198753,
      "grad_norm": 4.295345306396484,
      "learning_rate": 0.00018402782810348579,
      "loss": 0.1152,
      "step": 1103
    },
    {
      "epoch": 0.08000869659745624,
      "grad_norm": 3.7535581588745117,
      "learning_rate": 0.00018401333429958694,
      "loss": 0.1654,
      "step": 1104
    },
    {
      "epoch": 0.08008116824292495,
      "grad_norm": 4.000245571136475,
      "learning_rate": 0.0001839988404956881,
      "loss": 0.1772,
      "step": 1105
    },
    {
      "epoch": 0.08015363988839366,
      "grad_norm": 4.561868667602539,
      "learning_rate": 0.00018398434669178928,
      "loss": 0.1403,
      "step": 1106
    },
    {
      "epoch": 0.08022611153386237,
      "grad_norm": 1.1122462749481201,
      "learning_rate": 0.00018396985288789044,
      "loss": 0.1031,
      "step": 1107
    },
    {
      "epoch": 0.08029858317933108,
      "grad_norm": 1.5216026306152344,
      "learning_rate": 0.0001839553590839916,
      "loss": 0.1082,
      "step": 1108
    },
    {
      "epoch": 0.0803710548247998,
      "grad_norm": 3.552633047103882,
      "learning_rate": 0.00018394086528009278,
      "loss": 0.1785,
      "step": 1109
    },
    {
      "epoch": 0.0804435264702685,
      "grad_norm": 4.263783931732178,
      "learning_rate": 0.00018392637147619394,
      "loss": 0.1725,
      "step": 1110
    },
    {
      "epoch": 0.08051599811573722,
      "grad_norm": 4.201430320739746,
      "learning_rate": 0.0001839118776722951,
      "loss": 0.0754,
      "step": 1111
    },
    {
      "epoch": 0.08058846976120593,
      "grad_norm": 1.7387089729309082,
      "learning_rate": 0.00018389738386839628,
      "loss": 0.1253,
      "step": 1112
    },
    {
      "epoch": 0.08066094140667464,
      "grad_norm": 3.7715020179748535,
      "learning_rate": 0.00018388289006449743,
      "loss": 0.1802,
      "step": 1113
    },
    {
      "epoch": 0.08073341305214335,
      "grad_norm": 2.914642095565796,
      "learning_rate": 0.0001838683962605986,
      "loss": 0.1345,
      "step": 1114
    },
    {
      "epoch": 0.08080588469761206,
      "grad_norm": 3.3695316314697266,
      "learning_rate": 0.00018385390245669977,
      "loss": 0.2012,
      "step": 1115
    },
    {
      "epoch": 0.08087835634308077,
      "grad_norm": 4.228922367095947,
      "learning_rate": 0.00018383940865280093,
      "loss": 0.2591,
      "step": 1116
    },
    {
      "epoch": 0.08095082798854948,
      "grad_norm": 1.713046669960022,
      "learning_rate": 0.00018382491484890209,
      "loss": 0.1229,
      "step": 1117
    },
    {
      "epoch": 0.08102329963401819,
      "grad_norm": 3.816636323928833,
      "learning_rate": 0.00018381042104500327,
      "loss": 0.187,
      "step": 1118
    },
    {
      "epoch": 0.0810957712794869,
      "grad_norm": 1.5166138410568237,
      "learning_rate": 0.00018379592724110443,
      "loss": 0.136,
      "step": 1119
    },
    {
      "epoch": 0.08116824292495561,
      "grad_norm": 2.638364553451538,
      "learning_rate": 0.0001837814334372056,
      "loss": 0.1358,
      "step": 1120
    },
    {
      "epoch": 0.08124071457042432,
      "grad_norm": 2.2190470695495605,
      "learning_rate": 0.00018376693963330677,
      "loss": 0.0873,
      "step": 1121
    },
    {
      "epoch": 0.08131318621589304,
      "grad_norm": 3.7312357425689697,
      "learning_rate": 0.00018375244582940795,
      "loss": 0.1539,
      "step": 1122
    },
    {
      "epoch": 0.08138565786136175,
      "grad_norm": 2.133699893951416,
      "learning_rate": 0.0001837379520255091,
      "loss": 0.1133,
      "step": 1123
    },
    {
      "epoch": 0.08145812950683046,
      "grad_norm": 2.0802252292633057,
      "learning_rate": 0.0001837234582216103,
      "loss": 0.1513,
      "step": 1124
    },
    {
      "epoch": 0.08153060115229917,
      "grad_norm": 1.2386009693145752,
      "learning_rate": 0.00018370896441771145,
      "loss": 0.0324,
      "step": 1125
    },
    {
      "epoch": 0.08160307279776788,
      "grad_norm": 3.1790497303009033,
      "learning_rate": 0.0001836944706138126,
      "loss": 0.1236,
      "step": 1126
    },
    {
      "epoch": 0.08167554444323659,
      "grad_norm": 4.365001201629639,
      "learning_rate": 0.00018367997680991379,
      "loss": 0.1487,
      "step": 1127
    },
    {
      "epoch": 0.0817480160887053,
      "grad_norm": 2.2181851863861084,
      "learning_rate": 0.00018366548300601494,
      "loss": 0.1754,
      "step": 1128
    },
    {
      "epoch": 0.08182048773417401,
      "grad_norm": 1.4365683794021606,
      "learning_rate": 0.0001836509892021161,
      "loss": 0.0654,
      "step": 1129
    },
    {
      "epoch": 0.08189295937964272,
      "grad_norm": 2.1424052715301514,
      "learning_rate": 0.00018363649539821728,
      "loss": 0.1525,
      "step": 1130
    },
    {
      "epoch": 0.08196543102511143,
      "grad_norm": 3.073591709136963,
      "learning_rate": 0.00018362200159431844,
      "loss": 0.1162,
      "step": 1131
    },
    {
      "epoch": 0.08203790267058013,
      "grad_norm": 4.286574840545654,
      "learning_rate": 0.0001836075077904196,
      "loss": 0.1588,
      "step": 1132
    },
    {
      "epoch": 0.08211037431604884,
      "grad_norm": 1.7230329513549805,
      "learning_rate": 0.00018359301398652078,
      "loss": 0.1044,
      "step": 1133
    },
    {
      "epoch": 0.08218284596151755,
      "grad_norm": 1.476057767868042,
      "learning_rate": 0.00018357852018262194,
      "loss": 0.0594,
      "step": 1134
    },
    {
      "epoch": 0.08225531760698626,
      "grad_norm": 3.8191540241241455,
      "learning_rate": 0.0001835640263787231,
      "loss": 0.1372,
      "step": 1135
    },
    {
      "epoch": 0.08232778925245497,
      "grad_norm": 2.2092630863189697,
      "learning_rate": 0.00018354953257482428,
      "loss": 0.1387,
      "step": 1136
    },
    {
      "epoch": 0.08240026089792368,
      "grad_norm": 3.9884583950042725,
      "learning_rate": 0.00018353503877092543,
      "loss": 0.1537,
      "step": 1137
    },
    {
      "epoch": 0.0824727325433924,
      "grad_norm": 3.2961244583129883,
      "learning_rate": 0.0001835205449670266,
      "loss": 0.1432,
      "step": 1138
    },
    {
      "epoch": 0.0825452041888611,
      "grad_norm": 2.0734927654266357,
      "learning_rate": 0.00018350605116312777,
      "loss": 0.1008,
      "step": 1139
    },
    {
      "epoch": 0.08261767583432982,
      "grad_norm": 1.5707521438598633,
      "learning_rate": 0.00018349155735922893,
      "loss": 0.0763,
      "step": 1140
    },
    {
      "epoch": 0.08269014747979853,
      "grad_norm": 7.773425579071045,
      "learning_rate": 0.00018347706355533009,
      "loss": 0.1437,
      "step": 1141
    },
    {
      "epoch": 0.08276261912526724,
      "grad_norm": 3.64573335647583,
      "learning_rate": 0.00018346256975143127,
      "loss": 0.0707,
      "step": 1142
    },
    {
      "epoch": 0.08283509077073595,
      "grad_norm": 2.5814080238342285,
      "learning_rate": 0.00018344807594753243,
      "loss": 0.0434,
      "step": 1143
    },
    {
      "epoch": 0.08290756241620466,
      "grad_norm": 13.196320533752441,
      "learning_rate": 0.0001834335821436336,
      "loss": 0.2663,
      "step": 1144
    },
    {
      "epoch": 0.08298003406167337,
      "grad_norm": 4.033727645874023,
      "learning_rate": 0.0001834190883397348,
      "loss": 0.2819,
      "step": 1145
    },
    {
      "epoch": 0.08305250570714208,
      "grad_norm": 5.754244804382324,
      "learning_rate": 0.00018340459453583595,
      "loss": 0.3764,
      "step": 1146
    },
    {
      "epoch": 0.08312497735261079,
      "grad_norm": 3.530261754989624,
      "learning_rate": 0.0001833901007319371,
      "loss": 0.2,
      "step": 1147
    },
    {
      "epoch": 0.0831974489980795,
      "grad_norm": 1.9516751766204834,
      "learning_rate": 0.0001833756069280383,
      "loss": 0.1385,
      "step": 1148
    },
    {
      "epoch": 0.08326992064354821,
      "grad_norm": 2.320873260498047,
      "learning_rate": 0.00018336111312413945,
      "loss": 0.1278,
      "step": 1149
    },
    {
      "epoch": 0.08334239228901692,
      "grad_norm": 2.006740093231201,
      "learning_rate": 0.0001833466193202406,
      "loss": 0.1123,
      "step": 1150
    },
    {
      "epoch": 0.08341486393448563,
      "grad_norm": 1.2984775304794312,
      "learning_rate": 0.00018333212551634179,
      "loss": 0.0863,
      "step": 1151
    },
    {
      "epoch": 0.08348733557995434,
      "grad_norm": 2.6373188495635986,
      "learning_rate": 0.00018331763171244294,
      "loss": 0.1175,
      "step": 1152
    },
    {
      "epoch": 0.08355980722542306,
      "grad_norm": 6.039948463439941,
      "learning_rate": 0.0001833031379085441,
      "loss": 0.1782,
      "step": 1153
    },
    {
      "epoch": 0.08363227887089177,
      "grad_norm": 1.5467201471328735,
      "learning_rate": 0.00018328864410464528,
      "loss": 0.0833,
      "step": 1154
    },
    {
      "epoch": 0.08370475051636048,
      "grad_norm": 3.8139824867248535,
      "learning_rate": 0.00018327415030074644,
      "loss": 0.1513,
      "step": 1155
    },
    {
      "epoch": 0.08377722216182919,
      "grad_norm": 1.1758558750152588,
      "learning_rate": 0.0001832596564968476,
      "loss": 0.0879,
      "step": 1156
    },
    {
      "epoch": 0.0838496938072979,
      "grad_norm": 2.212646961212158,
      "learning_rate": 0.00018324516269294878,
      "loss": 0.1077,
      "step": 1157
    },
    {
      "epoch": 0.08392216545276661,
      "grad_norm": 3.4412343502044678,
      "learning_rate": 0.00018323066888904993,
      "loss": 0.1295,
      "step": 1158
    },
    {
      "epoch": 0.08399463709823532,
      "grad_norm": 2.7239086627960205,
      "learning_rate": 0.0001832161750851511,
      "loss": 0.0489,
      "step": 1159
    },
    {
      "epoch": 0.08406710874370403,
      "grad_norm": 2.618150234222412,
      "learning_rate": 0.00018320168128125228,
      "loss": 0.2433,
      "step": 1160
    },
    {
      "epoch": 0.08413958038917274,
      "grad_norm": 2.004053831100464,
      "learning_rate": 0.00018318718747735343,
      "loss": 0.0938,
      "step": 1161
    },
    {
      "epoch": 0.08421205203464145,
      "grad_norm": 2.670933246612549,
      "learning_rate": 0.0001831726936734546,
      "loss": 0.1772,
      "step": 1162
    },
    {
      "epoch": 0.08428452368011016,
      "grad_norm": 1.8180367946624756,
      "learning_rate": 0.00018315819986955577,
      "loss": 0.123,
      "step": 1163
    },
    {
      "epoch": 0.08435699532557887,
      "grad_norm": 4.107572555541992,
      "learning_rate": 0.00018314370606565693,
      "loss": 0.1198,
      "step": 1164
    },
    {
      "epoch": 0.08442946697104758,
      "grad_norm": 1.1883896589279175,
      "learning_rate": 0.0001831292122617581,
      "loss": 0.0818,
      "step": 1165
    },
    {
      "epoch": 0.08450193861651628,
      "grad_norm": 1.0991641283035278,
      "learning_rate": 0.00018311471845785927,
      "loss": 0.0557,
      "step": 1166
    },
    {
      "epoch": 0.08457441026198499,
      "grad_norm": 2.7120814323425293,
      "learning_rate": 0.00018310022465396045,
      "loss": 0.0781,
      "step": 1167
    },
    {
      "epoch": 0.0846468819074537,
      "grad_norm": 1.9614055156707764,
      "learning_rate": 0.0001830857308500616,
      "loss": 0.1786,
      "step": 1168
    },
    {
      "epoch": 0.08471935355292241,
      "grad_norm": 2.8798491954803467,
      "learning_rate": 0.0001830712370461628,
      "loss": 0.1118,
      "step": 1169
    },
    {
      "epoch": 0.08479182519839112,
      "grad_norm": 0.7006492614746094,
      "learning_rate": 0.00018305674324226395,
      "loss": 0.031,
      "step": 1170
    },
    {
      "epoch": 0.08486429684385983,
      "grad_norm": 4.5554094314575195,
      "learning_rate": 0.0001830422494383651,
      "loss": 0.2665,
      "step": 1171
    },
    {
      "epoch": 0.08493676848932855,
      "grad_norm": 4.958590984344482,
      "learning_rate": 0.0001830277556344663,
      "loss": 0.1343,
      "step": 1172
    },
    {
      "epoch": 0.08500924013479726,
      "grad_norm": 2.389739751815796,
      "learning_rate": 0.00018301326183056744,
      "loss": 0.1232,
      "step": 1173
    },
    {
      "epoch": 0.08508171178026597,
      "grad_norm": 1.3210426568984985,
      "learning_rate": 0.0001829987680266686,
      "loss": 0.0412,
      "step": 1174
    },
    {
      "epoch": 0.08515418342573468,
      "grad_norm": 1.7801202535629272,
      "learning_rate": 0.00018298427422276978,
      "loss": 0.111,
      "step": 1175
    },
    {
      "epoch": 0.08522665507120339,
      "grad_norm": 0.9553307294845581,
      "learning_rate": 0.00018296978041887094,
      "loss": 0.0927,
      "step": 1176
    },
    {
      "epoch": 0.0852991267166721,
      "grad_norm": 1.9126384258270264,
      "learning_rate": 0.0001829552866149721,
      "loss": 0.0705,
      "step": 1177
    },
    {
      "epoch": 0.08537159836214081,
      "grad_norm": 2.4514992237091064,
      "learning_rate": 0.00018294079281107328,
      "loss": 0.0858,
      "step": 1178
    },
    {
      "epoch": 0.08544407000760952,
      "grad_norm": 3.021411418914795,
      "learning_rate": 0.00018292629900717444,
      "loss": 0.1757,
      "step": 1179
    },
    {
      "epoch": 0.08551654165307823,
      "grad_norm": 3.109703779220581,
      "learning_rate": 0.0001829118052032756,
      "loss": 0.2088,
      "step": 1180
    },
    {
      "epoch": 0.08558901329854694,
      "grad_norm": 2.04329514503479,
      "learning_rate": 0.00018289731139937678,
      "loss": 0.1152,
      "step": 1181
    },
    {
      "epoch": 0.08566148494401565,
      "grad_norm": 1.764296293258667,
      "learning_rate": 0.00018288281759547793,
      "loss": 0.1481,
      "step": 1182
    },
    {
      "epoch": 0.08573395658948436,
      "grad_norm": 3.990553379058838,
      "learning_rate": 0.0001828683237915791,
      "loss": 0.1703,
      "step": 1183
    },
    {
      "epoch": 0.08580642823495307,
      "grad_norm": 3.499950408935547,
      "learning_rate": 0.00018285382998768027,
      "loss": 0.1825,
      "step": 1184
    },
    {
      "epoch": 0.08587889988042179,
      "grad_norm": 0.9144764542579651,
      "learning_rate": 0.00018283933618378143,
      "loss": 0.0359,
      "step": 1185
    },
    {
      "epoch": 0.0859513715258905,
      "grad_norm": 2.7379376888275146,
      "learning_rate": 0.0001828248423798826,
      "loss": 0.1095,
      "step": 1186
    },
    {
      "epoch": 0.08602384317135921,
      "grad_norm": 1.7050726413726807,
      "learning_rate": 0.00018281034857598377,
      "loss": 0.0665,
      "step": 1187
    },
    {
      "epoch": 0.08609631481682792,
      "grad_norm": 3.187730550765991,
      "learning_rate": 0.00018279585477208493,
      "loss": 0.3062,
      "step": 1188
    },
    {
      "epoch": 0.08616878646229663,
      "grad_norm": 2.3071541786193848,
      "learning_rate": 0.0001827813609681861,
      "loss": 0.1537,
      "step": 1189
    },
    {
      "epoch": 0.08624125810776534,
      "grad_norm": 0.962233304977417,
      "learning_rate": 0.00018276686716428727,
      "loss": 0.0572,
      "step": 1190
    },
    {
      "epoch": 0.08631372975323405,
      "grad_norm": 0.685123860836029,
      "learning_rate": 0.00018275237336038845,
      "loss": 0.0257,
      "step": 1191
    },
    {
      "epoch": 0.08638620139870276,
      "grad_norm": 6.5804829597473145,
      "learning_rate": 0.0001827378795564896,
      "loss": 0.1715,
      "step": 1192
    },
    {
      "epoch": 0.08645867304417147,
      "grad_norm": 3.5092782974243164,
      "learning_rate": 0.0001827233857525908,
      "loss": 0.1459,
      "step": 1193
    },
    {
      "epoch": 0.08653114468964018,
      "grad_norm": 1.7148441076278687,
      "learning_rate": 0.00018270889194869195,
      "loss": 0.0667,
      "step": 1194
    },
    {
      "epoch": 0.0866036163351089,
      "grad_norm": 3.0714004039764404,
      "learning_rate": 0.0001826943981447931,
      "loss": 0.0854,
      "step": 1195
    },
    {
      "epoch": 0.0866760879805776,
      "grad_norm": 3.3522729873657227,
      "learning_rate": 0.0001826799043408943,
      "loss": 0.1558,
      "step": 1196
    },
    {
      "epoch": 0.08674855962604631,
      "grad_norm": 2.278970718383789,
      "learning_rate": 0.00018266541053699544,
      "loss": 0.0535,
      "step": 1197
    },
    {
      "epoch": 0.08682103127151503,
      "grad_norm": 2.8669559955596924,
      "learning_rate": 0.0001826509167330966,
      "loss": 0.1385,
      "step": 1198
    },
    {
      "epoch": 0.08689350291698374,
      "grad_norm": 2.6919257640838623,
      "learning_rate": 0.00018263642292919778,
      "loss": 0.1349,
      "step": 1199
    },
    {
      "epoch": 0.08696597456245245,
      "grad_norm": 3.5050899982452393,
      "learning_rate": 0.00018262192912529894,
      "loss": 0.1153,
      "step": 1200
    },
    {
      "epoch": 0.08703844620792114,
      "grad_norm": 1.417089819908142,
      "learning_rate": 0.0001826074353214001,
      "loss": 0.1111,
      "step": 1201
    },
    {
      "epoch": 0.08711091785338985,
      "grad_norm": 1.1630922555923462,
      "learning_rate": 0.00018259294151750128,
      "loss": 0.068,
      "step": 1202
    },
    {
      "epoch": 0.08718338949885857,
      "grad_norm": 1.948704481124878,
      "learning_rate": 0.00018257844771360244,
      "loss": 0.087,
      "step": 1203
    },
    {
      "epoch": 0.08725586114432728,
      "grad_norm": 2.7375423908233643,
      "learning_rate": 0.0001825639539097036,
      "loss": 0.1254,
      "step": 1204
    },
    {
      "epoch": 0.08732833278979599,
      "grad_norm": 2.0910024642944336,
      "learning_rate": 0.00018254946010580478,
      "loss": 0.0757,
      "step": 1205
    },
    {
      "epoch": 0.0874008044352647,
      "grad_norm": 3.1029930114746094,
      "learning_rate": 0.00018253496630190593,
      "loss": 0.0943,
      "step": 1206
    },
    {
      "epoch": 0.08747327608073341,
      "grad_norm": 1.3250900506973267,
      "learning_rate": 0.0001825204724980071,
      "loss": 0.0747,
      "step": 1207
    },
    {
      "epoch": 0.08754574772620212,
      "grad_norm": 5.288297176361084,
      "learning_rate": 0.00018250597869410827,
      "loss": 0.278,
      "step": 1208
    },
    {
      "epoch": 0.08761821937167083,
      "grad_norm": 1.8343524932861328,
      "learning_rate": 0.00018249148489020943,
      "loss": 0.1245,
      "step": 1209
    },
    {
      "epoch": 0.08769069101713954,
      "grad_norm": 1.9116978645324707,
      "learning_rate": 0.0001824769910863106,
      "loss": 0.1317,
      "step": 1210
    },
    {
      "epoch": 0.08776316266260825,
      "grad_norm": 2.0934441089630127,
      "learning_rate": 0.00018246249728241177,
      "loss": 0.0624,
      "step": 1211
    },
    {
      "epoch": 0.08783563430807696,
      "grad_norm": 1.914883017539978,
      "learning_rate": 0.00018244800347851295,
      "loss": 0.0774,
      "step": 1212
    },
    {
      "epoch": 0.08790810595354567,
      "grad_norm": 2.655435085296631,
      "learning_rate": 0.0001824335096746141,
      "loss": 0.083,
      "step": 1213
    },
    {
      "epoch": 0.08798057759901438,
      "grad_norm": 3.324669122695923,
      "learning_rate": 0.0001824190158707153,
      "loss": 0.1843,
      "step": 1214
    },
    {
      "epoch": 0.0880530492444831,
      "grad_norm": 5.439347743988037,
      "learning_rate": 0.00018240452206681645,
      "loss": 0.1579,
      "step": 1215
    },
    {
      "epoch": 0.0881255208899518,
      "grad_norm": 0.8853480815887451,
      "learning_rate": 0.0001823900282629176,
      "loss": 0.0442,
      "step": 1216
    },
    {
      "epoch": 0.08819799253542052,
      "grad_norm": 2.6390089988708496,
      "learning_rate": 0.0001823755344590188,
      "loss": 0.0988,
      "step": 1217
    },
    {
      "epoch": 0.08827046418088923,
      "grad_norm": 1.0099754333496094,
      "learning_rate": 0.00018236104065511995,
      "loss": 0.0443,
      "step": 1218
    },
    {
      "epoch": 0.08834293582635794,
      "grad_norm": 3.610747814178467,
      "learning_rate": 0.00018234654685122113,
      "loss": 0.1137,
      "step": 1219
    },
    {
      "epoch": 0.08841540747182665,
      "grad_norm": 1.8053228855133057,
      "learning_rate": 0.0001823320530473223,
      "loss": 0.0692,
      "step": 1220
    },
    {
      "epoch": 0.08848787911729536,
      "grad_norm": 3.0708892345428467,
      "learning_rate": 0.00018231755924342344,
      "loss": 0.2043,
      "step": 1221
    },
    {
      "epoch": 0.08856035076276407,
      "grad_norm": 1.7024927139282227,
      "learning_rate": 0.00018230306543952463,
      "loss": 0.0655,
      "step": 1222
    },
    {
      "epoch": 0.08863282240823278,
      "grad_norm": 2.6167263984680176,
      "learning_rate": 0.00018228857163562578,
      "loss": 0.1446,
      "step": 1223
    },
    {
      "epoch": 0.08870529405370149,
      "grad_norm": 5.77899169921875,
      "learning_rate": 0.00018227407783172694,
      "loss": 0.1513,
      "step": 1224
    },
    {
      "epoch": 0.0887777656991702,
      "grad_norm": 5.260217666625977,
      "learning_rate": 0.00018225958402782812,
      "loss": 0.2156,
      "step": 1225
    },
    {
      "epoch": 0.08885023734463891,
      "grad_norm": 6.036696910858154,
      "learning_rate": 0.00018224509022392928,
      "loss": 0.1963,
      "step": 1226
    },
    {
      "epoch": 0.08892270899010762,
      "grad_norm": 3.293484687805176,
      "learning_rate": 0.00018223059642003044,
      "loss": 0.1359,
      "step": 1227
    },
    {
      "epoch": 0.08899518063557633,
      "grad_norm": 3.5677590370178223,
      "learning_rate": 0.00018221610261613162,
      "loss": 0.0833,
      "step": 1228
    },
    {
      "epoch": 0.08906765228104505,
      "grad_norm": 2.016268491744995,
      "learning_rate": 0.00018220160881223278,
      "loss": 0.1152,
      "step": 1229
    },
    {
      "epoch": 0.08914012392651376,
      "grad_norm": 2.7726669311523438,
      "learning_rate": 0.00018218711500833393,
      "loss": 0.1733,
      "step": 1230
    },
    {
      "epoch": 0.08921259557198247,
      "grad_norm": 5.170132160186768,
      "learning_rate": 0.00018217262120443512,
      "loss": 0.1908,
      "step": 1231
    },
    {
      "epoch": 0.08928506721745118,
      "grad_norm": 2.4883623123168945,
      "learning_rate": 0.00018215812740053627,
      "loss": 0.1633,
      "step": 1232
    },
    {
      "epoch": 0.08935753886291989,
      "grad_norm": 1.8195040225982666,
      "learning_rate": 0.00018214363359663743,
      "loss": 0.1816,
      "step": 1233
    },
    {
      "epoch": 0.0894300105083886,
      "grad_norm": 1.3857944011688232,
      "learning_rate": 0.00018212913979273861,
      "loss": 0.1128,
      "step": 1234
    },
    {
      "epoch": 0.08950248215385731,
      "grad_norm": 5.2305145263671875,
      "learning_rate": 0.00018211464598883977,
      "loss": 0.158,
      "step": 1235
    },
    {
      "epoch": 0.08957495379932601,
      "grad_norm": 1.4443788528442383,
      "learning_rate": 0.00018210015218494095,
      "loss": 0.091,
      "step": 1236
    },
    {
      "epoch": 0.08964742544479472,
      "grad_norm": 2.749319553375244,
      "learning_rate": 0.0001820856583810421,
      "loss": 0.232,
      "step": 1237
    },
    {
      "epoch": 0.08971989709026343,
      "grad_norm": 3.460080862045288,
      "learning_rate": 0.0001820711645771433,
      "loss": 0.1487,
      "step": 1238
    },
    {
      "epoch": 0.08979236873573214,
      "grad_norm": 3.1388027667999268,
      "learning_rate": 0.00018205667077324445,
      "loss": 0.198,
      "step": 1239
    },
    {
      "epoch": 0.08986484038120085,
      "grad_norm": 1.7140048742294312,
      "learning_rate": 0.00018204217696934563,
      "loss": 0.1095,
      "step": 1240
    },
    {
      "epoch": 0.08993731202666956,
      "grad_norm": 2.1144165992736816,
      "learning_rate": 0.0001820276831654468,
      "loss": 0.095,
      "step": 1241
    },
    {
      "epoch": 0.09000978367213827,
      "grad_norm": 5.009487628936768,
      "learning_rate": 0.00018201318936154795,
      "loss": 0.2972,
      "step": 1242
    },
    {
      "epoch": 0.09008225531760698,
      "grad_norm": 5.475874423980713,
      "learning_rate": 0.00018199869555764913,
      "loss": 0.417,
      "step": 1243
    },
    {
      "epoch": 0.0901547269630757,
      "grad_norm": 3.1106374263763428,
      "learning_rate": 0.0001819842017537503,
      "loss": 0.1589,
      "step": 1244
    },
    {
      "epoch": 0.0902271986085444,
      "grad_norm": 2.001262903213501,
      "learning_rate": 0.00018196970794985144,
      "loss": 0.1199,
      "step": 1245
    },
    {
      "epoch": 0.09029967025401311,
      "grad_norm": 6.40566349029541,
      "learning_rate": 0.00018195521414595263,
      "loss": 0.1598,
      "step": 1246
    },
    {
      "epoch": 0.09037214189948183,
      "grad_norm": 3.321545362472534,
      "learning_rate": 0.00018194072034205378,
      "loss": 0.1287,
      "step": 1247
    },
    {
      "epoch": 0.09044461354495054,
      "grad_norm": 3.216395378112793,
      "learning_rate": 0.00018192622653815494,
      "loss": 0.1039,
      "step": 1248
    },
    {
      "epoch": 0.09051708519041925,
      "grad_norm": 2.2988688945770264,
      "learning_rate": 0.00018191173273425612,
      "loss": 0.0761,
      "step": 1249
    },
    {
      "epoch": 0.09058955683588796,
      "grad_norm": 6.79495906829834,
      "learning_rate": 0.00018189723893035728,
      "loss": 0.2757,
      "step": 1250
    },
    {
      "epoch": 0.09066202848135667,
      "grad_norm": 3.0777928829193115,
      "learning_rate": 0.00018188274512645844,
      "loss": 0.1312,
      "step": 1251
    },
    {
      "epoch": 0.09073450012682538,
      "grad_norm": 3.2491838932037354,
      "learning_rate": 0.00018186825132255962,
      "loss": 0.1326,
      "step": 1252
    },
    {
      "epoch": 0.09080697177229409,
      "grad_norm": 2.134105920791626,
      "learning_rate": 0.00018185375751866078,
      "loss": 0.1384,
      "step": 1253
    },
    {
      "epoch": 0.0908794434177628,
      "grad_norm": 3.200763463973999,
      "learning_rate": 0.00018183926371476193,
      "loss": 0.1512,
      "step": 1254
    },
    {
      "epoch": 0.09095191506323151,
      "grad_norm": 2.187152624130249,
      "learning_rate": 0.00018182476991086312,
      "loss": 0.1162,
      "step": 1255
    },
    {
      "epoch": 0.09102438670870022,
      "grad_norm": 2.3800265789031982,
      "learning_rate": 0.00018181027610696427,
      "loss": 0.0612,
      "step": 1256
    },
    {
      "epoch": 0.09109685835416893,
      "grad_norm": 2.9195175170898438,
      "learning_rate": 0.00018179578230306543,
      "loss": 0.0489,
      "step": 1257
    },
    {
      "epoch": 0.09116932999963764,
      "grad_norm": 2.658630609512329,
      "learning_rate": 0.0001817812884991666,
      "loss": 0.0587,
      "step": 1258
    },
    {
      "epoch": 0.09124180164510635,
      "grad_norm": 2.530453681945801,
      "learning_rate": 0.0001817667946952678,
      "loss": 0.1122,
      "step": 1259
    },
    {
      "epoch": 0.09131427329057507,
      "grad_norm": 4.081998825073242,
      "learning_rate": 0.00018175230089136895,
      "loss": 0.1618,
      "step": 1260
    },
    {
      "epoch": 0.09138674493604378,
      "grad_norm": 6.536550998687744,
      "learning_rate": 0.00018173780708747014,
      "loss": 0.2888,
      "step": 1261
    },
    {
      "epoch": 0.09145921658151249,
      "grad_norm": 4.007652282714844,
      "learning_rate": 0.0001817233132835713,
      "loss": 0.0948,
      "step": 1262
    },
    {
      "epoch": 0.0915316882269812,
      "grad_norm": 2.617546558380127,
      "learning_rate": 0.00018170881947967245,
      "loss": 0.1841,
      "step": 1263
    },
    {
      "epoch": 0.09160415987244991,
      "grad_norm": 3.0026559829711914,
      "learning_rate": 0.00018169432567577363,
      "loss": 0.0984,
      "step": 1264
    },
    {
      "epoch": 0.09167663151791862,
      "grad_norm": 10.949918746948242,
      "learning_rate": 0.0001816798318718748,
      "loss": 0.2223,
      "step": 1265
    },
    {
      "epoch": 0.09174910316338733,
      "grad_norm": 4.885951042175293,
      "learning_rate": 0.00018166533806797595,
      "loss": 0.1695,
      "step": 1266
    },
    {
      "epoch": 0.09182157480885604,
      "grad_norm": 2.57468318939209,
      "learning_rate": 0.00018165084426407713,
      "loss": 0.0841,
      "step": 1267
    },
    {
      "epoch": 0.09189404645432475,
      "grad_norm": 3.801400899887085,
      "learning_rate": 0.0001816363504601783,
      "loss": 0.2139,
      "step": 1268
    },
    {
      "epoch": 0.09196651809979346,
      "grad_norm": 1.0656629800796509,
      "learning_rate": 0.00018162185665627944,
      "loss": 0.0479,
      "step": 1269
    },
    {
      "epoch": 0.09203898974526217,
      "grad_norm": 2.8768155574798584,
      "learning_rate": 0.00018160736285238063,
      "loss": 0.2305,
      "step": 1270
    },
    {
      "epoch": 0.09211146139073087,
      "grad_norm": 3.1581461429595947,
      "learning_rate": 0.00018159286904848178,
      "loss": 0.0833,
      "step": 1271
    },
    {
      "epoch": 0.09218393303619958,
      "grad_norm": 2.050461769104004,
      "learning_rate": 0.00018157837524458294,
      "loss": 0.1008,
      "step": 1272
    },
    {
      "epoch": 0.09225640468166829,
      "grad_norm": 3.586808919906616,
      "learning_rate": 0.00018156388144068412,
      "loss": 0.1615,
      "step": 1273
    },
    {
      "epoch": 0.092328876327137,
      "grad_norm": 4.150472164154053,
      "learning_rate": 0.00018154938763678528,
      "loss": 0.1568,
      "step": 1274
    },
    {
      "epoch": 0.09240134797260571,
      "grad_norm": 4.551959991455078,
      "learning_rate": 0.00018153489383288644,
      "loss": 0.1412,
      "step": 1275
    },
    {
      "epoch": 0.09247381961807442,
      "grad_norm": 2.5859127044677734,
      "learning_rate": 0.00018152040002898762,
      "loss": 0.1437,
      "step": 1276
    },
    {
      "epoch": 0.09254629126354313,
      "grad_norm": 3.737616539001465,
      "learning_rate": 0.00018150590622508878,
      "loss": 0.1093,
      "step": 1277
    },
    {
      "epoch": 0.09261876290901185,
      "grad_norm": 4.063570022583008,
      "learning_rate": 0.00018149141242118993,
      "loss": 0.1503,
      "step": 1278
    },
    {
      "epoch": 0.09269123455448056,
      "grad_norm": 3.500849485397339,
      "learning_rate": 0.00018147691861729112,
      "loss": 0.1867,
      "step": 1279
    },
    {
      "epoch": 0.09276370619994927,
      "grad_norm": 5.119848251342773,
      "learning_rate": 0.00018146242481339227,
      "loss": 0.1504,
      "step": 1280
    },
    {
      "epoch": 0.09283617784541798,
      "grad_norm": 3.182783603668213,
      "learning_rate": 0.00018144793100949346,
      "loss": 0.2113,
      "step": 1281
    },
    {
      "epoch": 0.09290864949088669,
      "grad_norm": 3.0105621814727783,
      "learning_rate": 0.0001814334372055946,
      "loss": 0.145,
      "step": 1282
    },
    {
      "epoch": 0.0929811211363554,
      "grad_norm": 4.624301910400391,
      "learning_rate": 0.0001814189434016958,
      "loss": 0.2952,
      "step": 1283
    },
    {
      "epoch": 0.09305359278182411,
      "grad_norm": 5.417420864105225,
      "learning_rate": 0.00018140444959779695,
      "loss": 0.1622,
      "step": 1284
    },
    {
      "epoch": 0.09312606442729282,
      "grad_norm": 1.9509718418121338,
      "learning_rate": 0.00018138995579389814,
      "loss": 0.1306,
      "step": 1285
    },
    {
      "epoch": 0.09319853607276153,
      "grad_norm": 2.9345529079437256,
      "learning_rate": 0.0001813754619899993,
      "loss": 0.1396,
      "step": 1286
    },
    {
      "epoch": 0.09327100771823024,
      "grad_norm": 1.4855456352233887,
      "learning_rate": 0.00018136096818610045,
      "loss": 0.0943,
      "step": 1287
    },
    {
      "epoch": 0.09334347936369895,
      "grad_norm": 1.3151921033859253,
      "learning_rate": 0.00018134647438220163,
      "loss": 0.0924,
      "step": 1288
    },
    {
      "epoch": 0.09341595100916766,
      "grad_norm": 3.3745956420898438,
      "learning_rate": 0.0001813319805783028,
      "loss": 0.1475,
      "step": 1289
    },
    {
      "epoch": 0.09348842265463637,
      "grad_norm": 3.083970069885254,
      "learning_rate": 0.00018131748677440395,
      "loss": 0.1441,
      "step": 1290
    },
    {
      "epoch": 0.09356089430010509,
      "grad_norm": 2.5577802658081055,
      "learning_rate": 0.00018130299297050513,
      "loss": 0.116,
      "step": 1291
    },
    {
      "epoch": 0.0936333659455738,
      "grad_norm": 5.3414626121521,
      "learning_rate": 0.00018128849916660629,
      "loss": 0.1664,
      "step": 1292
    },
    {
      "epoch": 0.0937058375910425,
      "grad_norm": 2.3088834285736084,
      "learning_rate": 0.00018127400536270744,
      "loss": 0.1066,
      "step": 1293
    },
    {
      "epoch": 0.09377830923651122,
      "grad_norm": 4.7901291847229,
      "learning_rate": 0.00018125951155880863,
      "loss": 0.2047,
      "step": 1294
    },
    {
      "epoch": 0.09385078088197993,
      "grad_norm": 3.2858188152313232,
      "learning_rate": 0.00018124501775490978,
      "loss": 0.1724,
      "step": 1295
    },
    {
      "epoch": 0.09392325252744864,
      "grad_norm": 3.7297513484954834,
      "learning_rate": 0.00018123052395101094,
      "loss": 0.1502,
      "step": 1296
    },
    {
      "epoch": 0.09399572417291735,
      "grad_norm": 3.2265946865081787,
      "learning_rate": 0.00018121603014711212,
      "loss": 0.1805,
      "step": 1297
    },
    {
      "epoch": 0.09406819581838606,
      "grad_norm": 3.6791226863861084,
      "learning_rate": 0.00018120153634321328,
      "loss": 0.2325,
      "step": 1298
    },
    {
      "epoch": 0.09414066746385477,
      "grad_norm": 2.5371739864349365,
      "learning_rate": 0.00018118704253931444,
      "loss": 0.1333,
      "step": 1299
    },
    {
      "epoch": 0.09421313910932348,
      "grad_norm": 4.930749416351318,
      "learning_rate": 0.00018117254873541562,
      "loss": 0.1635,
      "step": 1300
    },
    {
      "epoch": 0.09428561075479219,
      "grad_norm": 2.0042190551757812,
      "learning_rate": 0.00018115805493151678,
      "loss": 0.0749,
      "step": 1301
    },
    {
      "epoch": 0.0943580824002609,
      "grad_norm": 1.5328214168548584,
      "learning_rate": 0.00018114356112761793,
      "loss": 0.0422,
      "step": 1302
    },
    {
      "epoch": 0.09443055404572961,
      "grad_norm": 1.4867700338363647,
      "learning_rate": 0.00018112906732371912,
      "loss": 0.0642,
      "step": 1303
    },
    {
      "epoch": 0.09450302569119833,
      "grad_norm": 3.7422938346862793,
      "learning_rate": 0.00018111457351982027,
      "loss": 0.1594,
      "step": 1304
    },
    {
      "epoch": 0.09457549733666704,
      "grad_norm": 2.0558383464813232,
      "learning_rate": 0.00018110007971592146,
      "loss": 0.1497,
      "step": 1305
    },
    {
      "epoch": 0.09464796898213573,
      "grad_norm": 1.3537639379501343,
      "learning_rate": 0.0001810855859120226,
      "loss": 0.0504,
      "step": 1306
    },
    {
      "epoch": 0.09472044062760444,
      "grad_norm": 2.0129172801971436,
      "learning_rate": 0.0001810710921081238,
      "loss": 0.1221,
      "step": 1307
    },
    {
      "epoch": 0.09479291227307315,
      "grad_norm": 3.1767935752868652,
      "learning_rate": 0.00018105659830422495,
      "loss": 0.0499,
      "step": 1308
    },
    {
      "epoch": 0.09486538391854187,
      "grad_norm": 2.864053249359131,
      "learning_rate": 0.00018104210450032614,
      "loss": 0.1434,
      "step": 1309
    },
    {
      "epoch": 0.09493785556401058,
      "grad_norm": 3.1695539951324463,
      "learning_rate": 0.0001810276106964273,
      "loss": 0.0543,
      "step": 1310
    },
    {
      "epoch": 0.09501032720947929,
      "grad_norm": 3.501215696334839,
      "learning_rate": 0.00018101311689252845,
      "loss": 0.2707,
      "step": 1311
    },
    {
      "epoch": 0.095082798854948,
      "grad_norm": 1.2855266332626343,
      "learning_rate": 0.00018099862308862963,
      "loss": 0.103,
      "step": 1312
    },
    {
      "epoch": 0.09515527050041671,
      "grad_norm": 5.7396745681762695,
      "learning_rate": 0.0001809841292847308,
      "loss": 0.1575,
      "step": 1313
    },
    {
      "epoch": 0.09522774214588542,
      "grad_norm": 1.9736164808273315,
      "learning_rate": 0.00018096963548083195,
      "loss": 0.1475,
      "step": 1314
    },
    {
      "epoch": 0.09530021379135413,
      "grad_norm": 1.7796419858932495,
      "learning_rate": 0.00018095514167693313,
      "loss": 0.1467,
      "step": 1315
    },
    {
      "epoch": 0.09537268543682284,
      "grad_norm": 1.2708146572113037,
      "learning_rate": 0.00018094064787303429,
      "loss": 0.0746,
      "step": 1316
    },
    {
      "epoch": 0.09544515708229155,
      "grad_norm": 1.7305786609649658,
      "learning_rate": 0.00018092615406913544,
      "loss": 0.0641,
      "step": 1317
    },
    {
      "epoch": 0.09551762872776026,
      "grad_norm": 2.989989995956421,
      "learning_rate": 0.00018091166026523663,
      "loss": 0.1267,
      "step": 1318
    },
    {
      "epoch": 0.09559010037322897,
      "grad_norm": 1.7040998935699463,
      "learning_rate": 0.00018089716646133778,
      "loss": 0.0631,
      "step": 1319
    },
    {
      "epoch": 0.09566257201869768,
      "grad_norm": 3.320413112640381,
      "learning_rate": 0.00018088267265743894,
      "loss": 0.1613,
      "step": 1320
    },
    {
      "epoch": 0.0957350436641664,
      "grad_norm": 2.786518096923828,
      "learning_rate": 0.00018086817885354012,
      "loss": 0.1168,
      "step": 1321
    },
    {
      "epoch": 0.0958075153096351,
      "grad_norm": 3.7423903942108154,
      "learning_rate": 0.00018085368504964128,
      "loss": 0.1141,
      "step": 1322
    },
    {
      "epoch": 0.09587998695510382,
      "grad_norm": 4.726957321166992,
      "learning_rate": 0.00018083919124574244,
      "loss": 0.1131,
      "step": 1323
    },
    {
      "epoch": 0.09595245860057253,
      "grad_norm": 7.846912384033203,
      "learning_rate": 0.00018082469744184362,
      "loss": 0.1938,
      "step": 1324
    },
    {
      "epoch": 0.09602493024604124,
      "grad_norm": 6.4007439613342285,
      "learning_rate": 0.00018081020363794478,
      "loss": 0.4803,
      "step": 1325
    },
    {
      "epoch": 0.09609740189150995,
      "grad_norm": 2.9609744548797607,
      "learning_rate": 0.00018079570983404593,
      "loss": 0.0948,
      "step": 1326
    },
    {
      "epoch": 0.09616987353697866,
      "grad_norm": 4.508550643920898,
      "learning_rate": 0.00018078121603014712,
      "loss": 0.162,
      "step": 1327
    },
    {
      "epoch": 0.09624234518244737,
      "grad_norm": 5.521080493927002,
      "learning_rate": 0.0001807667222262483,
      "loss": 0.2682,
      "step": 1328
    },
    {
      "epoch": 0.09631481682791608,
      "grad_norm": 4.881511688232422,
      "learning_rate": 0.00018075222842234946,
      "loss": 0.1676,
      "step": 1329
    },
    {
      "epoch": 0.09638728847338479,
      "grad_norm": 3.7236709594726562,
      "learning_rate": 0.00018073773461845064,
      "loss": 0.2123,
      "step": 1330
    },
    {
      "epoch": 0.0964597601188535,
      "grad_norm": 1.7798960208892822,
      "learning_rate": 0.0001807232408145518,
      "loss": 0.0994,
      "step": 1331
    },
    {
      "epoch": 0.09653223176432221,
      "grad_norm": 2.6659882068634033,
      "learning_rate": 0.00018070874701065295,
      "loss": 0.1203,
      "step": 1332
    },
    {
      "epoch": 0.09660470340979092,
      "grad_norm": 2.995903491973877,
      "learning_rate": 0.00018069425320675414,
      "loss": 0.2025,
      "step": 1333
    },
    {
      "epoch": 0.09667717505525963,
      "grad_norm": 2.0484910011291504,
      "learning_rate": 0.0001806797594028553,
      "loss": 0.1221,
      "step": 1334
    },
    {
      "epoch": 0.09674964670072835,
      "grad_norm": 2.7300918102264404,
      "learning_rate": 0.00018066526559895645,
      "loss": 0.286,
      "step": 1335
    },
    {
      "epoch": 0.09682211834619706,
      "grad_norm": 1.23600435256958,
      "learning_rate": 0.00018065077179505763,
      "loss": 0.0992,
      "step": 1336
    },
    {
      "epoch": 0.09689458999166577,
      "grad_norm": 1.6807091236114502,
      "learning_rate": 0.0001806362779911588,
      "loss": 0.1209,
      "step": 1337
    },
    {
      "epoch": 0.09696706163713448,
      "grad_norm": 5.117468357086182,
      "learning_rate": 0.00018062178418725995,
      "loss": 0.0934,
      "step": 1338
    },
    {
      "epoch": 0.09703953328260319,
      "grad_norm": 6.507981300354004,
      "learning_rate": 0.00018060729038336113,
      "loss": 0.1645,
      "step": 1339
    },
    {
      "epoch": 0.09711200492807189,
      "grad_norm": 2.0839943885803223,
      "learning_rate": 0.00018059279657946229,
      "loss": 0.1166,
      "step": 1340
    },
    {
      "epoch": 0.0971844765735406,
      "grad_norm": 1.7560521364212036,
      "learning_rate": 0.00018057830277556344,
      "loss": 0.132,
      "step": 1341
    },
    {
      "epoch": 0.0972569482190093,
      "grad_norm": 1.2455710172653198,
      "learning_rate": 0.00018056380897166463,
      "loss": 0.0792,
      "step": 1342
    },
    {
      "epoch": 0.09732941986447802,
      "grad_norm": 1.0760029554367065,
      "learning_rate": 0.00018054931516776578,
      "loss": 0.0728,
      "step": 1343
    },
    {
      "epoch": 0.09740189150994673,
      "grad_norm": 0.923606812953949,
      "learning_rate": 0.00018053482136386694,
      "loss": 0.0624,
      "step": 1344
    },
    {
      "epoch": 0.09747436315541544,
      "grad_norm": 2.270575761795044,
      "learning_rate": 0.00018052032755996812,
      "loss": 0.1025,
      "step": 1345
    },
    {
      "epoch": 0.09754683480088415,
      "grad_norm": 3.4055566787719727,
      "learning_rate": 0.00018050583375606928,
      "loss": 0.1026,
      "step": 1346
    },
    {
      "epoch": 0.09761930644635286,
      "grad_norm": 3.151764392852783,
      "learning_rate": 0.00018049133995217044,
      "loss": 0.1384,
      "step": 1347
    },
    {
      "epoch": 0.09769177809182157,
      "grad_norm": 3.5991384983062744,
      "learning_rate": 0.00018047684614827162,
      "loss": 0.1884,
      "step": 1348
    },
    {
      "epoch": 0.09776424973729028,
      "grad_norm": 2.108396291732788,
      "learning_rate": 0.00018046235234437278,
      "loss": 0.1689,
      "step": 1349
    },
    {
      "epoch": 0.09783672138275899,
      "grad_norm": 2.110063076019287,
      "learning_rate": 0.00018044785854047396,
      "loss": 0.1488,
      "step": 1350
    },
    {
      "epoch": 0.0979091930282277,
      "grad_norm": 1.4270052909851074,
      "learning_rate": 0.00018043336473657512,
      "loss": 0.1358,
      "step": 1351
    },
    {
      "epoch": 0.09798166467369641,
      "grad_norm": 1.4291871786117554,
      "learning_rate": 0.0001804188709326763,
      "loss": 0.1651,
      "step": 1352
    },
    {
      "epoch": 0.09805413631916512,
      "grad_norm": 2.5403707027435303,
      "learning_rate": 0.00018040437712877746,
      "loss": 0.1037,
      "step": 1353
    },
    {
      "epoch": 0.09812660796463384,
      "grad_norm": 7.642873287200928,
      "learning_rate": 0.00018038988332487864,
      "loss": 0.0971,
      "step": 1354
    },
    {
      "epoch": 0.09819907961010255,
      "grad_norm": 1.3790823221206665,
      "learning_rate": 0.0001803753895209798,
      "loss": 0.0897,
      "step": 1355
    },
    {
      "epoch": 0.09827155125557126,
      "grad_norm": 2.4065468311309814,
      "learning_rate": 0.00018036089571708095,
      "loss": 0.1747,
      "step": 1356
    },
    {
      "epoch": 0.09834402290103997,
      "grad_norm": 3.1613447666168213,
      "learning_rate": 0.00018034640191318214,
      "loss": 0.174,
      "step": 1357
    },
    {
      "epoch": 0.09841649454650868,
      "grad_norm": 4.932269096374512,
      "learning_rate": 0.0001803319081092833,
      "loss": 0.2426,
      "step": 1358
    },
    {
      "epoch": 0.09848896619197739,
      "grad_norm": 7.334715366363525,
      "learning_rate": 0.00018031741430538445,
      "loss": 0.2599,
      "step": 1359
    },
    {
      "epoch": 0.0985614378374461,
      "grad_norm": 4.1327667236328125,
      "learning_rate": 0.00018030292050148563,
      "loss": 0.2073,
      "step": 1360
    },
    {
      "epoch": 0.09863390948291481,
      "grad_norm": 2.5486559867858887,
      "learning_rate": 0.0001802884266975868,
      "loss": 0.0729,
      "step": 1361
    },
    {
      "epoch": 0.09870638112838352,
      "grad_norm": 2.1104888916015625,
      "learning_rate": 0.00018027393289368795,
      "loss": 0.1041,
      "step": 1362
    },
    {
      "epoch": 0.09877885277385223,
      "grad_norm": 1.8527165651321411,
      "learning_rate": 0.00018025943908978913,
      "loss": 0.1037,
      "step": 1363
    },
    {
      "epoch": 0.09885132441932094,
      "grad_norm": 1.7532650232315063,
      "learning_rate": 0.00018024494528589029,
      "loss": 0.1127,
      "step": 1364
    },
    {
      "epoch": 0.09892379606478965,
      "grad_norm": 4.596972465515137,
      "learning_rate": 0.00018023045148199144,
      "loss": 0.0838,
      "step": 1365
    },
    {
      "epoch": 0.09899626771025836,
      "grad_norm": 2.513183832168579,
      "learning_rate": 0.00018021595767809263,
      "loss": 0.1752,
      "step": 1366
    },
    {
      "epoch": 0.09906873935572708,
      "grad_norm": 1.0858670473098755,
      "learning_rate": 0.00018020146387419378,
      "loss": 0.079,
      "step": 1367
    },
    {
      "epoch": 0.09914121100119579,
      "grad_norm": 3.739955425262451,
      "learning_rate": 0.00018018697007029494,
      "loss": 0.216,
      "step": 1368
    },
    {
      "epoch": 0.0992136826466645,
      "grad_norm": 2.7927281856536865,
      "learning_rate": 0.00018017247626639612,
      "loss": 0.1275,
      "step": 1369
    },
    {
      "epoch": 0.09928615429213321,
      "grad_norm": 4.546814441680908,
      "learning_rate": 0.00018015798246249728,
      "loss": 0.1504,
      "step": 1370
    },
    {
      "epoch": 0.09935862593760192,
      "grad_norm": 2.5589449405670166,
      "learning_rate": 0.00018014348865859843,
      "loss": 0.0817,
      "step": 1371
    },
    {
      "epoch": 0.09943109758307063,
      "grad_norm": 2.746091842651367,
      "learning_rate": 0.00018012899485469962,
      "loss": 0.212,
      "step": 1372
    },
    {
      "epoch": 0.09950356922853934,
      "grad_norm": 3.2172775268554688,
      "learning_rate": 0.00018011450105080077,
      "loss": 0.2054,
      "step": 1373
    },
    {
      "epoch": 0.09957604087400805,
      "grad_norm": 5.680804252624512,
      "learning_rate": 0.00018010000724690196,
      "loss": 0.126,
      "step": 1374
    },
    {
      "epoch": 0.09964851251947675,
      "grad_norm": 2.141700029373169,
      "learning_rate": 0.00018008551344300314,
      "loss": 0.1085,
      "step": 1375
    },
    {
      "epoch": 0.09972098416494546,
      "grad_norm": 1.7461894750595093,
      "learning_rate": 0.0001800710196391043,
      "loss": 0.1238,
      "step": 1376
    },
    {
      "epoch": 0.09979345581041417,
      "grad_norm": 2.8661749362945557,
      "learning_rate": 0.00018005652583520545,
      "loss": 0.1301,
      "step": 1377
    },
    {
      "epoch": 0.09986592745588288,
      "grad_norm": 0.8473427295684814,
      "learning_rate": 0.00018004203203130664,
      "loss": 0.0241,
      "step": 1378
    },
    {
      "epoch": 0.09993839910135159,
      "grad_norm": 2.3563170433044434,
      "learning_rate": 0.0001800275382274078,
      "loss": 0.1488,
      "step": 1379
    },
    {
      "epoch": 0.1000108707468203,
      "grad_norm": 3.4388396739959717,
      "learning_rate": 0.00018001304442350895,
      "loss": 0.1821,
      "step": 1380
    },
    {
      "epoch": 0.10008334239228901,
      "grad_norm": 6.274263858795166,
      "learning_rate": 0.00017999855061961014,
      "loss": 0.1371,
      "step": 1381
    },
    {
      "epoch": 0.10015581403775772,
      "grad_norm": 1.1072810888290405,
      "learning_rate": 0.0001799840568157113,
      "loss": 0.068,
      "step": 1382
    },
    {
      "epoch": 0.10022828568322643,
      "grad_norm": 3.3531885147094727,
      "learning_rate": 0.00017996956301181248,
      "loss": 0.198,
      "step": 1383
    },
    {
      "epoch": 0.10030075732869514,
      "grad_norm": 2.259392261505127,
      "learning_rate": 0.00017995506920791363,
      "loss": 0.1675,
      "step": 1384
    },
    {
      "epoch": 0.10037322897416386,
      "grad_norm": 4.947396755218506,
      "learning_rate": 0.0001799405754040148,
      "loss": 0.1553,
      "step": 1385
    },
    {
      "epoch": 0.10044570061963257,
      "grad_norm": 3.772080898284912,
      "learning_rate": 0.00017992608160011597,
      "loss": 0.1105,
      "step": 1386
    },
    {
      "epoch": 0.10051817226510128,
      "grad_norm": 3.478320360183716,
      "learning_rate": 0.00017991158779621713,
      "loss": 0.169,
      "step": 1387
    },
    {
      "epoch": 0.10059064391056999,
      "grad_norm": 6.037578582763672,
      "learning_rate": 0.00017989709399231828,
      "loss": 0.1089,
      "step": 1388
    },
    {
      "epoch": 0.1006631155560387,
      "grad_norm": 2.371095895767212,
      "learning_rate": 0.00017988260018841947,
      "loss": 0.0732,
      "step": 1389
    },
    {
      "epoch": 0.10073558720150741,
      "grad_norm": 2.599379539489746,
      "learning_rate": 0.00017986810638452062,
      "loss": 0.1039,
      "step": 1390
    },
    {
      "epoch": 0.10080805884697612,
      "grad_norm": 4.991875171661377,
      "learning_rate": 0.00017985361258062178,
      "loss": 0.1798,
      "step": 1391
    },
    {
      "epoch": 0.10088053049244483,
      "grad_norm": 2.046083927154541,
      "learning_rate": 0.00017983911877672296,
      "loss": 0.1522,
      "step": 1392
    },
    {
      "epoch": 0.10095300213791354,
      "grad_norm": 2.681541919708252,
      "learning_rate": 0.00017982462497282412,
      "loss": 0.1694,
      "step": 1393
    },
    {
      "epoch": 0.10102547378338225,
      "grad_norm": 2.7108192443847656,
      "learning_rate": 0.00017981013116892528,
      "loss": 0.11,
      "step": 1394
    },
    {
      "epoch": 0.10109794542885096,
      "grad_norm": 1.1119006872177124,
      "learning_rate": 0.00017979563736502646,
      "loss": 0.0777,
      "step": 1395
    },
    {
      "epoch": 0.10117041707431967,
      "grad_norm": 2.713672399520874,
      "learning_rate": 0.00017978114356112762,
      "loss": 0.1155,
      "step": 1396
    },
    {
      "epoch": 0.10124288871978838,
      "grad_norm": 1.3040229082107544,
      "learning_rate": 0.0001797666497572288,
      "loss": 0.0514,
      "step": 1397
    },
    {
      "epoch": 0.1013153603652571,
      "grad_norm": 1.576615810394287,
      "learning_rate": 0.00017975215595332996,
      "loss": 0.1025,
      "step": 1398
    },
    {
      "epoch": 0.1013878320107258,
      "grad_norm": 2.388394355773926,
      "learning_rate": 0.00017973766214943114,
      "loss": 0.1411,
      "step": 1399
    },
    {
      "epoch": 0.10146030365619452,
      "grad_norm": 4.1651458740234375,
      "learning_rate": 0.0001797231683455323,
      "loss": 0.1573,
      "step": 1400
    },
    {
      "epoch": 0.10153277530166323,
      "grad_norm": 5.65399694442749,
      "learning_rate": 0.00017970867454163348,
      "loss": 0.1325,
      "step": 1401
    },
    {
      "epoch": 0.10160524694713194,
      "grad_norm": 1.929624080657959,
      "learning_rate": 0.00017969418073773464,
      "loss": 0.0906,
      "step": 1402
    },
    {
      "epoch": 0.10167771859260065,
      "grad_norm": 4.9601521492004395,
      "learning_rate": 0.0001796796869338358,
      "loss": 0.0857,
      "step": 1403
    },
    {
      "epoch": 0.10175019023806936,
      "grad_norm": 2.507920026779175,
      "learning_rate": 0.00017966519312993698,
      "loss": 0.039,
      "step": 1404
    },
    {
      "epoch": 0.10182266188353807,
      "grad_norm": 1.0897630453109741,
      "learning_rate": 0.00017965069932603813,
      "loss": 0.0647,
      "step": 1405
    },
    {
      "epoch": 0.10189513352900678,
      "grad_norm": 3.641683578491211,
      "learning_rate": 0.0001796362055221393,
      "loss": 0.0936,
      "step": 1406
    },
    {
      "epoch": 0.10196760517447549,
      "grad_norm": 3.0482289791107178,
      "learning_rate": 0.00017962171171824047,
      "loss": 0.1979,
      "step": 1407
    },
    {
      "epoch": 0.1020400768199442,
      "grad_norm": 2.679324150085449,
      "learning_rate": 0.00017960721791434163,
      "loss": 0.1043,
      "step": 1408
    },
    {
      "epoch": 0.10211254846541291,
      "grad_norm": 0.7106040716171265,
      "learning_rate": 0.0001795927241104428,
      "loss": 0.0162,
      "step": 1409
    },
    {
      "epoch": 0.10218502011088161,
      "grad_norm": 2.7904582023620605,
      "learning_rate": 0.00017957823030654397,
      "loss": 0.0859,
      "step": 1410
    },
    {
      "epoch": 0.10225749175635032,
      "grad_norm": 4.328295707702637,
      "learning_rate": 0.00017956373650264513,
      "loss": 0.1149,
      "step": 1411
    },
    {
      "epoch": 0.10232996340181903,
      "grad_norm": 2.987478256225586,
      "learning_rate": 0.00017954924269874628,
      "loss": 0.1458,
      "step": 1412
    },
    {
      "epoch": 0.10240243504728774,
      "grad_norm": 3.9319703578948975,
      "learning_rate": 0.00017953474889484747,
      "loss": 0.0853,
      "step": 1413
    },
    {
      "epoch": 0.10247490669275645,
      "grad_norm": 2.9918863773345947,
      "learning_rate": 0.00017952025509094862,
      "loss": 0.0725,
      "step": 1414
    },
    {
      "epoch": 0.10254737833822516,
      "grad_norm": 2.427933931350708,
      "learning_rate": 0.00017950576128704978,
      "loss": 0.1557,
      "step": 1415
    },
    {
      "epoch": 0.10261984998369388,
      "grad_norm": 4.93873929977417,
      "learning_rate": 0.00017949126748315096,
      "loss": 0.1042,
      "step": 1416
    },
    {
      "epoch": 0.10269232162916259,
      "grad_norm": 2.6672301292419434,
      "learning_rate": 0.00017947677367925212,
      "loss": 0.1504,
      "step": 1417
    },
    {
      "epoch": 0.1027647932746313,
      "grad_norm": 1.1666179895401,
      "learning_rate": 0.00017946227987535328,
      "loss": 0.0653,
      "step": 1418
    },
    {
      "epoch": 0.10283726492010001,
      "grad_norm": 3.0017876625061035,
      "learning_rate": 0.00017944778607145446,
      "loss": 0.1195,
      "step": 1419
    },
    {
      "epoch": 0.10290973656556872,
      "grad_norm": 2.1298553943634033,
      "learning_rate": 0.00017943329226755562,
      "loss": 0.0956,
      "step": 1420
    },
    {
      "epoch": 0.10298220821103743,
      "grad_norm": 1.5586389303207397,
      "learning_rate": 0.0001794187984636568,
      "loss": 0.0929,
      "step": 1421
    },
    {
      "epoch": 0.10305467985650614,
      "grad_norm": 0.8170949220657349,
      "learning_rate": 0.00017940430465975798,
      "loss": 0.027,
      "step": 1422
    },
    {
      "epoch": 0.10312715150197485,
      "grad_norm": 2.187546491622925,
      "learning_rate": 0.00017938981085585914,
      "loss": 0.0713,
      "step": 1423
    },
    {
      "epoch": 0.10319962314744356,
      "grad_norm": 4.171625137329102,
      "learning_rate": 0.0001793753170519603,
      "loss": 0.1468,
      "step": 1424
    },
    {
      "epoch": 0.10327209479291227,
      "grad_norm": 1.7886288166046143,
      "learning_rate": 0.00017936082324806148,
      "loss": 0.0196,
      "step": 1425
    },
    {
      "epoch": 0.10334456643838098,
      "grad_norm": 2.9838171005249023,
      "learning_rate": 0.00017934632944416264,
      "loss": 0.042,
      "step": 1426
    },
    {
      "epoch": 0.1034170380838497,
      "grad_norm": 2.468358278274536,
      "learning_rate": 0.0001793318356402638,
      "loss": 0.1092,
      "step": 1427
    },
    {
      "epoch": 0.1034895097293184,
      "grad_norm": 1.7639142274856567,
      "learning_rate": 0.00017931734183636498,
      "loss": 0.0371,
      "step": 1428
    },
    {
      "epoch": 0.10356198137478712,
      "grad_norm": 3.683804750442505,
      "learning_rate": 0.00017930284803246613,
      "loss": 0.1189,
      "step": 1429
    },
    {
      "epoch": 0.10363445302025583,
      "grad_norm": 2.5969481468200684,
      "learning_rate": 0.0001792883542285673,
      "loss": 0.0747,
      "step": 1430
    },
    {
      "epoch": 0.10370692466572454,
      "grad_norm": 2.235126495361328,
      "learning_rate": 0.00017927386042466847,
      "loss": 0.1762,
      "step": 1431
    },
    {
      "epoch": 0.10377939631119325,
      "grad_norm": 3.612267255783081,
      "learning_rate": 0.00017925936662076963,
      "loss": 0.1473,
      "step": 1432
    },
    {
      "epoch": 0.10385186795666196,
      "grad_norm": 2.67768931388855,
      "learning_rate": 0.0001792448728168708,
      "loss": 0.0855,
      "step": 1433
    },
    {
      "epoch": 0.10392433960213067,
      "grad_norm": 4.03574800491333,
      "learning_rate": 0.00017923037901297197,
      "loss": 0.2723,
      "step": 1434
    },
    {
      "epoch": 0.10399681124759938,
      "grad_norm": 1.8882958889007568,
      "learning_rate": 0.00017921588520907313,
      "loss": 0.1004,
      "step": 1435
    },
    {
      "epoch": 0.10406928289306809,
      "grad_norm": 1.9534912109375,
      "learning_rate": 0.00017920139140517428,
      "loss": 0.0836,
      "step": 1436
    },
    {
      "epoch": 0.1041417545385368,
      "grad_norm": 2.201134204864502,
      "learning_rate": 0.00017918689760127547,
      "loss": 0.1832,
      "step": 1437
    },
    {
      "epoch": 0.10421422618400551,
      "grad_norm": 1.5469753742218018,
      "learning_rate": 0.00017917240379737662,
      "loss": 0.0786,
      "step": 1438
    },
    {
      "epoch": 0.10428669782947422,
      "grad_norm": 2.235271692276001,
      "learning_rate": 0.00017915790999347778,
      "loss": 0.1571,
      "step": 1439
    },
    {
      "epoch": 0.10435916947494293,
      "grad_norm": 5.41135311126709,
      "learning_rate": 0.00017914341618957896,
      "loss": 0.2166,
      "step": 1440
    },
    {
      "epoch": 0.10443164112041164,
      "grad_norm": 2.901571750640869,
      "learning_rate": 0.00017912892238568012,
      "loss": 0.0527,
      "step": 1441
    },
    {
      "epoch": 0.10450411276588036,
      "grad_norm": 1.6404279470443726,
      "learning_rate": 0.0001791144285817813,
      "loss": 0.0865,
      "step": 1442
    },
    {
      "epoch": 0.10457658441134907,
      "grad_norm": 4.8426194190979,
      "learning_rate": 0.00017909993477788246,
      "loss": 0.0894,
      "step": 1443
    },
    {
      "epoch": 0.10464905605681778,
      "grad_norm": 2.733198881149292,
      "learning_rate": 0.00017908544097398364,
      "loss": 0.0774,
      "step": 1444
    },
    {
      "epoch": 0.10472152770228647,
      "grad_norm": 2.1610188484191895,
      "learning_rate": 0.0001790709471700848,
      "loss": 0.1005,
      "step": 1445
    },
    {
      "epoch": 0.10479399934775518,
      "grad_norm": 3.883984327316284,
      "learning_rate": 0.00017905645336618598,
      "loss": 0.08,
      "step": 1446
    },
    {
      "epoch": 0.1048664709932239,
      "grad_norm": 2.394136428833008,
      "learning_rate": 0.00017904195956228714,
      "loss": 0.0869,
      "step": 1447
    },
    {
      "epoch": 0.1049389426386926,
      "grad_norm": 2.133535385131836,
      "learning_rate": 0.0001790274657583883,
      "loss": 0.0984,
      "step": 1448
    },
    {
      "epoch": 0.10501141428416132,
      "grad_norm": 1.8566087484359741,
      "learning_rate": 0.00017901297195448948,
      "loss": 0.0826,
      "step": 1449
    },
    {
      "epoch": 0.10508388592963003,
      "grad_norm": 1.4101345539093018,
      "learning_rate": 0.00017899847815059064,
      "loss": 0.0577,
      "step": 1450
    },
    {
      "epoch": 0.10515635757509874,
      "grad_norm": 1.3976088762283325,
      "learning_rate": 0.0001789839843466918,
      "loss": 0.0852,
      "step": 1451
    },
    {
      "epoch": 0.10522882922056745,
      "grad_norm": 11.548410415649414,
      "learning_rate": 0.00017896949054279298,
      "loss": 0.4136,
      "step": 1452
    },
    {
      "epoch": 0.10530130086603616,
      "grad_norm": 2.649291753768921,
      "learning_rate": 0.00017895499673889413,
      "loss": 0.1304,
      "step": 1453
    },
    {
      "epoch": 0.10537377251150487,
      "grad_norm": 4.181845664978027,
      "learning_rate": 0.0001789405029349953,
      "loss": 0.137,
      "step": 1454
    },
    {
      "epoch": 0.10544624415697358,
      "grad_norm": 3.220891237258911,
      "learning_rate": 0.00017892600913109647,
      "loss": 0.1349,
      "step": 1455
    },
    {
      "epoch": 0.10551871580244229,
      "grad_norm": 2.2803890705108643,
      "learning_rate": 0.00017891151532719763,
      "loss": 0.0384,
      "step": 1456
    },
    {
      "epoch": 0.105591187447911,
      "grad_norm": 4.103394508361816,
      "learning_rate": 0.0001788970215232988,
      "loss": 0.1068,
      "step": 1457
    },
    {
      "epoch": 0.10566365909337971,
      "grad_norm": 1.332482099533081,
      "learning_rate": 0.00017888252771939997,
      "loss": 0.1156,
      "step": 1458
    },
    {
      "epoch": 0.10573613073884842,
      "grad_norm": 4.435896873474121,
      "learning_rate": 0.00017886803391550113,
      "loss": 0.2059,
      "step": 1459
    },
    {
      "epoch": 0.10580860238431714,
      "grad_norm": 4.604030132293701,
      "learning_rate": 0.00017885354011160228,
      "loss": 0.1773,
      "step": 1460
    },
    {
      "epoch": 0.10588107402978585,
      "grad_norm": 2.698629140853882,
      "learning_rate": 0.00017883904630770347,
      "loss": 0.176,
      "step": 1461
    },
    {
      "epoch": 0.10595354567525456,
      "grad_norm": 6.997786045074463,
      "learning_rate": 0.00017882455250380462,
      "loss": 0.1892,
      "step": 1462
    },
    {
      "epoch": 0.10602601732072327,
      "grad_norm": 3.826812505722046,
      "learning_rate": 0.00017881005869990578,
      "loss": 0.1581,
      "step": 1463
    },
    {
      "epoch": 0.10609848896619198,
      "grad_norm": 4.347752094268799,
      "learning_rate": 0.00017879556489600696,
      "loss": 0.1305,
      "step": 1464
    },
    {
      "epoch": 0.10617096061166069,
      "grad_norm": 1.7592884302139282,
      "learning_rate": 0.00017878107109210812,
      "loss": 0.1058,
      "step": 1465
    },
    {
      "epoch": 0.1062434322571294,
      "grad_norm": 2.6775763034820557,
      "learning_rate": 0.0001787665772882093,
      "loss": 0.1555,
      "step": 1466
    },
    {
      "epoch": 0.10631590390259811,
      "grad_norm": 1.3879177570343018,
      "learning_rate": 0.00017875208348431046,
      "loss": 0.093,
      "step": 1467
    },
    {
      "epoch": 0.10638837554806682,
      "grad_norm": 1.615095853805542,
      "learning_rate": 0.00017873758968041164,
      "loss": 0.1053,
      "step": 1468
    },
    {
      "epoch": 0.10646084719353553,
      "grad_norm": 4.59297513961792,
      "learning_rate": 0.0001787230958765128,
      "loss": 0.2614,
      "step": 1469
    },
    {
      "epoch": 0.10653331883900424,
      "grad_norm": 4.043720245361328,
      "learning_rate": 0.00017870860207261398,
      "loss": 0.1514,
      "step": 1470
    },
    {
      "epoch": 0.10660579048447295,
      "grad_norm": 1.1977782249450684,
      "learning_rate": 0.00017869410826871514,
      "loss": 0.0677,
      "step": 1471
    },
    {
      "epoch": 0.10667826212994166,
      "grad_norm": 1.7213075160980225,
      "learning_rate": 0.0001786796144648163,
      "loss": 0.2203,
      "step": 1472
    },
    {
      "epoch": 0.10675073377541038,
      "grad_norm": 5.116703033447266,
      "learning_rate": 0.00017866512066091748,
      "loss": 0.1787,
      "step": 1473
    },
    {
      "epoch": 0.10682320542087909,
      "grad_norm": 2.8777267932891846,
      "learning_rate": 0.00017865062685701864,
      "loss": 0.1531,
      "step": 1474
    },
    {
      "epoch": 0.1068956770663478,
      "grad_norm": 1.5375502109527588,
      "learning_rate": 0.0001786361330531198,
      "loss": 0.1259,
      "step": 1475
    },
    {
      "epoch": 0.10696814871181651,
      "grad_norm": 1.909236192703247,
      "learning_rate": 0.00017862163924922098,
      "loss": 0.1788,
      "step": 1476
    },
    {
      "epoch": 0.10704062035728522,
      "grad_norm": 1.5270717144012451,
      "learning_rate": 0.00017860714544532213,
      "loss": 0.1435,
      "step": 1477
    },
    {
      "epoch": 0.10711309200275393,
      "grad_norm": 3.8191113471984863,
      "learning_rate": 0.0001785926516414233,
      "loss": 0.1175,
      "step": 1478
    },
    {
      "epoch": 0.10718556364822264,
      "grad_norm": 1.4880633354187012,
      "learning_rate": 0.00017857815783752447,
      "loss": 0.1566,
      "step": 1479
    },
    {
      "epoch": 0.10725803529369134,
      "grad_norm": 1.1394089460372925,
      "learning_rate": 0.00017856366403362563,
      "loss": 0.0382,
      "step": 1480
    },
    {
      "epoch": 0.10733050693916005,
      "grad_norm": 4.432038307189941,
      "learning_rate": 0.0001785491702297268,
      "loss": 0.1049,
      "step": 1481
    },
    {
      "epoch": 0.10740297858462876,
      "grad_norm": 2.934234380722046,
      "learning_rate": 0.00017853467642582797,
      "loss": 0.1165,
      "step": 1482
    },
    {
      "epoch": 0.10747545023009747,
      "grad_norm": 3.864638090133667,
      "learning_rate": 0.00017852018262192913,
      "loss": 0.2617,
      "step": 1483
    },
    {
      "epoch": 0.10754792187556618,
      "grad_norm": 1.7729626893997192,
      "learning_rate": 0.00017850568881803028,
      "loss": 0.0328,
      "step": 1484
    },
    {
      "epoch": 0.10762039352103489,
      "grad_norm": 1.366479516029358,
      "learning_rate": 0.00017849119501413147,
      "loss": 0.079,
      "step": 1485
    },
    {
      "epoch": 0.1076928651665036,
      "grad_norm": 1.3012889623641968,
      "learning_rate": 0.00017847670121023262,
      "loss": 0.0741,
      "step": 1486
    },
    {
      "epoch": 0.10776533681197231,
      "grad_norm": 2.0729382038116455,
      "learning_rate": 0.00017846220740633378,
      "loss": 0.1377,
      "step": 1487
    },
    {
      "epoch": 0.10783780845744102,
      "grad_norm": 0.889324963092804,
      "learning_rate": 0.00017844771360243496,
      "loss": 0.0206,
      "step": 1488
    },
    {
      "epoch": 0.10791028010290973,
      "grad_norm": 1.674278974533081,
      "learning_rate": 0.00017843321979853612,
      "loss": 0.0347,
      "step": 1489
    },
    {
      "epoch": 0.10798275174837844,
      "grad_norm": 8.459722518920898,
      "learning_rate": 0.0001784187259946373,
      "loss": 0.184,
      "step": 1490
    },
    {
      "epoch": 0.10805522339384716,
      "grad_norm": 3.2062296867370605,
      "learning_rate": 0.0001784042321907385,
      "loss": 0.2211,
      "step": 1491
    },
    {
      "epoch": 0.10812769503931587,
      "grad_norm": 5.580251216888428,
      "learning_rate": 0.00017838973838683964,
      "loss": 0.3802,
      "step": 1492
    },
    {
      "epoch": 0.10820016668478458,
      "grad_norm": 2.985450506210327,
      "learning_rate": 0.0001783752445829408,
      "loss": 0.1496,
      "step": 1493
    },
    {
      "epoch": 0.10827263833025329,
      "grad_norm": 7.061200141906738,
      "learning_rate": 0.00017836075077904198,
      "loss": 0.2015,
      "step": 1494
    },
    {
      "epoch": 0.108345109975722,
      "grad_norm": 0.7421994805335999,
      "learning_rate": 0.00017834625697514314,
      "loss": 0.0318,
      "step": 1495
    },
    {
      "epoch": 0.10841758162119071,
      "grad_norm": 2.0049474239349365,
      "learning_rate": 0.0001783317631712443,
      "loss": 0.0936,
      "step": 1496
    },
    {
      "epoch": 0.10849005326665942,
      "grad_norm": 3.9557900428771973,
      "learning_rate": 0.00017831726936734548,
      "loss": 0.1638,
      "step": 1497
    },
    {
      "epoch": 0.10856252491212813,
      "grad_norm": 3.4275341033935547,
      "learning_rate": 0.00017830277556344664,
      "loss": 0.2468,
      "step": 1498
    },
    {
      "epoch": 0.10863499655759684,
      "grad_norm": 3.0864615440368652,
      "learning_rate": 0.0001782882817595478,
      "loss": 0.1522,
      "step": 1499
    },
    {
      "epoch": 0.10870746820306555,
      "grad_norm": 4.958225727081299,
      "learning_rate": 0.00017827378795564898,
      "loss": 0.1731,
      "step": 1500
    },
    {
      "epoch": 0.10877993984853426,
      "grad_norm": 4.006035327911377,
      "learning_rate": 0.00017825929415175013,
      "loss": 0.2214,
      "step": 1501
    },
    {
      "epoch": 0.10885241149400297,
      "grad_norm": 1.2064381837844849,
      "learning_rate": 0.0001782448003478513,
      "loss": 0.0472,
      "step": 1502
    },
    {
      "epoch": 0.10892488313947168,
      "grad_norm": 2.1446831226348877,
      "learning_rate": 0.00017823030654395247,
      "loss": 0.1062,
      "step": 1503
    },
    {
      "epoch": 0.1089973547849404,
      "grad_norm": 1.578149437904358,
      "learning_rate": 0.00017821581274005363,
      "loss": 0.0981,
      "step": 1504
    },
    {
      "epoch": 0.1090698264304091,
      "grad_norm": 1.183034896850586,
      "learning_rate": 0.00017820131893615479,
      "loss": 0.1175,
      "step": 1505
    },
    {
      "epoch": 0.10914229807587782,
      "grad_norm": 5.482789993286133,
      "learning_rate": 0.00017818682513225597,
      "loss": 0.1253,
      "step": 1506
    },
    {
      "epoch": 0.10921476972134653,
      "grad_norm": 1.6043341159820557,
      "learning_rate": 0.00017817233132835713,
      "loss": 0.0509,
      "step": 1507
    },
    {
      "epoch": 0.10928724136681524,
      "grad_norm": 1.7224210500717163,
      "learning_rate": 0.00017815783752445828,
      "loss": 0.0741,
      "step": 1508
    },
    {
      "epoch": 0.10935971301228395,
      "grad_norm": 5.30763578414917,
      "learning_rate": 0.00017814334372055947,
      "loss": 0.1364,
      "step": 1509
    },
    {
      "epoch": 0.10943218465775266,
      "grad_norm": 4.648036003112793,
      "learning_rate": 0.00017812884991666062,
      "loss": 0.2564,
      "step": 1510
    },
    {
      "epoch": 0.10950465630322137,
      "grad_norm": 7.765186309814453,
      "learning_rate": 0.0001781143561127618,
      "loss": 0.1364,
      "step": 1511
    },
    {
      "epoch": 0.10957712794869008,
      "grad_norm": 0.9734866619110107,
      "learning_rate": 0.00017809986230886296,
      "loss": 0.0449,
      "step": 1512
    },
    {
      "epoch": 0.10964959959415879,
      "grad_norm": 3.2808265686035156,
      "learning_rate": 0.00017808536850496415,
      "loss": 0.1334,
      "step": 1513
    },
    {
      "epoch": 0.10972207123962749,
      "grad_norm": 3.2471156120300293,
      "learning_rate": 0.0001780708747010653,
      "loss": 0.242,
      "step": 1514
    },
    {
      "epoch": 0.1097945428850962,
      "grad_norm": 1.1819053888320923,
      "learning_rate": 0.0001780563808971665,
      "loss": 0.1006,
      "step": 1515
    },
    {
      "epoch": 0.10986701453056491,
      "grad_norm": 4.3747076988220215,
      "learning_rate": 0.00017804188709326764,
      "loss": 0.2097,
      "step": 1516
    },
    {
      "epoch": 0.10993948617603362,
      "grad_norm": 5.55285120010376,
      "learning_rate": 0.0001780273932893688,
      "loss": 0.3172,
      "step": 1517
    },
    {
      "epoch": 0.11001195782150233,
      "grad_norm": 2.322460889816284,
      "learning_rate": 0.00017801289948546998,
      "loss": 0.1587,
      "step": 1518
    },
    {
      "epoch": 0.11008442946697104,
      "grad_norm": 2.1179864406585693,
      "learning_rate": 0.00017799840568157114,
      "loss": 0.0864,
      "step": 1519
    },
    {
      "epoch": 0.11015690111243975,
      "grad_norm": 2.6656718254089355,
      "learning_rate": 0.0001779839118776723,
      "loss": 0.2063,
      "step": 1520
    },
    {
      "epoch": 0.11022937275790846,
      "grad_norm": 1.4348526000976562,
      "learning_rate": 0.00017796941807377348,
      "loss": 0.1004,
      "step": 1521
    },
    {
      "epoch": 0.11030184440337717,
      "grad_norm": 4.630540370941162,
      "learning_rate": 0.00017795492426987464,
      "loss": 0.3888,
      "step": 1522
    },
    {
      "epoch": 0.11037431604884589,
      "grad_norm": 3.5225706100463867,
      "learning_rate": 0.0001779404304659758,
      "loss": 0.1136,
      "step": 1523
    },
    {
      "epoch": 0.1104467876943146,
      "grad_norm": 2.001279830932617,
      "learning_rate": 0.00017792593666207698,
      "loss": 0.0914,
      "step": 1524
    },
    {
      "epoch": 0.11051925933978331,
      "grad_norm": 2.6506834030151367,
      "learning_rate": 0.00017791144285817813,
      "loss": 0.1261,
      "step": 1525
    },
    {
      "epoch": 0.11059173098525202,
      "grad_norm": 1.934295654296875,
      "learning_rate": 0.0001778969490542793,
      "loss": 0.1255,
      "step": 1526
    },
    {
      "epoch": 0.11066420263072073,
      "grad_norm": 3.3425722122192383,
      "learning_rate": 0.00017788245525038047,
      "loss": 0.1176,
      "step": 1527
    },
    {
      "epoch": 0.11073667427618944,
      "grad_norm": 2.402106285095215,
      "learning_rate": 0.00017786796144648163,
      "loss": 0.1037,
      "step": 1528
    },
    {
      "epoch": 0.11080914592165815,
      "grad_norm": 2.238618850708008,
      "learning_rate": 0.00017785346764258279,
      "loss": 0.1618,
      "step": 1529
    },
    {
      "epoch": 0.11088161756712686,
      "grad_norm": 0.6464071869850159,
      "learning_rate": 0.00017783897383868397,
      "loss": 0.0267,
      "step": 1530
    },
    {
      "epoch": 0.11095408921259557,
      "grad_norm": 2.626547336578369,
      "learning_rate": 0.00017782448003478513,
      "loss": 0.0848,
      "step": 1531
    },
    {
      "epoch": 0.11102656085806428,
      "grad_norm": 1.226782202720642,
      "learning_rate": 0.00017780998623088628,
      "loss": 0.0806,
      "step": 1532
    },
    {
      "epoch": 0.111099032503533,
      "grad_norm": 1.5287060737609863,
      "learning_rate": 0.00017779549242698747,
      "loss": 0.0659,
      "step": 1533
    },
    {
      "epoch": 0.1111715041490017,
      "grad_norm": 3.3525550365448,
      "learning_rate": 0.00017778099862308862,
      "loss": 0.1443,
      "step": 1534
    },
    {
      "epoch": 0.11124397579447041,
      "grad_norm": 2.18559193611145,
      "learning_rate": 0.0001777665048191898,
      "loss": 0.0948,
      "step": 1535
    },
    {
      "epoch": 0.11131644743993913,
      "grad_norm": 3.4976818561553955,
      "learning_rate": 0.00017775201101529096,
      "loss": 0.0993,
      "step": 1536
    },
    {
      "epoch": 0.11138891908540784,
      "grad_norm": 1.7583643198013306,
      "learning_rate": 0.00017773751721139215,
      "loss": 0.1059,
      "step": 1537
    },
    {
      "epoch": 0.11146139073087655,
      "grad_norm": 1.0931416749954224,
      "learning_rate": 0.0001777230234074933,
      "loss": 0.0517,
      "step": 1538
    },
    {
      "epoch": 0.11153386237634526,
      "grad_norm": 4.877151012420654,
      "learning_rate": 0.00017770852960359449,
      "loss": 0.2148,
      "step": 1539
    },
    {
      "epoch": 0.11160633402181397,
      "grad_norm": 1.0812971591949463,
      "learning_rate": 0.00017769403579969564,
      "loss": 0.0385,
      "step": 1540
    },
    {
      "epoch": 0.11167880566728268,
      "grad_norm": 2.2674190998077393,
      "learning_rate": 0.0001776795419957968,
      "loss": 0.0725,
      "step": 1541
    },
    {
      "epoch": 0.11175127731275139,
      "grad_norm": 5.928223133087158,
      "learning_rate": 0.00017766504819189798,
      "loss": 0.2403,
      "step": 1542
    },
    {
      "epoch": 0.1118237489582201,
      "grad_norm": 3.0391595363616943,
      "learning_rate": 0.00017765055438799914,
      "loss": 0.1252,
      "step": 1543
    },
    {
      "epoch": 0.11189622060368881,
      "grad_norm": 4.392242908477783,
      "learning_rate": 0.00017763606058410032,
      "loss": 0.1365,
      "step": 1544
    },
    {
      "epoch": 0.11196869224915752,
      "grad_norm": 3.0213375091552734,
      "learning_rate": 0.00017762156678020148,
      "loss": 0.1067,
      "step": 1545
    },
    {
      "epoch": 0.11204116389462623,
      "grad_norm": 6.596036434173584,
      "learning_rate": 0.00017760707297630264,
      "loss": 0.1812,
      "step": 1546
    },
    {
      "epoch": 0.11211363554009494,
      "grad_norm": 3.2065677642822266,
      "learning_rate": 0.00017759257917240382,
      "loss": 0.1032,
      "step": 1547
    },
    {
      "epoch": 0.11218610718556365,
      "grad_norm": 3.1385626792907715,
      "learning_rate": 0.00017757808536850498,
      "loss": 0.1168,
      "step": 1548
    },
    {
      "epoch": 0.11225857883103235,
      "grad_norm": 2.1660709381103516,
      "learning_rate": 0.00017756359156460613,
      "loss": 0.1509,
      "step": 1549
    },
    {
      "epoch": 0.11233105047650106,
      "grad_norm": 2.9579050540924072,
      "learning_rate": 0.00017754909776070732,
      "loss": 0.1248,
      "step": 1550
    },
    {
      "epoch": 0.11240352212196977,
      "grad_norm": 6.568997383117676,
      "learning_rate": 0.00017753460395680847,
      "loss": 0.1852,
      "step": 1551
    },
    {
      "epoch": 0.11247599376743848,
      "grad_norm": 3.2865185737609863,
      "learning_rate": 0.00017752011015290963,
      "loss": 0.1512,
      "step": 1552
    },
    {
      "epoch": 0.1125484654129072,
      "grad_norm": 7.908718585968018,
      "learning_rate": 0.0001775056163490108,
      "loss": 0.2436,
      "step": 1553
    },
    {
      "epoch": 0.1126209370583759,
      "grad_norm": 3.6280226707458496,
      "learning_rate": 0.00017749112254511197,
      "loss": 0.0982,
      "step": 1554
    },
    {
      "epoch": 0.11269340870384462,
      "grad_norm": 3.0702638626098633,
      "learning_rate": 0.00017747662874121313,
      "loss": 0.0749,
      "step": 1555
    },
    {
      "epoch": 0.11276588034931333,
      "grad_norm": 1.874761700630188,
      "learning_rate": 0.0001774621349373143,
      "loss": 0.1095,
      "step": 1556
    },
    {
      "epoch": 0.11283835199478204,
      "grad_norm": 4.235588550567627,
      "learning_rate": 0.00017744764113341547,
      "loss": 0.268,
      "step": 1557
    },
    {
      "epoch": 0.11291082364025075,
      "grad_norm": 2.2437212467193604,
      "learning_rate": 0.00017743314732951665,
      "loss": 0.0875,
      "step": 1558
    },
    {
      "epoch": 0.11298329528571946,
      "grad_norm": 2.0112924575805664,
      "learning_rate": 0.0001774186535256178,
      "loss": 0.1361,
      "step": 1559
    },
    {
      "epoch": 0.11305576693118817,
      "grad_norm": 0.9667683243751526,
      "learning_rate": 0.000177404159721719,
      "loss": 0.0288,
      "step": 1560
    },
    {
      "epoch": 0.11312823857665688,
      "grad_norm": 2.3194360733032227,
      "learning_rate": 0.00017738966591782015,
      "loss": 0.201,
      "step": 1561
    },
    {
      "epoch": 0.11320071022212559,
      "grad_norm": 1.7738494873046875,
      "learning_rate": 0.00017737517211392133,
      "loss": 0.1988,
      "step": 1562
    },
    {
      "epoch": 0.1132731818675943,
      "grad_norm": 3.507270574569702,
      "learning_rate": 0.00017736067831002249,
      "loss": 0.1746,
      "step": 1563
    },
    {
      "epoch": 0.11334565351306301,
      "grad_norm": 2.6934638023376465,
      "learning_rate": 0.00017734618450612364,
      "loss": 0.1448,
      "step": 1564
    },
    {
      "epoch": 0.11341812515853172,
      "grad_norm": 1.489296555519104,
      "learning_rate": 0.00017733169070222483,
      "loss": 0.1348,
      "step": 1565
    },
    {
      "epoch": 0.11349059680400043,
      "grad_norm": 2.2641546726226807,
      "learning_rate": 0.00017731719689832598,
      "loss": 0.0948,
      "step": 1566
    },
    {
      "epoch": 0.11356306844946915,
      "grad_norm": 1.543896198272705,
      "learning_rate": 0.00017730270309442714,
      "loss": 0.1402,
      "step": 1567
    },
    {
      "epoch": 0.11363554009493786,
      "grad_norm": 1.453232765197754,
      "learning_rate": 0.00017728820929052832,
      "loss": 0.108,
      "step": 1568
    },
    {
      "epoch": 0.11370801174040657,
      "grad_norm": 3.1686391830444336,
      "learning_rate": 0.00017727371548662948,
      "loss": 0.2026,
      "step": 1569
    },
    {
      "epoch": 0.11378048338587528,
      "grad_norm": 0.9698818325996399,
      "learning_rate": 0.00017725922168273064,
      "loss": 0.05,
      "step": 1570
    },
    {
      "epoch": 0.11385295503134399,
      "grad_norm": 1.411539077758789,
      "learning_rate": 0.00017724472787883182,
      "loss": 0.0883,
      "step": 1571
    },
    {
      "epoch": 0.1139254266768127,
      "grad_norm": 3.2110934257507324,
      "learning_rate": 0.00017723023407493298,
      "loss": 0.1124,
      "step": 1572
    },
    {
      "epoch": 0.11399789832228141,
      "grad_norm": 1.2364081144332886,
      "learning_rate": 0.00017721574027103413,
      "loss": 0.0598,
      "step": 1573
    },
    {
      "epoch": 0.11407036996775012,
      "grad_norm": 4.136524200439453,
      "learning_rate": 0.00017720124646713532,
      "loss": 0.2482,
      "step": 1574
    },
    {
      "epoch": 0.11414284161321883,
      "grad_norm": 0.6211189031600952,
      "learning_rate": 0.00017718675266323647,
      "loss": 0.027,
      "step": 1575
    },
    {
      "epoch": 0.11421531325868754,
      "grad_norm": 0.506069540977478,
      "learning_rate": 0.00017717225885933763,
      "loss": 0.0193,
      "step": 1576
    },
    {
      "epoch": 0.11428778490415625,
      "grad_norm": 1.2020399570465088,
      "learning_rate": 0.0001771577650554388,
      "loss": 0.0515,
      "step": 1577
    },
    {
      "epoch": 0.11436025654962496,
      "grad_norm": 5.022972106933594,
      "learning_rate": 0.00017714327125153997,
      "loss": 0.167,
      "step": 1578
    },
    {
      "epoch": 0.11443272819509367,
      "grad_norm": 2.280949831008911,
      "learning_rate": 0.00017712877744764112,
      "loss": 0.1058,
      "step": 1579
    },
    {
      "epoch": 0.11450519984056239,
      "grad_norm": 4.428574562072754,
      "learning_rate": 0.0001771142836437423,
      "loss": 0.15,
      "step": 1580
    },
    {
      "epoch": 0.1145776714860311,
      "grad_norm": 1.7225252389907837,
      "learning_rate": 0.00017709978983984347,
      "loss": 0.0359,
      "step": 1581
    },
    {
      "epoch": 0.11465014313149981,
      "grad_norm": 1.1917080879211426,
      "learning_rate": 0.00017708529603594465,
      "loss": 0.0473,
      "step": 1582
    },
    {
      "epoch": 0.11472261477696852,
      "grad_norm": 3.1302008628845215,
      "learning_rate": 0.0001770708022320458,
      "loss": 0.073,
      "step": 1583
    },
    {
      "epoch": 0.11479508642243721,
      "grad_norm": 3.3622305393218994,
      "learning_rate": 0.000177056308428147,
      "loss": 0.2072,
      "step": 1584
    },
    {
      "epoch": 0.11486755806790593,
      "grad_norm": 1.5713200569152832,
      "learning_rate": 0.00017704181462424815,
      "loss": 0.1041,
      "step": 1585
    },
    {
      "epoch": 0.11494002971337464,
      "grad_norm": 4.126971244812012,
      "learning_rate": 0.00017702732082034933,
      "loss": 0.1172,
      "step": 1586
    },
    {
      "epoch": 0.11501250135884335,
      "grad_norm": 2.464811325073242,
      "learning_rate": 0.00017701282701645049,
      "loss": 0.0479,
      "step": 1587
    },
    {
      "epoch": 0.11508497300431206,
      "grad_norm": 5.385898113250732,
      "learning_rate": 0.00017699833321255164,
      "loss": 0.1584,
      "step": 1588
    },
    {
      "epoch": 0.11515744464978077,
      "grad_norm": 3.916851758956909,
      "learning_rate": 0.00017698383940865283,
      "loss": 0.1668,
      "step": 1589
    },
    {
      "epoch": 0.11522991629524948,
      "grad_norm": 2.6882503032684326,
      "learning_rate": 0.00017696934560475398,
      "loss": 0.206,
      "step": 1590
    },
    {
      "epoch": 0.11530238794071819,
      "grad_norm": 2.6727421283721924,
      "learning_rate": 0.00017695485180085514,
      "loss": 0.1587,
      "step": 1591
    },
    {
      "epoch": 0.1153748595861869,
      "grad_norm": 6.665027141571045,
      "learning_rate": 0.00017694035799695632,
      "loss": 0.2204,
      "step": 1592
    },
    {
      "epoch": 0.11544733123165561,
      "grad_norm": 2.260423183441162,
      "learning_rate": 0.00017692586419305748,
      "loss": 0.0975,
      "step": 1593
    },
    {
      "epoch": 0.11551980287712432,
      "grad_norm": 2.9413838386535645,
      "learning_rate": 0.00017691137038915863,
      "loss": 0.1659,
      "step": 1594
    },
    {
      "epoch": 0.11559227452259303,
      "grad_norm": 1.8378117084503174,
      "learning_rate": 0.00017689687658525982,
      "loss": 0.147,
      "step": 1595
    },
    {
      "epoch": 0.11566474616806174,
      "grad_norm": 1.3948098421096802,
      "learning_rate": 0.00017688238278136097,
      "loss": 0.0597,
      "step": 1596
    },
    {
      "epoch": 0.11573721781353045,
      "grad_norm": 1.3161427974700928,
      "learning_rate": 0.00017686788897746213,
      "loss": 0.0985,
      "step": 1597
    },
    {
      "epoch": 0.11580968945899917,
      "grad_norm": 5.032840728759766,
      "learning_rate": 0.00017685339517356332,
      "loss": 0.1388,
      "step": 1598
    },
    {
      "epoch": 0.11588216110446788,
      "grad_norm": 1.2625901699066162,
      "learning_rate": 0.00017683890136966447,
      "loss": 0.0843,
      "step": 1599
    },
    {
      "epoch": 0.11595463274993659,
      "grad_norm": 1.3747589588165283,
      "learning_rate": 0.00017682440756576563,
      "loss": 0.0872,
      "step": 1600
    },
    {
      "epoch": 0.1160271043954053,
      "grad_norm": 1.653609275817871,
      "learning_rate": 0.0001768099137618668,
      "loss": 0.153,
      "step": 1601
    },
    {
      "epoch": 0.11609957604087401,
      "grad_norm": 3.7951674461364746,
      "learning_rate": 0.00017679541995796797,
      "loss": 0.1817,
      "step": 1602
    },
    {
      "epoch": 0.11617204768634272,
      "grad_norm": 2.5156450271606445,
      "learning_rate": 0.00017678092615406912,
      "loss": 0.1293,
      "step": 1603
    },
    {
      "epoch": 0.11624451933181143,
      "grad_norm": 3.1307806968688965,
      "learning_rate": 0.0001767664323501703,
      "loss": 0.1696,
      "step": 1604
    },
    {
      "epoch": 0.11631699097728014,
      "grad_norm": 2.4619479179382324,
      "learning_rate": 0.0001767519385462715,
      "loss": 0.2295,
      "step": 1605
    },
    {
      "epoch": 0.11638946262274885,
      "grad_norm": 2.2312381267547607,
      "learning_rate": 0.00017673744474237265,
      "loss": 0.2191,
      "step": 1606
    },
    {
      "epoch": 0.11646193426821756,
      "grad_norm": 5.62612247467041,
      "learning_rate": 0.00017672295093847383,
      "loss": 0.1812,
      "step": 1607
    },
    {
      "epoch": 0.11653440591368627,
      "grad_norm": 3.702608108520508,
      "learning_rate": 0.000176708457134575,
      "loss": 0.4065,
      "step": 1608
    },
    {
      "epoch": 0.11660687755915498,
      "grad_norm": 2.9387333393096924,
      "learning_rate": 0.00017669396333067614,
      "loss": 0.1392,
      "step": 1609
    },
    {
      "epoch": 0.1166793492046237,
      "grad_norm": 3.248476266860962,
      "learning_rate": 0.00017667946952677733,
      "loss": 0.1654,
      "step": 1610
    },
    {
      "epoch": 0.1167518208500924,
      "grad_norm": 3.243828296661377,
      "learning_rate": 0.00017666497572287848,
      "loss": 0.0663,
      "step": 1611
    },
    {
      "epoch": 0.11682429249556112,
      "grad_norm": 2.2754757404327393,
      "learning_rate": 0.00017665048191897964,
      "loss": 0.0832,
      "step": 1612
    },
    {
      "epoch": 0.11689676414102983,
      "grad_norm": 1.6491669416427612,
      "learning_rate": 0.00017663598811508082,
      "loss": 0.1404,
      "step": 1613
    },
    {
      "epoch": 0.11696923578649854,
      "grad_norm": 3.501464366912842,
      "learning_rate": 0.00017662149431118198,
      "loss": 0.1526,
      "step": 1614
    },
    {
      "epoch": 0.11704170743196725,
      "grad_norm": 3.0109946727752686,
      "learning_rate": 0.00017660700050728314,
      "loss": 0.14,
      "step": 1615
    },
    {
      "epoch": 0.11711417907743596,
      "grad_norm": 5.039720058441162,
      "learning_rate": 0.00017659250670338432,
      "loss": 0.2401,
      "step": 1616
    },
    {
      "epoch": 0.11718665072290467,
      "grad_norm": 3.8434836864471436,
      "learning_rate": 0.00017657801289948548,
      "loss": 0.1163,
      "step": 1617
    },
    {
      "epoch": 0.11725912236837338,
      "grad_norm": 1.9629884958267212,
      "learning_rate": 0.00017656351909558663,
      "loss": 0.1895,
      "step": 1618
    },
    {
      "epoch": 0.11733159401384208,
      "grad_norm": 3.905369997024536,
      "learning_rate": 0.00017654902529168782,
      "loss": 0.0923,
      "step": 1619
    },
    {
      "epoch": 0.11740406565931079,
      "grad_norm": 2.626737356185913,
      "learning_rate": 0.00017653453148778897,
      "loss": 0.1493,
      "step": 1620
    },
    {
      "epoch": 0.1174765373047795,
      "grad_norm": 5.129194736480713,
      "learning_rate": 0.00017652003768389013,
      "loss": 0.2454,
      "step": 1621
    },
    {
      "epoch": 0.11754900895024821,
      "grad_norm": 1.6186915636062622,
      "learning_rate": 0.00017650554387999131,
      "loss": 0.0912,
      "step": 1622
    },
    {
      "epoch": 0.11762148059571692,
      "grad_norm": 2.639380693435669,
      "learning_rate": 0.00017649105007609247,
      "loss": 0.0823,
      "step": 1623
    },
    {
      "epoch": 0.11769395224118563,
      "grad_norm": 0.5760453939437866,
      "learning_rate": 0.00017647655627219363,
      "loss": 0.0184,
      "step": 1624
    },
    {
      "epoch": 0.11776642388665434,
      "grad_norm": 3.7107222080230713,
      "learning_rate": 0.0001764620624682948,
      "loss": 0.0765,
      "step": 1625
    },
    {
      "epoch": 0.11783889553212305,
      "grad_norm": 1.539233922958374,
      "learning_rate": 0.00017644756866439597,
      "loss": 0.0915,
      "step": 1626
    },
    {
      "epoch": 0.11791136717759176,
      "grad_norm": 3.2757325172424316,
      "learning_rate": 0.00017643307486049715,
      "loss": 0.1121,
      "step": 1627
    },
    {
      "epoch": 0.11798383882306047,
      "grad_norm": 2.395179271697998,
      "learning_rate": 0.0001764185810565983,
      "loss": 0.1141,
      "step": 1628
    },
    {
      "epoch": 0.11805631046852919,
      "grad_norm": 2.525230884552002,
      "learning_rate": 0.0001764040872526995,
      "loss": 0.0943,
      "step": 1629
    },
    {
      "epoch": 0.1181287821139979,
      "grad_norm": 3.077521562576294,
      "learning_rate": 0.00017638959344880065,
      "loss": 0.1743,
      "step": 1630
    },
    {
      "epoch": 0.1182012537594666,
      "grad_norm": 3.585824489593506,
      "learning_rate": 0.00017637509964490183,
      "loss": 0.1161,
      "step": 1631
    },
    {
      "epoch": 0.11827372540493532,
      "grad_norm": 3.8431711196899414,
      "learning_rate": 0.000176360605841003,
      "loss": 0.0871,
      "step": 1632
    },
    {
      "epoch": 0.11834619705040403,
      "grad_norm": 3.55888032913208,
      "learning_rate": 0.00017634611203710414,
      "loss": 0.2127,
      "step": 1633
    },
    {
      "epoch": 0.11841866869587274,
      "grad_norm": 8.263312339782715,
      "learning_rate": 0.00017633161823320533,
      "loss": 0.1736,
      "step": 1634
    },
    {
      "epoch": 0.11849114034134145,
      "grad_norm": 3.040611505508423,
      "learning_rate": 0.00017631712442930648,
      "loss": 0.1246,
      "step": 1635
    },
    {
      "epoch": 0.11856361198681016,
      "grad_norm": 3.119370222091675,
      "learning_rate": 0.00017630263062540764,
      "loss": 0.1584,
      "step": 1636
    },
    {
      "epoch": 0.11863608363227887,
      "grad_norm": 2.373910903930664,
      "learning_rate": 0.00017628813682150882,
      "loss": 0.1101,
      "step": 1637
    },
    {
      "epoch": 0.11870855527774758,
      "grad_norm": 2.3982651233673096,
      "learning_rate": 0.00017627364301760998,
      "loss": 0.1979,
      "step": 1638
    },
    {
      "epoch": 0.11878102692321629,
      "grad_norm": 1.4144999980926514,
      "learning_rate": 0.00017625914921371114,
      "loss": 0.0615,
      "step": 1639
    },
    {
      "epoch": 0.118853498568685,
      "grad_norm": 1.444650411605835,
      "learning_rate": 0.00017624465540981232,
      "loss": 0.0876,
      "step": 1640
    },
    {
      "epoch": 0.11892597021415371,
      "grad_norm": 2.2052783966064453,
      "learning_rate": 0.00017623016160591348,
      "loss": 0.1132,
      "step": 1641
    },
    {
      "epoch": 0.11899844185962243,
      "grad_norm": 1.4241050481796265,
      "learning_rate": 0.00017621566780201463,
      "loss": 0.0775,
      "step": 1642
    },
    {
      "epoch": 0.11907091350509114,
      "grad_norm": 2.8850789070129395,
      "learning_rate": 0.00017620117399811582,
      "loss": 0.0577,
      "step": 1643
    },
    {
      "epoch": 0.11914338515055985,
      "grad_norm": 1.6953163146972656,
      "learning_rate": 0.00017618668019421697,
      "loss": 0.1069,
      "step": 1644
    },
    {
      "epoch": 0.11921585679602856,
      "grad_norm": 4.694288730621338,
      "learning_rate": 0.00017617218639031813,
      "loss": 0.2839,
      "step": 1645
    },
    {
      "epoch": 0.11928832844149727,
      "grad_norm": 4.132978916168213,
      "learning_rate": 0.00017615769258641931,
      "loss": 0.27,
      "step": 1646
    },
    {
      "epoch": 0.11936080008696598,
      "grad_norm": 2.4784319400787354,
      "learning_rate": 0.00017614319878252047,
      "loss": 0.0539,
      "step": 1647
    },
    {
      "epoch": 0.11943327173243469,
      "grad_norm": 1.9715969562530518,
      "learning_rate": 0.00017612870497862163,
      "loss": 0.0646,
      "step": 1648
    },
    {
      "epoch": 0.1195057433779034,
      "grad_norm": 3.22529935836792,
      "learning_rate": 0.0001761142111747228,
      "loss": 0.1992,
      "step": 1649
    },
    {
      "epoch": 0.11957821502337211,
      "grad_norm": 2.556866407394409,
      "learning_rate": 0.00017609971737082397,
      "loss": 0.12,
      "step": 1650
    },
    {
      "epoch": 0.11965068666884082,
      "grad_norm": 3.7435460090637207,
      "learning_rate": 0.00017608522356692515,
      "loss": 0.205,
      "step": 1651
    },
    {
      "epoch": 0.11972315831430953,
      "grad_norm": 7.430492877960205,
      "learning_rate": 0.0001760707297630263,
      "loss": 0.1851,
      "step": 1652
    },
    {
      "epoch": 0.11979562995977824,
      "grad_norm": 1.2657581567764282,
      "learning_rate": 0.0001760562359591275,
      "loss": 0.1146,
      "step": 1653
    },
    {
      "epoch": 0.11986810160524694,
      "grad_norm": 2.0733747482299805,
      "learning_rate": 0.00017604174215522865,
      "loss": 0.1197,
      "step": 1654
    },
    {
      "epoch": 0.11994057325071565,
      "grad_norm": 1.525038480758667,
      "learning_rate": 0.00017602724835132983,
      "loss": 0.0783,
      "step": 1655
    },
    {
      "epoch": 0.12001304489618436,
      "grad_norm": 2.698976993560791,
      "learning_rate": 0.000176012754547431,
      "loss": 0.208,
      "step": 1656
    },
    {
      "epoch": 0.12008551654165307,
      "grad_norm": 1.9018900394439697,
      "learning_rate": 0.00017599826074353214,
      "loss": 0.0392,
      "step": 1657
    },
    {
      "epoch": 0.12015798818712178,
      "grad_norm": 3.5739080905914307,
      "learning_rate": 0.00017598376693963333,
      "loss": 0.1026,
      "step": 1658
    },
    {
      "epoch": 0.1202304598325905,
      "grad_norm": 2.641136407852173,
      "learning_rate": 0.00017596927313573448,
      "loss": 0.1514,
      "step": 1659
    },
    {
      "epoch": 0.1203029314780592,
      "grad_norm": 4.1366658210754395,
      "learning_rate": 0.00017595477933183564,
      "loss": 0.1952,
      "step": 1660
    },
    {
      "epoch": 0.12037540312352792,
      "grad_norm": 1.040632963180542,
      "learning_rate": 0.00017594028552793682,
      "loss": 0.066,
      "step": 1661
    },
    {
      "epoch": 0.12044787476899663,
      "grad_norm": 3.633643627166748,
      "learning_rate": 0.00017592579172403798,
      "loss": 0.2117,
      "step": 1662
    },
    {
      "epoch": 0.12052034641446534,
      "grad_norm": 2.6927740573883057,
      "learning_rate": 0.00017591129792013914,
      "loss": 0.1362,
      "step": 1663
    },
    {
      "epoch": 0.12059281805993405,
      "grad_norm": 22.34673500061035,
      "learning_rate": 0.00017589680411624032,
      "loss": 0.1582,
      "step": 1664
    },
    {
      "epoch": 0.12066528970540276,
      "grad_norm": 5.024310111999512,
      "learning_rate": 0.00017588231031234148,
      "loss": 0.215,
      "step": 1665
    },
    {
      "epoch": 0.12073776135087147,
      "grad_norm": 1.1186116933822632,
      "learning_rate": 0.00017586781650844263,
      "loss": 0.0536,
      "step": 1666
    },
    {
      "epoch": 0.12081023299634018,
      "grad_norm": 2.0581064224243164,
      "learning_rate": 0.00017585332270454382,
      "loss": 0.0572,
      "step": 1667
    },
    {
      "epoch": 0.12088270464180889,
      "grad_norm": 2.6630518436431885,
      "learning_rate": 0.00017583882890064497,
      "loss": 0.1477,
      "step": 1668
    },
    {
      "epoch": 0.1209551762872776,
      "grad_norm": 2.4578864574432373,
      "learning_rate": 0.00017582433509674613,
      "loss": 0.1699,
      "step": 1669
    },
    {
      "epoch": 0.12102764793274631,
      "grad_norm": 3.810932159423828,
      "learning_rate": 0.00017580984129284731,
      "loss": 0.0598,
      "step": 1670
    },
    {
      "epoch": 0.12110011957821502,
      "grad_norm": 2.0148632526397705,
      "learning_rate": 0.00017579534748894847,
      "loss": 0.1616,
      "step": 1671
    },
    {
      "epoch": 0.12117259122368373,
      "grad_norm": 2.3317973613739014,
      "learning_rate": 0.00017578085368504963,
      "loss": 0.1046,
      "step": 1672
    },
    {
      "epoch": 0.12124506286915245,
      "grad_norm": 2.906850814819336,
      "learning_rate": 0.0001757663598811508,
      "loss": 0.1139,
      "step": 1673
    },
    {
      "epoch": 0.12131753451462116,
      "grad_norm": 2.8298146724700928,
      "learning_rate": 0.000175751866077252,
      "loss": 0.0877,
      "step": 1674
    },
    {
      "epoch": 0.12139000616008987,
      "grad_norm": 4.528700351715088,
      "learning_rate": 0.00017573737227335315,
      "loss": 0.1664,
      "step": 1675
    },
    {
      "epoch": 0.12146247780555858,
      "grad_norm": 0.698372483253479,
      "learning_rate": 0.00017572287846945433,
      "loss": 0.0237,
      "step": 1676
    },
    {
      "epoch": 0.12153494945102729,
      "grad_norm": 2.889061450958252,
      "learning_rate": 0.0001757083846655555,
      "loss": 0.1895,
      "step": 1677
    },
    {
      "epoch": 0.121607421096496,
      "grad_norm": 3.5517592430114746,
      "learning_rate": 0.00017569389086165665,
      "loss": 0.1128,
      "step": 1678
    },
    {
      "epoch": 0.12167989274196471,
      "grad_norm": 2.225809335708618,
      "learning_rate": 0.00017567939705775783,
      "loss": 0.1898,
      "step": 1679
    },
    {
      "epoch": 0.12175236438743342,
      "grad_norm": 3.9495115280151367,
      "learning_rate": 0.000175664903253859,
      "loss": 0.2134,
      "step": 1680
    },
    {
      "epoch": 0.12182483603290213,
      "grad_norm": 1.5280629396438599,
      "learning_rate": 0.00017565040944996014,
      "loss": 0.1096,
      "step": 1681
    },
    {
      "epoch": 0.12189730767837084,
      "grad_norm": 2.1636769771575928,
      "learning_rate": 0.00017563591564606133,
      "loss": 0.1324,
      "step": 1682
    },
    {
      "epoch": 0.12196977932383955,
      "grad_norm": 0.8321727514266968,
      "learning_rate": 0.00017562142184216248,
      "loss": 0.033,
      "step": 1683
    },
    {
      "epoch": 0.12204225096930826,
      "grad_norm": 2.4902849197387695,
      "learning_rate": 0.00017560692803826364,
      "loss": 0.1255,
      "step": 1684
    },
    {
      "epoch": 0.12211472261477697,
      "grad_norm": 2.1969690322875977,
      "learning_rate": 0.00017559243423436482,
      "loss": 0.1803,
      "step": 1685
    },
    {
      "epoch": 0.12218719426024569,
      "grad_norm": 3.6130499839782715,
      "learning_rate": 0.00017557794043046598,
      "loss": 0.1435,
      "step": 1686
    },
    {
      "epoch": 0.1222596659057144,
      "grad_norm": 1.3096296787261963,
      "learning_rate": 0.00017556344662656714,
      "loss": 0.0842,
      "step": 1687
    },
    {
      "epoch": 0.12233213755118309,
      "grad_norm": 2.1723947525024414,
      "learning_rate": 0.00017554895282266832,
      "loss": 0.1286,
      "step": 1688
    },
    {
      "epoch": 0.1224046091966518,
      "grad_norm": 0.8756292462348938,
      "learning_rate": 0.00017553445901876948,
      "loss": 0.0199,
      "step": 1689
    },
    {
      "epoch": 0.12247708084212051,
      "grad_norm": 1.016276478767395,
      "learning_rate": 0.00017551996521487063,
      "loss": 0.0399,
      "step": 1690
    },
    {
      "epoch": 0.12254955248758923,
      "grad_norm": 3.401289463043213,
      "learning_rate": 0.00017550547141097182,
      "loss": 0.1399,
      "step": 1691
    },
    {
      "epoch": 0.12262202413305794,
      "grad_norm": 4.367883682250977,
      "learning_rate": 0.00017549097760707297,
      "loss": 0.3056,
      "step": 1692
    },
    {
      "epoch": 0.12269449577852665,
      "grad_norm": 3.0526540279388428,
      "learning_rate": 0.00017547648380317413,
      "loss": 0.1568,
      "step": 1693
    },
    {
      "epoch": 0.12276696742399536,
      "grad_norm": 1.5292260646820068,
      "learning_rate": 0.0001754619899992753,
      "loss": 0.1139,
      "step": 1694
    },
    {
      "epoch": 0.12283943906946407,
      "grad_norm": 2.0920772552490234,
      "learning_rate": 0.00017544749619537647,
      "loss": 0.0882,
      "step": 1695
    },
    {
      "epoch": 0.12291191071493278,
      "grad_norm": 0.976381242275238,
      "learning_rate": 0.00017543300239147765,
      "loss": 0.062,
      "step": 1696
    },
    {
      "epoch": 0.12298438236040149,
      "grad_norm": 1.4836277961730957,
      "learning_rate": 0.0001754185085875788,
      "loss": 0.095,
      "step": 1697
    },
    {
      "epoch": 0.1230568540058702,
      "grad_norm": 3.707380533218384,
      "learning_rate": 0.00017540401478368,
      "loss": 0.1401,
      "step": 1698
    },
    {
      "epoch": 0.12312932565133891,
      "grad_norm": 1.7727800607681274,
      "learning_rate": 0.00017538952097978115,
      "loss": 0.1363,
      "step": 1699
    },
    {
      "epoch": 0.12320179729680762,
      "grad_norm": 1.308388113975525,
      "learning_rate": 0.00017537502717588233,
      "loss": 0.0492,
      "step": 1700
    },
    {
      "epoch": 0.12327426894227633,
      "grad_norm": 2.374255418777466,
      "learning_rate": 0.0001753605333719835,
      "loss": 0.1657,
      "step": 1701
    },
    {
      "epoch": 0.12334674058774504,
      "grad_norm": 1.5632303953170776,
      "learning_rate": 0.00017534603956808465,
      "loss": 0.1234,
      "step": 1702
    },
    {
      "epoch": 0.12341921223321375,
      "grad_norm": 2.048002243041992,
      "learning_rate": 0.00017533154576418583,
      "loss": 0.1124,
      "step": 1703
    },
    {
      "epoch": 0.12349168387868246,
      "grad_norm": 2.2952980995178223,
      "learning_rate": 0.000175317051960287,
      "loss": 0.1196,
      "step": 1704
    },
    {
      "epoch": 0.12356415552415118,
      "grad_norm": 1.3810651302337646,
      "learning_rate": 0.00017530255815638814,
      "loss": 0.1374,
      "step": 1705
    },
    {
      "epoch": 0.12363662716961989,
      "grad_norm": 3.1718428134918213,
      "learning_rate": 0.00017528806435248933,
      "loss": 0.1891,
      "step": 1706
    },
    {
      "epoch": 0.1237090988150886,
      "grad_norm": 2.635349988937378,
      "learning_rate": 0.00017527357054859048,
      "loss": 0.1079,
      "step": 1707
    },
    {
      "epoch": 0.12378157046055731,
      "grad_norm": 4.091890335083008,
      "learning_rate": 0.00017525907674469167,
      "loss": 0.0825,
      "step": 1708
    },
    {
      "epoch": 0.12385404210602602,
      "grad_norm": 4.335143566131592,
      "learning_rate": 0.00017524458294079282,
      "loss": 0.0682,
      "step": 1709
    },
    {
      "epoch": 0.12392651375149473,
      "grad_norm": 3.2671256065368652,
      "learning_rate": 0.00017523008913689398,
      "loss": 0.077,
      "step": 1710
    },
    {
      "epoch": 0.12399898539696344,
      "grad_norm": 1.5470082759857178,
      "learning_rate": 0.00017521559533299516,
      "loss": 0.2006,
      "step": 1711
    },
    {
      "epoch": 0.12407145704243215,
      "grad_norm": 3.2144579887390137,
      "learning_rate": 0.00017520110152909632,
      "loss": 0.1272,
      "step": 1712
    },
    {
      "epoch": 0.12414392868790086,
      "grad_norm": 4.00850772857666,
      "learning_rate": 0.00017518660772519748,
      "loss": 0.2101,
      "step": 1713
    },
    {
      "epoch": 0.12421640033336957,
      "grad_norm": 2.693798542022705,
      "learning_rate": 0.00017517211392129866,
      "loss": 0.2024,
      "step": 1714
    },
    {
      "epoch": 0.12428887197883828,
      "grad_norm": 2.9380722045898438,
      "learning_rate": 0.00017515762011739982,
      "loss": 0.1272,
      "step": 1715
    },
    {
      "epoch": 0.124361343624307,
      "grad_norm": 2.39662766456604,
      "learning_rate": 0.00017514312631350097,
      "loss": 0.0773,
      "step": 1716
    },
    {
      "epoch": 0.1244338152697757,
      "grad_norm": 2.4382970333099365,
      "learning_rate": 0.00017512863250960216,
      "loss": 0.1651,
      "step": 1717
    },
    {
      "epoch": 0.12450628691524442,
      "grad_norm": 1.7022771835327148,
      "learning_rate": 0.0001751141387057033,
      "loss": 0.1059,
      "step": 1718
    },
    {
      "epoch": 0.12457875856071313,
      "grad_norm": 1.2547379732131958,
      "learning_rate": 0.00017509964490180447,
      "loss": 0.1257,
      "step": 1719
    },
    {
      "epoch": 0.12465123020618184,
      "grad_norm": 2.671116352081299,
      "learning_rate": 0.00017508515109790565,
      "loss": 0.1007,
      "step": 1720
    },
    {
      "epoch": 0.12472370185165055,
      "grad_norm": 1.8770676851272583,
      "learning_rate": 0.00017507065729400684,
      "loss": 0.0965,
      "step": 1721
    },
    {
      "epoch": 0.12479617349711926,
      "grad_norm": 6.330056190490723,
      "learning_rate": 0.000175056163490108,
      "loss": 0.2083,
      "step": 1722
    },
    {
      "epoch": 0.12486864514258796,
      "grad_norm": 2.8018243312835693,
      "learning_rate": 0.00017504166968620918,
      "loss": 0.1417,
      "step": 1723
    },
    {
      "epoch": 0.12494111678805667,
      "grad_norm": 1.62462317943573,
      "learning_rate": 0.00017502717588231033,
      "loss": 0.1205,
      "step": 1724
    },
    {
      "epoch": 0.1250135884335254,
      "grad_norm": 2.504506826400757,
      "learning_rate": 0.0001750126820784115,
      "loss": 0.1265,
      "step": 1725
    },
    {
      "epoch": 0.1250860600789941,
      "grad_norm": 1.2317166328430176,
      "learning_rate": 0.00017499818827451267,
      "loss": 0.1152,
      "step": 1726
    },
    {
      "epoch": 0.1251585317244628,
      "grad_norm": 5.233171463012695,
      "learning_rate": 0.00017498369447061383,
      "loss": 0.1199,
      "step": 1727
    },
    {
      "epoch": 0.1252310033699315,
      "grad_norm": 1.7273995876312256,
      "learning_rate": 0.00017496920066671499,
      "loss": 0.0813,
      "step": 1728
    },
    {
      "epoch": 0.12530347501540023,
      "grad_norm": 1.8861528635025024,
      "learning_rate": 0.00017495470686281617,
      "loss": 0.1291,
      "step": 1729
    },
    {
      "epoch": 0.12537594666086893,
      "grad_norm": 5.199698448181152,
      "learning_rate": 0.00017494021305891733,
      "loss": 0.1733,
      "step": 1730
    },
    {
      "epoch": 0.12544841830633766,
      "grad_norm": 2.898218870162964,
      "learning_rate": 0.00017492571925501848,
      "loss": 0.1631,
      "step": 1731
    },
    {
      "epoch": 0.12552088995180635,
      "grad_norm": 2.5108540058135986,
      "learning_rate": 0.00017491122545111967,
      "loss": 0.0333,
      "step": 1732
    },
    {
      "epoch": 0.12559336159727508,
      "grad_norm": 2.398266077041626,
      "learning_rate": 0.00017489673164722082,
      "loss": 0.1574,
      "step": 1733
    },
    {
      "epoch": 0.12566583324274377,
      "grad_norm": 2.903507947921753,
      "learning_rate": 0.00017488223784332198,
      "loss": 0.044,
      "step": 1734
    },
    {
      "epoch": 0.1257383048882125,
      "grad_norm": 3.065739154815674,
      "learning_rate": 0.00017486774403942316,
      "loss": 0.1569,
      "step": 1735
    },
    {
      "epoch": 0.1258107765336812,
      "grad_norm": 2.4462196826934814,
      "learning_rate": 0.00017485325023552432,
      "loss": 0.079,
      "step": 1736
    },
    {
      "epoch": 0.12588324817914992,
      "grad_norm": 6.849796295166016,
      "learning_rate": 0.00017483875643162548,
      "loss": 0.2277,
      "step": 1737
    },
    {
      "epoch": 0.12595571982461862,
      "grad_norm": 7.537743091583252,
      "learning_rate": 0.00017482426262772666,
      "loss": 0.2636,
      "step": 1738
    },
    {
      "epoch": 0.12602819147008734,
      "grad_norm": 3.9515833854675293,
      "learning_rate": 0.00017480976882382782,
      "loss": 0.1943,
      "step": 1739
    },
    {
      "epoch": 0.12610066311555604,
      "grad_norm": 4.883309841156006,
      "learning_rate": 0.00017479527501992897,
      "loss": 0.135,
      "step": 1740
    },
    {
      "epoch": 0.12617313476102474,
      "grad_norm": 2.228898763656616,
      "learning_rate": 0.00017478078121603016,
      "loss": 0.1109,
      "step": 1741
    },
    {
      "epoch": 0.12624560640649346,
      "grad_norm": 2.9706170558929443,
      "learning_rate": 0.0001747662874121313,
      "loss": 0.1702,
      "step": 1742
    },
    {
      "epoch": 0.12631807805196216,
      "grad_norm": 0.7268871665000916,
      "learning_rate": 0.0001747517936082325,
      "loss": 0.0417,
      "step": 1743
    },
    {
      "epoch": 0.12639054969743088,
      "grad_norm": 1.6114466190338135,
      "learning_rate": 0.00017473729980433365,
      "loss": 0.156,
      "step": 1744
    },
    {
      "epoch": 0.12646302134289958,
      "grad_norm": 5.669537544250488,
      "learning_rate": 0.00017472280600043484,
      "loss": 0.2124,
      "step": 1745
    },
    {
      "epoch": 0.1265354929883683,
      "grad_norm": 3.0886502265930176,
      "learning_rate": 0.000174708312196536,
      "loss": 0.1261,
      "step": 1746
    },
    {
      "epoch": 0.126607964633837,
      "grad_norm": 0.9915623664855957,
      "learning_rate": 0.00017469381839263718,
      "loss": 0.0696,
      "step": 1747
    },
    {
      "epoch": 0.12668043627930572,
      "grad_norm": 2.4593231678009033,
      "learning_rate": 0.00017467932458873833,
      "loss": 0.1504,
      "step": 1748
    },
    {
      "epoch": 0.12675290792477442,
      "grad_norm": 1.3562397956848145,
      "learning_rate": 0.0001746648307848395,
      "loss": 0.0813,
      "step": 1749
    },
    {
      "epoch": 0.12682537957024315,
      "grad_norm": 1.8442742824554443,
      "learning_rate": 0.00017465033698094067,
      "loss": 0.1318,
      "step": 1750
    },
    {
      "epoch": 0.12689785121571184,
      "grad_norm": 1.7059197425842285,
      "learning_rate": 0.00017463584317704183,
      "loss": 0.0925,
      "step": 1751
    },
    {
      "epoch": 0.12697032286118057,
      "grad_norm": 3.059194326400757,
      "learning_rate": 0.00017462134937314299,
      "loss": 0.0959,
      "step": 1752
    },
    {
      "epoch": 0.12704279450664926,
      "grad_norm": 2.921203374862671,
      "learning_rate": 0.00017460685556924417,
      "loss": 0.1413,
      "step": 1753
    },
    {
      "epoch": 0.127115266152118,
      "grad_norm": 3.7549808025360107,
      "learning_rate": 0.00017459236176534533,
      "loss": 0.162,
      "step": 1754
    },
    {
      "epoch": 0.1271877377975867,
      "grad_norm": 5.0909810066223145,
      "learning_rate": 0.00017457786796144648,
      "loss": 0.1011,
      "step": 1755
    },
    {
      "epoch": 0.1272602094430554,
      "grad_norm": 1.981837511062622,
      "learning_rate": 0.00017456337415754767,
      "loss": 0.0921,
      "step": 1756
    },
    {
      "epoch": 0.1273326810885241,
      "grad_norm": 3.8224937915802,
      "learning_rate": 0.00017454888035364882,
      "loss": 0.2078,
      "step": 1757
    },
    {
      "epoch": 0.12740515273399283,
      "grad_norm": 2.3303639888763428,
      "learning_rate": 0.00017453438654974998,
      "loss": 0.1053,
      "step": 1758
    },
    {
      "epoch": 0.12747762437946153,
      "grad_norm": 2.532069206237793,
      "learning_rate": 0.00017451989274585116,
      "loss": 0.0868,
      "step": 1759
    },
    {
      "epoch": 0.12755009602493025,
      "grad_norm": 3.429743766784668,
      "learning_rate": 0.00017450539894195232,
      "loss": 0.1733,
      "step": 1760
    },
    {
      "epoch": 0.12762256767039895,
      "grad_norm": 0.8958027362823486,
      "learning_rate": 0.00017449090513805348,
      "loss": 0.0613,
      "step": 1761
    },
    {
      "epoch": 0.12769503931586768,
      "grad_norm": 4.120465278625488,
      "learning_rate": 0.00017447641133415466,
      "loss": 0.1507,
      "step": 1762
    },
    {
      "epoch": 0.12776751096133637,
      "grad_norm": 1.2972900867462158,
      "learning_rate": 0.00017446191753025582,
      "loss": 0.0594,
      "step": 1763
    },
    {
      "epoch": 0.1278399826068051,
      "grad_norm": 4.675338268280029,
      "learning_rate": 0.00017444742372635697,
      "loss": 0.1008,
      "step": 1764
    },
    {
      "epoch": 0.1279124542522738,
      "grad_norm": 2.373178005218506,
      "learning_rate": 0.00017443292992245816,
      "loss": 0.0879,
      "step": 1765
    },
    {
      "epoch": 0.12798492589774252,
      "grad_norm": 1.5571507215499878,
      "learning_rate": 0.0001744184361185593,
      "loss": 0.1033,
      "step": 1766
    },
    {
      "epoch": 0.12805739754321122,
      "grad_norm": 4.748425483703613,
      "learning_rate": 0.0001744039423146605,
      "loss": 0.1649,
      "step": 1767
    },
    {
      "epoch": 0.12812986918867994,
      "grad_norm": 2.6301751136779785,
      "learning_rate": 0.00017438944851076168,
      "loss": 0.055,
      "step": 1768
    },
    {
      "epoch": 0.12820234083414864,
      "grad_norm": 1.248695731163025,
      "learning_rate": 0.00017437495470686284,
      "loss": 0.0578,
      "step": 1769
    },
    {
      "epoch": 0.12827481247961736,
      "grad_norm": 3.011202335357666,
      "learning_rate": 0.000174360460902964,
      "loss": 0.1276,
      "step": 1770
    },
    {
      "epoch": 0.12834728412508606,
      "grad_norm": 2.1760945320129395,
      "learning_rate": 0.00017434596709906518,
      "loss": 0.1054,
      "step": 1771
    },
    {
      "epoch": 0.12841975577055478,
      "grad_norm": 1.271131157875061,
      "learning_rate": 0.00017433147329516633,
      "loss": 0.063,
      "step": 1772
    },
    {
      "epoch": 0.12849222741602348,
      "grad_norm": 2.139810800552368,
      "learning_rate": 0.0001743169794912675,
      "loss": 0.1022,
      "step": 1773
    },
    {
      "epoch": 0.1285646990614922,
      "grad_norm": 1.7655417919158936,
      "learning_rate": 0.00017430248568736867,
      "loss": 0.0603,
      "step": 1774
    },
    {
      "epoch": 0.1286371707069609,
      "grad_norm": 5.382352828979492,
      "learning_rate": 0.00017428799188346983,
      "loss": 0.1349,
      "step": 1775
    },
    {
      "epoch": 0.1287096423524296,
      "grad_norm": 2.321045160293579,
      "learning_rate": 0.00017427349807957099,
      "loss": 0.0992,
      "step": 1776
    },
    {
      "epoch": 0.12878211399789832,
      "grad_norm": 1.9518119096755981,
      "learning_rate": 0.00017425900427567217,
      "loss": 0.1854,
      "step": 1777
    },
    {
      "epoch": 0.12885458564336702,
      "grad_norm": 3.7666516304016113,
      "learning_rate": 0.00017424451047177333,
      "loss": 0.1163,
      "step": 1778
    },
    {
      "epoch": 0.12892705728883574,
      "grad_norm": 1.9074152708053589,
      "learning_rate": 0.00017423001666787448,
      "loss": 0.131,
      "step": 1779
    },
    {
      "epoch": 0.12899952893430444,
      "grad_norm": 1.4744901657104492,
      "learning_rate": 0.00017421552286397567,
      "loss": 0.0725,
      "step": 1780
    },
    {
      "epoch": 0.12907200057977317,
      "grad_norm": 2.869319200515747,
      "learning_rate": 0.00017420102906007682,
      "loss": 0.1714,
      "step": 1781
    },
    {
      "epoch": 0.12914447222524186,
      "grad_norm": 2.6713340282440186,
      "learning_rate": 0.00017418653525617798,
      "loss": 0.0843,
      "step": 1782
    },
    {
      "epoch": 0.1292169438707106,
      "grad_norm": 1.8596625328063965,
      "learning_rate": 0.00017417204145227916,
      "loss": 0.0718,
      "step": 1783
    },
    {
      "epoch": 0.12928941551617928,
      "grad_norm": 3.5301921367645264,
      "learning_rate": 0.00017415754764838032,
      "loss": 0.161,
      "step": 1784
    },
    {
      "epoch": 0.129361887161648,
      "grad_norm": 2.1989667415618896,
      "learning_rate": 0.00017414305384448148,
      "loss": 0.1592,
      "step": 1785
    },
    {
      "epoch": 0.1294343588071167,
      "grad_norm": 3.3315269947052,
      "learning_rate": 0.00017412856004058266,
      "loss": 0.1557,
      "step": 1786
    },
    {
      "epoch": 0.12950683045258543,
      "grad_norm": 0.7663152813911438,
      "learning_rate": 0.00017411406623668382,
      "loss": 0.0094,
      "step": 1787
    },
    {
      "epoch": 0.12957930209805413,
      "grad_norm": 1.601499319076538,
      "learning_rate": 0.000174099572432785,
      "loss": 0.1117,
      "step": 1788
    },
    {
      "epoch": 0.12965177374352285,
      "grad_norm": 2.2153210639953613,
      "learning_rate": 0.00017408507862888616,
      "loss": 0.1566,
      "step": 1789
    },
    {
      "epoch": 0.12972424538899155,
      "grad_norm": 3.3116214275360107,
      "learning_rate": 0.00017407058482498734,
      "loss": 0.1215,
      "step": 1790
    },
    {
      "epoch": 0.12979671703446027,
      "grad_norm": 3.989847183227539,
      "learning_rate": 0.0001740560910210885,
      "loss": 0.1061,
      "step": 1791
    },
    {
      "epoch": 0.12986918867992897,
      "grad_norm": 2.9656901359558105,
      "learning_rate": 0.00017404159721718968,
      "loss": 0.0735,
      "step": 1792
    },
    {
      "epoch": 0.1299416603253977,
      "grad_norm": 5.228427886962891,
      "learning_rate": 0.00017402710341329084,
      "loss": 0.159,
      "step": 1793
    },
    {
      "epoch": 0.1300141319708664,
      "grad_norm": 2.152513027191162,
      "learning_rate": 0.000174012609609392,
      "loss": 0.096,
      "step": 1794
    },
    {
      "epoch": 0.13008660361633512,
      "grad_norm": 1.4051461219787598,
      "learning_rate": 0.00017399811580549318,
      "loss": 0.1478,
      "step": 1795
    },
    {
      "epoch": 0.1301590752618038,
      "grad_norm": 2.3264822959899902,
      "learning_rate": 0.00017398362200159433,
      "loss": 0.1193,
      "step": 1796
    },
    {
      "epoch": 0.13023154690727254,
      "grad_norm": 1.6007661819458008,
      "learning_rate": 0.0001739691281976955,
      "loss": 0.0919,
      "step": 1797
    },
    {
      "epoch": 0.13030401855274124,
      "grad_norm": 1.345708966255188,
      "learning_rate": 0.00017395463439379667,
      "loss": 0.0987,
      "step": 1798
    },
    {
      "epoch": 0.13037649019820996,
      "grad_norm": 0.8824725151062012,
      "learning_rate": 0.00017394014058989783,
      "loss": 0.0455,
      "step": 1799
    },
    {
      "epoch": 0.13044896184367866,
      "grad_norm": 1.8756778240203857,
      "learning_rate": 0.00017392564678599899,
      "loss": 0.0892,
      "step": 1800
    },
    {
      "epoch": 0.13052143348914738,
      "grad_norm": 0.813318133354187,
      "learning_rate": 0.00017391115298210017,
      "loss": 0.0077,
      "step": 1801
    },
    {
      "epoch": 0.13059390513461608,
      "grad_norm": 3.017709493637085,
      "learning_rate": 0.00017389665917820133,
      "loss": 0.0991,
      "step": 1802
    },
    {
      "epoch": 0.1306663767800848,
      "grad_norm": 4.411162853240967,
      "learning_rate": 0.00017388216537430248,
      "loss": 0.1041,
      "step": 1803
    },
    {
      "epoch": 0.1307388484255535,
      "grad_norm": 3.157724380493164,
      "learning_rate": 0.00017386767157040367,
      "loss": 0.1671,
      "step": 1804
    },
    {
      "epoch": 0.13081132007102222,
      "grad_norm": 2.9371860027313232,
      "learning_rate": 0.00017385317776650482,
      "loss": 0.0636,
      "step": 1805
    },
    {
      "epoch": 0.13088379171649092,
      "grad_norm": 1.5976064205169678,
      "learning_rate": 0.00017383868396260598,
      "loss": 0.0332,
      "step": 1806
    },
    {
      "epoch": 0.13095626336195965,
      "grad_norm": 7.7864532470703125,
      "learning_rate": 0.00017382419015870716,
      "loss": 0.1499,
      "step": 1807
    },
    {
      "epoch": 0.13102873500742834,
      "grad_norm": 2.1499440670013428,
      "learning_rate": 0.00017380969635480832,
      "loss": 0.1222,
      "step": 1808
    },
    {
      "epoch": 0.13110120665289707,
      "grad_norm": 4.336635589599609,
      "learning_rate": 0.00017379520255090947,
      "loss": 0.3006,
      "step": 1809
    },
    {
      "epoch": 0.13117367829836576,
      "grad_norm": 3.2118871212005615,
      "learning_rate": 0.00017378070874701066,
      "loss": 0.0581,
      "step": 1810
    },
    {
      "epoch": 0.13124614994383446,
      "grad_norm": 1.1098805665969849,
      "learning_rate": 0.00017376621494311181,
      "loss": 0.0243,
      "step": 1811
    },
    {
      "epoch": 0.13131862158930319,
      "grad_norm": 2.5863707065582275,
      "learning_rate": 0.000173751721139213,
      "loss": 0.1892,
      "step": 1812
    },
    {
      "epoch": 0.13139109323477188,
      "grad_norm": 0.6556212902069092,
      "learning_rate": 0.00017373722733531415,
      "loss": 0.0237,
      "step": 1813
    },
    {
      "epoch": 0.1314635648802406,
      "grad_norm": 5.613372325897217,
      "learning_rate": 0.00017372273353141534,
      "loss": 0.1834,
      "step": 1814
    },
    {
      "epoch": 0.1315360365257093,
      "grad_norm": 4.35701847076416,
      "learning_rate": 0.0001737082397275165,
      "loss": 0.1612,
      "step": 1815
    },
    {
      "epoch": 0.13160850817117803,
      "grad_norm": 2.968891143798828,
      "learning_rate": 0.00017369374592361768,
      "loss": 0.1277,
      "step": 1816
    },
    {
      "epoch": 0.13168097981664673,
      "grad_norm": 1.6944377422332764,
      "learning_rate": 0.00017367925211971884,
      "loss": 0.0952,
      "step": 1817
    },
    {
      "epoch": 0.13175345146211545,
      "grad_norm": 1.4298301935195923,
      "learning_rate": 0.00017366475831582,
      "loss": 0.0876,
      "step": 1818
    },
    {
      "epoch": 0.13182592310758415,
      "grad_norm": 2.2810757160186768,
      "learning_rate": 0.00017365026451192118,
      "loss": 0.1663,
      "step": 1819
    },
    {
      "epoch": 0.13189839475305287,
      "grad_norm": 2.917376756668091,
      "learning_rate": 0.00017363577070802233,
      "loss": 0.1942,
      "step": 1820
    },
    {
      "epoch": 0.13197086639852157,
      "grad_norm": 3.150402069091797,
      "learning_rate": 0.0001736212769041235,
      "loss": 0.1541,
      "step": 1821
    },
    {
      "epoch": 0.1320433380439903,
      "grad_norm": 1.7310211658477783,
      "learning_rate": 0.00017360678310022467,
      "loss": 0.1625,
      "step": 1822
    },
    {
      "epoch": 0.132115809689459,
      "grad_norm": 1.4920400381088257,
      "learning_rate": 0.00017359228929632583,
      "loss": 0.0784,
      "step": 1823
    },
    {
      "epoch": 0.13218828133492772,
      "grad_norm": 2.4006412029266357,
      "learning_rate": 0.00017357779549242698,
      "loss": 0.1211,
      "step": 1824
    },
    {
      "epoch": 0.1322607529803964,
      "grad_norm": 1.226488471031189,
      "learning_rate": 0.00017356330168852817,
      "loss": 0.0596,
      "step": 1825
    },
    {
      "epoch": 0.13233322462586514,
      "grad_norm": 3.844248056411743,
      "learning_rate": 0.00017354880788462932,
      "loss": 0.1526,
      "step": 1826
    },
    {
      "epoch": 0.13240569627133383,
      "grad_norm": 1.5854841470718384,
      "learning_rate": 0.00017353431408073048,
      "loss": 0.0459,
      "step": 1827
    },
    {
      "epoch": 0.13247816791680256,
      "grad_norm": 2.229191780090332,
      "learning_rate": 0.00017351982027683166,
      "loss": 0.164,
      "step": 1828
    },
    {
      "epoch": 0.13255063956227126,
      "grad_norm": 1.7108473777770996,
      "learning_rate": 0.00017350532647293282,
      "loss": 0.086,
      "step": 1829
    },
    {
      "epoch": 0.13262311120773998,
      "grad_norm": 2.8600265979766846,
      "learning_rate": 0.00017349083266903398,
      "loss": 0.0767,
      "step": 1830
    },
    {
      "epoch": 0.13269558285320868,
      "grad_norm": 2.214327335357666,
      "learning_rate": 0.00017347633886513516,
      "loss": 0.1038,
      "step": 1831
    },
    {
      "epoch": 0.1327680544986774,
      "grad_norm": 2.2124438285827637,
      "learning_rate": 0.00017346184506123632,
      "loss": 0.1287,
      "step": 1832
    },
    {
      "epoch": 0.1328405261441461,
      "grad_norm": 1.577898383140564,
      "learning_rate": 0.00017344735125733747,
      "loss": 0.1406,
      "step": 1833
    },
    {
      "epoch": 0.13291299778961482,
      "grad_norm": 1.9697881937026978,
      "learning_rate": 0.00017343285745343866,
      "loss": 0.0565,
      "step": 1834
    },
    {
      "epoch": 0.13298546943508352,
      "grad_norm": 1.7694220542907715,
      "learning_rate": 0.00017341836364953981,
      "loss": 0.1185,
      "step": 1835
    },
    {
      "epoch": 0.13305794108055224,
      "grad_norm": 3.1495614051818848,
      "learning_rate": 0.000173403869845641,
      "loss": 0.1216,
      "step": 1836
    },
    {
      "epoch": 0.13313041272602094,
      "grad_norm": 2.105360269546509,
      "learning_rate": 0.00017338937604174218,
      "loss": 0.1307,
      "step": 1837
    },
    {
      "epoch": 0.13320288437148967,
      "grad_norm": 3.694615364074707,
      "learning_rate": 0.00017337488223784334,
      "loss": 0.1385,
      "step": 1838
    },
    {
      "epoch": 0.13327535601695836,
      "grad_norm": 1.9168744087219238,
      "learning_rate": 0.0001733603884339445,
      "loss": 0.0763,
      "step": 1839
    },
    {
      "epoch": 0.1333478276624271,
      "grad_norm": 3.771613836288452,
      "learning_rate": 0.00017334589463004568,
      "loss": 0.249,
      "step": 1840
    },
    {
      "epoch": 0.13342029930789578,
      "grad_norm": 8.894440650939941,
      "learning_rate": 0.00017333140082614683,
      "loss": 0.306,
      "step": 1841
    },
    {
      "epoch": 0.1334927709533645,
      "grad_norm": 2.416940212249756,
      "learning_rate": 0.000173316907022248,
      "loss": 0.1109,
      "step": 1842
    },
    {
      "epoch": 0.1335652425988332,
      "grad_norm": 4.668516159057617,
      "learning_rate": 0.00017330241321834917,
      "loss": 0.1693,
      "step": 1843
    },
    {
      "epoch": 0.13363771424430193,
      "grad_norm": 3.2742912769317627,
      "learning_rate": 0.00017328791941445033,
      "loss": 0.0536,
      "step": 1844
    },
    {
      "epoch": 0.13371018588977063,
      "grad_norm": 3.1625936031341553,
      "learning_rate": 0.0001732734256105515,
      "loss": 0.1694,
      "step": 1845
    },
    {
      "epoch": 0.13378265753523932,
      "grad_norm": 2.743701457977295,
      "learning_rate": 0.00017325893180665267,
      "loss": 0.1773,
      "step": 1846
    },
    {
      "epoch": 0.13385512918070805,
      "grad_norm": 2.359295129776001,
      "learning_rate": 0.00017324443800275383,
      "loss": 0.1288,
      "step": 1847
    },
    {
      "epoch": 0.13392760082617675,
      "grad_norm": 2.7368698120117188,
      "learning_rate": 0.00017322994419885498,
      "loss": 0.1429,
      "step": 1848
    },
    {
      "epoch": 0.13400007247164547,
      "grad_norm": 5.1010613441467285,
      "learning_rate": 0.00017321545039495617,
      "loss": 0.1075,
      "step": 1849
    },
    {
      "epoch": 0.13407254411711417,
      "grad_norm": 2.3242132663726807,
      "learning_rate": 0.00017320095659105732,
      "loss": 0.1509,
      "step": 1850
    },
    {
      "epoch": 0.1341450157625829,
      "grad_norm": 1.9202278852462769,
      "learning_rate": 0.00017318646278715848,
      "loss": 0.0675,
      "step": 1851
    },
    {
      "epoch": 0.1342174874080516,
      "grad_norm": 0.9409880042076111,
      "learning_rate": 0.00017317196898325966,
      "loss": 0.0646,
      "step": 1852
    },
    {
      "epoch": 0.1342899590535203,
      "grad_norm": 2.364643096923828,
      "learning_rate": 0.00017315747517936082,
      "loss": 0.2101,
      "step": 1853
    },
    {
      "epoch": 0.134362430698989,
      "grad_norm": 1.5844849348068237,
      "learning_rate": 0.00017314298137546198,
      "loss": 0.1178,
      "step": 1854
    },
    {
      "epoch": 0.13443490234445774,
      "grad_norm": 1.2534714937210083,
      "learning_rate": 0.00017312848757156316,
      "loss": 0.0489,
      "step": 1855
    },
    {
      "epoch": 0.13450737398992643,
      "grad_norm": 2.8382506370544434,
      "learning_rate": 0.00017311399376766432,
      "loss": 0.0901,
      "step": 1856
    },
    {
      "epoch": 0.13457984563539516,
      "grad_norm": 2.078636646270752,
      "learning_rate": 0.0001730994999637655,
      "loss": 0.1505,
      "step": 1857
    },
    {
      "epoch": 0.13465231728086385,
      "grad_norm": 1.6639540195465088,
      "learning_rate": 0.00017308500615986666,
      "loss": 0.1215,
      "step": 1858
    },
    {
      "epoch": 0.13472478892633258,
      "grad_norm": 1.4694336652755737,
      "learning_rate": 0.00017307051235596784,
      "loss": 0.0883,
      "step": 1859
    },
    {
      "epoch": 0.13479726057180128,
      "grad_norm": 1.2497855424880981,
      "learning_rate": 0.000173056018552069,
      "loss": 0.0528,
      "step": 1860
    },
    {
      "epoch": 0.13486973221727,
      "grad_norm": 1.1595624685287476,
      "learning_rate": 0.00017304152474817018,
      "loss": 0.0522,
      "step": 1861
    },
    {
      "epoch": 0.1349422038627387,
      "grad_norm": 1.3197394609451294,
      "learning_rate": 0.00017302703094427134,
      "loss": 0.0581,
      "step": 1862
    },
    {
      "epoch": 0.13501467550820742,
      "grad_norm": 3.3690669536590576,
      "learning_rate": 0.0001730125371403725,
      "loss": 0.1636,
      "step": 1863
    },
    {
      "epoch": 0.13508714715367612,
      "grad_norm": 1.8214856386184692,
      "learning_rate": 0.00017299804333647368,
      "loss": 0.1466,
      "step": 1864
    },
    {
      "epoch": 0.13515961879914484,
      "grad_norm": 1.0710718631744385,
      "learning_rate": 0.00017298354953257483,
      "loss": 0.0452,
      "step": 1865
    },
    {
      "epoch": 0.13523209044461354,
      "grad_norm": 1.6859185695648193,
      "learning_rate": 0.000172969055728676,
      "loss": 0.0763,
      "step": 1866
    },
    {
      "epoch": 0.13530456209008226,
      "grad_norm": 0.765516459941864,
      "learning_rate": 0.00017295456192477717,
      "loss": 0.0202,
      "step": 1867
    },
    {
      "epoch": 0.13537703373555096,
      "grad_norm": 9.77281379699707,
      "learning_rate": 0.00017294006812087833,
      "loss": 0.3056,
      "step": 1868
    },
    {
      "epoch": 0.13544950538101969,
      "grad_norm": 4.570301532745361,
      "learning_rate": 0.00017292557431697951,
      "loss": 0.1701,
      "step": 1869
    },
    {
      "epoch": 0.13552197702648838,
      "grad_norm": 5.685872554779053,
      "learning_rate": 0.00017291108051308067,
      "loss": 0.2316,
      "step": 1870
    },
    {
      "epoch": 0.1355944486719571,
      "grad_norm": 6.133869647979736,
      "learning_rate": 0.00017289658670918183,
      "loss": 0.1416,
      "step": 1871
    },
    {
      "epoch": 0.1356669203174258,
      "grad_norm": 3.7814204692840576,
      "learning_rate": 0.000172882092905283,
      "loss": 0.3285,
      "step": 1872
    },
    {
      "epoch": 0.13573939196289453,
      "grad_norm": 4.097508907318115,
      "learning_rate": 0.00017286759910138417,
      "loss": 0.0739,
      "step": 1873
    },
    {
      "epoch": 0.13581186360836323,
      "grad_norm": 2.525179624557495,
      "learning_rate": 0.00017285310529748532,
      "loss": 0.1375,
      "step": 1874
    },
    {
      "epoch": 0.13588433525383195,
      "grad_norm": 0.2219589650630951,
      "learning_rate": 0.0001728386114935865,
      "loss": 0.0087,
      "step": 1875
    },
    {
      "epoch": 0.13595680689930065,
      "grad_norm": 1.6921623945236206,
      "learning_rate": 0.00017282411768968766,
      "loss": 0.0267,
      "step": 1876
    },
    {
      "epoch": 0.13602927854476937,
      "grad_norm": 7.367464542388916,
      "learning_rate": 0.00017280962388578882,
      "loss": 0.1208,
      "step": 1877
    },
    {
      "epoch": 0.13610175019023807,
      "grad_norm": 4.638823986053467,
      "learning_rate": 0.00017279513008189,
      "loss": 0.1093,
      "step": 1878
    },
    {
      "epoch": 0.1361742218357068,
      "grad_norm": 6.113086700439453,
      "learning_rate": 0.00017278063627799116,
      "loss": 0.1505,
      "step": 1879
    },
    {
      "epoch": 0.1362466934811755,
      "grad_norm": 5.814613342285156,
      "learning_rate": 0.00017276614247409232,
      "loss": 0.0816,
      "step": 1880
    },
    {
      "epoch": 0.1363191651266442,
      "grad_norm": 0.7798976898193359,
      "learning_rate": 0.0001727516486701935,
      "loss": 0.0649,
      "step": 1881
    },
    {
      "epoch": 0.1363916367721129,
      "grad_norm": 4.869588851928711,
      "learning_rate": 0.00017273715486629466,
      "loss": 0.1587,
      "step": 1882
    },
    {
      "epoch": 0.1364641084175816,
      "grad_norm": 6.483962535858154,
      "learning_rate": 0.00017272266106239584,
      "loss": 0.3182,
      "step": 1883
    },
    {
      "epoch": 0.13653658006305033,
      "grad_norm": 2.1933655738830566,
      "learning_rate": 0.00017270816725849702,
      "loss": 0.1147,
      "step": 1884
    },
    {
      "epoch": 0.13660905170851903,
      "grad_norm": 2.59832501411438,
      "learning_rate": 0.00017269367345459818,
      "loss": 0.0624,
      "step": 1885
    },
    {
      "epoch": 0.13668152335398775,
      "grad_norm": 6.59619665145874,
      "learning_rate": 0.00017267917965069934,
      "loss": 0.1329,
      "step": 1886
    },
    {
      "epoch": 0.13675399499945645,
      "grad_norm": 3.1432740688323975,
      "learning_rate": 0.00017266468584680052,
      "loss": 0.1215,
      "step": 1887
    },
    {
      "epoch": 0.13682646664492518,
      "grad_norm": 1.6232692003250122,
      "learning_rate": 0.00017265019204290168,
      "loss": 0.0838,
      "step": 1888
    },
    {
      "epoch": 0.13689893829039387,
      "grad_norm": 1.8085905313491821,
      "learning_rate": 0.00017263569823900283,
      "loss": 0.1107,
      "step": 1889
    },
    {
      "epoch": 0.1369714099358626,
      "grad_norm": 5.374395847320557,
      "learning_rate": 0.00017262120443510402,
      "loss": 0.146,
      "step": 1890
    },
    {
      "epoch": 0.1370438815813313,
      "grad_norm": 3.2589948177337646,
      "learning_rate": 0.00017260671063120517,
      "loss": 0.0983,
      "step": 1891
    },
    {
      "epoch": 0.13711635322680002,
      "grad_norm": 6.8055877685546875,
      "learning_rate": 0.00017259221682730633,
      "loss": 0.1148,
      "step": 1892
    },
    {
      "epoch": 0.13718882487226872,
      "grad_norm": 7.4877519607543945,
      "learning_rate": 0.00017257772302340751,
      "loss": 0.1563,
      "step": 1893
    },
    {
      "epoch": 0.13726129651773744,
      "grad_norm": 5.149839878082275,
      "learning_rate": 0.00017256322921950867,
      "loss": 0.1133,
      "step": 1894
    },
    {
      "epoch": 0.13733376816320614,
      "grad_norm": 1.9276841878890991,
      "learning_rate": 0.00017254873541560983,
      "loss": 0.0765,
      "step": 1895
    },
    {
      "epoch": 0.13740623980867486,
      "grad_norm": 1.4515204429626465,
      "learning_rate": 0.000172534241611711,
      "loss": 0.1002,
      "step": 1896
    },
    {
      "epoch": 0.13747871145414356,
      "grad_norm": 4.962104797363281,
      "learning_rate": 0.00017251974780781217,
      "loss": 0.1832,
      "step": 1897
    },
    {
      "epoch": 0.13755118309961228,
      "grad_norm": 2.756295680999756,
      "learning_rate": 0.00017250525400391332,
      "loss": 0.1108,
      "step": 1898
    },
    {
      "epoch": 0.13762365474508098,
      "grad_norm": 1.1105356216430664,
      "learning_rate": 0.0001724907602000145,
      "loss": 0.0489,
      "step": 1899
    },
    {
      "epoch": 0.1376961263905497,
      "grad_norm": 0.6928471922874451,
      "learning_rate": 0.00017247626639611566,
      "loss": 0.0363,
      "step": 1900
    },
    {
      "epoch": 0.1377685980360184,
      "grad_norm": 2.3316233158111572,
      "learning_rate": 0.00017246177259221682,
      "loss": 0.0595,
      "step": 1901
    },
    {
      "epoch": 0.13784106968148713,
      "grad_norm": 4.709534168243408,
      "learning_rate": 0.000172447278788318,
      "loss": 0.14,
      "step": 1902
    },
    {
      "epoch": 0.13791354132695582,
      "grad_norm": 1.7404567003250122,
      "learning_rate": 0.00017243278498441916,
      "loss": 0.0988,
      "step": 1903
    },
    {
      "epoch": 0.13798601297242455,
      "grad_norm": 1.8269346952438354,
      "learning_rate": 0.00017241829118052034,
      "loss": 0.1071,
      "step": 1904
    },
    {
      "epoch": 0.13805848461789325,
      "grad_norm": 4.467745304107666,
      "learning_rate": 0.0001724037973766215,
      "loss": 0.0928,
      "step": 1905
    },
    {
      "epoch": 0.13813095626336197,
      "grad_norm": 2.794381856918335,
      "learning_rate": 0.00017238930357272268,
      "loss": 0.0638,
      "step": 1906
    },
    {
      "epoch": 0.13820342790883067,
      "grad_norm": 3.61047625541687,
      "learning_rate": 0.00017237480976882384,
      "loss": 0.292,
      "step": 1907
    },
    {
      "epoch": 0.1382758995542994,
      "grad_norm": 3.937065839767456,
      "learning_rate": 0.00017236031596492502,
      "loss": 0.1762,
      "step": 1908
    },
    {
      "epoch": 0.1383483711997681,
      "grad_norm": 2.271207332611084,
      "learning_rate": 0.00017234582216102618,
      "loss": 0.1559,
      "step": 1909
    },
    {
      "epoch": 0.1384208428452368,
      "grad_norm": 1.3648184537887573,
      "learning_rate": 0.00017233132835712734,
      "loss": 0.0889,
      "step": 1910
    },
    {
      "epoch": 0.1384933144907055,
      "grad_norm": 5.153927803039551,
      "learning_rate": 0.00017231683455322852,
      "loss": 0.052,
      "step": 1911
    },
    {
      "epoch": 0.13856578613617423,
      "grad_norm": 1.9499537944793701,
      "learning_rate": 0.00017230234074932968,
      "loss": 0.1511,
      "step": 1912
    },
    {
      "epoch": 0.13863825778164293,
      "grad_norm": 1.0480364561080933,
      "learning_rate": 0.00017228784694543083,
      "loss": 0.0505,
      "step": 1913
    },
    {
      "epoch": 0.13871072942711166,
      "grad_norm": 1.0059510469436646,
      "learning_rate": 0.00017227335314153202,
      "loss": 0.0386,
      "step": 1914
    },
    {
      "epoch": 0.13878320107258035,
      "grad_norm": 3.866910457611084,
      "learning_rate": 0.00017225885933763317,
      "loss": 0.0999,
      "step": 1915
    },
    {
      "epoch": 0.13885567271804905,
      "grad_norm": 2.9633002281188965,
      "learning_rate": 0.00017224436553373433,
      "loss": 0.1166,
      "step": 1916
    },
    {
      "epoch": 0.13892814436351777,
      "grad_norm": 1.8154081106185913,
      "learning_rate": 0.0001722298717298355,
      "loss": 0.0963,
      "step": 1917
    },
    {
      "epoch": 0.13900061600898647,
      "grad_norm": 2.9441752433776855,
      "learning_rate": 0.00017221537792593667,
      "loss": 0.1608,
      "step": 1918
    },
    {
      "epoch": 0.1390730876544552,
      "grad_norm": 1.3090801239013672,
      "learning_rate": 0.00017220088412203783,
      "loss": 0.0622,
      "step": 1919
    },
    {
      "epoch": 0.1391455592999239,
      "grad_norm": 2.516780138015747,
      "learning_rate": 0.000172186390318139,
      "loss": 0.1634,
      "step": 1920
    },
    {
      "epoch": 0.13921803094539262,
      "grad_norm": 2.25905704498291,
      "learning_rate": 0.00017217189651424017,
      "loss": 0.0516,
      "step": 1921
    },
    {
      "epoch": 0.13929050259086131,
      "grad_norm": 1.3344589471817017,
      "learning_rate": 0.00017215740271034132,
      "loss": 0.0824,
      "step": 1922
    },
    {
      "epoch": 0.13936297423633004,
      "grad_norm": 1.0419825315475464,
      "learning_rate": 0.0001721429089064425,
      "loss": 0.0681,
      "step": 1923
    },
    {
      "epoch": 0.13943544588179874,
      "grad_norm": 2.686615467071533,
      "learning_rate": 0.00017212841510254366,
      "loss": 0.1057,
      "step": 1924
    },
    {
      "epoch": 0.13950791752726746,
      "grad_norm": 1.458438515663147,
      "learning_rate": 0.00017211392129864482,
      "loss": 0.0343,
      "step": 1925
    },
    {
      "epoch": 0.13958038917273616,
      "grad_norm": 3.6489570140838623,
      "learning_rate": 0.000172099427494746,
      "loss": 0.0992,
      "step": 1926
    },
    {
      "epoch": 0.13965286081820488,
      "grad_norm": 1.2733650207519531,
      "learning_rate": 0.00017208493369084716,
      "loss": 0.0631,
      "step": 1927
    },
    {
      "epoch": 0.13972533246367358,
      "grad_norm": 2.5831122398376465,
      "learning_rate": 0.00017207043988694834,
      "loss": 0.132,
      "step": 1928
    },
    {
      "epoch": 0.1397978041091423,
      "grad_norm": 2.537707567214966,
      "learning_rate": 0.0001720559460830495,
      "loss": 0.1398,
      "step": 1929
    },
    {
      "epoch": 0.139870275754611,
      "grad_norm": 1.8798846006393433,
      "learning_rate": 0.00017204145227915068,
      "loss": 0.0299,
      "step": 1930
    },
    {
      "epoch": 0.13994274740007973,
      "grad_norm": 7.256489276885986,
      "learning_rate": 0.00017202695847525184,
      "loss": 0.1686,
      "step": 1931
    },
    {
      "epoch": 0.14001521904554842,
      "grad_norm": 3.9337291717529297,
      "learning_rate": 0.00017201246467135302,
      "loss": 0.0463,
      "step": 1932
    },
    {
      "epoch": 0.14008769069101715,
      "grad_norm": 1.5740313529968262,
      "learning_rate": 0.00017199797086745418,
      "loss": 0.0775,
      "step": 1933
    },
    {
      "epoch": 0.14016016233648584,
      "grad_norm": 4.976583957672119,
      "learning_rate": 0.00017198347706355534,
      "loss": 0.0766,
      "step": 1934
    },
    {
      "epoch": 0.14023263398195457,
      "grad_norm": 6.721803188323975,
      "learning_rate": 0.00017196898325965652,
      "loss": 0.1674,
      "step": 1935
    },
    {
      "epoch": 0.14030510562742327,
      "grad_norm": 2.689934730529785,
      "learning_rate": 0.00017195448945575768,
      "loss": 0.2083,
      "step": 1936
    },
    {
      "epoch": 0.140377577272892,
      "grad_norm": 3.671241521835327,
      "learning_rate": 0.00017193999565185883,
      "loss": 0.2864,
      "step": 1937
    },
    {
      "epoch": 0.1404500489183607,
      "grad_norm": 2.413897752761841,
      "learning_rate": 0.00017192550184796002,
      "loss": 0.0894,
      "step": 1938
    },
    {
      "epoch": 0.1405225205638294,
      "grad_norm": 2.6132988929748535,
      "learning_rate": 0.00017191100804406117,
      "loss": 0.1017,
      "step": 1939
    },
    {
      "epoch": 0.1405949922092981,
      "grad_norm": 3.456554412841797,
      "learning_rate": 0.00017189651424016233,
      "loss": 0.151,
      "step": 1940
    },
    {
      "epoch": 0.14066746385476683,
      "grad_norm": 3.9558401107788086,
      "learning_rate": 0.0001718820204362635,
      "loss": 0.2471,
      "step": 1941
    },
    {
      "epoch": 0.14073993550023553,
      "grad_norm": 2.000127077102661,
      "learning_rate": 0.00017186752663236467,
      "loss": 0.1008,
      "step": 1942
    },
    {
      "epoch": 0.14081240714570425,
      "grad_norm": 1.0756126642227173,
      "learning_rate": 0.00017185303282846583,
      "loss": 0.1012,
      "step": 1943
    },
    {
      "epoch": 0.14088487879117295,
      "grad_norm": 1.2984904050827026,
      "learning_rate": 0.000171838539024567,
      "loss": 0.0306,
      "step": 1944
    },
    {
      "epoch": 0.14095735043664168,
      "grad_norm": 3.928532123565674,
      "learning_rate": 0.00017182404522066817,
      "loss": 0.1625,
      "step": 1945
    },
    {
      "epoch": 0.14102982208211037,
      "grad_norm": 1.5976759195327759,
      "learning_rate": 0.00017180955141676932,
      "loss": 0.0992,
      "step": 1946
    },
    {
      "epoch": 0.1411022937275791,
      "grad_norm": 2.6444787979125977,
      "learning_rate": 0.0001717950576128705,
      "loss": 0.1395,
      "step": 1947
    },
    {
      "epoch": 0.1411747653730478,
      "grad_norm": 4.146473407745361,
      "learning_rate": 0.00017178056380897166,
      "loss": 0.145,
      "step": 1948
    },
    {
      "epoch": 0.1412472370185165,
      "grad_norm": 1.1414685249328613,
      "learning_rate": 0.00017176607000507282,
      "loss": 0.065,
      "step": 1949
    },
    {
      "epoch": 0.14131970866398522,
      "grad_norm": 1.8852018117904663,
      "learning_rate": 0.000171751576201174,
      "loss": 0.0912,
      "step": 1950
    },
    {
      "epoch": 0.1413921803094539,
      "grad_norm": 0.9471429586410522,
      "learning_rate": 0.00017173708239727519,
      "loss": 0.0521,
      "step": 1951
    },
    {
      "epoch": 0.14146465195492264,
      "grad_norm": 2.0344841480255127,
      "learning_rate": 0.00017172258859337634,
      "loss": 0.083,
      "step": 1952
    },
    {
      "epoch": 0.14153712360039133,
      "grad_norm": 4.1080708503723145,
      "learning_rate": 0.00017170809478947753,
      "loss": 0.1153,
      "step": 1953
    },
    {
      "epoch": 0.14160959524586006,
      "grad_norm": 2.772247791290283,
      "learning_rate": 0.00017169360098557868,
      "loss": 0.0968,
      "step": 1954
    },
    {
      "epoch": 0.14168206689132876,
      "grad_norm": 1.9436172246932983,
      "learning_rate": 0.00017167910718167984,
      "loss": 0.1274,
      "step": 1955
    },
    {
      "epoch": 0.14175453853679748,
      "grad_norm": 1.0860309600830078,
      "learning_rate": 0.00017166461337778102,
      "loss": 0.0556,
      "step": 1956
    },
    {
      "epoch": 0.14182701018226618,
      "grad_norm": 1.1705020666122437,
      "learning_rate": 0.00017165011957388218,
      "loss": 0.0739,
      "step": 1957
    },
    {
      "epoch": 0.1418994818277349,
      "grad_norm": 0.5598568320274353,
      "learning_rate": 0.00017163562576998334,
      "loss": 0.0326,
      "step": 1958
    },
    {
      "epoch": 0.1419719534732036,
      "grad_norm": 0.6604034900665283,
      "learning_rate": 0.00017162113196608452,
      "loss": 0.0221,
      "step": 1959
    },
    {
      "epoch": 0.14204442511867232,
      "grad_norm": 3.116039752960205,
      "learning_rate": 0.00017160663816218568,
      "loss": 0.112,
      "step": 1960
    },
    {
      "epoch": 0.14211689676414102,
      "grad_norm": 3.2084014415740967,
      "learning_rate": 0.00017159214435828683,
      "loss": 0.0519,
      "step": 1961
    },
    {
      "epoch": 0.14218936840960975,
      "grad_norm": 0.5238231420516968,
      "learning_rate": 0.00017157765055438802,
      "loss": 0.0229,
      "step": 1962
    },
    {
      "epoch": 0.14226184005507844,
      "grad_norm": 4.732389450073242,
      "learning_rate": 0.00017156315675048917,
      "loss": 0.138,
      "step": 1963
    },
    {
      "epoch": 0.14233431170054717,
      "grad_norm": 4.814565658569336,
      "learning_rate": 0.00017154866294659033,
      "loss": 0.1628,
      "step": 1964
    },
    {
      "epoch": 0.14240678334601586,
      "grad_norm": 2.9840497970581055,
      "learning_rate": 0.0001715341691426915,
      "loss": 0.0885,
      "step": 1965
    },
    {
      "epoch": 0.1424792549914846,
      "grad_norm": 4.457313537597656,
      "learning_rate": 0.00017151967533879267,
      "loss": 0.1146,
      "step": 1966
    },
    {
      "epoch": 0.14255172663695329,
      "grad_norm": 3.995455026626587,
      "learning_rate": 0.00017150518153489383,
      "loss": 0.1032,
      "step": 1967
    },
    {
      "epoch": 0.142624198282422,
      "grad_norm": 5.150465965270996,
      "learning_rate": 0.000171490687730995,
      "loss": 0.1415,
      "step": 1968
    },
    {
      "epoch": 0.1426966699278907,
      "grad_norm": 3.8973045349121094,
      "learning_rate": 0.00017147619392709617,
      "loss": 0.0873,
      "step": 1969
    },
    {
      "epoch": 0.14276914157335943,
      "grad_norm": 2.7614364624023438,
      "learning_rate": 0.00017146170012319732,
      "loss": 0.1178,
      "step": 1970
    },
    {
      "epoch": 0.14284161321882813,
      "grad_norm": 1.881767988204956,
      "learning_rate": 0.0001714472063192985,
      "loss": 0.0308,
      "step": 1971
    },
    {
      "epoch": 0.14291408486429685,
      "grad_norm": 2.745668888092041,
      "learning_rate": 0.00017143271251539966,
      "loss": 0.1126,
      "step": 1972
    },
    {
      "epoch": 0.14298655650976555,
      "grad_norm": 3.7778749465942383,
      "learning_rate": 0.00017141821871150085,
      "loss": 0.2382,
      "step": 1973
    },
    {
      "epoch": 0.14305902815523427,
      "grad_norm": 4.063710689544678,
      "learning_rate": 0.000171403724907602,
      "loss": 0.0711,
      "step": 1974
    },
    {
      "epoch": 0.14313149980070297,
      "grad_norm": 2.443293809890747,
      "learning_rate": 0.00017138923110370319,
      "loss": 0.0715,
      "step": 1975
    },
    {
      "epoch": 0.1432039714461717,
      "grad_norm": 2.586315393447876,
      "learning_rate": 0.00017137473729980434,
      "loss": 0.2098,
      "step": 1976
    },
    {
      "epoch": 0.1432764430916404,
      "grad_norm": 4.551491737365723,
      "learning_rate": 0.00017136024349590553,
      "loss": 0.0866,
      "step": 1977
    },
    {
      "epoch": 0.14334891473710912,
      "grad_norm": 3.196465015411377,
      "learning_rate": 0.00017134574969200668,
      "loss": 0.0638,
      "step": 1978
    },
    {
      "epoch": 0.14342138638257781,
      "grad_norm": 1.0591589212417603,
      "learning_rate": 0.00017133125588810784,
      "loss": 0.0604,
      "step": 1979
    },
    {
      "epoch": 0.14349385802804654,
      "grad_norm": 5.385892391204834,
      "learning_rate": 0.00017131676208420902,
      "loss": 0.1805,
      "step": 1980
    },
    {
      "epoch": 0.14356632967351524,
      "grad_norm": 4.482591152191162,
      "learning_rate": 0.00017130226828031018,
      "loss": 0.1553,
      "step": 1981
    },
    {
      "epoch": 0.14363880131898396,
      "grad_norm": 2.606374502182007,
      "learning_rate": 0.00017128777447641134,
      "loss": 0.1504,
      "step": 1982
    },
    {
      "epoch": 0.14371127296445266,
      "grad_norm": 2.2535386085510254,
      "learning_rate": 0.00017127328067251252,
      "loss": 0.0952,
      "step": 1983
    },
    {
      "epoch": 0.14378374460992135,
      "grad_norm": 1.2412420511245728,
      "learning_rate": 0.00017125878686861368,
      "loss": 0.0585,
      "step": 1984
    },
    {
      "epoch": 0.14385621625539008,
      "grad_norm": 3.2706809043884277,
      "learning_rate": 0.00017124429306471483,
      "loss": 0.0725,
      "step": 1985
    },
    {
      "epoch": 0.14392868790085878,
      "grad_norm": 2.2333431243896484,
      "learning_rate": 0.00017122979926081602,
      "loss": 0.0775,
      "step": 1986
    },
    {
      "epoch": 0.1440011595463275,
      "grad_norm": 3.093289852142334,
      "learning_rate": 0.00017121530545691717,
      "loss": 0.0966,
      "step": 1987
    },
    {
      "epoch": 0.1440736311917962,
      "grad_norm": 1.150322437286377,
      "learning_rate": 0.00017120081165301833,
      "loss": 0.0723,
      "step": 1988
    },
    {
      "epoch": 0.14414610283726492,
      "grad_norm": 1.9670531749725342,
      "learning_rate": 0.0001711863178491195,
      "loss": 0.1783,
      "step": 1989
    },
    {
      "epoch": 0.14421857448273362,
      "grad_norm": 1.1018970012664795,
      "learning_rate": 0.00017117182404522067,
      "loss": 0.0666,
      "step": 1990
    },
    {
      "epoch": 0.14429104612820234,
      "grad_norm": 3.5322391986846924,
      "learning_rate": 0.00017115733024132183,
      "loss": 0.1569,
      "step": 1991
    },
    {
      "epoch": 0.14436351777367104,
      "grad_norm": 1.034918189048767,
      "learning_rate": 0.000171142836437423,
      "loss": 0.0461,
      "step": 1992
    },
    {
      "epoch": 0.14443598941913977,
      "grad_norm": 1.2447973489761353,
      "learning_rate": 0.00017112834263352417,
      "loss": 0.0456,
      "step": 1993
    },
    {
      "epoch": 0.14450846106460846,
      "grad_norm": 10.203088760375977,
      "learning_rate": 0.00017111384882962532,
      "loss": 0.1404,
      "step": 1994
    },
    {
      "epoch": 0.1445809327100772,
      "grad_norm": 2.9473936557769775,
      "learning_rate": 0.0001710993550257265,
      "loss": 0.1333,
      "step": 1995
    },
    {
      "epoch": 0.14465340435554588,
      "grad_norm": 3.575239896774292,
      "learning_rate": 0.00017108486122182766,
      "loss": 0.0743,
      "step": 1996
    },
    {
      "epoch": 0.1447258760010146,
      "grad_norm": 2.4222326278686523,
      "learning_rate": 0.00017107036741792885,
      "loss": 0.1025,
      "step": 1997
    },
    {
      "epoch": 0.1447983476464833,
      "grad_norm": 1.156463861465454,
      "learning_rate": 0.00017105587361403003,
      "loss": 0.0455,
      "step": 1998
    },
    {
      "epoch": 0.14487081929195203,
      "grad_norm": 2.0376787185668945,
      "learning_rate": 0.00017104137981013119,
      "loss": 0.1247,
      "step": 1999
    },
    {
      "epoch": 0.14494329093742073,
      "grad_norm": 3.38948655128479,
      "learning_rate": 0.00017102688600623234,
      "loss": 0.0874,
      "step": 2000
    },
    {
      "epoch": 0.14501576258288945,
      "grad_norm": 3.2483832836151123,
      "learning_rate": 0.00017101239220233353,
      "loss": 0.1195,
      "step": 2001
    },
    {
      "epoch": 0.14508823422835815,
      "grad_norm": 1.4150456190109253,
      "learning_rate": 0.00017099789839843468,
      "loss": 0.0528,
      "step": 2002
    },
    {
      "epoch": 0.14516070587382687,
      "grad_norm": 1.3223224878311157,
      "learning_rate": 0.00017098340459453584,
      "loss": 0.0934,
      "step": 2003
    },
    {
      "epoch": 0.14523317751929557,
      "grad_norm": 3.076234817504883,
      "learning_rate": 0.00017096891079063702,
      "loss": 0.0669,
      "step": 2004
    },
    {
      "epoch": 0.1453056491647643,
      "grad_norm": 2.8199622631073,
      "learning_rate": 0.00017095441698673818,
      "loss": 0.1247,
      "step": 2005
    },
    {
      "epoch": 0.145378120810233,
      "grad_norm": 3.2159652709960938,
      "learning_rate": 0.00017093992318283934,
      "loss": 0.1534,
      "step": 2006
    },
    {
      "epoch": 0.14545059245570172,
      "grad_norm": 3.0713016986846924,
      "learning_rate": 0.00017092542937894052,
      "loss": 0.1605,
      "step": 2007
    },
    {
      "epoch": 0.1455230641011704,
      "grad_norm": 2.5645060539245605,
      "learning_rate": 0.00017091093557504168,
      "loss": 0.1101,
      "step": 2008
    },
    {
      "epoch": 0.14559553574663914,
      "grad_norm": 1.803636074066162,
      "learning_rate": 0.00017089644177114283,
      "loss": 0.0865,
      "step": 2009
    },
    {
      "epoch": 0.14566800739210783,
      "grad_norm": 2.618159294128418,
      "learning_rate": 0.00017088194796724402,
      "loss": 0.1398,
      "step": 2010
    },
    {
      "epoch": 0.14574047903757656,
      "grad_norm": 3.757753610610962,
      "learning_rate": 0.00017086745416334517,
      "loss": 0.0954,
      "step": 2011
    },
    {
      "epoch": 0.14581295068304526,
      "grad_norm": 2.3179619312286377,
      "learning_rate": 0.00017085296035944633,
      "loss": 0.0803,
      "step": 2012
    },
    {
      "epoch": 0.14588542232851398,
      "grad_norm": 1.6922757625579834,
      "learning_rate": 0.0001708384665555475,
      "loss": 0.0849,
      "step": 2013
    },
    {
      "epoch": 0.14595789397398268,
      "grad_norm": 4.089603900909424,
      "learning_rate": 0.00017082397275164867,
      "loss": 0.166,
      "step": 2014
    },
    {
      "epoch": 0.1460303656194514,
      "grad_norm": 3.088756561279297,
      "learning_rate": 0.00017080947894774982,
      "loss": 0.1302,
      "step": 2015
    },
    {
      "epoch": 0.1461028372649201,
      "grad_norm": 3.992684841156006,
      "learning_rate": 0.000170794985143851,
      "loss": 0.1835,
      "step": 2016
    },
    {
      "epoch": 0.14617530891038882,
      "grad_norm": 1.5305302143096924,
      "learning_rate": 0.00017078049133995216,
      "loss": 0.093,
      "step": 2017
    },
    {
      "epoch": 0.14624778055585752,
      "grad_norm": 0.8451176285743713,
      "learning_rate": 0.00017076599753605332,
      "loss": 0.0405,
      "step": 2018
    },
    {
      "epoch": 0.14632025220132622,
      "grad_norm": 1.3368220329284668,
      "learning_rate": 0.0001707515037321545,
      "loss": 0.118,
      "step": 2019
    },
    {
      "epoch": 0.14639272384679494,
      "grad_norm": 2.2725327014923096,
      "learning_rate": 0.0001707370099282557,
      "loss": 0.0401,
      "step": 2020
    },
    {
      "epoch": 0.14646519549226364,
      "grad_norm": 4.229928493499756,
      "learning_rate": 0.00017072251612435685,
      "loss": 0.1233,
      "step": 2021
    },
    {
      "epoch": 0.14653766713773236,
      "grad_norm": 2.488884925842285,
      "learning_rate": 0.00017070802232045803,
      "loss": 0.1164,
      "step": 2022
    },
    {
      "epoch": 0.14661013878320106,
      "grad_norm": 1.6304068565368652,
      "learning_rate": 0.00017069352851655919,
      "loss": 0.1348,
      "step": 2023
    },
    {
      "epoch": 0.14668261042866979,
      "grad_norm": 4.485703945159912,
      "learning_rate": 0.00017067903471266034,
      "loss": 0.1003,
      "step": 2024
    },
    {
      "epoch": 0.14675508207413848,
      "grad_norm": 1.1116081476211548,
      "learning_rate": 0.00017066454090876153,
      "loss": 0.0838,
      "step": 2025
    },
    {
      "epoch": 0.1468275537196072,
      "grad_norm": 2.052130699157715,
      "learning_rate": 0.00017065004710486268,
      "loss": 0.0505,
      "step": 2026
    },
    {
      "epoch": 0.1469000253650759,
      "grad_norm": 3.12282395362854,
      "learning_rate": 0.00017063555330096384,
      "loss": 0.0222,
      "step": 2027
    },
    {
      "epoch": 0.14697249701054463,
      "grad_norm": 2.268667459487915,
      "learning_rate": 0.00017062105949706502,
      "loss": 0.1123,
      "step": 2028
    },
    {
      "epoch": 0.14704496865601333,
      "grad_norm": 5.06124210357666,
      "learning_rate": 0.00017060656569316618,
      "loss": 0.1871,
      "step": 2029
    },
    {
      "epoch": 0.14711744030148205,
      "grad_norm": 1.6026310920715332,
      "learning_rate": 0.00017059207188926733,
      "loss": 0.1736,
      "step": 2030
    },
    {
      "epoch": 0.14718991194695075,
      "grad_norm": 1.5391466617584229,
      "learning_rate": 0.00017057757808536852,
      "loss": 0.084,
      "step": 2031
    },
    {
      "epoch": 0.14726238359241947,
      "grad_norm": 3.8363394737243652,
      "learning_rate": 0.00017056308428146967,
      "loss": 0.189,
      "step": 2032
    },
    {
      "epoch": 0.14733485523788817,
      "grad_norm": 3.3412060737609863,
      "learning_rate": 0.00017054859047757086,
      "loss": 0.249,
      "step": 2033
    },
    {
      "epoch": 0.1474073268833569,
      "grad_norm": 2.103874683380127,
      "learning_rate": 0.00017053409667367201,
      "loss": 0.1545,
      "step": 2034
    },
    {
      "epoch": 0.1474797985288256,
      "grad_norm": 0.9628002047538757,
      "learning_rate": 0.00017051960286977317,
      "loss": 0.0479,
      "step": 2035
    },
    {
      "epoch": 0.14755227017429431,
      "grad_norm": 1.7637979984283447,
      "learning_rate": 0.00017050510906587435,
      "loss": 0.0836,
      "step": 2036
    },
    {
      "epoch": 0.147624741819763,
      "grad_norm": 1.898024320602417,
      "learning_rate": 0.0001704906152619755,
      "loss": 0.0635,
      "step": 2037
    },
    {
      "epoch": 0.14769721346523174,
      "grad_norm": 1.4195237159729004,
      "learning_rate": 0.00017047612145807667,
      "loss": 0.0522,
      "step": 2038
    },
    {
      "epoch": 0.14776968511070043,
      "grad_norm": 2.208564281463623,
      "learning_rate": 0.00017046162765417785,
      "loss": 0.0806,
      "step": 2039
    },
    {
      "epoch": 0.14784215675616916,
      "grad_norm": 3.735726833343506,
      "learning_rate": 0.000170447133850279,
      "loss": 0.044,
      "step": 2040
    },
    {
      "epoch": 0.14791462840163785,
      "grad_norm": 2.1795365810394287,
      "learning_rate": 0.00017043264004638016,
      "loss": 0.0776,
      "step": 2041
    },
    {
      "epoch": 0.14798710004710658,
      "grad_norm": 2.716496706008911,
      "learning_rate": 0.00017041814624248135,
      "loss": 0.1162,
      "step": 2042
    },
    {
      "epoch": 0.14805957169257528,
      "grad_norm": 2.2719504833221436,
      "learning_rate": 0.0001704036524385825,
      "loss": 0.0775,
      "step": 2043
    },
    {
      "epoch": 0.148132043338044,
      "grad_norm": 2.5064854621887207,
      "learning_rate": 0.0001703891586346837,
      "loss": 0.0882,
      "step": 2044
    },
    {
      "epoch": 0.1482045149835127,
      "grad_norm": 4.118587493896484,
      "learning_rate": 0.00017037466483078484,
      "loss": 0.2112,
      "step": 2045
    },
    {
      "epoch": 0.14827698662898142,
      "grad_norm": 1.801080584526062,
      "learning_rate": 0.00017036017102688603,
      "loss": 0.0466,
      "step": 2046
    },
    {
      "epoch": 0.14834945827445012,
      "grad_norm": 2.181624174118042,
      "learning_rate": 0.00017034567722298718,
      "loss": 0.1108,
      "step": 2047
    },
    {
      "epoch": 0.14842192991991884,
      "grad_norm": 2.80069637298584,
      "learning_rate": 0.00017033118341908837,
      "loss": 0.1217,
      "step": 2048
    },
    {
      "epoch": 0.14849440156538754,
      "grad_norm": 3.5047202110290527,
      "learning_rate": 0.00017031668961518952,
      "loss": 0.064,
      "step": 2049
    },
    {
      "epoch": 0.14856687321085627,
      "grad_norm": 1.943137288093567,
      "learning_rate": 0.00017030219581129068,
      "loss": 0.0661,
      "step": 2050
    },
    {
      "epoch": 0.14863934485632496,
      "grad_norm": 8.302128791809082,
      "learning_rate": 0.00017028770200739186,
      "loss": 0.194,
      "step": 2051
    },
    {
      "epoch": 0.1487118165017937,
      "grad_norm": 1.40969717502594,
      "learning_rate": 0.00017027320820349302,
      "loss": 0.0906,
      "step": 2052
    },
    {
      "epoch": 0.14878428814726238,
      "grad_norm": 4.066763877868652,
      "learning_rate": 0.00017025871439959418,
      "loss": 0.1008,
      "step": 2053
    },
    {
      "epoch": 0.14885675979273108,
      "grad_norm": 3.5233371257781982,
      "learning_rate": 0.00017024422059569536,
      "loss": 0.2136,
      "step": 2054
    },
    {
      "epoch": 0.1489292314381998,
      "grad_norm": 2.5234177112579346,
      "learning_rate": 0.00017022972679179652,
      "loss": 0.1251,
      "step": 2055
    },
    {
      "epoch": 0.1490017030836685,
      "grad_norm": 3.186561346054077,
      "learning_rate": 0.00017021523298789767,
      "loss": 0.0367,
      "step": 2056
    },
    {
      "epoch": 0.14907417472913723,
      "grad_norm": 5.984371662139893,
      "learning_rate": 0.00017020073918399886,
      "loss": 0.1266,
      "step": 2057
    },
    {
      "epoch": 0.14914664637460592,
      "grad_norm": 3.626654863357544,
      "learning_rate": 0.00017018624538010001,
      "loss": 0.2096,
      "step": 2058
    },
    {
      "epoch": 0.14921911802007465,
      "grad_norm": 1.848304033279419,
      "learning_rate": 0.00017017175157620117,
      "loss": 0.055,
      "step": 2059
    },
    {
      "epoch": 0.14929158966554334,
      "grad_norm": 1.3719700574874878,
      "learning_rate": 0.00017015725777230235,
      "loss": 0.0721,
      "step": 2060
    },
    {
      "epoch": 0.14936406131101207,
      "grad_norm": 1.8198015689849854,
      "learning_rate": 0.0001701427639684035,
      "loss": 0.0661,
      "step": 2061
    },
    {
      "epoch": 0.14943653295648077,
      "grad_norm": 3.789672613143921,
      "learning_rate": 0.00017012827016450467,
      "loss": 0.0765,
      "step": 2062
    },
    {
      "epoch": 0.1495090046019495,
      "grad_norm": 5.416086673736572,
      "learning_rate": 0.00017011377636060585,
      "loss": 0.316,
      "step": 2063
    },
    {
      "epoch": 0.1495814762474182,
      "grad_norm": 2.2127184867858887,
      "learning_rate": 0.000170099282556707,
      "loss": 0.0741,
      "step": 2064
    },
    {
      "epoch": 0.1496539478928869,
      "grad_norm": 1.5675921440124512,
      "learning_rate": 0.00017008478875280816,
      "loss": 0.0403,
      "step": 2065
    },
    {
      "epoch": 0.1497264195383556,
      "grad_norm": 0.9189698696136475,
      "learning_rate": 0.00017007029494890935,
      "loss": 0.0371,
      "step": 2066
    },
    {
      "epoch": 0.14979889118382433,
      "grad_norm": 2.882063865661621,
      "learning_rate": 0.00017005580114501053,
      "loss": 0.1502,
      "step": 2067
    },
    {
      "epoch": 0.14987136282929303,
      "grad_norm": 4.155716896057129,
      "learning_rate": 0.0001700413073411117,
      "loss": 0.1301,
      "step": 2068
    },
    {
      "epoch": 0.14994383447476176,
      "grad_norm": 2.976766347885132,
      "learning_rate": 0.00017002681353721287,
      "loss": 0.0716,
      "step": 2069
    },
    {
      "epoch": 0.15001630612023045,
      "grad_norm": 9.7157564163208,
      "learning_rate": 0.00017001231973331403,
      "loss": 0.2364,
      "step": 2070
    },
    {
      "epoch": 0.15008877776569918,
      "grad_norm": 3.104689836502075,
      "learning_rate": 0.00016999782592941518,
      "loss": 0.1747,
      "step": 2071
    },
    {
      "epoch": 0.15016124941116787,
      "grad_norm": 3.882753849029541,
      "learning_rate": 0.00016998333212551637,
      "loss": 0.2295,
      "step": 2072
    },
    {
      "epoch": 0.1502337210566366,
      "grad_norm": 3.4782841205596924,
      "learning_rate": 0.00016996883832161752,
      "loss": 0.1527,
      "step": 2073
    },
    {
      "epoch": 0.1503061927021053,
      "grad_norm": 1.554389238357544,
      "learning_rate": 0.00016995434451771868,
      "loss": 0.076,
      "step": 2074
    },
    {
      "epoch": 0.15037866434757402,
      "grad_norm": 1.1815069913864136,
      "learning_rate": 0.00016993985071381986,
      "loss": 0.053,
      "step": 2075
    },
    {
      "epoch": 0.15045113599304272,
      "grad_norm": 2.0168819427490234,
      "learning_rate": 0.00016992535690992102,
      "loss": 0.0899,
      "step": 2076
    },
    {
      "epoch": 0.15052360763851144,
      "grad_norm": 1.0990098714828491,
      "learning_rate": 0.00016991086310602218,
      "loss": 0.0555,
      "step": 2077
    },
    {
      "epoch": 0.15059607928398014,
      "grad_norm": 6.291202068328857,
      "learning_rate": 0.00016989636930212336,
      "loss": 0.1609,
      "step": 2078
    },
    {
      "epoch": 0.15066855092944886,
      "grad_norm": 2.5797295570373535,
      "learning_rate": 0.00016988187549822452,
      "loss": 0.0955,
      "step": 2079
    },
    {
      "epoch": 0.15074102257491756,
      "grad_norm": 4.312334060668945,
      "learning_rate": 0.00016986738169432567,
      "loss": 0.2133,
      "step": 2080
    },
    {
      "epoch": 0.15081349422038628,
      "grad_norm": 2.2650904655456543,
      "learning_rate": 0.00016985288789042686,
      "loss": 0.1117,
      "step": 2081
    },
    {
      "epoch": 0.15088596586585498,
      "grad_norm": 2.056206703186035,
      "learning_rate": 0.00016983839408652801,
      "loss": 0.0863,
      "step": 2082
    },
    {
      "epoch": 0.1509584375113237,
      "grad_norm": 1.532220482826233,
      "learning_rate": 0.00016982390028262917,
      "loss": 0.0483,
      "step": 2083
    },
    {
      "epoch": 0.1510309091567924,
      "grad_norm": 3.108172655105591,
      "learning_rate": 0.00016980940647873035,
      "loss": 0.1293,
      "step": 2084
    },
    {
      "epoch": 0.15110338080226113,
      "grad_norm": 3.0218868255615234,
      "learning_rate": 0.0001697949126748315,
      "loss": 0.1353,
      "step": 2085
    },
    {
      "epoch": 0.15117585244772982,
      "grad_norm": 1.5216033458709717,
      "learning_rate": 0.00016978041887093267,
      "loss": 0.0656,
      "step": 2086
    },
    {
      "epoch": 0.15124832409319855,
      "grad_norm": 2.661074638366699,
      "learning_rate": 0.00016976592506703385,
      "loss": 0.0848,
      "step": 2087
    },
    {
      "epoch": 0.15132079573866725,
      "grad_norm": 3.5628786087036133,
      "learning_rate": 0.000169751431263135,
      "loss": 0.1876,
      "step": 2088
    },
    {
      "epoch": 0.15139326738413594,
      "grad_norm": 1.297057867050171,
      "learning_rate": 0.0001697369374592362,
      "loss": 0.0854,
      "step": 2089
    },
    {
      "epoch": 0.15146573902960467,
      "grad_norm": 4.5275444984436035,
      "learning_rate": 0.00016972244365533735,
      "loss": 0.1215,
      "step": 2090
    },
    {
      "epoch": 0.15153821067507336,
      "grad_norm": 1.4176405668258667,
      "learning_rate": 0.00016970794985143853,
      "loss": 0.0741,
      "step": 2091
    },
    {
      "epoch": 0.1516106823205421,
      "grad_norm": 1.4467799663543701,
      "learning_rate": 0.0001696934560475397,
      "loss": 0.082,
      "step": 2092
    },
    {
      "epoch": 0.1516831539660108,
      "grad_norm": 2.3391013145446777,
      "learning_rate": 0.00016967896224364087,
      "loss": 0.1805,
      "step": 2093
    },
    {
      "epoch": 0.1517556256114795,
      "grad_norm": 0.9258960485458374,
      "learning_rate": 0.00016966446843974203,
      "loss": 0.0341,
      "step": 2094
    },
    {
      "epoch": 0.1518280972569482,
      "grad_norm": 1.4486734867095947,
      "learning_rate": 0.00016964997463584318,
      "loss": 0.0646,
      "step": 2095
    },
    {
      "epoch": 0.15190056890241693,
      "grad_norm": 2.8014869689941406,
      "learning_rate": 0.00016963548083194437,
      "loss": 0.0839,
      "step": 2096
    },
    {
      "epoch": 0.15197304054788563,
      "grad_norm": 2.156445026397705,
      "learning_rate": 0.00016962098702804552,
      "loss": 0.0268,
      "step": 2097
    },
    {
      "epoch": 0.15204551219335435,
      "grad_norm": 2.27313232421875,
      "learning_rate": 0.00016960649322414668,
      "loss": 0.0902,
      "step": 2098
    },
    {
      "epoch": 0.15211798383882305,
      "grad_norm": 4.0166802406311035,
      "learning_rate": 0.00016959199942024786,
      "loss": 0.1612,
      "step": 2099
    },
    {
      "epoch": 0.15219045548429178,
      "grad_norm": 2.3910419940948486,
      "learning_rate": 0.00016957750561634902,
      "loss": 0.0808,
      "step": 2100
    },
    {
      "epoch": 0.15226292712976047,
      "grad_norm": 4.843901634216309,
      "learning_rate": 0.00016956301181245018,
      "loss": 0.0594,
      "step": 2101
    },
    {
      "epoch": 0.1523353987752292,
      "grad_norm": 1.045108675956726,
      "learning_rate": 0.00016954851800855136,
      "loss": 0.0246,
      "step": 2102
    },
    {
      "epoch": 0.1524078704206979,
      "grad_norm": 2.8710203170776367,
      "learning_rate": 0.00016953402420465252,
      "loss": 0.1105,
      "step": 2103
    },
    {
      "epoch": 0.15248034206616662,
      "grad_norm": 2.08750319480896,
      "learning_rate": 0.00016951953040075367,
      "loss": 0.0669,
      "step": 2104
    },
    {
      "epoch": 0.15255281371163532,
      "grad_norm": 4.310903072357178,
      "learning_rate": 0.00016950503659685486,
      "loss": 0.1936,
      "step": 2105
    },
    {
      "epoch": 0.15262528535710404,
      "grad_norm": 2.674530029296875,
      "learning_rate": 0.00016949054279295601,
      "loss": 0.0936,
      "step": 2106
    },
    {
      "epoch": 0.15269775700257274,
      "grad_norm": 1.7181700468063354,
      "learning_rate": 0.00016947604898905717,
      "loss": 0.1348,
      "step": 2107
    },
    {
      "epoch": 0.15277022864804146,
      "grad_norm": 2.9578614234924316,
      "learning_rate": 0.00016946155518515835,
      "loss": 0.2897,
      "step": 2108
    },
    {
      "epoch": 0.15284270029351016,
      "grad_norm": 1.640713095664978,
      "learning_rate": 0.0001694470613812595,
      "loss": 0.0753,
      "step": 2109
    },
    {
      "epoch": 0.15291517193897888,
      "grad_norm": 1.9091109037399292,
      "learning_rate": 0.00016943256757736067,
      "loss": 0.1268,
      "step": 2110
    },
    {
      "epoch": 0.15298764358444758,
      "grad_norm": 3.2223501205444336,
      "learning_rate": 0.00016941807377346185,
      "loss": 0.1653,
      "step": 2111
    },
    {
      "epoch": 0.1530601152299163,
      "grad_norm": 2.0736818313598633,
      "learning_rate": 0.000169403579969563,
      "loss": 0.1419,
      "step": 2112
    },
    {
      "epoch": 0.153132586875385,
      "grad_norm": 3.6139607429504395,
      "learning_rate": 0.0001693890861656642,
      "loss": 0.1057,
      "step": 2113
    },
    {
      "epoch": 0.15320505852085373,
      "grad_norm": 1.2980716228485107,
      "learning_rate": 0.00016937459236176537,
      "loss": 0.0907,
      "step": 2114
    },
    {
      "epoch": 0.15327753016632242,
      "grad_norm": 3.558931827545166,
      "learning_rate": 0.00016936009855786653,
      "loss": 0.2356,
      "step": 2115
    },
    {
      "epoch": 0.15335000181179115,
      "grad_norm": 1.4136502742767334,
      "learning_rate": 0.0001693456047539677,
      "loss": 0.0598,
      "step": 2116
    },
    {
      "epoch": 0.15342247345725984,
      "grad_norm": 2.538696050643921,
      "learning_rate": 0.00016933111095006887,
      "loss": 0.1147,
      "step": 2117
    },
    {
      "epoch": 0.15349494510272857,
      "grad_norm": 1.7874547243118286,
      "learning_rate": 0.00016931661714617003,
      "loss": 0.1617,
      "step": 2118
    },
    {
      "epoch": 0.15356741674819727,
      "grad_norm": 1.4694623947143555,
      "learning_rate": 0.00016930212334227118,
      "loss": 0.0385,
      "step": 2119
    },
    {
      "epoch": 0.153639888393666,
      "grad_norm": 0.7820358276367188,
      "learning_rate": 0.00016928762953837237,
      "loss": 0.0439,
      "step": 2120
    },
    {
      "epoch": 0.1537123600391347,
      "grad_norm": 1.0734009742736816,
      "learning_rate": 0.00016927313573447352,
      "loss": 0.0799,
      "step": 2121
    },
    {
      "epoch": 0.1537848316846034,
      "grad_norm": 1.0864864587783813,
      "learning_rate": 0.00016925864193057468,
      "loss": 0.075,
      "step": 2122
    },
    {
      "epoch": 0.1538573033300721,
      "grad_norm": 0.660449743270874,
      "learning_rate": 0.00016924414812667586,
      "loss": 0.0342,
      "step": 2123
    },
    {
      "epoch": 0.1539297749755408,
      "grad_norm": 2.326143741607666,
      "learning_rate": 0.00016922965432277702,
      "loss": 0.1086,
      "step": 2124
    },
    {
      "epoch": 0.15400224662100953,
      "grad_norm": 1.6552354097366333,
      "learning_rate": 0.00016921516051887818,
      "loss": 0.0817,
      "step": 2125
    },
    {
      "epoch": 0.15407471826647823,
      "grad_norm": 1.4640144109725952,
      "learning_rate": 0.00016920066671497936,
      "loss": 0.0216,
      "step": 2126
    },
    {
      "epoch": 0.15414718991194695,
      "grad_norm": 0.9878193736076355,
      "learning_rate": 0.00016918617291108052,
      "loss": 0.0303,
      "step": 2127
    },
    {
      "epoch": 0.15421966155741565,
      "grad_norm": 2.2203428745269775,
      "learning_rate": 0.00016917167910718167,
      "loss": 0.0426,
      "step": 2128
    },
    {
      "epoch": 0.15429213320288437,
      "grad_norm": 1.9873549938201904,
      "learning_rate": 0.00016915718530328286,
      "loss": 0.1377,
      "step": 2129
    },
    {
      "epoch": 0.15436460484835307,
      "grad_norm": 3.533438205718994,
      "learning_rate": 0.000169142691499384,
      "loss": 0.2082,
      "step": 2130
    },
    {
      "epoch": 0.1544370764938218,
      "grad_norm": 3.7687346935272217,
      "learning_rate": 0.00016912819769548517,
      "loss": 0.0496,
      "step": 2131
    },
    {
      "epoch": 0.1545095481392905,
      "grad_norm": 2.3865668773651123,
      "learning_rate": 0.00016911370389158635,
      "loss": 0.105,
      "step": 2132
    },
    {
      "epoch": 0.15458201978475922,
      "grad_norm": 1.2539154291152954,
      "learning_rate": 0.0001690992100876875,
      "loss": 0.0429,
      "step": 2133
    },
    {
      "epoch": 0.15465449143022791,
      "grad_norm": 5.883755683898926,
      "learning_rate": 0.0001690847162837887,
      "loss": 0.2054,
      "step": 2134
    },
    {
      "epoch": 0.15472696307569664,
      "grad_norm": 8.245930671691895,
      "learning_rate": 0.00016907022247988985,
      "loss": 0.1297,
      "step": 2135
    },
    {
      "epoch": 0.15479943472116534,
      "grad_norm": 3.731088161468506,
      "learning_rate": 0.00016905572867599103,
      "loss": 0.1051,
      "step": 2136
    },
    {
      "epoch": 0.15487190636663406,
      "grad_norm": 2.535137891769409,
      "learning_rate": 0.0001690412348720922,
      "loss": 0.1682,
      "step": 2137
    },
    {
      "epoch": 0.15494437801210276,
      "grad_norm": 3.718284845352173,
      "learning_rate": 0.00016902674106819337,
      "loss": 0.1038,
      "step": 2138
    },
    {
      "epoch": 0.15501684965757148,
      "grad_norm": 4.5216217041015625,
      "learning_rate": 0.00016901224726429453,
      "loss": 0.1524,
      "step": 2139
    },
    {
      "epoch": 0.15508932130304018,
      "grad_norm": 2.207242965698242,
      "learning_rate": 0.0001689977534603957,
      "loss": 0.0947,
      "step": 2140
    },
    {
      "epoch": 0.1551617929485089,
      "grad_norm": 2.838364362716675,
      "learning_rate": 0.00016898325965649687,
      "loss": 0.1445,
      "step": 2141
    },
    {
      "epoch": 0.1552342645939776,
      "grad_norm": 3.010166645050049,
      "learning_rate": 0.00016896876585259803,
      "loss": 0.1648,
      "step": 2142
    },
    {
      "epoch": 0.15530673623944632,
      "grad_norm": 0.7609692811965942,
      "learning_rate": 0.00016895427204869918,
      "loss": 0.0258,
      "step": 2143
    },
    {
      "epoch": 0.15537920788491502,
      "grad_norm": 3.230074882507324,
      "learning_rate": 0.00016893977824480037,
      "loss": 0.1066,
      "step": 2144
    },
    {
      "epoch": 0.15545167953038375,
      "grad_norm": 4.942470550537109,
      "learning_rate": 0.00016892528444090152,
      "loss": 0.0732,
      "step": 2145
    },
    {
      "epoch": 0.15552415117585244,
      "grad_norm": 2.9228906631469727,
      "learning_rate": 0.00016891079063700268,
      "loss": 0.1857,
      "step": 2146
    },
    {
      "epoch": 0.15559662282132117,
      "grad_norm": 1.291387915611267,
      "learning_rate": 0.00016889629683310386,
      "loss": 0.0635,
      "step": 2147
    },
    {
      "epoch": 0.15566909446678986,
      "grad_norm": 1.6011358499526978,
      "learning_rate": 0.00016888180302920502,
      "loss": 0.1172,
      "step": 2148
    },
    {
      "epoch": 0.1557415661122586,
      "grad_norm": 1.7047313451766968,
      "learning_rate": 0.00016886730922530618,
      "loss": 0.0637,
      "step": 2149
    },
    {
      "epoch": 0.1558140377577273,
      "grad_norm": 6.351770401000977,
      "learning_rate": 0.00016885281542140736,
      "loss": 0.1347,
      "step": 2150
    },
    {
      "epoch": 0.155886509403196,
      "grad_norm": 3.3828954696655273,
      "learning_rate": 0.00016883832161750852,
      "loss": 0.0558,
      "step": 2151
    },
    {
      "epoch": 0.1559589810486647,
      "grad_norm": 1.5412201881408691,
      "learning_rate": 0.00016882382781360967,
      "loss": 0.0625,
      "step": 2152
    },
    {
      "epoch": 0.15603145269413343,
      "grad_norm": 1.9297966957092285,
      "learning_rate": 0.00016880933400971086,
      "loss": 0.0769,
      "step": 2153
    },
    {
      "epoch": 0.15610392433960213,
      "grad_norm": 2.6898438930511475,
      "learning_rate": 0.000168794840205812,
      "loss": 0.0993,
      "step": 2154
    },
    {
      "epoch": 0.15617639598507085,
      "grad_norm": 5.008145332336426,
      "learning_rate": 0.00016878034640191317,
      "loss": 0.148,
      "step": 2155
    },
    {
      "epoch": 0.15624886763053955,
      "grad_norm": 4.321317672729492,
      "learning_rate": 0.00016876585259801435,
      "loss": 0.0691,
      "step": 2156
    },
    {
      "epoch": 0.15632133927600828,
      "grad_norm": 1.3927857875823975,
      "learning_rate": 0.0001687513587941155,
      "loss": 0.0937,
      "step": 2157
    },
    {
      "epoch": 0.15639381092147697,
      "grad_norm": 2.664599657058716,
      "learning_rate": 0.0001687368649902167,
      "loss": 0.0817,
      "step": 2158
    },
    {
      "epoch": 0.15646628256694567,
      "grad_norm": 2.6843395233154297,
      "learning_rate": 0.00016872237118631785,
      "loss": 0.1387,
      "step": 2159
    },
    {
      "epoch": 0.1565387542124144,
      "grad_norm": 2.286353588104248,
      "learning_rate": 0.00016870787738241903,
      "loss": 0.0803,
      "step": 2160
    },
    {
      "epoch": 0.1566112258578831,
      "grad_norm": 4.030706405639648,
      "learning_rate": 0.0001686933835785202,
      "loss": 0.1223,
      "step": 2161
    },
    {
      "epoch": 0.15668369750335182,
      "grad_norm": 0.9958400130271912,
      "learning_rate": 0.00016867888977462137,
      "loss": 0.0399,
      "step": 2162
    },
    {
      "epoch": 0.1567561691488205,
      "grad_norm": 1.1608291864395142,
      "learning_rate": 0.00016866439597072253,
      "loss": 0.0601,
      "step": 2163
    },
    {
      "epoch": 0.15682864079428924,
      "grad_norm": 1.2183529138565063,
      "learning_rate": 0.00016864990216682369,
      "loss": 0.1047,
      "step": 2164
    },
    {
      "epoch": 0.15690111243975793,
      "grad_norm": 1.873618483543396,
      "learning_rate": 0.00016863540836292487,
      "loss": 0.1051,
      "step": 2165
    },
    {
      "epoch": 0.15697358408522666,
      "grad_norm": 4.275970458984375,
      "learning_rate": 0.00016862091455902603,
      "loss": 0.0665,
      "step": 2166
    },
    {
      "epoch": 0.15704605573069536,
      "grad_norm": 2.3377678394317627,
      "learning_rate": 0.00016860642075512718,
      "loss": 0.1572,
      "step": 2167
    },
    {
      "epoch": 0.15711852737616408,
      "grad_norm": 1.5188641548156738,
      "learning_rate": 0.00016859192695122837,
      "loss": 0.0922,
      "step": 2168
    },
    {
      "epoch": 0.15719099902163278,
      "grad_norm": 6.089908123016357,
      "learning_rate": 0.00016857743314732952,
      "loss": 0.0864,
      "step": 2169
    },
    {
      "epoch": 0.1572634706671015,
      "grad_norm": 3.7701447010040283,
      "learning_rate": 0.00016856293934343068,
      "loss": 0.1672,
      "step": 2170
    },
    {
      "epoch": 0.1573359423125702,
      "grad_norm": 0.18461954593658447,
      "learning_rate": 0.00016854844553953186,
      "loss": 0.0059,
      "step": 2171
    },
    {
      "epoch": 0.15740841395803892,
      "grad_norm": 2.9316256046295166,
      "learning_rate": 0.00016853395173563302,
      "loss": 0.1627,
      "step": 2172
    },
    {
      "epoch": 0.15748088560350762,
      "grad_norm": 0.43250149488449097,
      "learning_rate": 0.00016851945793173418,
      "loss": 0.0161,
      "step": 2173
    },
    {
      "epoch": 0.15755335724897634,
      "grad_norm": 3.474862813949585,
      "learning_rate": 0.00016850496412783536,
      "loss": 0.0952,
      "step": 2174
    },
    {
      "epoch": 0.15762582889444504,
      "grad_norm": 0.6375793814659119,
      "learning_rate": 0.00016849047032393652,
      "loss": 0.034,
      "step": 2175
    },
    {
      "epoch": 0.15769830053991377,
      "grad_norm": 1.9588932991027832,
      "learning_rate": 0.00016847597652003767,
      "loss": 0.0984,
      "step": 2176
    },
    {
      "epoch": 0.15777077218538246,
      "grad_norm": 1.6799132823944092,
      "learning_rate": 0.00016846148271613886,
      "loss": 0.084,
      "step": 2177
    },
    {
      "epoch": 0.1578432438308512,
      "grad_norm": 2.059919834136963,
      "learning_rate": 0.00016844698891224,
      "loss": 0.1788,
      "step": 2178
    },
    {
      "epoch": 0.15791571547631988,
      "grad_norm": 2.0733704566955566,
      "learning_rate": 0.00016843249510834117,
      "loss": 0.1206,
      "step": 2179
    },
    {
      "epoch": 0.1579881871217886,
      "grad_norm": 2.5370993614196777,
      "learning_rate": 0.00016841800130444235,
      "loss": 0.1028,
      "step": 2180
    },
    {
      "epoch": 0.1580606587672573,
      "grad_norm": 2.903416872024536,
      "learning_rate": 0.0001684035075005435,
      "loss": 0.1727,
      "step": 2181
    },
    {
      "epoch": 0.15813313041272603,
      "grad_norm": 3.4165139198303223,
      "learning_rate": 0.0001683890136966447,
      "loss": 0.108,
      "step": 2182
    },
    {
      "epoch": 0.15820560205819473,
      "grad_norm": 5.4233222007751465,
      "learning_rate": 0.00016837451989274588,
      "loss": 0.1496,
      "step": 2183
    },
    {
      "epoch": 0.15827807370366345,
      "grad_norm": 4.012469291687012,
      "learning_rate": 0.00016836002608884703,
      "loss": 0.1332,
      "step": 2184
    },
    {
      "epoch": 0.15835054534913215,
      "grad_norm": 0.7315307855606079,
      "learning_rate": 0.0001683455322849482,
      "loss": 0.0178,
      "step": 2185
    },
    {
      "epoch": 0.15842301699460087,
      "grad_norm": 0.6140175461769104,
      "learning_rate": 0.00016833103848104937,
      "loss": 0.0558,
      "step": 2186
    },
    {
      "epoch": 0.15849548864006957,
      "grad_norm": 2.075598955154419,
      "learning_rate": 0.00016831654467715053,
      "loss": 0.0605,
      "step": 2187
    },
    {
      "epoch": 0.1585679602855383,
      "grad_norm": 2.818974494934082,
      "learning_rate": 0.00016830205087325169,
      "loss": 0.1317,
      "step": 2188
    },
    {
      "epoch": 0.158640431931007,
      "grad_norm": 2.4122047424316406,
      "learning_rate": 0.00016828755706935287,
      "loss": 0.1127,
      "step": 2189
    },
    {
      "epoch": 0.15871290357647572,
      "grad_norm": 2.1955339908599854,
      "learning_rate": 0.00016827306326545403,
      "loss": 0.0335,
      "step": 2190
    },
    {
      "epoch": 0.1587853752219444,
      "grad_norm": 2.430664539337158,
      "learning_rate": 0.00016825856946155518,
      "loss": 0.1424,
      "step": 2191
    },
    {
      "epoch": 0.15885784686741314,
      "grad_norm": 2.8110511302948,
      "learning_rate": 0.00016824407565765637,
      "loss": 0.1663,
      "step": 2192
    },
    {
      "epoch": 0.15893031851288184,
      "grad_norm": 2.970858097076416,
      "learning_rate": 0.00016822958185375752,
      "loss": 0.1459,
      "step": 2193
    },
    {
      "epoch": 0.15900279015835053,
      "grad_norm": 0.899541437625885,
      "learning_rate": 0.0001682150880498587,
      "loss": 0.017,
      "step": 2194
    },
    {
      "epoch": 0.15907526180381926,
      "grad_norm": 3.838834762573242,
      "learning_rate": 0.00016820059424595986,
      "loss": 0.1422,
      "step": 2195
    },
    {
      "epoch": 0.15914773344928795,
      "grad_norm": 3.29672908782959,
      "learning_rate": 0.00016818610044206102,
      "loss": 0.2083,
      "step": 2196
    },
    {
      "epoch": 0.15922020509475668,
      "grad_norm": 1.3029897212982178,
      "learning_rate": 0.0001681716066381622,
      "loss": 0.0418,
      "step": 2197
    },
    {
      "epoch": 0.15929267674022538,
      "grad_norm": 1.1725857257843018,
      "learning_rate": 0.00016815711283426336,
      "loss": 0.0896,
      "step": 2198
    },
    {
      "epoch": 0.1593651483856941,
      "grad_norm": 1.1420972347259521,
      "learning_rate": 0.00016814261903036452,
      "loss": 0.0479,
      "step": 2199
    },
    {
      "epoch": 0.1594376200311628,
      "grad_norm": 1.6200109720230103,
      "learning_rate": 0.0001681281252264657,
      "loss": 0.1157,
      "step": 2200
    },
    {
      "epoch": 0.15951009167663152,
      "grad_norm": 1.061501145362854,
      "learning_rate": 0.00016811363142256686,
      "loss": 0.0764,
      "step": 2201
    },
    {
      "epoch": 0.15958256332210022,
      "grad_norm": 2.622269630432129,
      "learning_rate": 0.000168099137618668,
      "loss": 0.1363,
      "step": 2202
    },
    {
      "epoch": 0.15965503496756894,
      "grad_norm": 1.8794753551483154,
      "learning_rate": 0.0001680846438147692,
      "loss": 0.0602,
      "step": 2203
    },
    {
      "epoch": 0.15972750661303764,
      "grad_norm": 1.3526078462600708,
      "learning_rate": 0.00016807015001087035,
      "loss": 0.111,
      "step": 2204
    },
    {
      "epoch": 0.15979997825850636,
      "grad_norm": 1.018603801727295,
      "learning_rate": 0.00016805565620697154,
      "loss": 0.0888,
      "step": 2205
    },
    {
      "epoch": 0.15987244990397506,
      "grad_norm": 1.5012526512145996,
      "learning_rate": 0.0001680411624030727,
      "loss": 0.075,
      "step": 2206
    },
    {
      "epoch": 0.15994492154944379,
      "grad_norm": 1.097861647605896,
      "learning_rate": 0.00016802666859917388,
      "loss": 0.0411,
      "step": 2207
    },
    {
      "epoch": 0.16001739319491248,
      "grad_norm": 1.303780436515808,
      "learning_rate": 0.00016801217479527503,
      "loss": 0.086,
      "step": 2208
    },
    {
      "epoch": 0.1600898648403812,
      "grad_norm": 1.2959914207458496,
      "learning_rate": 0.00016799768099137622,
      "loss": 0.0632,
      "step": 2209
    },
    {
      "epoch": 0.1601623364858499,
      "grad_norm": 4.887043476104736,
      "learning_rate": 0.00016798318718747737,
      "loss": 0.1659,
      "step": 2210
    },
    {
      "epoch": 0.16023480813131863,
      "grad_norm": 1.4956438541412354,
      "learning_rate": 0.00016796869338357853,
      "loss": 0.0865,
      "step": 2211
    },
    {
      "epoch": 0.16030727977678733,
      "grad_norm": 2.4175631999969482,
      "learning_rate": 0.0001679541995796797,
      "loss": 0.1936,
      "step": 2212
    },
    {
      "epoch": 0.16037975142225605,
      "grad_norm": 1.1596965789794922,
      "learning_rate": 0.00016793970577578087,
      "loss": 0.034,
      "step": 2213
    },
    {
      "epoch": 0.16045222306772475,
      "grad_norm": 1.9813640117645264,
      "learning_rate": 0.00016792521197188203,
      "loss": 0.0831,
      "step": 2214
    },
    {
      "epoch": 0.16052469471319347,
      "grad_norm": 2.122586727142334,
      "learning_rate": 0.0001679107181679832,
      "loss": 0.1515,
      "step": 2215
    },
    {
      "epoch": 0.16059716635866217,
      "grad_norm": 1.0549479722976685,
      "learning_rate": 0.00016789622436408437,
      "loss": 0.0218,
      "step": 2216
    },
    {
      "epoch": 0.1606696380041309,
      "grad_norm": 6.13655948638916,
      "learning_rate": 0.00016788173056018552,
      "loss": 0.232,
      "step": 2217
    },
    {
      "epoch": 0.1607421096495996,
      "grad_norm": 2.1763739585876465,
      "learning_rate": 0.0001678672367562867,
      "loss": 0.1157,
      "step": 2218
    },
    {
      "epoch": 0.16081458129506832,
      "grad_norm": 1.9349348545074463,
      "learning_rate": 0.00016785274295238786,
      "loss": 0.1495,
      "step": 2219
    },
    {
      "epoch": 0.160887052940537,
      "grad_norm": 4.151727676391602,
      "learning_rate": 0.00016783824914848902,
      "loss": 0.2182,
      "step": 2220
    },
    {
      "epoch": 0.16095952458600574,
      "grad_norm": 2.9996750354766846,
      "learning_rate": 0.0001678237553445902,
      "loss": 0.1426,
      "step": 2221
    },
    {
      "epoch": 0.16103199623147443,
      "grad_norm": 2.8392488956451416,
      "learning_rate": 0.00016780926154069136,
      "loss": 0.0989,
      "step": 2222
    },
    {
      "epoch": 0.16110446787694316,
      "grad_norm": 2.0782763957977295,
      "learning_rate": 0.00016779476773679252,
      "loss": 0.0653,
      "step": 2223
    },
    {
      "epoch": 0.16117693952241186,
      "grad_norm": 3.211780548095703,
      "learning_rate": 0.0001677802739328937,
      "loss": 0.1257,
      "step": 2224
    },
    {
      "epoch": 0.16124941116788058,
      "grad_norm": 1.8458771705627441,
      "learning_rate": 0.00016776578012899486,
      "loss": 0.0775,
      "step": 2225
    },
    {
      "epoch": 0.16132188281334928,
      "grad_norm": 2.0821094512939453,
      "learning_rate": 0.000167751286325096,
      "loss": 0.1059,
      "step": 2226
    },
    {
      "epoch": 0.161394354458818,
      "grad_norm": 1.5954583883285522,
      "learning_rate": 0.0001677367925211972,
      "loss": 0.0978,
      "step": 2227
    },
    {
      "epoch": 0.1614668261042867,
      "grad_norm": 1.1294701099395752,
      "learning_rate": 0.00016772229871729835,
      "loss": 0.0634,
      "step": 2228
    },
    {
      "epoch": 0.1615392977497554,
      "grad_norm": 0.5937644839286804,
      "learning_rate": 0.00016770780491339954,
      "loss": 0.0241,
      "step": 2229
    },
    {
      "epoch": 0.16161176939522412,
      "grad_norm": 1.383192539215088,
      "learning_rate": 0.00016769331110950072,
      "loss": 0.0908,
      "step": 2230
    },
    {
      "epoch": 0.16168424104069282,
      "grad_norm": 3.609006404876709,
      "learning_rate": 0.00016767881730560188,
      "loss": 0.1545,
      "step": 2231
    },
    {
      "epoch": 0.16175671268616154,
      "grad_norm": 4.81192684173584,
      "learning_rate": 0.00016766432350170303,
      "loss": 0.1636,
      "step": 2232
    },
    {
      "epoch": 0.16182918433163024,
      "grad_norm": 3.2377827167510986,
      "learning_rate": 0.00016764982969780422,
      "loss": 0.1423,
      "step": 2233
    },
    {
      "epoch": 0.16190165597709896,
      "grad_norm": 4.785726070404053,
      "learning_rate": 0.00016763533589390537,
      "loss": 0.233,
      "step": 2234
    },
    {
      "epoch": 0.16197412762256766,
      "grad_norm": 3.148226737976074,
      "learning_rate": 0.00016762084209000653,
      "loss": 0.2656,
      "step": 2235
    },
    {
      "epoch": 0.16204659926803638,
      "grad_norm": 0.9945107698440552,
      "learning_rate": 0.0001676063482861077,
      "loss": 0.0492,
      "step": 2236
    },
    {
      "epoch": 0.16211907091350508,
      "grad_norm": 4.38231897354126,
      "learning_rate": 0.00016759185448220887,
      "loss": 0.2092,
      "step": 2237
    },
    {
      "epoch": 0.1621915425589738,
      "grad_norm": 0.9155983924865723,
      "learning_rate": 0.00016757736067831002,
      "loss": 0.0903,
      "step": 2238
    },
    {
      "epoch": 0.1622640142044425,
      "grad_norm": 2.641793727874756,
      "learning_rate": 0.0001675628668744112,
      "loss": 0.0758,
      "step": 2239
    },
    {
      "epoch": 0.16233648584991123,
      "grad_norm": 3.1596548557281494,
      "learning_rate": 0.00016754837307051237,
      "loss": 0.1112,
      "step": 2240
    },
    {
      "epoch": 0.16240895749537992,
      "grad_norm": 3.6668460369110107,
      "learning_rate": 0.00016753387926661352,
      "loss": 0.2303,
      "step": 2241
    },
    {
      "epoch": 0.16248142914084865,
      "grad_norm": 1.2399612665176392,
      "learning_rate": 0.0001675193854627147,
      "loss": 0.0912,
      "step": 2242
    },
    {
      "epoch": 0.16255390078631735,
      "grad_norm": 2.6197140216827393,
      "learning_rate": 0.00016750489165881586,
      "loss": 0.1587,
      "step": 2243
    },
    {
      "epoch": 0.16262637243178607,
      "grad_norm": 4.664282321929932,
      "learning_rate": 0.00016749039785491702,
      "loss": 0.1957,
      "step": 2244
    },
    {
      "epoch": 0.16269884407725477,
      "grad_norm": 1.6535911560058594,
      "learning_rate": 0.0001674759040510182,
      "loss": 0.0721,
      "step": 2245
    },
    {
      "epoch": 0.1627713157227235,
      "grad_norm": 1.1238740682601929,
      "learning_rate": 0.00016746141024711936,
      "loss": 0.0961,
      "step": 2246
    },
    {
      "epoch": 0.1628437873681922,
      "grad_norm": 1.7706832885742188,
      "learning_rate": 0.00016744691644322051,
      "loss": 0.0593,
      "step": 2247
    },
    {
      "epoch": 0.1629162590136609,
      "grad_norm": 2.132371425628662,
      "learning_rate": 0.0001674324226393217,
      "loss": 0.0981,
      "step": 2248
    },
    {
      "epoch": 0.1629887306591296,
      "grad_norm": 0.7925326824188232,
      "learning_rate": 0.00016741792883542285,
      "loss": 0.0426,
      "step": 2249
    },
    {
      "epoch": 0.16306120230459833,
      "grad_norm": 2.779700517654419,
      "learning_rate": 0.00016740343503152404,
      "loss": 0.0774,
      "step": 2250
    },
    {
      "epoch": 0.16313367395006703,
      "grad_norm": 2.114682674407959,
      "learning_rate": 0.0001673889412276252,
      "loss": 0.0686,
      "step": 2251
    },
    {
      "epoch": 0.16320614559553576,
      "grad_norm": 1.724115252494812,
      "learning_rate": 0.00016737444742372638,
      "loss": 0.1162,
      "step": 2252
    },
    {
      "epoch": 0.16327861724100445,
      "grad_norm": 1.1345750093460083,
      "learning_rate": 0.00016735995361982753,
      "loss": 0.1016,
      "step": 2253
    },
    {
      "epoch": 0.16335108888647318,
      "grad_norm": 1.4959168434143066,
      "learning_rate": 0.00016734545981592872,
      "loss": 0.0847,
      "step": 2254
    },
    {
      "epoch": 0.16342356053194187,
      "grad_norm": 2.1697545051574707,
      "learning_rate": 0.00016733096601202987,
      "loss": 0.1766,
      "step": 2255
    },
    {
      "epoch": 0.1634960321774106,
      "grad_norm": 3.2637879848480225,
      "learning_rate": 0.00016731647220813103,
      "loss": 0.1349,
      "step": 2256
    },
    {
      "epoch": 0.1635685038228793,
      "grad_norm": 1.8669352531433105,
      "learning_rate": 0.00016730197840423222,
      "loss": 0.1009,
      "step": 2257
    },
    {
      "epoch": 0.16364097546834802,
      "grad_norm": 3.156233787536621,
      "learning_rate": 0.00016728748460033337,
      "loss": 0.185,
      "step": 2258
    },
    {
      "epoch": 0.16371344711381672,
      "grad_norm": 2.076033115386963,
      "learning_rate": 0.00016727299079643453,
      "loss": 0.1335,
      "step": 2259
    },
    {
      "epoch": 0.16378591875928544,
      "grad_norm": 4.20161247253418,
      "learning_rate": 0.0001672584969925357,
      "loss": 0.2015,
      "step": 2260
    },
    {
      "epoch": 0.16385839040475414,
      "grad_norm": 1.3459666967391968,
      "learning_rate": 0.00016724400318863687,
      "loss": 0.053,
      "step": 2261
    },
    {
      "epoch": 0.16393086205022286,
      "grad_norm": 2.2789013385772705,
      "learning_rate": 0.00016722950938473802,
      "loss": 0.1725,
      "step": 2262
    },
    {
      "epoch": 0.16400333369569156,
      "grad_norm": 1.6742521524429321,
      "learning_rate": 0.0001672150155808392,
      "loss": 0.0861,
      "step": 2263
    },
    {
      "epoch": 0.16407580534116026,
      "grad_norm": 1.1367262601852417,
      "learning_rate": 0.00016720052177694036,
      "loss": 0.1026,
      "step": 2264
    },
    {
      "epoch": 0.16414827698662898,
      "grad_norm": 3.0679550170898438,
      "learning_rate": 0.00016718602797304152,
      "loss": 0.0897,
      "step": 2265
    },
    {
      "epoch": 0.16422074863209768,
      "grad_norm": 1.5224530696868896,
      "learning_rate": 0.0001671715341691427,
      "loss": 0.1407,
      "step": 2266
    },
    {
      "epoch": 0.1642932202775664,
      "grad_norm": 2.9832143783569336,
      "learning_rate": 0.00016715704036524386,
      "loss": 0.1571,
      "step": 2267
    },
    {
      "epoch": 0.1643656919230351,
      "grad_norm": 3.5488011837005615,
      "learning_rate": 0.00016714254656134502,
      "loss": 0.2224,
      "step": 2268
    },
    {
      "epoch": 0.16443816356850383,
      "grad_norm": 1.6654971837997437,
      "learning_rate": 0.0001671280527574462,
      "loss": 0.1087,
      "step": 2269
    },
    {
      "epoch": 0.16451063521397252,
      "grad_norm": 2.490002393722534,
      "learning_rate": 0.00016711355895354736,
      "loss": 0.1031,
      "step": 2270
    },
    {
      "epoch": 0.16458310685944125,
      "grad_norm": 2.416313648223877,
      "learning_rate": 0.00016709906514964851,
      "loss": 0.0897,
      "step": 2271
    },
    {
      "epoch": 0.16465557850490994,
      "grad_norm": 1.433289885520935,
      "learning_rate": 0.0001670845713457497,
      "loss": 0.056,
      "step": 2272
    },
    {
      "epoch": 0.16472805015037867,
      "grad_norm": 4.484535217285156,
      "learning_rate": 0.00016707007754185085,
      "loss": 0.107,
      "step": 2273
    },
    {
      "epoch": 0.16480052179584737,
      "grad_norm": 2.0085439682006836,
      "learning_rate": 0.00016705558373795204,
      "loss": 0.0862,
      "step": 2274
    },
    {
      "epoch": 0.1648729934413161,
      "grad_norm": 1.725993037223816,
      "learning_rate": 0.0001670410899340532,
      "loss": 0.089,
      "step": 2275
    },
    {
      "epoch": 0.1649454650867848,
      "grad_norm": 2.7327122688293457,
      "learning_rate": 0.00016702659613015438,
      "loss": 0.1869,
      "step": 2276
    },
    {
      "epoch": 0.1650179367322535,
      "grad_norm": 3.023310899734497,
      "learning_rate": 0.00016701210232625553,
      "loss": 0.081,
      "step": 2277
    },
    {
      "epoch": 0.1650904083777222,
      "grad_norm": 2.171675443649292,
      "learning_rate": 0.00016699760852235672,
      "loss": 0.1835,
      "step": 2278
    },
    {
      "epoch": 0.16516288002319093,
      "grad_norm": 1.9040988683700562,
      "learning_rate": 0.00016698311471845787,
      "loss": 0.1142,
      "step": 2279
    },
    {
      "epoch": 0.16523535166865963,
      "grad_norm": 0.9355494379997253,
      "learning_rate": 0.00016696862091455903,
      "loss": 0.1053,
      "step": 2280
    },
    {
      "epoch": 0.16530782331412835,
      "grad_norm": 0.9619709849357605,
      "learning_rate": 0.00016695412711066021,
      "loss": 0.063,
      "step": 2281
    },
    {
      "epoch": 0.16538029495959705,
      "grad_norm": 1.8228955268859863,
      "learning_rate": 0.00016693963330676137,
      "loss": 0.0702,
      "step": 2282
    },
    {
      "epoch": 0.16545276660506578,
      "grad_norm": 3.9019744396209717,
      "learning_rate": 0.00016692513950286253,
      "loss": 0.1063,
      "step": 2283
    },
    {
      "epoch": 0.16552523825053447,
      "grad_norm": 1.0340619087219238,
      "learning_rate": 0.0001669106456989637,
      "loss": 0.0732,
      "step": 2284
    },
    {
      "epoch": 0.1655977098960032,
      "grad_norm": 3.4925241470336914,
      "learning_rate": 0.00016689615189506487,
      "loss": 0.1869,
      "step": 2285
    },
    {
      "epoch": 0.1656701815414719,
      "grad_norm": 3.839448928833008,
      "learning_rate": 0.00016688165809116602,
      "loss": 0.1374,
      "step": 2286
    },
    {
      "epoch": 0.16574265318694062,
      "grad_norm": 0.8969495892524719,
      "learning_rate": 0.0001668671642872672,
      "loss": 0.026,
      "step": 2287
    },
    {
      "epoch": 0.16581512483240932,
      "grad_norm": 1.1355900764465332,
      "learning_rate": 0.00016685267048336836,
      "loss": 0.0917,
      "step": 2288
    },
    {
      "epoch": 0.16588759647787804,
      "grad_norm": 2.0194408893585205,
      "learning_rate": 0.00016683817667946952,
      "loss": 0.0901,
      "step": 2289
    },
    {
      "epoch": 0.16596006812334674,
      "grad_norm": 1.421828269958496,
      "learning_rate": 0.0001668236828755707,
      "loss": 0.0895,
      "step": 2290
    },
    {
      "epoch": 0.16603253976881546,
      "grad_norm": 1.702749490737915,
      "learning_rate": 0.00016680918907167186,
      "loss": 0.0455,
      "step": 2291
    },
    {
      "epoch": 0.16610501141428416,
      "grad_norm": 0.7804442048072815,
      "learning_rate": 0.00016679469526777302,
      "loss": 0.034,
      "step": 2292
    },
    {
      "epoch": 0.16617748305975288,
      "grad_norm": 0.40994369983673096,
      "learning_rate": 0.0001667802014638742,
      "loss": 0.0073,
      "step": 2293
    },
    {
      "epoch": 0.16624995470522158,
      "grad_norm": 1.452693223953247,
      "learning_rate": 0.00016676570765997536,
      "loss": 0.0158,
      "step": 2294
    },
    {
      "epoch": 0.1663224263506903,
      "grad_norm": 2.708946943283081,
      "learning_rate": 0.00016675121385607651,
      "loss": 0.1329,
      "step": 2295
    },
    {
      "epoch": 0.166394897996159,
      "grad_norm": 1.977162480354309,
      "learning_rate": 0.0001667367200521777,
      "loss": 0.0293,
      "step": 2296
    },
    {
      "epoch": 0.1664673696416277,
      "grad_norm": 1.2419459819793701,
      "learning_rate": 0.00016672222624827888,
      "loss": 0.0473,
      "step": 2297
    },
    {
      "epoch": 0.16653984128709642,
      "grad_norm": 2.7921066284179688,
      "learning_rate": 0.00016670773244438004,
      "loss": 0.1737,
      "step": 2298
    },
    {
      "epoch": 0.16661231293256512,
      "grad_norm": 0.6017293930053711,
      "learning_rate": 0.00016669323864048122,
      "loss": 0.0168,
      "step": 2299
    },
    {
      "epoch": 0.16668478457803385,
      "grad_norm": 2.0168254375457764,
      "learning_rate": 0.00016667874483658238,
      "loss": 0.1575,
      "step": 2300
    },
    {
      "epoch": 0.16675725622350254,
      "grad_norm": 0.8188347816467285,
      "learning_rate": 0.00016666425103268353,
      "loss": 0.0177,
      "step": 2301
    },
    {
      "epoch": 0.16682972786897127,
      "grad_norm": 12.472865104675293,
      "learning_rate": 0.00016664975722878472,
      "loss": 0.1531,
      "step": 2302
    },
    {
      "epoch": 0.16690219951443996,
      "grad_norm": 4.574882984161377,
      "learning_rate": 0.00016663526342488587,
      "loss": 0.1923,
      "step": 2303
    },
    {
      "epoch": 0.1669746711599087,
      "grad_norm": 7.356266021728516,
      "learning_rate": 0.00016662076962098703,
      "loss": 0.2218,
      "step": 2304
    },
    {
      "epoch": 0.16704714280537739,
      "grad_norm": 1.5656256675720215,
      "learning_rate": 0.00016660627581708821,
      "loss": 0.0589,
      "step": 2305
    },
    {
      "epoch": 0.1671196144508461,
      "grad_norm": 7.599698066711426,
      "learning_rate": 0.00016659178201318937,
      "loss": 0.1526,
      "step": 2306
    },
    {
      "epoch": 0.1671920860963148,
      "grad_norm": 2.6989524364471436,
      "learning_rate": 0.00016657728820929053,
      "loss": 0.2193,
      "step": 2307
    },
    {
      "epoch": 0.16726455774178353,
      "grad_norm": 1.598117709159851,
      "learning_rate": 0.0001665627944053917,
      "loss": 0.0919,
      "step": 2308
    },
    {
      "epoch": 0.16733702938725223,
      "grad_norm": 3.8895866870880127,
      "learning_rate": 0.00016654830060149287,
      "loss": 0.2058,
      "step": 2309
    },
    {
      "epoch": 0.16740950103272095,
      "grad_norm": 0.8391308784484863,
      "learning_rate": 0.00016653380679759402,
      "loss": 0.0636,
      "step": 2310
    },
    {
      "epoch": 0.16748197267818965,
      "grad_norm": 1.6025755405426025,
      "learning_rate": 0.0001665193129936952,
      "loss": 0.092,
      "step": 2311
    },
    {
      "epoch": 0.16755444432365837,
      "grad_norm": 2.880727529525757,
      "learning_rate": 0.00016650481918979636,
      "loss": 0.2618,
      "step": 2312
    },
    {
      "epoch": 0.16762691596912707,
      "grad_norm": 0.686540424823761,
      "learning_rate": 0.00016649032538589752,
      "loss": 0.0577,
      "step": 2313
    },
    {
      "epoch": 0.1676993876145958,
      "grad_norm": 1.3907663822174072,
      "learning_rate": 0.0001664758315819987,
      "loss": 0.085,
      "step": 2314
    },
    {
      "epoch": 0.1677718592600645,
      "grad_norm": 1.8930212259292603,
      "learning_rate": 0.00016646133777809986,
      "loss": 0.1467,
      "step": 2315
    },
    {
      "epoch": 0.16784433090553322,
      "grad_norm": 1.9851378202438354,
      "learning_rate": 0.00016644684397420102,
      "loss": 0.0816,
      "step": 2316
    },
    {
      "epoch": 0.16791680255100191,
      "grad_norm": 2.7428362369537354,
      "learning_rate": 0.0001664323501703022,
      "loss": 0.0929,
      "step": 2317
    },
    {
      "epoch": 0.16798927419647064,
      "grad_norm": 1.6373447179794312,
      "learning_rate": 0.00016641785636640336,
      "loss": 0.0954,
      "step": 2318
    },
    {
      "epoch": 0.16806174584193934,
      "grad_norm": 1.919402837753296,
      "learning_rate": 0.00016640336256250454,
      "loss": 0.11,
      "step": 2319
    },
    {
      "epoch": 0.16813421748740806,
      "grad_norm": 7.369819164276123,
      "learning_rate": 0.0001663888687586057,
      "loss": 0.178,
      "step": 2320
    },
    {
      "epoch": 0.16820668913287676,
      "grad_norm": 2.032932996749878,
      "learning_rate": 0.00016637437495470688,
      "loss": 0.1574,
      "step": 2321
    },
    {
      "epoch": 0.16827916077834548,
      "grad_norm": 0.9705230593681335,
      "learning_rate": 0.00016635988115080804,
      "loss": 0.0949,
      "step": 2322
    },
    {
      "epoch": 0.16835163242381418,
      "grad_norm": 2.9308536052703857,
      "learning_rate": 0.00016634538734690922,
      "loss": 0.1158,
      "step": 2323
    },
    {
      "epoch": 0.1684241040692829,
      "grad_norm": 2.7218286991119385,
      "learning_rate": 0.00016633089354301038,
      "loss": 0.0823,
      "step": 2324
    },
    {
      "epoch": 0.1684965757147516,
      "grad_norm": 3.6366145610809326,
      "learning_rate": 0.00016631639973911153,
      "loss": 0.0963,
      "step": 2325
    },
    {
      "epoch": 0.16856904736022033,
      "grad_norm": 1.0856424570083618,
      "learning_rate": 0.00016630190593521272,
      "loss": 0.097,
      "step": 2326
    },
    {
      "epoch": 0.16864151900568902,
      "grad_norm": 2.9712274074554443,
      "learning_rate": 0.00016628741213131387,
      "loss": 0.0492,
      "step": 2327
    },
    {
      "epoch": 0.16871399065115775,
      "grad_norm": 3.1132750511169434,
      "learning_rate": 0.00016627291832741503,
      "loss": 0.2608,
      "step": 2328
    },
    {
      "epoch": 0.16878646229662644,
      "grad_norm": 1.7858458757400513,
      "learning_rate": 0.00016625842452351621,
      "loss": 0.0943,
      "step": 2329
    },
    {
      "epoch": 0.16885893394209517,
      "grad_norm": 1.4206867218017578,
      "learning_rate": 0.00016624393071961737,
      "loss": 0.1161,
      "step": 2330
    },
    {
      "epoch": 0.16893140558756387,
      "grad_norm": 2.2501821517944336,
      "learning_rate": 0.00016622943691571853,
      "loss": 0.062,
      "step": 2331
    },
    {
      "epoch": 0.16900387723303256,
      "grad_norm": 1.3157445192337036,
      "learning_rate": 0.0001662149431118197,
      "loss": 0.129,
      "step": 2332
    },
    {
      "epoch": 0.1690763488785013,
      "grad_norm": 0.5818777680397034,
      "learning_rate": 0.00016620044930792087,
      "loss": 0.0243,
      "step": 2333
    },
    {
      "epoch": 0.16914882052396998,
      "grad_norm": 3.0750412940979004,
      "learning_rate": 0.00016618595550402202,
      "loss": 0.0371,
      "step": 2334
    },
    {
      "epoch": 0.1692212921694387,
      "grad_norm": 3.1480712890625,
      "learning_rate": 0.0001661714617001232,
      "loss": 0.1793,
      "step": 2335
    },
    {
      "epoch": 0.1692937638149074,
      "grad_norm": 2.258347749710083,
      "learning_rate": 0.00016615696789622436,
      "loss": 0.1852,
      "step": 2336
    },
    {
      "epoch": 0.16936623546037613,
      "grad_norm": 1.7366864681243896,
      "learning_rate": 0.00016614247409232552,
      "loss": 0.1403,
      "step": 2337
    },
    {
      "epoch": 0.16943870710584483,
      "grad_norm": 2.039217233657837,
      "learning_rate": 0.0001661279802884267,
      "loss": 0.0603,
      "step": 2338
    },
    {
      "epoch": 0.16951117875131355,
      "grad_norm": 4.7534356117248535,
      "learning_rate": 0.00016611348648452786,
      "loss": 0.1655,
      "step": 2339
    },
    {
      "epoch": 0.16958365039678225,
      "grad_norm": 1.2307047843933105,
      "learning_rate": 0.00016609899268062902,
      "loss": 0.0446,
      "step": 2340
    },
    {
      "epoch": 0.16965612204225097,
      "grad_norm": 3.015270471572876,
      "learning_rate": 0.0001660844988767302,
      "loss": 0.1411,
      "step": 2341
    },
    {
      "epoch": 0.16972859368771967,
      "grad_norm": 2.7519466876983643,
      "learning_rate": 0.00016607000507283136,
      "loss": 0.1288,
      "step": 2342
    },
    {
      "epoch": 0.1698010653331884,
      "grad_norm": 5.479787349700928,
      "learning_rate": 0.00016605551126893254,
      "loss": 0.1758,
      "step": 2343
    },
    {
      "epoch": 0.1698735369786571,
      "grad_norm": 0.41957467794418335,
      "learning_rate": 0.00016604101746503372,
      "loss": 0.0147,
      "step": 2344
    },
    {
      "epoch": 0.16994600862412582,
      "grad_norm": 1.0365625619888306,
      "learning_rate": 0.00016602652366113488,
      "loss": 0.0374,
      "step": 2345
    },
    {
      "epoch": 0.1700184802695945,
      "grad_norm": 2.202265739440918,
      "learning_rate": 0.00016601202985723604,
      "loss": 0.094,
      "step": 2346
    },
    {
      "epoch": 0.17009095191506324,
      "grad_norm": 0.49844080209732056,
      "learning_rate": 0.00016599753605333722,
      "loss": 0.015,
      "step": 2347
    },
    {
      "epoch": 0.17016342356053193,
      "grad_norm": 1.5302993059158325,
      "learning_rate": 0.00016598304224943838,
      "loss": 0.0959,
      "step": 2348
    },
    {
      "epoch": 0.17023589520600066,
      "grad_norm": 3.8859949111938477,
      "learning_rate": 0.00016596854844553953,
      "loss": 0.1172,
      "step": 2349
    },
    {
      "epoch": 0.17030836685146936,
      "grad_norm": 3.920654296875,
      "learning_rate": 0.00016595405464164072,
      "loss": 0.2341,
      "step": 2350
    },
    {
      "epoch": 0.17038083849693808,
      "grad_norm": 4.204777240753174,
      "learning_rate": 0.00016593956083774187,
      "loss": 0.1493,
      "step": 2351
    },
    {
      "epoch": 0.17045331014240678,
      "grad_norm": 3.416992425918579,
      "learning_rate": 0.00016592506703384303,
      "loss": 0.1322,
      "step": 2352
    },
    {
      "epoch": 0.1705257817878755,
      "grad_norm": 2.6022398471832275,
      "learning_rate": 0.0001659105732299442,
      "loss": 0.1328,
      "step": 2353
    },
    {
      "epoch": 0.1705982534333442,
      "grad_norm": 2.4380433559417725,
      "learning_rate": 0.00016589607942604537,
      "loss": 0.0533,
      "step": 2354
    },
    {
      "epoch": 0.17067072507881292,
      "grad_norm": 1.896775245666504,
      "learning_rate": 0.00016588158562214655,
      "loss": 0.0565,
      "step": 2355
    },
    {
      "epoch": 0.17074319672428162,
      "grad_norm": 7.462602615356445,
      "learning_rate": 0.0001658670918182477,
      "loss": 0.0495,
      "step": 2356
    },
    {
      "epoch": 0.17081566836975035,
      "grad_norm": 5.203921318054199,
      "learning_rate": 0.00016585259801434887,
      "loss": 0.1911,
      "step": 2357
    },
    {
      "epoch": 0.17088814001521904,
      "grad_norm": 2.499701976776123,
      "learning_rate": 0.00016583810421045005,
      "loss": 0.0828,
      "step": 2358
    },
    {
      "epoch": 0.17096061166068777,
      "grad_norm": 2.363369941711426,
      "learning_rate": 0.0001658236104065512,
      "loss": 0.1319,
      "step": 2359
    },
    {
      "epoch": 0.17103308330615646,
      "grad_norm": 2.7210497856140137,
      "learning_rate": 0.00016580911660265236,
      "loss": 0.1332,
      "step": 2360
    },
    {
      "epoch": 0.1711055549516252,
      "grad_norm": 2.3985912799835205,
      "learning_rate": 0.00016579462279875355,
      "loss": 0.0873,
      "step": 2361
    },
    {
      "epoch": 0.17117802659709389,
      "grad_norm": 2.154127597808838,
      "learning_rate": 0.0001657801289948547,
      "loss": 0.1222,
      "step": 2362
    },
    {
      "epoch": 0.1712504982425626,
      "grad_norm": 2.188692808151245,
      "learning_rate": 0.00016576563519095586,
      "loss": 0.035,
      "step": 2363
    },
    {
      "epoch": 0.1713229698880313,
      "grad_norm": 2.3325555324554443,
      "learning_rate": 0.00016575114138705704,
      "loss": 0.0759,
      "step": 2364
    },
    {
      "epoch": 0.17139544153350003,
      "grad_norm": 2.0650341510772705,
      "learning_rate": 0.0001657366475831582,
      "loss": 0.0921,
      "step": 2365
    },
    {
      "epoch": 0.17146791317896873,
      "grad_norm": 1.1205575466156006,
      "learning_rate": 0.00016572215377925938,
      "loss": 0.0473,
      "step": 2366
    },
    {
      "epoch": 0.17154038482443743,
      "grad_norm": 2.4867045879364014,
      "learning_rate": 0.00016570765997536054,
      "loss": 0.1924,
      "step": 2367
    },
    {
      "epoch": 0.17161285646990615,
      "grad_norm": 1.9718267917633057,
      "learning_rate": 0.00016569316617146172,
      "loss": 0.1452,
      "step": 2368
    },
    {
      "epoch": 0.17168532811537485,
      "grad_norm": 2.3482353687286377,
      "learning_rate": 0.00016567867236756288,
      "loss": 0.155,
      "step": 2369
    },
    {
      "epoch": 0.17175779976084357,
      "grad_norm": 2.7715396881103516,
      "learning_rate": 0.00016566417856366406,
      "loss": 0.0851,
      "step": 2370
    },
    {
      "epoch": 0.17183027140631227,
      "grad_norm": 2.7066051959991455,
      "learning_rate": 0.00016564968475976522,
      "loss": 0.0573,
      "step": 2371
    },
    {
      "epoch": 0.171902743051781,
      "grad_norm": 1.9780701398849487,
      "learning_rate": 0.00016563519095586638,
      "loss": 0.1556,
      "step": 2372
    },
    {
      "epoch": 0.1719752146972497,
      "grad_norm": 2.2236671447753906,
      "learning_rate": 0.00016562069715196756,
      "loss": 0.1041,
      "step": 2373
    },
    {
      "epoch": 0.17204768634271841,
      "grad_norm": 0.819819986820221,
      "learning_rate": 0.00016560620334806872,
      "loss": 0.0554,
      "step": 2374
    },
    {
      "epoch": 0.1721201579881871,
      "grad_norm": 2.8906617164611816,
      "learning_rate": 0.00016559170954416987,
      "loss": 0.0661,
      "step": 2375
    },
    {
      "epoch": 0.17219262963365584,
      "grad_norm": 2.5249314308166504,
      "learning_rate": 0.00016557721574027106,
      "loss": 0.1315,
      "step": 2376
    },
    {
      "epoch": 0.17226510127912453,
      "grad_norm": 2.6118743419647217,
      "learning_rate": 0.0001655627219363722,
      "loss": 0.1876,
      "step": 2377
    },
    {
      "epoch": 0.17233757292459326,
      "grad_norm": 3.138747453689575,
      "learning_rate": 0.00016554822813247337,
      "loss": 0.1683,
      "step": 2378
    },
    {
      "epoch": 0.17241004457006195,
      "grad_norm": 5.2831220626831055,
      "learning_rate": 0.00016553373432857455,
      "loss": 0.2697,
      "step": 2379
    },
    {
      "epoch": 0.17248251621553068,
      "grad_norm": 0.997941255569458,
      "learning_rate": 0.0001655192405246757,
      "loss": 0.0729,
      "step": 2380
    },
    {
      "epoch": 0.17255498786099938,
      "grad_norm": 2.280297040939331,
      "learning_rate": 0.00016550474672077687,
      "loss": 0.1825,
      "step": 2381
    },
    {
      "epoch": 0.1726274595064681,
      "grad_norm": 3.8815739154815674,
      "learning_rate": 0.00016549025291687805,
      "loss": 0.2298,
      "step": 2382
    },
    {
      "epoch": 0.1726999311519368,
      "grad_norm": 1.1040586233139038,
      "learning_rate": 0.0001654757591129792,
      "loss": 0.0561,
      "step": 2383
    },
    {
      "epoch": 0.17277240279740552,
      "grad_norm": 1.8928097486495972,
      "learning_rate": 0.00016546126530908036,
      "loss": 0.0948,
      "step": 2384
    },
    {
      "epoch": 0.17284487444287422,
      "grad_norm": 0.727505624294281,
      "learning_rate": 0.00016544677150518155,
      "loss": 0.0285,
      "step": 2385
    },
    {
      "epoch": 0.17291734608834294,
      "grad_norm": 0.8551616668701172,
      "learning_rate": 0.0001654322777012827,
      "loss": 0.0353,
      "step": 2386
    },
    {
      "epoch": 0.17298981773381164,
      "grad_norm": 5.805543899536133,
      "learning_rate": 0.00016541778389738386,
      "loss": 0.0785,
      "step": 2387
    },
    {
      "epoch": 0.17306228937928037,
      "grad_norm": 1.7830610275268555,
      "learning_rate": 0.00016540329009348504,
      "loss": 0.0457,
      "step": 2388
    },
    {
      "epoch": 0.17313476102474906,
      "grad_norm": 1.411832332611084,
      "learning_rate": 0.0001653887962895862,
      "loss": 0.0788,
      "step": 2389
    },
    {
      "epoch": 0.1732072326702178,
      "grad_norm": 2.348517656326294,
      "learning_rate": 0.00016537430248568738,
      "loss": 0.0851,
      "step": 2390
    },
    {
      "epoch": 0.17327970431568648,
      "grad_norm": 3.0762970447540283,
      "learning_rate": 0.00016535980868178854,
      "loss": 0.1725,
      "step": 2391
    },
    {
      "epoch": 0.1733521759611552,
      "grad_norm": 2.9145474433898926,
      "learning_rate": 0.00016534531487788972,
      "loss": 0.0496,
      "step": 2392
    },
    {
      "epoch": 0.1734246476066239,
      "grad_norm": 1.9783450365066528,
      "learning_rate": 0.00016533082107399088,
      "loss": 0.0547,
      "step": 2393
    },
    {
      "epoch": 0.17349711925209263,
      "grad_norm": 2.468120813369751,
      "learning_rate": 0.00016531632727009206,
      "loss": 0.0797,
      "step": 2394
    },
    {
      "epoch": 0.17356959089756133,
      "grad_norm": 2.3491034507751465,
      "learning_rate": 0.00016530183346619322,
      "loss": 0.0554,
      "step": 2395
    },
    {
      "epoch": 0.17364206254303005,
      "grad_norm": 3.508761405944824,
      "learning_rate": 0.00016528733966229438,
      "loss": 0.1206,
      "step": 2396
    },
    {
      "epoch": 0.17371453418849875,
      "grad_norm": 2.4652059078216553,
      "learning_rate": 0.00016527284585839556,
      "loss": 0.113,
      "step": 2397
    },
    {
      "epoch": 0.17378700583396747,
      "grad_norm": 2.536738634109497,
      "learning_rate": 0.00016525835205449672,
      "loss": 0.0555,
      "step": 2398
    },
    {
      "epoch": 0.17385947747943617,
      "grad_norm": 1.127508282661438,
      "learning_rate": 0.00016524385825059787,
      "loss": 0.0443,
      "step": 2399
    },
    {
      "epoch": 0.1739319491249049,
      "grad_norm": 3.739000082015991,
      "learning_rate": 0.00016522936444669906,
      "loss": 0.0874,
      "step": 2400
    },
    {
      "epoch": 0.1740044207703736,
      "grad_norm": 2.0998198986053467,
      "learning_rate": 0.0001652148706428002,
      "loss": 0.0608,
      "step": 2401
    },
    {
      "epoch": 0.1740768924158423,
      "grad_norm": 2.8769941329956055,
      "learning_rate": 0.00016520037683890137,
      "loss": 0.0653,
      "step": 2402
    },
    {
      "epoch": 0.174149364061311,
      "grad_norm": 0.9753144979476929,
      "learning_rate": 0.00016518588303500255,
      "loss": 0.0274,
      "step": 2403
    },
    {
      "epoch": 0.1742218357067797,
      "grad_norm": 1.7949016094207764,
      "learning_rate": 0.0001651713892311037,
      "loss": 0.0444,
      "step": 2404
    },
    {
      "epoch": 0.17429430735224843,
      "grad_norm": 4.049018859863281,
      "learning_rate": 0.00016515689542720487,
      "loss": 0.1011,
      "step": 2405
    },
    {
      "epoch": 0.17436677899771713,
      "grad_norm": 4.9346089363098145,
      "learning_rate": 0.00016514240162330605,
      "loss": 0.1393,
      "step": 2406
    },
    {
      "epoch": 0.17443925064318586,
      "grad_norm": 2.919656753540039,
      "learning_rate": 0.0001651279078194072,
      "loss": 0.1214,
      "step": 2407
    },
    {
      "epoch": 0.17451172228865455,
      "grad_norm": 2.1639750003814697,
      "learning_rate": 0.00016511341401550836,
      "loss": 0.0963,
      "step": 2408
    },
    {
      "epoch": 0.17458419393412328,
      "grad_norm": 3.7431254386901855,
      "learning_rate": 0.00016509892021160955,
      "loss": 0.1083,
      "step": 2409
    },
    {
      "epoch": 0.17465666557959197,
      "grad_norm": 4.411870002746582,
      "learning_rate": 0.0001650844264077107,
      "loss": 0.2297,
      "step": 2410
    },
    {
      "epoch": 0.1747291372250607,
      "grad_norm": 6.0247602462768555,
      "learning_rate": 0.00016506993260381186,
      "loss": 0.0991,
      "step": 2411
    },
    {
      "epoch": 0.1748016088705294,
      "grad_norm": 4.53955602645874,
      "learning_rate": 0.00016505543879991304,
      "loss": 0.1789,
      "step": 2412
    },
    {
      "epoch": 0.17487408051599812,
      "grad_norm": 3.610823631286621,
      "learning_rate": 0.00016504094499601423,
      "loss": 0.1201,
      "step": 2413
    },
    {
      "epoch": 0.17494655216146682,
      "grad_norm": 3.971844434738159,
      "learning_rate": 0.00016502645119211538,
      "loss": 0.0978,
      "step": 2414
    },
    {
      "epoch": 0.17501902380693554,
      "grad_norm": 1.727344274520874,
      "learning_rate": 0.00016501195738821657,
      "loss": 0.0658,
      "step": 2415
    },
    {
      "epoch": 0.17509149545240424,
      "grad_norm": 1.914381742477417,
      "learning_rate": 0.00016499746358431772,
      "loss": 0.0505,
      "step": 2416
    },
    {
      "epoch": 0.17516396709787296,
      "grad_norm": 1.1627388000488281,
      "learning_rate": 0.00016498296978041888,
      "loss": 0.0427,
      "step": 2417
    },
    {
      "epoch": 0.17523643874334166,
      "grad_norm": 2.2149014472961426,
      "learning_rate": 0.00016496847597652006,
      "loss": 0.0741,
      "step": 2418
    },
    {
      "epoch": 0.17530891038881039,
      "grad_norm": 1.0938262939453125,
      "learning_rate": 0.00016495398217262122,
      "loss": 0.0485,
      "step": 2419
    },
    {
      "epoch": 0.17538138203427908,
      "grad_norm": 2.374289035797119,
      "learning_rate": 0.00016493948836872238,
      "loss": 0.1255,
      "step": 2420
    },
    {
      "epoch": 0.1754538536797478,
      "grad_norm": 1.8950334787368774,
      "learning_rate": 0.00016492499456482356,
      "loss": 0.067,
      "step": 2421
    },
    {
      "epoch": 0.1755263253252165,
      "grad_norm": 0.8977147936820984,
      "learning_rate": 0.00016491050076092472,
      "loss": 0.0279,
      "step": 2422
    },
    {
      "epoch": 0.17559879697068523,
      "grad_norm": 2.8112435340881348,
      "learning_rate": 0.00016489600695702587,
      "loss": 0.1529,
      "step": 2423
    },
    {
      "epoch": 0.17567126861615392,
      "grad_norm": 1.4254220724105835,
      "learning_rate": 0.00016488151315312706,
      "loss": 0.0751,
      "step": 2424
    },
    {
      "epoch": 0.17574374026162265,
      "grad_norm": 1.3260005712509155,
      "learning_rate": 0.0001648670193492282,
      "loss": 0.0214,
      "step": 2425
    },
    {
      "epoch": 0.17581621190709135,
      "grad_norm": 2.434382200241089,
      "learning_rate": 0.00016485252554532937,
      "loss": 0.0448,
      "step": 2426
    },
    {
      "epoch": 0.17588868355256007,
      "grad_norm": 0.7977387309074402,
      "learning_rate": 0.00016483803174143055,
      "loss": 0.0161,
      "step": 2427
    },
    {
      "epoch": 0.17596115519802877,
      "grad_norm": 1.7185393571853638,
      "learning_rate": 0.0001648235379375317,
      "loss": 0.0853,
      "step": 2428
    },
    {
      "epoch": 0.1760336268434975,
      "grad_norm": 1.3943947553634644,
      "learning_rate": 0.00016480904413363287,
      "loss": 0.0641,
      "step": 2429
    },
    {
      "epoch": 0.1761060984889662,
      "grad_norm": 3.3521299362182617,
      "learning_rate": 0.00016479455032973405,
      "loss": 0.1269,
      "step": 2430
    },
    {
      "epoch": 0.17617857013443491,
      "grad_norm": 3.1996824741363525,
      "learning_rate": 0.0001647800565258352,
      "loss": 0.1581,
      "step": 2431
    },
    {
      "epoch": 0.1762510417799036,
      "grad_norm": 1.5982309579849243,
      "learning_rate": 0.00016476556272193636,
      "loss": 0.0612,
      "step": 2432
    },
    {
      "epoch": 0.17632351342537234,
      "grad_norm": 2.3815758228302,
      "learning_rate": 0.00016475106891803755,
      "loss": 0.0824,
      "step": 2433
    },
    {
      "epoch": 0.17639598507084103,
      "grad_norm": 1.944170355796814,
      "learning_rate": 0.0001647365751141387,
      "loss": 0.1377,
      "step": 2434
    },
    {
      "epoch": 0.17646845671630976,
      "grad_norm": 2.735769271850586,
      "learning_rate": 0.00016472208131023989,
      "loss": 0.0974,
      "step": 2435
    },
    {
      "epoch": 0.17654092836177845,
      "grad_norm": 1.8071492910385132,
      "learning_rate": 0.00016470758750634104,
      "loss": 0.097,
      "step": 2436
    },
    {
      "epoch": 0.17661340000724715,
      "grad_norm": 3.7480309009552,
      "learning_rate": 0.00016469309370244223,
      "loss": 0.1222,
      "step": 2437
    },
    {
      "epoch": 0.17668587165271588,
      "grad_norm": 4.491501808166504,
      "learning_rate": 0.00016467859989854338,
      "loss": 0.2037,
      "step": 2438
    },
    {
      "epoch": 0.17675834329818457,
      "grad_norm": 1.366495966911316,
      "learning_rate": 0.00016466410609464457,
      "loss": 0.0616,
      "step": 2439
    },
    {
      "epoch": 0.1768308149436533,
      "grad_norm": 1.0053606033325195,
      "learning_rate": 0.00016464961229074572,
      "loss": 0.0232,
      "step": 2440
    },
    {
      "epoch": 0.176903286589122,
      "grad_norm": 5.206878185272217,
      "learning_rate": 0.00016463511848684688,
      "loss": 0.2841,
      "step": 2441
    },
    {
      "epoch": 0.17697575823459072,
      "grad_norm": 3.561626672744751,
      "learning_rate": 0.00016462062468294806,
      "loss": 0.0606,
      "step": 2442
    },
    {
      "epoch": 0.17704822988005942,
      "grad_norm": 1.6208784580230713,
      "learning_rate": 0.00016460613087904922,
      "loss": 0.0549,
      "step": 2443
    },
    {
      "epoch": 0.17712070152552814,
      "grad_norm": 2.191678762435913,
      "learning_rate": 0.00016459163707515038,
      "loss": 0.053,
      "step": 2444
    },
    {
      "epoch": 0.17719317317099684,
      "grad_norm": 3.0879318714141846,
      "learning_rate": 0.00016457714327125156,
      "loss": 0.2752,
      "step": 2445
    },
    {
      "epoch": 0.17726564481646556,
      "grad_norm": 1.156516671180725,
      "learning_rate": 0.00016456264946735272,
      "loss": 0.0836,
      "step": 2446
    },
    {
      "epoch": 0.17733811646193426,
      "grad_norm": 1.6082078218460083,
      "learning_rate": 0.00016454815566345387,
      "loss": 0.0734,
      "step": 2447
    },
    {
      "epoch": 0.17741058810740298,
      "grad_norm": 1.8746623992919922,
      "learning_rate": 0.00016453366185955506,
      "loss": 0.1066,
      "step": 2448
    },
    {
      "epoch": 0.17748305975287168,
      "grad_norm": 1.787734866142273,
      "learning_rate": 0.0001645191680556562,
      "loss": 0.0611,
      "step": 2449
    },
    {
      "epoch": 0.1775555313983404,
      "grad_norm": 0.5024843811988831,
      "learning_rate": 0.00016450467425175737,
      "loss": 0.0285,
      "step": 2450
    },
    {
      "epoch": 0.1776280030438091,
      "grad_norm": 2.2245607376098633,
      "learning_rate": 0.00016449018044785855,
      "loss": 0.132,
      "step": 2451
    },
    {
      "epoch": 0.17770047468927783,
      "grad_norm": 1.9796993732452393,
      "learning_rate": 0.0001644756866439597,
      "loss": 0.0497,
      "step": 2452
    },
    {
      "epoch": 0.17777294633474652,
      "grad_norm": 1.7896252870559692,
      "learning_rate": 0.00016446119284006086,
      "loss": 0.0944,
      "step": 2453
    },
    {
      "epoch": 0.17784541798021525,
      "grad_norm": 1.5090911388397217,
      "learning_rate": 0.00016444669903616205,
      "loss": 0.0607,
      "step": 2454
    },
    {
      "epoch": 0.17791788962568394,
      "grad_norm": 3.111844062805176,
      "learning_rate": 0.0001644322052322632,
      "loss": 0.1114,
      "step": 2455
    },
    {
      "epoch": 0.17799036127115267,
      "grad_norm": 7.294995307922363,
      "learning_rate": 0.00016441771142836436,
      "loss": 0.1895,
      "step": 2456
    },
    {
      "epoch": 0.17806283291662137,
      "grad_norm": 1.9744142293930054,
      "learning_rate": 0.00016440321762446554,
      "loss": 0.1037,
      "step": 2457
    },
    {
      "epoch": 0.1781353045620901,
      "grad_norm": 1.687705397605896,
      "learning_rate": 0.0001643887238205667,
      "loss": 0.0715,
      "step": 2458
    },
    {
      "epoch": 0.1782077762075588,
      "grad_norm": 3.930379867553711,
      "learning_rate": 0.00016437423001666789,
      "loss": 0.1011,
      "step": 2459
    },
    {
      "epoch": 0.1782802478530275,
      "grad_norm": 2.4098966121673584,
      "learning_rate": 0.00016435973621276907,
      "loss": 0.0922,
      "step": 2460
    },
    {
      "epoch": 0.1783527194984962,
      "grad_norm": 5.056454658508301,
      "learning_rate": 0.00016434524240887023,
      "loss": 0.1197,
      "step": 2461
    },
    {
      "epoch": 0.17842519114396493,
      "grad_norm": 2.5358152389526367,
      "learning_rate": 0.00016433074860497138,
      "loss": 0.0469,
      "step": 2462
    },
    {
      "epoch": 0.17849766278943363,
      "grad_norm": 2.1234331130981445,
      "learning_rate": 0.00016431625480107257,
      "loss": 0.1382,
      "step": 2463
    },
    {
      "epoch": 0.17857013443490236,
      "grad_norm": 2.261765241622925,
      "learning_rate": 0.00016430176099717372,
      "loss": 0.0862,
      "step": 2464
    },
    {
      "epoch": 0.17864260608037105,
      "grad_norm": 1.8971877098083496,
      "learning_rate": 0.00016428726719327488,
      "loss": 0.1214,
      "step": 2465
    },
    {
      "epoch": 0.17871507772583978,
      "grad_norm": 2.1045942306518555,
      "learning_rate": 0.00016427277338937606,
      "loss": 0.0972,
      "step": 2466
    },
    {
      "epoch": 0.17878754937130847,
      "grad_norm": 2.0475692749023438,
      "learning_rate": 0.00016425827958547722,
      "loss": 0.0369,
      "step": 2467
    },
    {
      "epoch": 0.1788600210167772,
      "grad_norm": 1.8568300008773804,
      "learning_rate": 0.00016424378578157837,
      "loss": 0.0871,
      "step": 2468
    },
    {
      "epoch": 0.1789324926622459,
      "grad_norm": 2.394448757171631,
      "learning_rate": 0.00016422929197767956,
      "loss": 0.0999,
      "step": 2469
    },
    {
      "epoch": 0.17900496430771462,
      "grad_norm": 1.5613069534301758,
      "learning_rate": 0.00016421479817378071,
      "loss": 0.1221,
      "step": 2470
    },
    {
      "epoch": 0.17907743595318332,
      "grad_norm": 1.1977225542068481,
      "learning_rate": 0.00016420030436988187,
      "loss": 0.0808,
      "step": 2471
    },
    {
      "epoch": 0.17914990759865201,
      "grad_norm": 1.1584951877593994,
      "learning_rate": 0.00016418581056598305,
      "loss": 0.0766,
      "step": 2472
    },
    {
      "epoch": 0.17922237924412074,
      "grad_norm": 4.210771560668945,
      "learning_rate": 0.0001641713167620842,
      "loss": 0.1331,
      "step": 2473
    },
    {
      "epoch": 0.17929485088958944,
      "grad_norm": 2.668804407119751,
      "learning_rate": 0.00016415682295818537,
      "loss": 0.0894,
      "step": 2474
    },
    {
      "epoch": 0.17936732253505816,
      "grad_norm": 2.206015110015869,
      "learning_rate": 0.00016414232915428655,
      "loss": 0.0802,
      "step": 2475
    },
    {
      "epoch": 0.17943979418052686,
      "grad_norm": 4.31468391418457,
      "learning_rate": 0.0001641278353503877,
      "loss": 0.0907,
      "step": 2476
    },
    {
      "epoch": 0.17951226582599558,
      "grad_norm": 1.1395747661590576,
      "learning_rate": 0.00016411334154648886,
      "loss": 0.029,
      "step": 2477
    },
    {
      "epoch": 0.17958473747146428,
      "grad_norm": 2.105339765548706,
      "learning_rate": 0.00016409884774259005,
      "loss": 0.0418,
      "step": 2478
    },
    {
      "epoch": 0.179657209116933,
      "grad_norm": 3.784122943878174,
      "learning_rate": 0.0001640843539386912,
      "loss": 0.1785,
      "step": 2479
    },
    {
      "epoch": 0.1797296807624017,
      "grad_norm": 1.9502958059310913,
      "learning_rate": 0.0001640698601347924,
      "loss": 0.0611,
      "step": 2480
    },
    {
      "epoch": 0.17980215240787042,
      "grad_norm": 1.8728874921798706,
      "learning_rate": 0.00016405536633089354,
      "loss": 0.0699,
      "step": 2481
    },
    {
      "epoch": 0.17987462405333912,
      "grad_norm": 0.6731035113334656,
      "learning_rate": 0.00016404087252699473,
      "loss": 0.0242,
      "step": 2482
    },
    {
      "epoch": 0.17994709569880785,
      "grad_norm": 2.6211836338043213,
      "learning_rate": 0.00016402637872309588,
      "loss": 0.107,
      "step": 2483
    },
    {
      "epoch": 0.18001956734427654,
      "grad_norm": 1.0724714994430542,
      "learning_rate": 0.00016401188491919707,
      "loss": 0.0491,
      "step": 2484
    },
    {
      "epoch": 0.18009203898974527,
      "grad_norm": 6.730067729949951,
      "learning_rate": 0.00016399739111529822,
      "loss": 0.1466,
      "step": 2485
    },
    {
      "epoch": 0.18016451063521396,
      "grad_norm": 7.076924800872803,
      "learning_rate": 0.00016398289731139938,
      "loss": 0.2389,
      "step": 2486
    },
    {
      "epoch": 0.1802369822806827,
      "grad_norm": 3.7765486240386963,
      "learning_rate": 0.00016396840350750056,
      "loss": 0.0788,
      "step": 2487
    },
    {
      "epoch": 0.1803094539261514,
      "grad_norm": 2.625046968460083,
      "learning_rate": 0.00016395390970360172,
      "loss": 0.1307,
      "step": 2488
    },
    {
      "epoch": 0.1803819255716201,
      "grad_norm": 1.3706132173538208,
      "learning_rate": 0.00016393941589970288,
      "loss": 0.0906,
      "step": 2489
    },
    {
      "epoch": 0.1804543972170888,
      "grad_norm": 2.4904122352600098,
      "learning_rate": 0.00016392492209580406,
      "loss": 0.1042,
      "step": 2490
    },
    {
      "epoch": 0.18052686886255753,
      "grad_norm": 1.7044949531555176,
      "learning_rate": 0.00016391042829190522,
      "loss": 0.0536,
      "step": 2491
    },
    {
      "epoch": 0.18059934050802623,
      "grad_norm": 5.0794572830200195,
      "learning_rate": 0.00016389593448800637,
      "loss": 0.1276,
      "step": 2492
    },
    {
      "epoch": 0.18067181215349495,
      "grad_norm": 5.538592338562012,
      "learning_rate": 0.00016388144068410756,
      "loss": 0.0825,
      "step": 2493
    },
    {
      "epoch": 0.18074428379896365,
      "grad_norm": 1.9123573303222656,
      "learning_rate": 0.00016386694688020871,
      "loss": 0.0486,
      "step": 2494
    },
    {
      "epoch": 0.18081675544443238,
      "grad_norm": 4.6848955154418945,
      "learning_rate": 0.00016385245307630987,
      "loss": 0.1157,
      "step": 2495
    },
    {
      "epoch": 0.18088922708990107,
      "grad_norm": 0.8368679285049438,
      "learning_rate": 0.00016383795927241105,
      "loss": 0.0318,
      "step": 2496
    },
    {
      "epoch": 0.1809616987353698,
      "grad_norm": 1.5801990032196045,
      "learning_rate": 0.0001638234654685122,
      "loss": 0.0483,
      "step": 2497
    },
    {
      "epoch": 0.1810341703808385,
      "grad_norm": 1.466699242591858,
      "learning_rate": 0.00016380897166461337,
      "loss": 0.105,
      "step": 2498
    },
    {
      "epoch": 0.18110664202630722,
      "grad_norm": 1.302160382270813,
      "learning_rate": 0.00016379447786071455,
      "loss": 0.0359,
      "step": 2499
    },
    {
      "epoch": 0.18117911367177592,
      "grad_norm": 1.913821816444397,
      "learning_rate": 0.0001637799840568157,
      "loss": 0.158,
      "step": 2500
    },
    {
      "epoch": 0.18125158531724464,
      "grad_norm": 1.3284968137741089,
      "learning_rate": 0.00016376549025291686,
      "loss": 0.0279,
      "step": 2501
    },
    {
      "epoch": 0.18132405696271334,
      "grad_norm": 3.3667922019958496,
      "learning_rate": 0.00016375099644901805,
      "loss": 0.1232,
      "step": 2502
    },
    {
      "epoch": 0.18139652860818206,
      "grad_norm": 1.772912621498108,
      "learning_rate": 0.0001637365026451192,
      "loss": 0.0757,
      "step": 2503
    },
    {
      "epoch": 0.18146900025365076,
      "grad_norm": 6.1276960372924805,
      "learning_rate": 0.0001637220088412204,
      "loss": 0.0653,
      "step": 2504
    },
    {
      "epoch": 0.18154147189911948,
      "grad_norm": 2.1399004459381104,
      "learning_rate": 0.00016370751503732154,
      "loss": 0.0655,
      "step": 2505
    },
    {
      "epoch": 0.18161394354458818,
      "grad_norm": 2.4514713287353516,
      "learning_rate": 0.00016369302123342273,
      "loss": 0.1553,
      "step": 2506
    },
    {
      "epoch": 0.18168641519005688,
      "grad_norm": 1.7404086589813232,
      "learning_rate": 0.00016367852742952388,
      "loss": 0.0777,
      "step": 2507
    },
    {
      "epoch": 0.1817588868355256,
      "grad_norm": 1.6536005735397339,
      "learning_rate": 0.00016366403362562507,
      "loss": 0.0992,
      "step": 2508
    },
    {
      "epoch": 0.1818313584809943,
      "grad_norm": 4.1061201095581055,
      "learning_rate": 0.00016364953982172622,
      "loss": 0.1816,
      "step": 2509
    },
    {
      "epoch": 0.18190383012646302,
      "grad_norm": 3.853137969970703,
      "learning_rate": 0.00016363504601782738,
      "loss": 0.0942,
      "step": 2510
    },
    {
      "epoch": 0.18197630177193172,
      "grad_norm": 1.6987947225570679,
      "learning_rate": 0.00016362055221392856,
      "loss": 0.0783,
      "step": 2511
    },
    {
      "epoch": 0.18204877341740044,
      "grad_norm": 1.0884522199630737,
      "learning_rate": 0.00016360605841002972,
      "loss": 0.0594,
      "step": 2512
    },
    {
      "epoch": 0.18212124506286914,
      "grad_norm": 2.593059778213501,
      "learning_rate": 0.00016359156460613088,
      "loss": 0.0414,
      "step": 2513
    },
    {
      "epoch": 0.18219371670833787,
      "grad_norm": 2.039480686187744,
      "learning_rate": 0.00016357707080223206,
      "loss": 0.106,
      "step": 2514
    },
    {
      "epoch": 0.18226618835380656,
      "grad_norm": 1.2439618110656738,
      "learning_rate": 0.00016356257699833322,
      "loss": 0.0455,
      "step": 2515
    },
    {
      "epoch": 0.1823386599992753,
      "grad_norm": 0.7237947583198547,
      "learning_rate": 0.00016354808319443437,
      "loss": 0.0178,
      "step": 2516
    },
    {
      "epoch": 0.18241113164474398,
      "grad_norm": 4.870948314666748,
      "learning_rate": 0.00016353358939053556,
      "loss": 0.106,
      "step": 2517
    },
    {
      "epoch": 0.1824836032902127,
      "grad_norm": 1.0102392435073853,
      "learning_rate": 0.00016351909558663671,
      "loss": 0.0363,
      "step": 2518
    },
    {
      "epoch": 0.1825560749356814,
      "grad_norm": 2.2681210041046143,
      "learning_rate": 0.0001635046017827379,
      "loss": 0.1359,
      "step": 2519
    },
    {
      "epoch": 0.18262854658115013,
      "grad_norm": 3.0917320251464844,
      "learning_rate": 0.00016349010797883905,
      "loss": 0.1314,
      "step": 2520
    },
    {
      "epoch": 0.18270101822661883,
      "grad_norm": 2.4790210723876953,
      "learning_rate": 0.0001634756141749402,
      "loss": 0.1263,
      "step": 2521
    },
    {
      "epoch": 0.18277348987208755,
      "grad_norm": 3.512148857116699,
      "learning_rate": 0.0001634611203710414,
      "loss": 0.0882,
      "step": 2522
    },
    {
      "epoch": 0.18284596151755625,
      "grad_norm": 1.1401292085647583,
      "learning_rate": 0.00016344662656714255,
      "loss": 0.073,
      "step": 2523
    },
    {
      "epoch": 0.18291843316302497,
      "grad_norm": 4.563363075256348,
      "learning_rate": 0.0001634321327632437,
      "loss": 0.0934,
      "step": 2524
    },
    {
      "epoch": 0.18299090480849367,
      "grad_norm": 3.400080919265747,
      "learning_rate": 0.0001634176389593449,
      "loss": 0.1708,
      "step": 2525
    },
    {
      "epoch": 0.1830633764539624,
      "grad_norm": 0.33996883034706116,
      "learning_rate": 0.00016340314515544605,
      "loss": 0.0147,
      "step": 2526
    },
    {
      "epoch": 0.1831358480994311,
      "grad_norm": 1.4476706981658936,
      "learning_rate": 0.00016338865135154723,
      "loss": 0.09,
      "step": 2527
    },
    {
      "epoch": 0.18320831974489982,
      "grad_norm": 3.6290881633758545,
      "learning_rate": 0.0001633741575476484,
      "loss": 0.1931,
      "step": 2528
    },
    {
      "epoch": 0.1832807913903685,
      "grad_norm": 1.3705499172210693,
      "learning_rate": 0.00016335966374374957,
      "loss": 0.0784,
      "step": 2529
    },
    {
      "epoch": 0.18335326303583724,
      "grad_norm": 1.7429102659225464,
      "learning_rate": 0.00016334516993985073,
      "loss": 0.129,
      "step": 2530
    },
    {
      "epoch": 0.18342573468130594,
      "grad_norm": 2.0331342220306396,
      "learning_rate": 0.0001633306761359519,
      "loss": 0.044,
      "step": 2531
    },
    {
      "epoch": 0.18349820632677466,
      "grad_norm": 0.9514704942703247,
      "learning_rate": 0.00016331618233205307,
      "loss": 0.0311,
      "step": 2532
    },
    {
      "epoch": 0.18357067797224336,
      "grad_norm": 2.4346771240234375,
      "learning_rate": 0.00016330168852815422,
      "loss": 0.1274,
      "step": 2533
    },
    {
      "epoch": 0.18364314961771208,
      "grad_norm": 2.000861644744873,
      "learning_rate": 0.0001632871947242554,
      "loss": 0.0873,
      "step": 2534
    },
    {
      "epoch": 0.18371562126318078,
      "grad_norm": 1.5944820642471313,
      "learning_rate": 0.00016327270092035656,
      "loss": 0.1153,
      "step": 2535
    },
    {
      "epoch": 0.1837880929086495,
      "grad_norm": 1.7143634557724,
      "learning_rate": 0.00016325820711645772,
      "loss": 0.1328,
      "step": 2536
    },
    {
      "epoch": 0.1838605645541182,
      "grad_norm": 1.8636789321899414,
      "learning_rate": 0.0001632437133125589,
      "loss": 0.118,
      "step": 2537
    },
    {
      "epoch": 0.18393303619958692,
      "grad_norm": 2.091660261154175,
      "learning_rate": 0.00016322921950866006,
      "loss": 0.1458,
      "step": 2538
    },
    {
      "epoch": 0.18400550784505562,
      "grad_norm": 0.34588319063186646,
      "learning_rate": 0.00016321472570476122,
      "loss": 0.0117,
      "step": 2539
    },
    {
      "epoch": 0.18407797949052435,
      "grad_norm": 3.588484048843384,
      "learning_rate": 0.0001632002319008624,
      "loss": 0.0983,
      "step": 2540
    },
    {
      "epoch": 0.18415045113599304,
      "grad_norm": 0.9968945980072021,
      "learning_rate": 0.00016318573809696356,
      "loss": 0.0459,
      "step": 2541
    },
    {
      "epoch": 0.18422292278146174,
      "grad_norm": 1.1668599843978882,
      "learning_rate": 0.00016317124429306471,
      "loss": 0.0528,
      "step": 2542
    },
    {
      "epoch": 0.18429539442693046,
      "grad_norm": 3.4387927055358887,
      "learning_rate": 0.0001631567504891659,
      "loss": 0.0798,
      "step": 2543
    },
    {
      "epoch": 0.18436786607239916,
      "grad_norm": 0.7601985335350037,
      "learning_rate": 0.00016314225668526705,
      "loss": 0.0315,
      "step": 2544
    },
    {
      "epoch": 0.18444033771786789,
      "grad_norm": 0.8690347075462341,
      "learning_rate": 0.0001631277628813682,
      "loss": 0.1013,
      "step": 2545
    },
    {
      "epoch": 0.18451280936333658,
      "grad_norm": 3.3464925289154053,
      "learning_rate": 0.0001631132690774694,
      "loss": 0.2374,
      "step": 2546
    },
    {
      "epoch": 0.1845852810088053,
      "grad_norm": 1.267298936843872,
      "learning_rate": 0.00016309877527357055,
      "loss": 0.0359,
      "step": 2547
    },
    {
      "epoch": 0.184657752654274,
      "grad_norm": 5.0203728675842285,
      "learning_rate": 0.0001630842814696717,
      "loss": 0.2325,
      "step": 2548
    },
    {
      "epoch": 0.18473022429974273,
      "grad_norm": 1.3097913265228271,
      "learning_rate": 0.0001630697876657729,
      "loss": 0.0703,
      "step": 2549
    },
    {
      "epoch": 0.18480269594521143,
      "grad_norm": 1.566319465637207,
      "learning_rate": 0.00016305529386187405,
      "loss": 0.0297,
      "step": 2550
    },
    {
      "epoch": 0.18487516759068015,
      "grad_norm": 0.9530081152915955,
      "learning_rate": 0.00016304080005797523,
      "loss": 0.0539,
      "step": 2551
    },
    {
      "epoch": 0.18494763923614885,
      "grad_norm": 0.892127275466919,
      "learning_rate": 0.0001630263062540764,
      "loss": 0.0244,
      "step": 2552
    },
    {
      "epoch": 0.18502011088161757,
      "grad_norm": 2.509117841720581,
      "learning_rate": 0.00016301181245017757,
      "loss": 0.1029,
      "step": 2553
    },
    {
      "epoch": 0.18509258252708627,
      "grad_norm": 2.52807879447937,
      "learning_rate": 0.00016299731864627873,
      "loss": 0.182,
      "step": 2554
    },
    {
      "epoch": 0.185165054172555,
      "grad_norm": 3.5848240852355957,
      "learning_rate": 0.0001629828248423799,
      "loss": 0.1471,
      "step": 2555
    },
    {
      "epoch": 0.1852375258180237,
      "grad_norm": 1.9151941537857056,
      "learning_rate": 0.00016296833103848107,
      "loss": 0.0192,
      "step": 2556
    },
    {
      "epoch": 0.18530999746349242,
      "grad_norm": 6.007487773895264,
      "learning_rate": 0.00016295383723458222,
      "loss": 0.1814,
      "step": 2557
    },
    {
      "epoch": 0.1853824691089611,
      "grad_norm": 2.6504104137420654,
      "learning_rate": 0.0001629393434306834,
      "loss": 0.1515,
      "step": 2558
    },
    {
      "epoch": 0.18545494075442984,
      "grad_norm": 5.358514785766602,
      "learning_rate": 0.00016292484962678456,
      "loss": 0.1764,
      "step": 2559
    },
    {
      "epoch": 0.18552741239989853,
      "grad_norm": 2.4800641536712646,
      "learning_rate": 0.00016291035582288572,
      "loss": 0.046,
      "step": 2560
    },
    {
      "epoch": 0.18559988404536726,
      "grad_norm": 1.2488089799880981,
      "learning_rate": 0.0001628958620189869,
      "loss": 0.0362,
      "step": 2561
    },
    {
      "epoch": 0.18567235569083596,
      "grad_norm": 4.22720193862915,
      "learning_rate": 0.00016288136821508806,
      "loss": 0.1411,
      "step": 2562
    },
    {
      "epoch": 0.18574482733630468,
      "grad_norm": 5.9340410232543945,
      "learning_rate": 0.00016286687441118922,
      "loss": 0.1702,
      "step": 2563
    },
    {
      "epoch": 0.18581729898177338,
      "grad_norm": 0.7346470355987549,
      "learning_rate": 0.0001628523806072904,
      "loss": 0.0228,
      "step": 2564
    },
    {
      "epoch": 0.1858897706272421,
      "grad_norm": 2.4366464614868164,
      "learning_rate": 0.00016283788680339156,
      "loss": 0.1055,
      "step": 2565
    },
    {
      "epoch": 0.1859622422727108,
      "grad_norm": 3.35394549369812,
      "learning_rate": 0.0001628233929994927,
      "loss": 0.1828,
      "step": 2566
    },
    {
      "epoch": 0.18603471391817952,
      "grad_norm": 5.819589138031006,
      "learning_rate": 0.0001628088991955939,
      "loss": 0.1563,
      "step": 2567
    },
    {
      "epoch": 0.18610718556364822,
      "grad_norm": 3.1422886848449707,
      "learning_rate": 0.00016279440539169505,
      "loss": 0.1211,
      "step": 2568
    },
    {
      "epoch": 0.18617965720911694,
      "grad_norm": 1.7236742973327637,
      "learning_rate": 0.0001627799115877962,
      "loss": 0.1054,
      "step": 2569
    },
    {
      "epoch": 0.18625212885458564,
      "grad_norm": 3.740065336227417,
      "learning_rate": 0.0001627654177838974,
      "loss": 0.1191,
      "step": 2570
    },
    {
      "epoch": 0.18632460050005437,
      "grad_norm": 3.2518532276153564,
      "learning_rate": 0.00016275092397999855,
      "loss": 0.1655,
      "step": 2571
    },
    {
      "epoch": 0.18639707214552306,
      "grad_norm": 2.4503183364868164,
      "learning_rate": 0.0001627364301760997,
      "loss": 0.1345,
      "step": 2572
    },
    {
      "epoch": 0.1864695437909918,
      "grad_norm": 0.9724277257919312,
      "learning_rate": 0.0001627219363722009,
      "loss": 0.0351,
      "step": 2573
    },
    {
      "epoch": 0.18654201543646048,
      "grad_norm": 1.9752620458602905,
      "learning_rate": 0.00016270744256830205,
      "loss": 0.0801,
      "step": 2574
    },
    {
      "epoch": 0.1866144870819292,
      "grad_norm": 2.571157693862915,
      "learning_rate": 0.00016269294876440323,
      "loss": 0.0798,
      "step": 2575
    },
    {
      "epoch": 0.1866869587273979,
      "grad_norm": 4.05740213394165,
      "learning_rate": 0.0001626784549605044,
      "loss": 0.1319,
      "step": 2576
    },
    {
      "epoch": 0.1867594303728666,
      "grad_norm": 4.796931266784668,
      "learning_rate": 0.00016266396115660557,
      "loss": 0.0882,
      "step": 2577
    },
    {
      "epoch": 0.18683190201833533,
      "grad_norm": 1.5182169675827026,
      "learning_rate": 0.00016264946735270673,
      "loss": 0.0536,
      "step": 2578
    },
    {
      "epoch": 0.18690437366380402,
      "grad_norm": 2.864337682723999,
      "learning_rate": 0.0001626349735488079,
      "loss": 0.1252,
      "step": 2579
    },
    {
      "epoch": 0.18697684530927275,
      "grad_norm": 1.7281326055526733,
      "learning_rate": 0.00016262047974490907,
      "loss": 0.1094,
      "step": 2580
    },
    {
      "epoch": 0.18704931695474145,
      "grad_norm": 2.677898645401001,
      "learning_rate": 0.00016260598594101022,
      "loss": 0.0947,
      "step": 2581
    },
    {
      "epoch": 0.18712178860021017,
      "grad_norm": 1.5816445350646973,
      "learning_rate": 0.0001625914921371114,
      "loss": 0.0844,
      "step": 2582
    },
    {
      "epoch": 0.18719426024567887,
      "grad_norm": 1.2222634553909302,
      "learning_rate": 0.00016257699833321256,
      "loss": 0.0979,
      "step": 2583
    },
    {
      "epoch": 0.1872667318911476,
      "grad_norm": 1.9431544542312622,
      "learning_rate": 0.00016256250452931372,
      "loss": 0.1021,
      "step": 2584
    },
    {
      "epoch": 0.1873392035366163,
      "grad_norm": 1.7295666933059692,
      "learning_rate": 0.0001625480107254149,
      "loss": 0.1107,
      "step": 2585
    },
    {
      "epoch": 0.187411675182085,
      "grad_norm": 1.5057921409606934,
      "learning_rate": 0.00016253351692151606,
      "loss": 0.0524,
      "step": 2586
    },
    {
      "epoch": 0.1874841468275537,
      "grad_norm": 2.509549617767334,
      "learning_rate": 0.00016251902311761722,
      "loss": 0.0722,
      "step": 2587
    },
    {
      "epoch": 0.18755661847302244,
      "grad_norm": 3.262279987335205,
      "learning_rate": 0.0001625045293137184,
      "loss": 0.0862,
      "step": 2588
    },
    {
      "epoch": 0.18762909011849113,
      "grad_norm": 8.74073600769043,
      "learning_rate": 0.00016249003550981956,
      "loss": 0.1303,
      "step": 2589
    },
    {
      "epoch": 0.18770156176395986,
      "grad_norm": 1.6432455778121948,
      "learning_rate": 0.0001624755417059207,
      "loss": 0.1084,
      "step": 2590
    },
    {
      "epoch": 0.18777403340942855,
      "grad_norm": 5.282888889312744,
      "learning_rate": 0.0001624610479020219,
      "loss": 0.1138,
      "step": 2591
    },
    {
      "epoch": 0.18784650505489728,
      "grad_norm": 4.846173286437988,
      "learning_rate": 0.00016244655409812305,
      "loss": 0.1685,
      "step": 2592
    },
    {
      "epoch": 0.18791897670036598,
      "grad_norm": 3.382474660873413,
      "learning_rate": 0.0001624320602942242,
      "loss": 0.0503,
      "step": 2593
    },
    {
      "epoch": 0.1879914483458347,
      "grad_norm": 3.152966022491455,
      "learning_rate": 0.0001624175664903254,
      "loss": 0.0628,
      "step": 2594
    },
    {
      "epoch": 0.1880639199913034,
      "grad_norm": 3.4828524589538574,
      "learning_rate": 0.00016240307268642655,
      "loss": 0.0414,
      "step": 2595
    },
    {
      "epoch": 0.18813639163677212,
      "grad_norm": 2.2174007892608643,
      "learning_rate": 0.00016238857888252773,
      "loss": 0.17,
      "step": 2596
    },
    {
      "epoch": 0.18820886328224082,
      "grad_norm": 1.7413582801818848,
      "learning_rate": 0.0001623740850786289,
      "loss": 0.108,
      "step": 2597
    },
    {
      "epoch": 0.18828133492770954,
      "grad_norm": 1.1252977848052979,
      "learning_rate": 0.00016235959127473007,
      "loss": 0.0607,
      "step": 2598
    },
    {
      "epoch": 0.18835380657317824,
      "grad_norm": 4.7941694259643555,
      "learning_rate": 0.00016234509747083123,
      "loss": 0.2017,
      "step": 2599
    },
    {
      "epoch": 0.18842627821864696,
      "grad_norm": 3.6538686752319336,
      "learning_rate": 0.0001623306036669324,
      "loss": 0.1033,
      "step": 2600
    },
    {
      "epoch": 0.18849874986411566,
      "grad_norm": 3.1256327629089355,
      "learning_rate": 0.00016231610986303357,
      "loss": 0.0998,
      "step": 2601
    },
    {
      "epoch": 0.18857122150958439,
      "grad_norm": 2.0156660079956055,
      "learning_rate": 0.00016230161605913473,
      "loss": 0.0967,
      "step": 2602
    },
    {
      "epoch": 0.18864369315505308,
      "grad_norm": 2.8980867862701416,
      "learning_rate": 0.0001622871222552359,
      "loss": 0.0847,
      "step": 2603
    },
    {
      "epoch": 0.1887161648005218,
      "grad_norm": 2.0607635974884033,
      "learning_rate": 0.00016227262845133707,
      "loss": 0.0988,
      "step": 2604
    },
    {
      "epoch": 0.1887886364459905,
      "grad_norm": 3.398526668548584,
      "learning_rate": 0.00016225813464743822,
      "loss": 0.0649,
      "step": 2605
    },
    {
      "epoch": 0.18886110809145923,
      "grad_norm": 5.159978866577148,
      "learning_rate": 0.0001622436408435394,
      "loss": 0.1257,
      "step": 2606
    },
    {
      "epoch": 0.18893357973692793,
      "grad_norm": 1.1200493574142456,
      "learning_rate": 0.00016222914703964056,
      "loss": 0.0314,
      "step": 2607
    },
    {
      "epoch": 0.18900605138239665,
      "grad_norm": 2.453874111175537,
      "learning_rate": 0.00016221465323574172,
      "loss": 0.1112,
      "step": 2608
    },
    {
      "epoch": 0.18907852302786535,
      "grad_norm": 1.6552151441574097,
      "learning_rate": 0.0001622001594318429,
      "loss": 0.1167,
      "step": 2609
    },
    {
      "epoch": 0.18915099467333407,
      "grad_norm": 1.7201370000839233,
      "learning_rate": 0.00016218566562794406,
      "loss": 0.1035,
      "step": 2610
    },
    {
      "epoch": 0.18922346631880277,
      "grad_norm": 2.684617280960083,
      "learning_rate": 0.00016217117182404522,
      "loss": 0.1028,
      "step": 2611
    },
    {
      "epoch": 0.18929593796427147,
      "grad_norm": 3.3743152618408203,
      "learning_rate": 0.0001621566780201464,
      "loss": 0.0616,
      "step": 2612
    },
    {
      "epoch": 0.1893684096097402,
      "grad_norm": 3.003554582595825,
      "learning_rate": 0.00016214218421624756,
      "loss": 0.137,
      "step": 2613
    },
    {
      "epoch": 0.1894408812552089,
      "grad_norm": 2.2470803260803223,
      "learning_rate": 0.0001621276904123487,
      "loss": 0.0826,
      "step": 2614
    },
    {
      "epoch": 0.1895133529006776,
      "grad_norm": 2.088547706604004,
      "learning_rate": 0.0001621131966084499,
      "loss": 0.1199,
      "step": 2615
    },
    {
      "epoch": 0.1895858245461463,
      "grad_norm": 1.2016667127609253,
      "learning_rate": 0.00016209870280455105,
      "loss": 0.0493,
      "step": 2616
    },
    {
      "epoch": 0.18965829619161503,
      "grad_norm": 5.597634792327881,
      "learning_rate": 0.0001620842090006522,
      "loss": 0.1194,
      "step": 2617
    },
    {
      "epoch": 0.18973076783708373,
      "grad_norm": 1.5326650142669678,
      "learning_rate": 0.0001620697151967534,
      "loss": 0.063,
      "step": 2618
    },
    {
      "epoch": 0.18980323948255245,
      "grad_norm": 2.921318531036377,
      "learning_rate": 0.00016205522139285455,
      "loss": 0.0933,
      "step": 2619
    },
    {
      "epoch": 0.18987571112802115,
      "grad_norm": 3.3763182163238525,
      "learning_rate": 0.00016204072758895573,
      "loss": 0.1403,
      "step": 2620
    },
    {
      "epoch": 0.18994818277348988,
      "grad_norm": 4.020707130432129,
      "learning_rate": 0.0001620262337850569,
      "loss": 0.0989,
      "step": 2621
    },
    {
      "epoch": 0.19002065441895857,
      "grad_norm": 1.2336801290512085,
      "learning_rate": 0.00016201173998115807,
      "loss": 0.0378,
      "step": 2622
    },
    {
      "epoch": 0.1900931260644273,
      "grad_norm": 2.665776014328003,
      "learning_rate": 0.00016199724617725923,
      "loss": 0.0765,
      "step": 2623
    },
    {
      "epoch": 0.190165597709896,
      "grad_norm": 1.4663246870040894,
      "learning_rate": 0.0001619827523733604,
      "loss": 0.056,
      "step": 2624
    },
    {
      "epoch": 0.19023806935536472,
      "grad_norm": 2.1775014400482178,
      "learning_rate": 0.00016196825856946157,
      "loss": 0.065,
      "step": 2625
    },
    {
      "epoch": 0.19031054100083342,
      "grad_norm": 0.8986834287643433,
      "learning_rate": 0.00016195376476556273,
      "loss": 0.024,
      "step": 2626
    },
    {
      "epoch": 0.19038301264630214,
      "grad_norm": 4.3733696937561035,
      "learning_rate": 0.0001619392709616639,
      "loss": 0.1734,
      "step": 2627
    },
    {
      "epoch": 0.19045548429177084,
      "grad_norm": 2.3364486694335938,
      "learning_rate": 0.00016192477715776507,
      "loss": 0.1,
      "step": 2628
    },
    {
      "epoch": 0.19052795593723956,
      "grad_norm": 2.0017402172088623,
      "learning_rate": 0.00016191028335386622,
      "loss": 0.1487,
      "step": 2629
    },
    {
      "epoch": 0.19060042758270826,
      "grad_norm": 3.795407772064209,
      "learning_rate": 0.0001618957895499674,
      "loss": 0.1795,
      "step": 2630
    },
    {
      "epoch": 0.19067289922817698,
      "grad_norm": 2.593869686126709,
      "learning_rate": 0.00016188129574606856,
      "loss": 0.0888,
      "step": 2631
    },
    {
      "epoch": 0.19074537087364568,
      "grad_norm": 0.7447549700737,
      "learning_rate": 0.00016186680194216972,
      "loss": 0.0253,
      "step": 2632
    },
    {
      "epoch": 0.1908178425191144,
      "grad_norm": 2.989567995071411,
      "learning_rate": 0.0001618523081382709,
      "loss": 0.0616,
      "step": 2633
    },
    {
      "epoch": 0.1908903141645831,
      "grad_norm": 2.979065179824829,
      "learning_rate": 0.00016183781433437206,
      "loss": 0.1492,
      "step": 2634
    },
    {
      "epoch": 0.19096278581005183,
      "grad_norm": 2.403834581375122,
      "learning_rate": 0.00016182332053047322,
      "loss": 0.0742,
      "step": 2635
    },
    {
      "epoch": 0.19103525745552052,
      "grad_norm": 2.4838907718658447,
      "learning_rate": 0.0001618088267265744,
      "loss": 0.0865,
      "step": 2636
    },
    {
      "epoch": 0.19110772910098925,
      "grad_norm": 1.0895884037017822,
      "learning_rate": 0.00016179433292267556,
      "loss": 0.1155,
      "step": 2637
    },
    {
      "epoch": 0.19118020074645795,
      "grad_norm": 0.8090550899505615,
      "learning_rate": 0.0001617798391187767,
      "loss": 0.0144,
      "step": 2638
    },
    {
      "epoch": 0.19125267239192667,
      "grad_norm": 1.440301775932312,
      "learning_rate": 0.0001617653453148779,
      "loss": 0.066,
      "step": 2639
    },
    {
      "epoch": 0.19132514403739537,
      "grad_norm": 1.6066144704818726,
      "learning_rate": 0.00016175085151097905,
      "loss": 0.1127,
      "step": 2640
    },
    {
      "epoch": 0.1913976156828641,
      "grad_norm": 2.728903293609619,
      "learning_rate": 0.0001617363577070802,
      "loss": 0.1292,
      "step": 2641
    },
    {
      "epoch": 0.1914700873283328,
      "grad_norm": 3.4954633712768555,
      "learning_rate": 0.0001617218639031814,
      "loss": 0.101,
      "step": 2642
    },
    {
      "epoch": 0.1915425589738015,
      "grad_norm": 2.8593947887420654,
      "learning_rate": 0.00016170737009928258,
      "loss": 0.1544,
      "step": 2643
    },
    {
      "epoch": 0.1916150306192702,
      "grad_norm": 1.8720940351486206,
      "learning_rate": 0.00016169287629538373,
      "loss": 0.0777,
      "step": 2644
    },
    {
      "epoch": 0.1916875022647389,
      "grad_norm": 1.2243624925613403,
      "learning_rate": 0.00016167838249148492,
      "loss": 0.0592,
      "step": 2645
    },
    {
      "epoch": 0.19175997391020763,
      "grad_norm": 1.4886661767959595,
      "learning_rate": 0.00016166388868758607,
      "loss": 0.1145,
      "step": 2646
    },
    {
      "epoch": 0.19183244555567633,
      "grad_norm": 2.4906272888183594,
      "learning_rate": 0.00016164939488368723,
      "loss": 0.1202,
      "step": 2647
    },
    {
      "epoch": 0.19190491720114505,
      "grad_norm": 1.9146780967712402,
      "learning_rate": 0.0001616349010797884,
      "loss": 0.0919,
      "step": 2648
    },
    {
      "epoch": 0.19197738884661375,
      "grad_norm": 1.8378926515579224,
      "learning_rate": 0.00016162040727588957,
      "loss": 0.0734,
      "step": 2649
    },
    {
      "epoch": 0.19204986049208247,
      "grad_norm": 2.732774257659912,
      "learning_rate": 0.00016160591347199073,
      "loss": 0.0702,
      "step": 2650
    },
    {
      "epoch": 0.19212233213755117,
      "grad_norm": 1.1889971494674683,
      "learning_rate": 0.0001615914196680919,
      "loss": 0.0343,
      "step": 2651
    },
    {
      "epoch": 0.1921948037830199,
      "grad_norm": 1.542431116104126,
      "learning_rate": 0.00016157692586419307,
      "loss": 0.0608,
      "step": 2652
    },
    {
      "epoch": 0.1922672754284886,
      "grad_norm": 6.618546485900879,
      "learning_rate": 0.00016156243206029422,
      "loss": 0.2738,
      "step": 2653
    },
    {
      "epoch": 0.19233974707395732,
      "grad_norm": 4.472435474395752,
      "learning_rate": 0.0001615479382563954,
      "loss": 0.0751,
      "step": 2654
    },
    {
      "epoch": 0.19241221871942601,
      "grad_norm": 3.137521505355835,
      "learning_rate": 0.00016153344445249656,
      "loss": 0.0949,
      "step": 2655
    },
    {
      "epoch": 0.19248469036489474,
      "grad_norm": 2.127371072769165,
      "learning_rate": 0.00016151895064859772,
      "loss": 0.0895,
      "step": 2656
    },
    {
      "epoch": 0.19255716201036344,
      "grad_norm": 2.0296223163604736,
      "learning_rate": 0.0001615044568446989,
      "loss": 0.0478,
      "step": 2657
    },
    {
      "epoch": 0.19262963365583216,
      "grad_norm": 1.7834142446517944,
      "learning_rate": 0.00016148996304080006,
      "loss": 0.0377,
      "step": 2658
    },
    {
      "epoch": 0.19270210530130086,
      "grad_norm": 2.0456762313842773,
      "learning_rate": 0.00016147546923690121,
      "loss": 0.1373,
      "step": 2659
    },
    {
      "epoch": 0.19277457694676958,
      "grad_norm": 3.2739996910095215,
      "learning_rate": 0.0001614609754330024,
      "loss": 0.0468,
      "step": 2660
    },
    {
      "epoch": 0.19284704859223828,
      "grad_norm": 1.0499145984649658,
      "learning_rate": 0.00016144648162910356,
      "loss": 0.0742,
      "step": 2661
    },
    {
      "epoch": 0.192919520237707,
      "grad_norm": 1.1488004922866821,
      "learning_rate": 0.0001614319878252047,
      "loss": 0.0451,
      "step": 2662
    },
    {
      "epoch": 0.1929919918831757,
      "grad_norm": 4.894918918609619,
      "learning_rate": 0.0001614174940213059,
      "loss": 0.1234,
      "step": 2663
    },
    {
      "epoch": 0.19306446352864443,
      "grad_norm": 1.4981063604354858,
      "learning_rate": 0.00016140300021740705,
      "loss": 0.1338,
      "step": 2664
    },
    {
      "epoch": 0.19313693517411312,
      "grad_norm": 1.2649593353271484,
      "learning_rate": 0.00016138850641350824,
      "loss": 0.0495,
      "step": 2665
    },
    {
      "epoch": 0.19320940681958185,
      "grad_norm": 1.5286449193954468,
      "learning_rate": 0.0001613740126096094,
      "loss": 0.0327,
      "step": 2666
    },
    {
      "epoch": 0.19328187846505054,
      "grad_norm": 1.2426990270614624,
      "learning_rate": 0.00016135951880571058,
      "loss": 0.0437,
      "step": 2667
    },
    {
      "epoch": 0.19335435011051927,
      "grad_norm": 1.5237646102905273,
      "learning_rate": 0.00016134502500181173,
      "loss": 0.062,
      "step": 2668
    },
    {
      "epoch": 0.19342682175598797,
      "grad_norm": 3.592195987701416,
      "learning_rate": 0.00016133053119791292,
      "loss": 0.1005,
      "step": 2669
    },
    {
      "epoch": 0.1934992934014567,
      "grad_norm": 1.0217856168746948,
      "learning_rate": 0.00016131603739401407,
      "loss": 0.0081,
      "step": 2670
    },
    {
      "epoch": 0.1935717650469254,
      "grad_norm": 2.13059663772583,
      "learning_rate": 0.00016130154359011523,
      "loss": 0.0567,
      "step": 2671
    },
    {
      "epoch": 0.1936442366923941,
      "grad_norm": 1.6853768825531006,
      "learning_rate": 0.0001612870497862164,
      "loss": 0.0996,
      "step": 2672
    },
    {
      "epoch": 0.1937167083378628,
      "grad_norm": 6.509002208709717,
      "learning_rate": 0.00016127255598231757,
      "loss": 0.1214,
      "step": 2673
    },
    {
      "epoch": 0.19378917998333153,
      "grad_norm": 0.792096734046936,
      "learning_rate": 0.00016125806217841872,
      "loss": 0.072,
      "step": 2674
    },
    {
      "epoch": 0.19386165162880023,
      "grad_norm": 3.2743895053863525,
      "learning_rate": 0.0001612435683745199,
      "loss": 0.2339,
      "step": 2675
    },
    {
      "epoch": 0.19393412327426895,
      "grad_norm": 4.030036926269531,
      "learning_rate": 0.00016122907457062106,
      "loss": 0.1365,
      "step": 2676
    },
    {
      "epoch": 0.19400659491973765,
      "grad_norm": 1.8557802438735962,
      "learning_rate": 0.00016121458076672222,
      "loss": 0.029,
      "step": 2677
    },
    {
      "epoch": 0.19407906656520638,
      "grad_norm": 4.800601959228516,
      "learning_rate": 0.0001612000869628234,
      "loss": 0.1425,
      "step": 2678
    },
    {
      "epoch": 0.19415153821067507,
      "grad_norm": 1.6424858570098877,
      "learning_rate": 0.00016118559315892456,
      "loss": 0.0992,
      "step": 2679
    },
    {
      "epoch": 0.19422400985614377,
      "grad_norm": 1.312789797782898,
      "learning_rate": 0.00016117109935502575,
      "loss": 0.0454,
      "step": 2680
    },
    {
      "epoch": 0.1942964815016125,
      "grad_norm": 5.412648677825928,
      "learning_rate": 0.0001611566055511269,
      "loss": 0.0758,
      "step": 2681
    },
    {
      "epoch": 0.1943689531470812,
      "grad_norm": 2.025303363800049,
      "learning_rate": 0.00016114211174722806,
      "loss": 0.0858,
      "step": 2682
    },
    {
      "epoch": 0.19444142479254992,
      "grad_norm": 2.9573113918304443,
      "learning_rate": 0.00016112761794332924,
      "loss": 0.1772,
      "step": 2683
    },
    {
      "epoch": 0.1945138964380186,
      "grad_norm": 4.292925834655762,
      "learning_rate": 0.0001611131241394304,
      "loss": 0.0989,
      "step": 2684
    },
    {
      "epoch": 0.19458636808348734,
      "grad_norm": 3.0472118854522705,
      "learning_rate": 0.00016109863033553155,
      "loss": 0.1681,
      "step": 2685
    },
    {
      "epoch": 0.19465883972895603,
      "grad_norm": 2.0983521938323975,
      "learning_rate": 0.00016108413653163274,
      "loss": 0.1378,
      "step": 2686
    },
    {
      "epoch": 0.19473131137442476,
      "grad_norm": 1.262036681175232,
      "learning_rate": 0.0001610696427277339,
      "loss": 0.0587,
      "step": 2687
    },
    {
      "epoch": 0.19480378301989346,
      "grad_norm": 2.3180058002471924,
      "learning_rate": 0.00016105514892383505,
      "loss": 0.0809,
      "step": 2688
    },
    {
      "epoch": 0.19487625466536218,
      "grad_norm": 3.6132805347442627,
      "learning_rate": 0.00016104065511993623,
      "loss": 0.1014,
      "step": 2689
    },
    {
      "epoch": 0.19494872631083088,
      "grad_norm": 2.1605989933013916,
      "learning_rate": 0.00016102616131603742,
      "loss": 0.0837,
      "step": 2690
    },
    {
      "epoch": 0.1950211979562996,
      "grad_norm": 3.426820755004883,
      "learning_rate": 0.00016101166751213857,
      "loss": 0.119,
      "step": 2691
    },
    {
      "epoch": 0.1950936696017683,
      "grad_norm": 0.35022374987602234,
      "learning_rate": 0.00016099717370823976,
      "loss": 0.0237,
      "step": 2692
    },
    {
      "epoch": 0.19516614124723702,
      "grad_norm": 2.139940023422241,
      "learning_rate": 0.00016098267990434091,
      "loss": 0.1525,
      "step": 2693
    },
    {
      "epoch": 0.19523861289270572,
      "grad_norm": 1.27959406375885,
      "learning_rate": 0.00016096818610044207,
      "loss": 0.1038,
      "step": 2694
    },
    {
      "epoch": 0.19531108453817445,
      "grad_norm": 7.18413782119751,
      "learning_rate": 0.00016095369229654325,
      "loss": 0.1507,
      "step": 2695
    },
    {
      "epoch": 0.19538355618364314,
      "grad_norm": 2.267695188522339,
      "learning_rate": 0.0001609391984926444,
      "loss": 0.0706,
      "step": 2696
    },
    {
      "epoch": 0.19545602782911187,
      "grad_norm": 0.8919011354446411,
      "learning_rate": 0.00016092470468874557,
      "loss": 0.039,
      "step": 2697
    },
    {
      "epoch": 0.19552849947458056,
      "grad_norm": 2.1592180728912354,
      "learning_rate": 0.00016091021088484675,
      "loss": 0.0764,
      "step": 2698
    },
    {
      "epoch": 0.1956009711200493,
      "grad_norm": 1.547837734222412,
      "learning_rate": 0.0001608957170809479,
      "loss": 0.0586,
      "step": 2699
    },
    {
      "epoch": 0.19567344276551799,
      "grad_norm": 1.52045476436615,
      "learning_rate": 0.00016088122327704906,
      "loss": 0.0618,
      "step": 2700
    },
    {
      "epoch": 0.1957459144109867,
      "grad_norm": 2.982905864715576,
      "learning_rate": 0.00016086672947315025,
      "loss": 0.0928,
      "step": 2701
    },
    {
      "epoch": 0.1958183860564554,
      "grad_norm": 1.3964481353759766,
      "learning_rate": 0.0001608522356692514,
      "loss": 0.1066,
      "step": 2702
    },
    {
      "epoch": 0.19589085770192413,
      "grad_norm": 2.481785297393799,
      "learning_rate": 0.00016083774186535256,
      "loss": 0.0567,
      "step": 2703
    },
    {
      "epoch": 0.19596332934739283,
      "grad_norm": 1.3215574026107788,
      "learning_rate": 0.00016082324806145374,
      "loss": 0.0798,
      "step": 2704
    },
    {
      "epoch": 0.19603580099286155,
      "grad_norm": 4.360991477966309,
      "learning_rate": 0.0001608087542575549,
      "loss": 0.1763,
      "step": 2705
    },
    {
      "epoch": 0.19610827263833025,
      "grad_norm": 4.832333087921143,
      "learning_rate": 0.00016079426045365606,
      "loss": 0.088,
      "step": 2706
    },
    {
      "epoch": 0.19618074428379897,
      "grad_norm": 0.8815167546272278,
      "learning_rate": 0.00016077976664975724,
      "loss": 0.0404,
      "step": 2707
    },
    {
      "epoch": 0.19625321592926767,
      "grad_norm": 1.2444514036178589,
      "learning_rate": 0.0001607652728458584,
      "loss": 0.04,
      "step": 2708
    },
    {
      "epoch": 0.1963256875747364,
      "grad_norm": 0.8574497699737549,
      "learning_rate": 0.00016075077904195955,
      "loss": 0.0112,
      "step": 2709
    },
    {
      "epoch": 0.1963981592202051,
      "grad_norm": 8.043366432189941,
      "learning_rate": 0.00016073628523806074,
      "loss": 0.234,
      "step": 2710
    },
    {
      "epoch": 0.19647063086567382,
      "grad_norm": 2.306940793991089,
      "learning_rate": 0.0001607217914341619,
      "loss": 0.1058,
      "step": 2711
    },
    {
      "epoch": 0.19654310251114251,
      "grad_norm": 5.403515338897705,
      "learning_rate": 0.00016070729763026308,
      "loss": 0.2367,
      "step": 2712
    },
    {
      "epoch": 0.19661557415661124,
      "grad_norm": 2.405122995376587,
      "learning_rate": 0.00016069280382636423,
      "loss": 0.0902,
      "step": 2713
    },
    {
      "epoch": 0.19668804580207994,
      "grad_norm": 3.7472054958343506,
      "learning_rate": 0.00016067831002246542,
      "loss": 0.0653,
      "step": 2714
    },
    {
      "epoch": 0.19676051744754863,
      "grad_norm": 3.432389259338379,
      "learning_rate": 0.00016066381621856657,
      "loss": 0.1981,
      "step": 2715
    },
    {
      "epoch": 0.19683298909301736,
      "grad_norm": 1.8838623762130737,
      "learning_rate": 0.00016064932241466776,
      "loss": 0.133,
      "step": 2716
    },
    {
      "epoch": 0.19690546073848605,
      "grad_norm": 1.718397855758667,
      "learning_rate": 0.00016063482861076891,
      "loss": 0.0753,
      "step": 2717
    },
    {
      "epoch": 0.19697793238395478,
      "grad_norm": 1.7456272840499878,
      "learning_rate": 0.00016062033480687007,
      "loss": 0.0641,
      "step": 2718
    },
    {
      "epoch": 0.19705040402942348,
      "grad_norm": 7.0041937828063965,
      "learning_rate": 0.00016060584100297125,
      "loss": 0.2495,
      "step": 2719
    },
    {
      "epoch": 0.1971228756748922,
      "grad_norm": 4.01331090927124,
      "learning_rate": 0.0001605913471990724,
      "loss": 0.0707,
      "step": 2720
    },
    {
      "epoch": 0.1971953473203609,
      "grad_norm": 1.986674427986145,
      "learning_rate": 0.00016057685339517357,
      "loss": 0.1,
      "step": 2721
    },
    {
      "epoch": 0.19726781896582962,
      "grad_norm": 1.9131624698638916,
      "learning_rate": 0.00016056235959127475,
      "loss": 0.1074,
      "step": 2722
    },
    {
      "epoch": 0.19734029061129832,
      "grad_norm": 4.5321502685546875,
      "learning_rate": 0.0001605478657873759,
      "loss": 0.2551,
      "step": 2723
    },
    {
      "epoch": 0.19741276225676704,
      "grad_norm": 5.429724216461182,
      "learning_rate": 0.00016053337198347706,
      "loss": 0.1875,
      "step": 2724
    },
    {
      "epoch": 0.19748523390223574,
      "grad_norm": 1.9146062135696411,
      "learning_rate": 0.00016051887817957825,
      "loss": 0.1037,
      "step": 2725
    },
    {
      "epoch": 0.19755770554770447,
      "grad_norm": 2.349485158920288,
      "learning_rate": 0.0001605043843756794,
      "loss": 0.1613,
      "step": 2726
    },
    {
      "epoch": 0.19763017719317316,
      "grad_norm": 0.5813536047935486,
      "learning_rate": 0.00016048989057178056,
      "loss": 0.0392,
      "step": 2727
    },
    {
      "epoch": 0.1977026488386419,
      "grad_norm": 2.9468941688537598,
      "learning_rate": 0.00016047539676788174,
      "loss": 0.1714,
      "step": 2728
    },
    {
      "epoch": 0.19777512048411058,
      "grad_norm": 1.4875973463058472,
      "learning_rate": 0.0001604609029639829,
      "loss": 0.0752,
      "step": 2729
    },
    {
      "epoch": 0.1978475921295793,
      "grad_norm": 0.7028518319129944,
      "learning_rate": 0.00016044640916008406,
      "loss": 0.0344,
      "step": 2730
    },
    {
      "epoch": 0.197920063775048,
      "grad_norm": 0.8504709601402283,
      "learning_rate": 0.00016043191535618524,
      "loss": 0.0318,
      "step": 2731
    },
    {
      "epoch": 0.19799253542051673,
      "grad_norm": 1.8636380434036255,
      "learning_rate": 0.0001604174215522864,
      "loss": 0.0925,
      "step": 2732
    },
    {
      "epoch": 0.19806500706598543,
      "grad_norm": 2.252749443054199,
      "learning_rate": 0.00016040292774838755,
      "loss": 0.1445,
      "step": 2733
    },
    {
      "epoch": 0.19813747871145415,
      "grad_norm": 2.6214563846588135,
      "learning_rate": 0.00016038843394448874,
      "loss": 0.1376,
      "step": 2734
    },
    {
      "epoch": 0.19820995035692285,
      "grad_norm": 0.8610937595367432,
      "learning_rate": 0.0001603739401405899,
      "loss": 0.0329,
      "step": 2735
    },
    {
      "epoch": 0.19828242200239157,
      "grad_norm": 3.256347417831421,
      "learning_rate": 0.00016035944633669108,
      "loss": 0.1205,
      "step": 2736
    },
    {
      "epoch": 0.19835489364786027,
      "grad_norm": 1.3603391647338867,
      "learning_rate": 0.00016034495253279223,
      "loss": 0.0763,
      "step": 2737
    },
    {
      "epoch": 0.198427365293329,
      "grad_norm": 0.5272015929222107,
      "learning_rate": 0.00016033045872889342,
      "loss": 0.0276,
      "step": 2738
    },
    {
      "epoch": 0.1984998369387977,
      "grad_norm": 1.5383278131484985,
      "learning_rate": 0.00016031596492499457,
      "loss": 0.0548,
      "step": 2739
    },
    {
      "epoch": 0.19857230858426642,
      "grad_norm": 1.0753425359725952,
      "learning_rate": 0.00016030147112109576,
      "loss": 0.0449,
      "step": 2740
    },
    {
      "epoch": 0.1986447802297351,
      "grad_norm": 1.2969671487808228,
      "learning_rate": 0.00016028697731719691,
      "loss": 0.0561,
      "step": 2741
    },
    {
      "epoch": 0.19871725187520384,
      "grad_norm": 3.0992324352264404,
      "learning_rate": 0.00016027248351329807,
      "loss": 0.2251,
      "step": 2742
    },
    {
      "epoch": 0.19878972352067253,
      "grad_norm": 1.6122384071350098,
      "learning_rate": 0.00016025798970939925,
      "loss": 0.0358,
      "step": 2743
    },
    {
      "epoch": 0.19886219516614126,
      "grad_norm": 1.1866059303283691,
      "learning_rate": 0.0001602434959055004,
      "loss": 0.0941,
      "step": 2744
    },
    {
      "epoch": 0.19893466681160996,
      "grad_norm": 3.284759759902954,
      "learning_rate": 0.00016022900210160157,
      "loss": 0.1466,
      "step": 2745
    },
    {
      "epoch": 0.19900713845707868,
      "grad_norm": 4.742476940155029,
      "learning_rate": 0.00016021450829770275,
      "loss": 0.1776,
      "step": 2746
    },
    {
      "epoch": 0.19907961010254738,
      "grad_norm": 5.117251873016357,
      "learning_rate": 0.0001602000144938039,
      "loss": 0.1282,
      "step": 2747
    },
    {
      "epoch": 0.1991520817480161,
      "grad_norm": 0.6107352375984192,
      "learning_rate": 0.00016018552068990506,
      "loss": 0.0163,
      "step": 2748
    },
    {
      "epoch": 0.1992245533934848,
      "grad_norm": 3.2988386154174805,
      "learning_rate": 0.00016017102688600625,
      "loss": 0.1168,
      "step": 2749
    },
    {
      "epoch": 0.1992970250389535,
      "grad_norm": 2.366809368133545,
      "learning_rate": 0.0001601565330821074,
      "loss": 0.1316,
      "step": 2750
    },
    {
      "epoch": 0.19936949668442222,
      "grad_norm": 0.7313916087150574,
      "learning_rate": 0.00016014203927820856,
      "loss": 0.0272,
      "step": 2751
    },
    {
      "epoch": 0.19944196832989092,
      "grad_norm": 2.9922566413879395,
      "learning_rate": 0.00016012754547430974,
      "loss": 0.1885,
      "step": 2752
    },
    {
      "epoch": 0.19951443997535964,
      "grad_norm": 3.051468849182129,
      "learning_rate": 0.0001601130516704109,
      "loss": 0.086,
      "step": 2753
    },
    {
      "epoch": 0.19958691162082834,
      "grad_norm": 0.8617459535598755,
      "learning_rate": 0.00016009855786651206,
      "loss": 0.0224,
      "step": 2754
    },
    {
      "epoch": 0.19965938326629706,
      "grad_norm": 1.403369426727295,
      "learning_rate": 0.00016008406406261324,
      "loss": 0.0588,
      "step": 2755
    },
    {
      "epoch": 0.19973185491176576,
      "grad_norm": 2.9673402309417725,
      "learning_rate": 0.0001600695702587144,
      "loss": 0.1006,
      "step": 2756
    },
    {
      "epoch": 0.19980432655723449,
      "grad_norm": 2.553764820098877,
      "learning_rate": 0.00016005507645481555,
      "loss": 0.0953,
      "step": 2757
    },
    {
      "epoch": 0.19987679820270318,
      "grad_norm": 1.425750494003296,
      "learning_rate": 0.00016004058265091674,
      "loss": 0.0279,
      "step": 2758
    },
    {
      "epoch": 0.1999492698481719,
      "grad_norm": 1.960922122001648,
      "learning_rate": 0.00016002608884701792,
      "loss": 0.1085,
      "step": 2759
    },
    {
      "epoch": 0.2000217414936406,
      "grad_norm": 2.9368433952331543,
      "learning_rate": 0.00016001159504311908,
      "loss": 0.1283,
      "step": 2760
    },
    {
      "epoch": 0.20009421313910933,
      "grad_norm": 2.8985157012939453,
      "learning_rate": 0.00015999710123922026,
      "loss": 0.0751,
      "step": 2761
    },
    {
      "epoch": 0.20016668478457803,
      "grad_norm": 1.3191105127334595,
      "learning_rate": 0.00015998260743532142,
      "loss": 0.0747,
      "step": 2762
    },
    {
      "epoch": 0.20023915643004675,
      "grad_norm": 4.366697311401367,
      "learning_rate": 0.00015996811363142257,
      "loss": 0.1292,
      "step": 2763
    },
    {
      "epoch": 0.20031162807551545,
      "grad_norm": 2.8472940921783447,
      "learning_rate": 0.00015995361982752376,
      "loss": 0.0686,
      "step": 2764
    },
    {
      "epoch": 0.20038409972098417,
      "grad_norm": 2.5947091579437256,
      "learning_rate": 0.00015993912602362491,
      "loss": 0.1388,
      "step": 2765
    },
    {
      "epoch": 0.20045657136645287,
      "grad_norm": 1.5715852975845337,
      "learning_rate": 0.00015992463221972607,
      "loss": 0.074,
      "step": 2766
    },
    {
      "epoch": 0.2005290430119216,
      "grad_norm": 2.5476441383361816,
      "learning_rate": 0.00015991013841582725,
      "loss": 0.0845,
      "step": 2767
    },
    {
      "epoch": 0.2006015146573903,
      "grad_norm": 2.3801708221435547,
      "learning_rate": 0.0001598956446119284,
      "loss": 0.1105,
      "step": 2768
    },
    {
      "epoch": 0.20067398630285901,
      "grad_norm": 1.3875079154968262,
      "learning_rate": 0.00015988115080802957,
      "loss": 0.0958,
      "step": 2769
    },
    {
      "epoch": 0.2007464579483277,
      "grad_norm": 2.5457324981689453,
      "learning_rate": 0.00015986665700413075,
      "loss": 0.1698,
      "step": 2770
    },
    {
      "epoch": 0.20081892959379644,
      "grad_norm": 1.3836761713027954,
      "learning_rate": 0.0001598521632002319,
      "loss": 0.07,
      "step": 2771
    },
    {
      "epoch": 0.20089140123926513,
      "grad_norm": 1.9624207019805908,
      "learning_rate": 0.00015983766939633306,
      "loss": 0.173,
      "step": 2772
    },
    {
      "epoch": 0.20096387288473386,
      "grad_norm": 1.0728331804275513,
      "learning_rate": 0.00015982317559243425,
      "loss": 0.0838,
      "step": 2773
    },
    {
      "epoch": 0.20103634453020255,
      "grad_norm": 1.3549697399139404,
      "learning_rate": 0.0001598086817885354,
      "loss": 0.0656,
      "step": 2774
    },
    {
      "epoch": 0.20110881617567128,
      "grad_norm": 0.9562211036682129,
      "learning_rate": 0.00015979418798463656,
      "loss": 0.0529,
      "step": 2775
    },
    {
      "epoch": 0.20118128782113998,
      "grad_norm": 1.086534857749939,
      "learning_rate": 0.00015977969418073774,
      "loss": 0.0417,
      "step": 2776
    },
    {
      "epoch": 0.2012537594666087,
      "grad_norm": 2.811403274536133,
      "learning_rate": 0.0001597652003768389,
      "loss": 0.1261,
      "step": 2777
    },
    {
      "epoch": 0.2013262311120774,
      "grad_norm": 0.6756004095077515,
      "learning_rate": 0.00015975070657294006,
      "loss": 0.0299,
      "step": 2778
    },
    {
      "epoch": 0.20139870275754612,
      "grad_norm": 2.429211139678955,
      "learning_rate": 0.00015973621276904124,
      "loss": 0.1331,
      "step": 2779
    },
    {
      "epoch": 0.20147117440301482,
      "grad_norm": 4.374570846557617,
      "learning_rate": 0.0001597217189651424,
      "loss": 0.1302,
      "step": 2780
    },
    {
      "epoch": 0.20154364604848354,
      "grad_norm": 2.2888569831848145,
      "learning_rate": 0.00015970722516124358,
      "loss": 0.1124,
      "step": 2781
    },
    {
      "epoch": 0.20161611769395224,
      "grad_norm": 1.772444486618042,
      "learning_rate": 0.00015969273135734474,
      "loss": 0.1024,
      "step": 2782
    },
    {
      "epoch": 0.20168858933942097,
      "grad_norm": 3.3342862129211426,
      "learning_rate": 0.00015967823755344592,
      "loss": 0.0723,
      "step": 2783
    },
    {
      "epoch": 0.20176106098488966,
      "grad_norm": 1.4080091714859009,
      "learning_rate": 0.00015966374374954708,
      "loss": 0.0459,
      "step": 2784
    },
    {
      "epoch": 0.20183353263035836,
      "grad_norm": 3.3585824966430664,
      "learning_rate": 0.00015964924994564826,
      "loss": 0.0714,
      "step": 2785
    },
    {
      "epoch": 0.20190600427582708,
      "grad_norm": 2.9775402545928955,
      "learning_rate": 0.00015963475614174942,
      "loss": 0.176,
      "step": 2786
    },
    {
      "epoch": 0.20197847592129578,
      "grad_norm": 2.2690253257751465,
      "learning_rate": 0.00015962026233785057,
      "loss": 0.0469,
      "step": 2787
    },
    {
      "epoch": 0.2020509475667645,
      "grad_norm": 1.9324040412902832,
      "learning_rate": 0.00015960576853395176,
      "loss": 0.0295,
      "step": 2788
    },
    {
      "epoch": 0.2021234192122332,
      "grad_norm": 2.071107864379883,
      "learning_rate": 0.0001595912747300529,
      "loss": 0.1136,
      "step": 2789
    },
    {
      "epoch": 0.20219589085770193,
      "grad_norm": 1.4076117277145386,
      "learning_rate": 0.00015957678092615407,
      "loss": 0.0326,
      "step": 2790
    },
    {
      "epoch": 0.20226836250317062,
      "grad_norm": 2.2930476665496826,
      "learning_rate": 0.00015956228712225525,
      "loss": 0.122,
      "step": 2791
    },
    {
      "epoch": 0.20234083414863935,
      "grad_norm": 3.204850196838379,
      "learning_rate": 0.0001595477933183564,
      "loss": 0.1277,
      "step": 2792
    },
    {
      "epoch": 0.20241330579410804,
      "grad_norm": 2.033902406692505,
      "learning_rate": 0.00015953329951445757,
      "loss": 0.122,
      "step": 2793
    },
    {
      "epoch": 0.20248577743957677,
      "grad_norm": 2.019263982772827,
      "learning_rate": 0.00015951880571055875,
      "loss": 0.0973,
      "step": 2794
    },
    {
      "epoch": 0.20255824908504547,
      "grad_norm": 0.9058601260185242,
      "learning_rate": 0.0001595043119066599,
      "loss": 0.1028,
      "step": 2795
    },
    {
      "epoch": 0.2026307207305142,
      "grad_norm": 3.433696985244751,
      "learning_rate": 0.00015948981810276106,
      "loss": 0.0598,
      "step": 2796
    },
    {
      "epoch": 0.2027031923759829,
      "grad_norm": 2.1497573852539062,
      "learning_rate": 0.00015947532429886225,
      "loss": 0.0764,
      "step": 2797
    },
    {
      "epoch": 0.2027756640214516,
      "grad_norm": 1.375253677368164,
      "learning_rate": 0.0001594608304949634,
      "loss": 0.0922,
      "step": 2798
    },
    {
      "epoch": 0.2028481356669203,
      "grad_norm": 1.2445271015167236,
      "learning_rate": 0.00015944633669106456,
      "loss": 0.0793,
      "step": 2799
    },
    {
      "epoch": 0.20292060731238903,
      "grad_norm": 1.8811893463134766,
      "learning_rate": 0.00015943184288716574,
      "loss": 0.0462,
      "step": 2800
    },
    {
      "epoch": 0.20299307895785773,
      "grad_norm": 1.5702468156814575,
      "learning_rate": 0.0001594173490832669,
      "loss": 0.0536,
      "step": 2801
    },
    {
      "epoch": 0.20306555060332646,
      "grad_norm": 1.6666666269302368,
      "learning_rate": 0.00015940285527936806,
      "loss": 0.0907,
      "step": 2802
    },
    {
      "epoch": 0.20313802224879515,
      "grad_norm": 1.6163872480392456,
      "learning_rate": 0.00015938836147546924,
      "loss": 0.0796,
      "step": 2803
    },
    {
      "epoch": 0.20321049389426388,
      "grad_norm": 5.265373706817627,
      "learning_rate": 0.0001593738676715704,
      "loss": 0.1184,
      "step": 2804
    },
    {
      "epoch": 0.20328296553973257,
      "grad_norm": 1.295453667640686,
      "learning_rate": 0.00015935937386767158,
      "loss": 0.1076,
      "step": 2805
    },
    {
      "epoch": 0.2033554371852013,
      "grad_norm": 1.0303089618682861,
      "learning_rate": 0.00015934488006377276,
      "loss": 0.0391,
      "step": 2806
    },
    {
      "epoch": 0.20342790883067,
      "grad_norm": 1.0520044565200806,
      "learning_rate": 0.00015933038625987392,
      "loss": 0.1078,
      "step": 2807
    },
    {
      "epoch": 0.20350038047613872,
      "grad_norm": 4.0746989250183105,
      "learning_rate": 0.00015931589245597508,
      "loss": 0.1137,
      "step": 2808
    },
    {
      "epoch": 0.20357285212160742,
      "grad_norm": 2.380768060684204,
      "learning_rate": 0.00015930139865207626,
      "loss": 0.1314,
      "step": 2809
    },
    {
      "epoch": 0.20364532376707614,
      "grad_norm": 2.3944883346557617,
      "learning_rate": 0.00015928690484817742,
      "loss": 0.0546,
      "step": 2810
    },
    {
      "epoch": 0.20371779541254484,
      "grad_norm": 1.740450382232666,
      "learning_rate": 0.00015927241104427857,
      "loss": 0.105,
      "step": 2811
    },
    {
      "epoch": 0.20379026705801356,
      "grad_norm": 1.1059094667434692,
      "learning_rate": 0.00015925791724037976,
      "loss": 0.0631,
      "step": 2812
    },
    {
      "epoch": 0.20386273870348226,
      "grad_norm": 2.6598145961761475,
      "learning_rate": 0.0001592434234364809,
      "loss": 0.1107,
      "step": 2813
    },
    {
      "epoch": 0.20393521034895098,
      "grad_norm": 1.2693580389022827,
      "learning_rate": 0.00015922892963258207,
      "loss": 0.0581,
      "step": 2814
    },
    {
      "epoch": 0.20400768199441968,
      "grad_norm": 2.2795755863189697,
      "learning_rate": 0.00015921443582868325,
      "loss": 0.1011,
      "step": 2815
    },
    {
      "epoch": 0.2040801536398884,
      "grad_norm": 1.3549537658691406,
      "learning_rate": 0.0001591999420247844,
      "loss": 0.0563,
      "step": 2816
    },
    {
      "epoch": 0.2041526252853571,
      "grad_norm": 1.5385196208953857,
      "learning_rate": 0.00015918544822088557,
      "loss": 0.0778,
      "step": 2817
    },
    {
      "epoch": 0.20422509693082583,
      "grad_norm": 1.8064074516296387,
      "learning_rate": 0.00015917095441698675,
      "loss": 0.077,
      "step": 2818
    },
    {
      "epoch": 0.20429756857629452,
      "grad_norm": 1.404837727546692,
      "learning_rate": 0.0001591564606130879,
      "loss": 0.0753,
      "step": 2819
    },
    {
      "epoch": 0.20437004022176322,
      "grad_norm": 1.3097834587097168,
      "learning_rate": 0.00015914196680918906,
      "loss": 0.0776,
      "step": 2820
    },
    {
      "epoch": 0.20444251186723195,
      "grad_norm": 2.9194300174713135,
      "learning_rate": 0.00015912747300529025,
      "loss": 0.1353,
      "step": 2821
    },
    {
      "epoch": 0.20451498351270064,
      "grad_norm": 2.1347672939300537,
      "learning_rate": 0.0001591129792013914,
      "loss": 0.2058,
      "step": 2822
    },
    {
      "epoch": 0.20458745515816937,
      "grad_norm": 1.9999333620071411,
      "learning_rate": 0.00015909848539749256,
      "loss": 0.0558,
      "step": 2823
    },
    {
      "epoch": 0.20465992680363806,
      "grad_norm": 1.0945473909378052,
      "learning_rate": 0.00015908399159359374,
      "loss": 0.0528,
      "step": 2824
    },
    {
      "epoch": 0.2047323984491068,
      "grad_norm": 4.4907989501953125,
      "learning_rate": 0.0001590694977896949,
      "loss": 0.1284,
      "step": 2825
    },
    {
      "epoch": 0.2048048700945755,
      "grad_norm": 2.2609572410583496,
      "learning_rate": 0.00015905500398579608,
      "loss": 0.0532,
      "step": 2826
    },
    {
      "epoch": 0.2048773417400442,
      "grad_norm": 1.9583046436309814,
      "learning_rate": 0.00015904051018189724,
      "loss": 0.1336,
      "step": 2827
    },
    {
      "epoch": 0.2049498133855129,
      "grad_norm": 3.8895211219787598,
      "learning_rate": 0.00015902601637799842,
      "loss": 0.0811,
      "step": 2828
    },
    {
      "epoch": 0.20502228503098163,
      "grad_norm": 1.490525484085083,
      "learning_rate": 0.00015901152257409958,
      "loss": 0.0748,
      "step": 2829
    },
    {
      "epoch": 0.20509475667645033,
      "grad_norm": 1.909142255783081,
      "learning_rate": 0.00015899702877020076,
      "loss": 0.1727,
      "step": 2830
    },
    {
      "epoch": 0.20516722832191905,
      "grad_norm": 1.2275725603103638,
      "learning_rate": 0.00015898253496630192,
      "loss": 0.04,
      "step": 2831
    },
    {
      "epoch": 0.20523969996738775,
      "grad_norm": 1.1257749795913696,
      "learning_rate": 0.00015896804116240308,
      "loss": 0.069,
      "step": 2832
    },
    {
      "epoch": 0.20531217161285648,
      "grad_norm": 0.7257430553436279,
      "learning_rate": 0.00015895354735850426,
      "loss": 0.0191,
      "step": 2833
    },
    {
      "epoch": 0.20538464325832517,
      "grad_norm": 4.093291282653809,
      "learning_rate": 0.00015893905355460542,
      "loss": 0.2077,
      "step": 2834
    },
    {
      "epoch": 0.2054571149037939,
      "grad_norm": 4.34489107131958,
      "learning_rate": 0.00015892455975070657,
      "loss": 0.1834,
      "step": 2835
    },
    {
      "epoch": 0.2055295865492626,
      "grad_norm": 3.0968596935272217,
      "learning_rate": 0.00015891006594680776,
      "loss": 0.0551,
      "step": 2836
    },
    {
      "epoch": 0.20560205819473132,
      "grad_norm": 2.0540575981140137,
      "learning_rate": 0.0001588955721429089,
      "loss": 0.0305,
      "step": 2837
    },
    {
      "epoch": 0.20567452984020002,
      "grad_norm": 1.6094863414764404,
      "learning_rate": 0.00015888107833901007,
      "loss": 0.0995,
      "step": 2838
    },
    {
      "epoch": 0.20574700148566874,
      "grad_norm": 1.5466946363449097,
      "learning_rate": 0.00015886658453511125,
      "loss": 0.0608,
      "step": 2839
    },
    {
      "epoch": 0.20581947313113744,
      "grad_norm": 2.7349865436553955,
      "learning_rate": 0.0001588520907312124,
      "loss": 0.0714,
      "step": 2840
    },
    {
      "epoch": 0.20589194477660616,
      "grad_norm": 0.6650992631912231,
      "learning_rate": 0.00015883759692731357,
      "loss": 0.0249,
      "step": 2841
    },
    {
      "epoch": 0.20596441642207486,
      "grad_norm": 1.7704858779907227,
      "learning_rate": 0.00015882310312341475,
      "loss": 0.1075,
      "step": 2842
    },
    {
      "epoch": 0.20603688806754358,
      "grad_norm": 4.31046724319458,
      "learning_rate": 0.0001588086093195159,
      "loss": 0.1467,
      "step": 2843
    },
    {
      "epoch": 0.20610935971301228,
      "grad_norm": 3.3637731075286865,
      "learning_rate": 0.0001587941155156171,
      "loss": 0.2072,
      "step": 2844
    },
    {
      "epoch": 0.206181831358481,
      "grad_norm": 3.684011697769165,
      "learning_rate": 0.00015877962171171825,
      "loss": 0.0554,
      "step": 2845
    },
    {
      "epoch": 0.2062543030039497,
      "grad_norm": 2.743952989578247,
      "learning_rate": 0.0001587651279078194,
      "loss": 0.1121,
      "step": 2846
    },
    {
      "epoch": 0.20632677464941843,
      "grad_norm": 1.62990403175354,
      "learning_rate": 0.00015875063410392059,
      "loss": 0.0824,
      "step": 2847
    },
    {
      "epoch": 0.20639924629488712,
      "grad_norm": 2.920090436935425,
      "learning_rate": 0.00015873614030002174,
      "loss": 0.0936,
      "step": 2848
    },
    {
      "epoch": 0.20647171794035585,
      "grad_norm": 1.2413395643234253,
      "learning_rate": 0.0001587216464961229,
      "loss": 0.1014,
      "step": 2849
    },
    {
      "epoch": 0.20654418958582454,
      "grad_norm": 2.4398787021636963,
      "learning_rate": 0.00015870715269222408,
      "loss": 0.1486,
      "step": 2850
    },
    {
      "epoch": 0.20661666123129327,
      "grad_norm": 1.355694055557251,
      "learning_rate": 0.00015869265888832524,
      "loss": 0.0773,
      "step": 2851
    },
    {
      "epoch": 0.20668913287676197,
      "grad_norm": 2.811439037322998,
      "learning_rate": 0.00015867816508442642,
      "loss": 0.206,
      "step": 2852
    },
    {
      "epoch": 0.2067616045222307,
      "grad_norm": 2.2448155879974365,
      "learning_rate": 0.0001586636712805276,
      "loss": 0.0686,
      "step": 2853
    },
    {
      "epoch": 0.2068340761676994,
      "grad_norm": 3.0190351009368896,
      "learning_rate": 0.00015864917747662876,
      "loss": 0.101,
      "step": 2854
    },
    {
      "epoch": 0.20690654781316808,
      "grad_norm": 2.971475124359131,
      "learning_rate": 0.00015863468367272992,
      "loss": 0.0963,
      "step": 2855
    },
    {
      "epoch": 0.2069790194586368,
      "grad_norm": 5.92365837097168,
      "learning_rate": 0.0001586201898688311,
      "loss": 0.1059,
      "step": 2856
    },
    {
      "epoch": 0.2070514911041055,
      "grad_norm": 2.1132378578186035,
      "learning_rate": 0.00015860569606493226,
      "loss": 0.1379,
      "step": 2857
    },
    {
      "epoch": 0.20712396274957423,
      "grad_norm": 1.058985948562622,
      "learning_rate": 0.00015859120226103342,
      "loss": 0.0542,
      "step": 2858
    },
    {
      "epoch": 0.20719643439504293,
      "grad_norm": 2.9222493171691895,
      "learning_rate": 0.0001585767084571346,
      "loss": 0.1401,
      "step": 2859
    },
    {
      "epoch": 0.20726890604051165,
      "grad_norm": 2.292975902557373,
      "learning_rate": 0.00015856221465323576,
      "loss": 0.1241,
      "step": 2860
    },
    {
      "epoch": 0.20734137768598035,
      "grad_norm": 1.6673074960708618,
      "learning_rate": 0.0001585477208493369,
      "loss": 0.059,
      "step": 2861
    },
    {
      "epoch": 0.20741384933144907,
      "grad_norm": 1.0890017747879028,
      "learning_rate": 0.0001585332270454381,
      "loss": 0.0419,
      "step": 2862
    },
    {
      "epoch": 0.20748632097691777,
      "grad_norm": 4.526172161102295,
      "learning_rate": 0.00015851873324153925,
      "loss": 0.1141,
      "step": 2863
    },
    {
      "epoch": 0.2075587926223865,
      "grad_norm": 1.194868564605713,
      "learning_rate": 0.0001585042394376404,
      "loss": 0.0958,
      "step": 2864
    },
    {
      "epoch": 0.2076312642678552,
      "grad_norm": 3.218142509460449,
      "learning_rate": 0.0001584897456337416,
      "loss": 0.0908,
      "step": 2865
    },
    {
      "epoch": 0.20770373591332392,
      "grad_norm": 1.9955195188522339,
      "learning_rate": 0.00015847525182984275,
      "loss": 0.1047,
      "step": 2866
    },
    {
      "epoch": 0.2077762075587926,
      "grad_norm": 3.7732298374176025,
      "learning_rate": 0.0001584607580259439,
      "loss": 0.0867,
      "step": 2867
    },
    {
      "epoch": 0.20784867920426134,
      "grad_norm": 4.254472255706787,
      "learning_rate": 0.0001584462642220451,
      "loss": 0.1348,
      "step": 2868
    },
    {
      "epoch": 0.20792115084973004,
      "grad_norm": 2.8939802646636963,
      "learning_rate": 0.00015843177041814625,
      "loss": 0.0555,
      "step": 2869
    },
    {
      "epoch": 0.20799362249519876,
      "grad_norm": 4.272907257080078,
      "learning_rate": 0.0001584172766142474,
      "loss": 0.0438,
      "step": 2870
    },
    {
      "epoch": 0.20806609414066746,
      "grad_norm": 6.055713653564453,
      "learning_rate": 0.00015840278281034859,
      "loss": 0.0738,
      "step": 2871
    },
    {
      "epoch": 0.20813856578613618,
      "grad_norm": 1.47435462474823,
      "learning_rate": 0.00015838828900644974,
      "loss": 0.126,
      "step": 2872
    },
    {
      "epoch": 0.20821103743160488,
      "grad_norm": 0.2583642601966858,
      "learning_rate": 0.00015837379520255093,
      "loss": 0.0088,
      "step": 2873
    },
    {
      "epoch": 0.2082835090770736,
      "grad_norm": 4.08015251159668,
      "learning_rate": 0.00015835930139865208,
      "loss": 0.1668,
      "step": 2874
    },
    {
      "epoch": 0.2083559807225423,
      "grad_norm": 2.4045684337615967,
      "learning_rate": 0.00015834480759475327,
      "loss": 0.0964,
      "step": 2875
    },
    {
      "epoch": 0.20842845236801102,
      "grad_norm": 1.412386417388916,
      "learning_rate": 0.00015833031379085442,
      "loss": 0.049,
      "step": 2876
    },
    {
      "epoch": 0.20850092401347972,
      "grad_norm": 4.658693790435791,
      "learning_rate": 0.0001583158199869556,
      "loss": 0.1568,
      "step": 2877
    },
    {
      "epoch": 0.20857339565894845,
      "grad_norm": 1.3373661041259766,
      "learning_rate": 0.00015830132618305676,
      "loss": 0.0837,
      "step": 2878
    },
    {
      "epoch": 0.20864586730441714,
      "grad_norm": 0.7979799509048462,
      "learning_rate": 0.00015828683237915792,
      "loss": 0.0351,
      "step": 2879
    },
    {
      "epoch": 0.20871833894988587,
      "grad_norm": 0.8391203880310059,
      "learning_rate": 0.0001582723385752591,
      "loss": 0.0608,
      "step": 2880
    },
    {
      "epoch": 0.20879081059535456,
      "grad_norm": 1.8332692384719849,
      "learning_rate": 0.00015825784477136026,
      "loss": 0.0281,
      "step": 2881
    },
    {
      "epoch": 0.2088632822408233,
      "grad_norm": 2.237056016921997,
      "learning_rate": 0.00015824335096746142,
      "loss": 0.1169,
      "step": 2882
    },
    {
      "epoch": 0.20893575388629199,
      "grad_norm": 1.107372760772705,
      "learning_rate": 0.0001582288571635626,
      "loss": 0.0483,
      "step": 2883
    },
    {
      "epoch": 0.2090082255317607,
      "grad_norm": 1.4400043487548828,
      "learning_rate": 0.00015821436335966376,
      "loss": 0.0345,
      "step": 2884
    },
    {
      "epoch": 0.2090806971772294,
      "grad_norm": 3.898325204849243,
      "learning_rate": 0.0001581998695557649,
      "loss": 0.0825,
      "step": 2885
    },
    {
      "epoch": 0.20915316882269813,
      "grad_norm": 0.8708648085594177,
      "learning_rate": 0.0001581853757518661,
      "loss": 0.075,
      "step": 2886
    },
    {
      "epoch": 0.20922564046816683,
      "grad_norm": 3.9887194633483887,
      "learning_rate": 0.00015817088194796725,
      "loss": 0.0509,
      "step": 2887
    },
    {
      "epoch": 0.20929811211363555,
      "grad_norm": 2.8573172092437744,
      "learning_rate": 0.0001581563881440684,
      "loss": 0.1487,
      "step": 2888
    },
    {
      "epoch": 0.20937058375910425,
      "grad_norm": 5.674430847167969,
      "learning_rate": 0.0001581418943401696,
      "loss": 0.3601,
      "step": 2889
    },
    {
      "epoch": 0.20944305540457295,
      "grad_norm": 1.9679539203643799,
      "learning_rate": 0.00015812740053627075,
      "loss": 0.0664,
      "step": 2890
    },
    {
      "epoch": 0.20951552705004167,
      "grad_norm": 2.2107858657836914,
      "learning_rate": 0.0001581129067323719,
      "loss": 0.0827,
      "step": 2891
    },
    {
      "epoch": 0.20958799869551037,
      "grad_norm": 4.424962043762207,
      "learning_rate": 0.0001580984129284731,
      "loss": 0.1043,
      "step": 2892
    },
    {
      "epoch": 0.2096604703409791,
      "grad_norm": 1.2630677223205566,
      "learning_rate": 0.00015808391912457424,
      "loss": 0.0398,
      "step": 2893
    },
    {
      "epoch": 0.2097329419864478,
      "grad_norm": 2.073007345199585,
      "learning_rate": 0.0001580694253206754,
      "loss": 0.0762,
      "step": 2894
    },
    {
      "epoch": 0.20980541363191652,
      "grad_norm": 4.476803302764893,
      "learning_rate": 0.00015805493151677658,
      "loss": 0.1266,
      "step": 2895
    },
    {
      "epoch": 0.2098778852773852,
      "grad_norm": 0.9081141352653503,
      "learning_rate": 0.00015804043771287774,
      "loss": 0.0206,
      "step": 2896
    },
    {
      "epoch": 0.20995035692285394,
      "grad_norm": 5.163712501525879,
      "learning_rate": 0.00015802594390897892,
      "loss": 0.0934,
      "step": 2897
    },
    {
      "epoch": 0.21002282856832263,
      "grad_norm": 3.834184169769287,
      "learning_rate": 0.00015801145010508008,
      "loss": 0.1607,
      "step": 2898
    },
    {
      "epoch": 0.21009530021379136,
      "grad_norm": 5.334266185760498,
      "learning_rate": 0.00015799695630118127,
      "loss": 0.0563,
      "step": 2899
    },
    {
      "epoch": 0.21016777185926006,
      "grad_norm": 2.6405858993530273,
      "learning_rate": 0.00015798246249728242,
      "loss": 0.1002,
      "step": 2900
    },
    {
      "epoch": 0.21024024350472878,
      "grad_norm": 1.584033727645874,
      "learning_rate": 0.0001579679686933836,
      "loss": 0.0912,
      "step": 2901
    },
    {
      "epoch": 0.21031271515019748,
      "grad_norm": 1.626220703125,
      "learning_rate": 0.00015795347488948476,
      "loss": 0.0406,
      "step": 2902
    },
    {
      "epoch": 0.2103851867956662,
      "grad_norm": 1.188591480255127,
      "learning_rate": 0.00015793898108558592,
      "loss": 0.1059,
      "step": 2903
    },
    {
      "epoch": 0.2104576584411349,
      "grad_norm": 0.5258035063743591,
      "learning_rate": 0.0001579244872816871,
      "loss": 0.0124,
      "step": 2904
    },
    {
      "epoch": 0.21053013008660362,
      "grad_norm": 3.9948644638061523,
      "learning_rate": 0.00015790999347778826,
      "loss": 0.201,
      "step": 2905
    },
    {
      "epoch": 0.21060260173207232,
      "grad_norm": 1.5282962322235107,
      "learning_rate": 0.00015789549967388941,
      "loss": 0.0959,
      "step": 2906
    },
    {
      "epoch": 0.21067507337754104,
      "grad_norm": 1.0618623495101929,
      "learning_rate": 0.0001578810058699906,
      "loss": 0.0483,
      "step": 2907
    },
    {
      "epoch": 0.21074754502300974,
      "grad_norm": 0.9312400817871094,
      "learning_rate": 0.00015786651206609175,
      "loss": 0.0195,
      "step": 2908
    },
    {
      "epoch": 0.21082001666847847,
      "grad_norm": 1.1783390045166016,
      "learning_rate": 0.0001578520182621929,
      "loss": 0.0528,
      "step": 2909
    },
    {
      "epoch": 0.21089248831394716,
      "grad_norm": 1.5929982662200928,
      "learning_rate": 0.0001578375244582941,
      "loss": 0.1041,
      "step": 2910
    },
    {
      "epoch": 0.2109649599594159,
      "grad_norm": 3.0139851570129395,
      "learning_rate": 0.00015782303065439525,
      "loss": 0.1131,
      "step": 2911
    },
    {
      "epoch": 0.21103743160488458,
      "grad_norm": 1.1630733013153076,
      "learning_rate": 0.0001578085368504964,
      "loss": 0.0271,
      "step": 2912
    },
    {
      "epoch": 0.2111099032503533,
      "grad_norm": 2.1100351810455322,
      "learning_rate": 0.0001577940430465976,
      "loss": 0.1386,
      "step": 2913
    },
    {
      "epoch": 0.211182374895822,
      "grad_norm": 0.8518227934837341,
      "learning_rate": 0.00015777954924269875,
      "loss": 0.0196,
      "step": 2914
    },
    {
      "epoch": 0.21125484654129073,
      "grad_norm": 2.6924917697906494,
      "learning_rate": 0.0001577650554387999,
      "loss": 0.0917,
      "step": 2915
    },
    {
      "epoch": 0.21132731818675943,
      "grad_norm": 1.877312183380127,
      "learning_rate": 0.0001577505616349011,
      "loss": 0.0742,
      "step": 2916
    },
    {
      "epoch": 0.21139978983222815,
      "grad_norm": 3.2644309997558594,
      "learning_rate": 0.00015773606783100224,
      "loss": 0.0621,
      "step": 2917
    },
    {
      "epoch": 0.21147226147769685,
      "grad_norm": 1.1499234437942505,
      "learning_rate": 0.0001577215740271034,
      "loss": 0.055,
      "step": 2918
    },
    {
      "epoch": 0.21154473312316557,
      "grad_norm": 0.7193717360496521,
      "learning_rate": 0.00015770708022320458,
      "loss": 0.0215,
      "step": 2919
    },
    {
      "epoch": 0.21161720476863427,
      "grad_norm": 0.5081852674484253,
      "learning_rate": 0.00015769258641930574,
      "loss": 0.0337,
      "step": 2920
    },
    {
      "epoch": 0.211689676414103,
      "grad_norm": 2.5974438190460205,
      "learning_rate": 0.00015767809261540692,
      "loss": 0.0944,
      "step": 2921
    },
    {
      "epoch": 0.2117621480595717,
      "grad_norm": 1.1284875869750977,
      "learning_rate": 0.0001576635988115081,
      "loss": 0.0661,
      "step": 2922
    },
    {
      "epoch": 0.21183461970504042,
      "grad_norm": 2.786259412765503,
      "learning_rate": 0.00015764910500760926,
      "loss": 0.1393,
      "step": 2923
    },
    {
      "epoch": 0.2119070913505091,
      "grad_norm": 1.3431177139282227,
      "learning_rate": 0.00015763461120371042,
      "loss": 0.0618,
      "step": 2924
    },
    {
      "epoch": 0.2119795629959778,
      "grad_norm": 3.6408591270446777,
      "learning_rate": 0.0001576201173998116,
      "loss": 0.1738,
      "step": 2925
    },
    {
      "epoch": 0.21205203464144654,
      "grad_norm": 6.067451000213623,
      "learning_rate": 0.00015760562359591276,
      "loss": 0.2316,
      "step": 2926
    },
    {
      "epoch": 0.21212450628691523,
      "grad_norm": 3.0092897415161133,
      "learning_rate": 0.00015759112979201392,
      "loss": 0.188,
      "step": 2927
    },
    {
      "epoch": 0.21219697793238396,
      "grad_norm": 2.687748908996582,
      "learning_rate": 0.0001575766359881151,
      "loss": 0.0647,
      "step": 2928
    },
    {
      "epoch": 0.21226944957785265,
      "grad_norm": 2.218264579772949,
      "learning_rate": 0.00015756214218421626,
      "loss": 0.0729,
      "step": 2929
    },
    {
      "epoch": 0.21234192122332138,
      "grad_norm": 6.127944469451904,
      "learning_rate": 0.00015754764838031741,
      "loss": 0.2739,
      "step": 2930
    },
    {
      "epoch": 0.21241439286879008,
      "grad_norm": 1.5773626565933228,
      "learning_rate": 0.0001575331545764186,
      "loss": 0.0781,
      "step": 2931
    },
    {
      "epoch": 0.2124868645142588,
      "grad_norm": 0.750851035118103,
      "learning_rate": 0.00015751866077251975,
      "loss": 0.0196,
      "step": 2932
    },
    {
      "epoch": 0.2125593361597275,
      "grad_norm": 0.866067111492157,
      "learning_rate": 0.0001575041669686209,
      "loss": 0.046,
      "step": 2933
    },
    {
      "epoch": 0.21263180780519622,
      "grad_norm": 1.5677803754806519,
      "learning_rate": 0.0001574896731647221,
      "loss": 0.0668,
      "step": 2934
    },
    {
      "epoch": 0.21270427945066492,
      "grad_norm": 1.4187365770339966,
      "learning_rate": 0.00015747517936082325,
      "loss": 0.0677,
      "step": 2935
    },
    {
      "epoch": 0.21277675109613364,
      "grad_norm": 1.525634765625,
      "learning_rate": 0.0001574606855569244,
      "loss": 0.1531,
      "step": 2936
    },
    {
      "epoch": 0.21284922274160234,
      "grad_norm": 0.8679868578910828,
      "learning_rate": 0.0001574461917530256,
      "loss": 0.0292,
      "step": 2937
    },
    {
      "epoch": 0.21292169438707106,
      "grad_norm": 2.764178991317749,
      "learning_rate": 0.00015743169794912675,
      "loss": 0.0491,
      "step": 2938
    },
    {
      "epoch": 0.21299416603253976,
      "grad_norm": 1.2364681959152222,
      "learning_rate": 0.0001574172041452279,
      "loss": 0.0924,
      "step": 2939
    },
    {
      "epoch": 0.21306663767800849,
      "grad_norm": 1.8836385011672974,
      "learning_rate": 0.0001574027103413291,
      "loss": 0.0975,
      "step": 2940
    },
    {
      "epoch": 0.21313910932347718,
      "grad_norm": 2.9785006046295166,
      "learning_rate": 0.00015738821653743024,
      "loss": 0.1872,
      "step": 2941
    },
    {
      "epoch": 0.2132115809689459,
      "grad_norm": 2.5517399311065674,
      "learning_rate": 0.00015737372273353143,
      "loss": 0.0998,
      "step": 2942
    },
    {
      "epoch": 0.2132840526144146,
      "grad_norm": 1.3518553972244263,
      "learning_rate": 0.00015735922892963258,
      "loss": 0.0872,
      "step": 2943
    },
    {
      "epoch": 0.21335652425988333,
      "grad_norm": 1.6289819478988647,
      "learning_rate": 0.00015734473512573377,
      "loss": 0.092,
      "step": 2944
    },
    {
      "epoch": 0.21342899590535203,
      "grad_norm": 2.642578363418579,
      "learning_rate": 0.00015733024132183492,
      "loss": 0.0868,
      "step": 2945
    },
    {
      "epoch": 0.21350146755082075,
      "grad_norm": 4.067943572998047,
      "learning_rate": 0.0001573157475179361,
      "loss": 0.1788,
      "step": 2946
    },
    {
      "epoch": 0.21357393919628945,
      "grad_norm": 1.4193710088729858,
      "learning_rate": 0.00015730125371403726,
      "loss": 0.0581,
      "step": 2947
    },
    {
      "epoch": 0.21364641084175817,
      "grad_norm": 5.415647983551025,
      "learning_rate": 0.00015728675991013842,
      "loss": 0.1591,
      "step": 2948
    },
    {
      "epoch": 0.21371888248722687,
      "grad_norm": 0.4581931531429291,
      "learning_rate": 0.0001572722661062396,
      "loss": 0.019,
      "step": 2949
    },
    {
      "epoch": 0.2137913541326956,
      "grad_norm": 1.4881184101104736,
      "learning_rate": 0.00015725777230234076,
      "loss": 0.0583,
      "step": 2950
    },
    {
      "epoch": 0.2138638257781643,
      "grad_norm": 1.7396180629730225,
      "learning_rate": 0.00015724327849844192,
      "loss": 0.0901,
      "step": 2951
    },
    {
      "epoch": 0.21393629742363302,
      "grad_norm": 1.5852609872817993,
      "learning_rate": 0.0001572287846945431,
      "loss": 0.0893,
      "step": 2952
    },
    {
      "epoch": 0.2140087690691017,
      "grad_norm": 1.2495380640029907,
      "learning_rate": 0.00015721429089064426,
      "loss": 0.0613,
      "step": 2953
    },
    {
      "epoch": 0.21408124071457044,
      "grad_norm": 3.2614834308624268,
      "learning_rate": 0.00015719979708674541,
      "loss": 0.0502,
      "step": 2954
    },
    {
      "epoch": 0.21415371236003913,
      "grad_norm": 1.2913122177124023,
      "learning_rate": 0.0001571853032828466,
      "loss": 0.0665,
      "step": 2955
    },
    {
      "epoch": 0.21422618400550786,
      "grad_norm": 7.152415752410889,
      "learning_rate": 0.00015717080947894775,
      "loss": 0.1419,
      "step": 2956
    },
    {
      "epoch": 0.21429865565097655,
      "grad_norm": 4.871576309204102,
      "learning_rate": 0.0001571563156750489,
      "loss": 0.0619,
      "step": 2957
    },
    {
      "epoch": 0.21437112729644528,
      "grad_norm": 4.096548557281494,
      "learning_rate": 0.0001571418218711501,
      "loss": 0.1141,
      "step": 2958
    },
    {
      "epoch": 0.21444359894191398,
      "grad_norm": 1.5153812170028687,
      "learning_rate": 0.00015712732806725125,
      "loss": 0.0836,
      "step": 2959
    },
    {
      "epoch": 0.21451607058738267,
      "grad_norm": 2.920606851577759,
      "learning_rate": 0.0001571128342633524,
      "loss": 0.0896,
      "step": 2960
    },
    {
      "epoch": 0.2145885422328514,
      "grad_norm": 1.4597030878067017,
      "learning_rate": 0.0001570983404594536,
      "loss": 0.0943,
      "step": 2961
    },
    {
      "epoch": 0.2146610138783201,
      "grad_norm": 7.528316497802734,
      "learning_rate": 0.00015708384665555475,
      "loss": 0.2025,
      "step": 2962
    },
    {
      "epoch": 0.21473348552378882,
      "grad_norm": 4.56641960144043,
      "learning_rate": 0.0001570693528516559,
      "loss": 0.148,
      "step": 2963
    },
    {
      "epoch": 0.21480595716925752,
      "grad_norm": 1.0408990383148193,
      "learning_rate": 0.0001570548590477571,
      "loss": 0.0329,
      "step": 2964
    },
    {
      "epoch": 0.21487842881472624,
      "grad_norm": 4.716458320617676,
      "learning_rate": 0.00015704036524385824,
      "loss": 0.1058,
      "step": 2965
    },
    {
      "epoch": 0.21495090046019494,
      "grad_norm": 6.107815742492676,
      "learning_rate": 0.00015702587143995943,
      "loss": 0.2801,
      "step": 2966
    },
    {
      "epoch": 0.21502337210566366,
      "grad_norm": 0.8721784353256226,
      "learning_rate": 0.00015701137763606058,
      "loss": 0.0282,
      "step": 2967
    },
    {
      "epoch": 0.21509584375113236,
      "grad_norm": 4.246519088745117,
      "learning_rate": 0.00015699688383216177,
      "loss": 0.1477,
      "step": 2968
    },
    {
      "epoch": 0.21516831539660108,
      "grad_norm": 2.6705679893493652,
      "learning_rate": 0.00015698239002826292,
      "loss": 0.0777,
      "step": 2969
    },
    {
      "epoch": 0.21524078704206978,
      "grad_norm": 8.341449737548828,
      "learning_rate": 0.0001569678962243641,
      "loss": 0.1072,
      "step": 2970
    },
    {
      "epoch": 0.2153132586875385,
      "grad_norm": 3.8585498332977295,
      "learning_rate": 0.00015695340242046526,
      "loss": 0.1782,
      "step": 2971
    },
    {
      "epoch": 0.2153857303330072,
      "grad_norm": 2.3288333415985107,
      "learning_rate": 0.00015693890861656642,
      "loss": 0.0798,
      "step": 2972
    },
    {
      "epoch": 0.21545820197847593,
      "grad_norm": 2.4566876888275146,
      "learning_rate": 0.0001569244148126676,
      "loss": 0.188,
      "step": 2973
    },
    {
      "epoch": 0.21553067362394462,
      "grad_norm": 1.465632677078247,
      "learning_rate": 0.00015690992100876876,
      "loss": 0.1424,
      "step": 2974
    },
    {
      "epoch": 0.21560314526941335,
      "grad_norm": 0.8347660899162292,
      "learning_rate": 0.00015689542720486992,
      "loss": 0.0627,
      "step": 2975
    },
    {
      "epoch": 0.21567561691488205,
      "grad_norm": 0.5469751358032227,
      "learning_rate": 0.0001568809334009711,
      "loss": 0.0167,
      "step": 2976
    },
    {
      "epoch": 0.21574808856035077,
      "grad_norm": 4.904584884643555,
      "learning_rate": 0.00015686643959707226,
      "loss": 0.1918,
      "step": 2977
    },
    {
      "epoch": 0.21582056020581947,
      "grad_norm": 1.262831449508667,
      "learning_rate": 0.0001568519457931734,
      "loss": 0.0704,
      "step": 2978
    },
    {
      "epoch": 0.2158930318512882,
      "grad_norm": 3.8699185848236084,
      "learning_rate": 0.0001568374519892746,
      "loss": 0.0276,
      "step": 2979
    },
    {
      "epoch": 0.2159655034967569,
      "grad_norm": 1.718902587890625,
      "learning_rate": 0.00015682295818537575,
      "loss": 0.1049,
      "step": 2980
    },
    {
      "epoch": 0.2160379751422256,
      "grad_norm": 5.144228935241699,
      "learning_rate": 0.0001568084643814769,
      "loss": 0.0746,
      "step": 2981
    },
    {
      "epoch": 0.2161104467876943,
      "grad_norm": 1.5188530683517456,
      "learning_rate": 0.0001567939705775781,
      "loss": 0.1522,
      "step": 2982
    },
    {
      "epoch": 0.21618291843316303,
      "grad_norm": 4.288470268249512,
      "learning_rate": 0.00015677947677367925,
      "loss": 0.3143,
      "step": 2983
    },
    {
      "epoch": 0.21625539007863173,
      "grad_norm": 1.3268145322799683,
      "learning_rate": 0.0001567649829697804,
      "loss": 0.0632,
      "step": 2984
    },
    {
      "epoch": 0.21632786172410046,
      "grad_norm": 3.502814769744873,
      "learning_rate": 0.0001567504891658816,
      "loss": 0.1177,
      "step": 2985
    },
    {
      "epoch": 0.21640033336956915,
      "grad_norm": 2.7578542232513428,
      "learning_rate": 0.00015673599536198275,
      "loss": 0.064,
      "step": 2986
    },
    {
      "epoch": 0.21647280501503788,
      "grad_norm": 1.265061616897583,
      "learning_rate": 0.0001567215015580839,
      "loss": 0.0623,
      "step": 2987
    },
    {
      "epoch": 0.21654527666050657,
      "grad_norm": 1.935315489768982,
      "learning_rate": 0.0001567070077541851,
      "loss": 0.1001,
      "step": 2988
    },
    {
      "epoch": 0.2166177483059753,
      "grad_norm": 1.2486999034881592,
      "learning_rate": 0.00015669251395028627,
      "loss": 0.0411,
      "step": 2989
    },
    {
      "epoch": 0.216690219951444,
      "grad_norm": 3.225630521774292,
      "learning_rate": 0.00015667802014638743,
      "loss": 0.0866,
      "step": 2990
    },
    {
      "epoch": 0.21676269159691272,
      "grad_norm": 1.8244872093200684,
      "learning_rate": 0.0001566635263424886,
      "loss": 0.0926,
      "step": 2991
    },
    {
      "epoch": 0.21683516324238142,
      "grad_norm": 1.92142653465271,
      "learning_rate": 0.00015664903253858977,
      "loss": 0.0333,
      "step": 2992
    },
    {
      "epoch": 0.21690763488785011,
      "grad_norm": 2.9313480854034424,
      "learning_rate": 0.00015663453873469092,
      "loss": 0.1015,
      "step": 2993
    },
    {
      "epoch": 0.21698010653331884,
      "grad_norm": 3.205587148666382,
      "learning_rate": 0.0001566200449307921,
      "loss": 0.0578,
      "step": 2994
    },
    {
      "epoch": 0.21705257817878754,
      "grad_norm": 2.0100998878479004,
      "learning_rate": 0.00015660555112689326,
      "loss": 0.1256,
      "step": 2995
    },
    {
      "epoch": 0.21712504982425626,
      "grad_norm": 1.3534871339797974,
      "learning_rate": 0.00015659105732299442,
      "loss": 0.1064,
      "step": 2996
    },
    {
      "epoch": 0.21719752146972496,
      "grad_norm": 1.7638052701950073,
      "learning_rate": 0.0001565765635190956,
      "loss": 0.0525,
      "step": 2997
    },
    {
      "epoch": 0.21726999311519368,
      "grad_norm": 2.196364641189575,
      "learning_rate": 0.00015656206971519676,
      "loss": 0.1055,
      "step": 2998
    },
    {
      "epoch": 0.21734246476066238,
      "grad_norm": 3.4061391353607178,
      "learning_rate": 0.00015654757591129792,
      "loss": 0.1044,
      "step": 2999
    },
    {
      "epoch": 0.2174149364061311,
      "grad_norm": 1.9145100116729736,
      "learning_rate": 0.0001565330821073991,
      "loss": 0.1185,
      "step": 3000
    },
    {
      "epoch": 0.2174874080515998,
      "grad_norm": 1.4163048267364502,
      "learning_rate": 0.00015651858830350026,
      "loss": 0.0661,
      "step": 3001
    },
    {
      "epoch": 0.21755987969706853,
      "grad_norm": 1.3172016143798828,
      "learning_rate": 0.0001565040944996014,
      "loss": 0.0492,
      "step": 3002
    },
    {
      "epoch": 0.21763235134253722,
      "grad_norm": 5.175261974334717,
      "learning_rate": 0.0001564896006957026,
      "loss": 0.0808,
      "step": 3003
    },
    {
      "epoch": 0.21770482298800595,
      "grad_norm": 1.0928833484649658,
      "learning_rate": 0.00015647510689180375,
      "loss": 0.038,
      "step": 3004
    },
    {
      "epoch": 0.21777729463347464,
      "grad_norm": 8.21975040435791,
      "learning_rate": 0.00015646061308790494,
      "loss": 0.1859,
      "step": 3005
    },
    {
      "epoch": 0.21784976627894337,
      "grad_norm": 4.152621269226074,
      "learning_rate": 0.0001564461192840061,
      "loss": 0.0997,
      "step": 3006
    },
    {
      "epoch": 0.21792223792441207,
      "grad_norm": 1.0737648010253906,
      "learning_rate": 0.00015643162548010725,
      "loss": 0.0531,
      "step": 3007
    },
    {
      "epoch": 0.2179947095698808,
      "grad_norm": 2.3897125720977783,
      "learning_rate": 0.00015641713167620843,
      "loss": 0.0931,
      "step": 3008
    },
    {
      "epoch": 0.2180671812153495,
      "grad_norm": 1.8240374326705933,
      "learning_rate": 0.0001564026378723096,
      "loss": 0.1252,
      "step": 3009
    },
    {
      "epoch": 0.2181396528608182,
      "grad_norm": 4.243017196655273,
      "learning_rate": 0.00015638814406841075,
      "loss": 0.1527,
      "step": 3010
    },
    {
      "epoch": 0.2182121245062869,
      "grad_norm": 2.806129217147827,
      "learning_rate": 0.00015637365026451193,
      "loss": 0.1258,
      "step": 3011
    },
    {
      "epoch": 0.21828459615175563,
      "grad_norm": 0.8135555386543274,
      "learning_rate": 0.00015635915646061309,
      "loss": 0.0696,
      "step": 3012
    },
    {
      "epoch": 0.21835706779722433,
      "grad_norm": 2.2379887104034424,
      "learning_rate": 0.00015634466265671427,
      "loss": 0.1019,
      "step": 3013
    },
    {
      "epoch": 0.21842953944269305,
      "grad_norm": 4.0004119873046875,
      "learning_rate": 0.00015633016885281543,
      "loss": 0.1753,
      "step": 3014
    },
    {
      "epoch": 0.21850201108816175,
      "grad_norm": 2.6146655082702637,
      "learning_rate": 0.0001563156750489166,
      "loss": 0.1552,
      "step": 3015
    },
    {
      "epoch": 0.21857448273363048,
      "grad_norm": 3.6382596492767334,
      "learning_rate": 0.00015630118124501777,
      "loss": 0.1406,
      "step": 3016
    },
    {
      "epoch": 0.21864695437909917,
      "grad_norm": 0.9182126522064209,
      "learning_rate": 0.00015628668744111895,
      "loss": 0.0394,
      "step": 3017
    },
    {
      "epoch": 0.2187194260245679,
      "grad_norm": 1.8400650024414062,
      "learning_rate": 0.0001562721936372201,
      "loss": 0.0363,
      "step": 3018
    },
    {
      "epoch": 0.2187918976700366,
      "grad_norm": 1.6332452297210693,
      "learning_rate": 0.00015625769983332126,
      "loss": 0.0279,
      "step": 3019
    },
    {
      "epoch": 0.21886436931550532,
      "grad_norm": 2.0746121406555176,
      "learning_rate": 0.00015624320602942245,
      "loss": 0.1012,
      "step": 3020
    },
    {
      "epoch": 0.21893684096097402,
      "grad_norm": 2.31203031539917,
      "learning_rate": 0.0001562287122255236,
      "loss": 0.1532,
      "step": 3021
    },
    {
      "epoch": 0.21900931260644274,
      "grad_norm": 1.0502660274505615,
      "learning_rate": 0.00015621421842162476,
      "loss": 0.1029,
      "step": 3022
    },
    {
      "epoch": 0.21908178425191144,
      "grad_norm": 1.7958874702453613,
      "learning_rate": 0.00015619972461772594,
      "loss": 0.0521,
      "step": 3023
    },
    {
      "epoch": 0.21915425589738016,
      "grad_norm": 3.2685136795043945,
      "learning_rate": 0.0001561852308138271,
      "loss": 0.2678,
      "step": 3024
    },
    {
      "epoch": 0.21922672754284886,
      "grad_norm": 2.580242156982422,
      "learning_rate": 0.00015617073700992826,
      "loss": 0.1126,
      "step": 3025
    },
    {
      "epoch": 0.21929919918831758,
      "grad_norm": 0.9682989716529846,
      "learning_rate": 0.00015615624320602944,
      "loss": 0.0379,
      "step": 3026
    },
    {
      "epoch": 0.21937167083378628,
      "grad_norm": 1.1929779052734375,
      "learning_rate": 0.0001561417494021306,
      "loss": 0.0794,
      "step": 3027
    },
    {
      "epoch": 0.21944414247925498,
      "grad_norm": 1.83673894405365,
      "learning_rate": 0.00015612725559823175,
      "loss": 0.0581,
      "step": 3028
    },
    {
      "epoch": 0.2195166141247237,
      "grad_norm": 3.489069938659668,
      "learning_rate": 0.00015611276179433294,
      "loss": 0.2306,
      "step": 3029
    },
    {
      "epoch": 0.2195890857701924,
      "grad_norm": 1.2386285066604614,
      "learning_rate": 0.0001560982679904341,
      "loss": 0.0753,
      "step": 3030
    },
    {
      "epoch": 0.21966155741566112,
      "grad_norm": 3.885843276977539,
      "learning_rate": 0.00015608377418653525,
      "loss": 0.1424,
      "step": 3031
    },
    {
      "epoch": 0.21973402906112982,
      "grad_norm": 0.751436710357666,
      "learning_rate": 0.00015606928038263643,
      "loss": 0.0419,
      "step": 3032
    },
    {
      "epoch": 0.21980650070659855,
      "grad_norm": 0.5958542227745056,
      "learning_rate": 0.0001560547865787376,
      "loss": 0.0246,
      "step": 3033
    },
    {
      "epoch": 0.21987897235206724,
      "grad_norm": 2.021294593811035,
      "learning_rate": 0.00015604029277483875,
      "loss": 0.1381,
      "step": 3034
    },
    {
      "epoch": 0.21995144399753597,
      "grad_norm": 0.9725141525268555,
      "learning_rate": 0.00015602579897093993,
      "loss": 0.0256,
      "step": 3035
    },
    {
      "epoch": 0.22002391564300466,
      "grad_norm": 1.3200687170028687,
      "learning_rate": 0.0001560113051670411,
      "loss": 0.0531,
      "step": 3036
    },
    {
      "epoch": 0.2200963872884734,
      "grad_norm": 1.9036188125610352,
      "learning_rate": 0.00015599681136314227,
      "loss": 0.1082,
      "step": 3037
    },
    {
      "epoch": 0.22016885893394209,
      "grad_norm": 0.8793178200721741,
      "learning_rate": 0.00015598231755924345,
      "loss": 0.0359,
      "step": 3038
    },
    {
      "epoch": 0.2202413305794108,
      "grad_norm": 0.6759175062179565,
      "learning_rate": 0.0001559678237553446,
      "loss": 0.017,
      "step": 3039
    },
    {
      "epoch": 0.2203138022248795,
      "grad_norm": 1.2220879793167114,
      "learning_rate": 0.00015595332995144577,
      "loss": 0.0419,
      "step": 3040
    },
    {
      "epoch": 0.22038627387034823,
      "grad_norm": 2.2480454444885254,
      "learning_rate": 0.00015593883614754695,
      "loss": 0.1324,
      "step": 3041
    },
    {
      "epoch": 0.22045874551581693,
      "grad_norm": 4.212742805480957,
      "learning_rate": 0.0001559243423436481,
      "loss": 0.1348,
      "step": 3042
    },
    {
      "epoch": 0.22053121716128565,
      "grad_norm": 2.150101661682129,
      "learning_rate": 0.00015590984853974926,
      "loss": 0.0855,
      "step": 3043
    },
    {
      "epoch": 0.22060368880675435,
      "grad_norm": 1.2917598485946655,
      "learning_rate": 0.00015589535473585045,
      "loss": 0.0345,
      "step": 3044
    },
    {
      "epoch": 0.22067616045222307,
      "grad_norm": 1.0290334224700928,
      "learning_rate": 0.0001558808609319516,
      "loss": 0.019,
      "step": 3045
    },
    {
      "epoch": 0.22074863209769177,
      "grad_norm": 7.499780178070068,
      "learning_rate": 0.00015586636712805276,
      "loss": 0.1945,
      "step": 3046
    },
    {
      "epoch": 0.2208211037431605,
      "grad_norm": 1.193490982055664,
      "learning_rate": 0.00015585187332415394,
      "loss": 0.082,
      "step": 3047
    },
    {
      "epoch": 0.2208935753886292,
      "grad_norm": 2.067814826965332,
      "learning_rate": 0.0001558373795202551,
      "loss": 0.0921,
      "step": 3048
    },
    {
      "epoch": 0.22096604703409792,
      "grad_norm": 1.012974739074707,
      "learning_rate": 0.00015582288571635626,
      "loss": 0.0635,
      "step": 3049
    },
    {
      "epoch": 0.22103851867956661,
      "grad_norm": 4.7938456535339355,
      "learning_rate": 0.00015580839191245744,
      "loss": 0.1285,
      "step": 3050
    },
    {
      "epoch": 0.22111099032503534,
      "grad_norm": 1.9345371723175049,
      "learning_rate": 0.0001557938981085586,
      "loss": 0.1702,
      "step": 3051
    },
    {
      "epoch": 0.22118346197050404,
      "grad_norm": 1.4054378271102905,
      "learning_rate": 0.00015577940430465975,
      "loss": 0.0578,
      "step": 3052
    },
    {
      "epoch": 0.22125593361597276,
      "grad_norm": 2.10683012008667,
      "learning_rate": 0.00015576491050076094,
      "loss": 0.0777,
      "step": 3053
    },
    {
      "epoch": 0.22132840526144146,
      "grad_norm": 2.5054075717926025,
      "learning_rate": 0.0001557504166968621,
      "loss": 0.0918,
      "step": 3054
    },
    {
      "epoch": 0.22140087690691018,
      "grad_norm": 0.9670161604881287,
      "learning_rate": 0.00015573592289296325,
      "loss": 0.0484,
      "step": 3055
    },
    {
      "epoch": 0.22147334855237888,
      "grad_norm": 0.4135684669017792,
      "learning_rate": 0.00015572142908906443,
      "loss": 0.0235,
      "step": 3056
    },
    {
      "epoch": 0.2215458201978476,
      "grad_norm": 2.09856915473938,
      "learning_rate": 0.0001557069352851656,
      "loss": 0.1261,
      "step": 3057
    },
    {
      "epoch": 0.2216182918433163,
      "grad_norm": 4.762932300567627,
      "learning_rate": 0.00015569244148126677,
      "loss": 0.1467,
      "step": 3058
    },
    {
      "epoch": 0.22169076348878503,
      "grad_norm": 1.9779764413833618,
      "learning_rate": 0.00015567794767736793,
      "loss": 0.0445,
      "step": 3059
    },
    {
      "epoch": 0.22176323513425372,
      "grad_norm": 1.0409212112426758,
      "learning_rate": 0.0001556634538734691,
      "loss": 0.0709,
      "step": 3060
    },
    {
      "epoch": 0.22183570677972245,
      "grad_norm": 1.1887601613998413,
      "learning_rate": 0.00015564896006957027,
      "loss": 0.044,
      "step": 3061
    },
    {
      "epoch": 0.22190817842519114,
      "grad_norm": 2.6180918216705322,
      "learning_rate": 0.00015563446626567145,
      "loss": 0.0816,
      "step": 3062
    },
    {
      "epoch": 0.22198065007065984,
      "grad_norm": 1.8477121591567993,
      "learning_rate": 0.0001556199724617726,
      "loss": 0.0755,
      "step": 3063
    },
    {
      "epoch": 0.22205312171612857,
      "grad_norm": 1.5377248525619507,
      "learning_rate": 0.00015560547865787377,
      "loss": 0.0638,
      "step": 3064
    },
    {
      "epoch": 0.22212559336159726,
      "grad_norm": 1.9704272747039795,
      "learning_rate": 0.00015559098485397495,
      "loss": 0.0366,
      "step": 3065
    },
    {
      "epoch": 0.222198065007066,
      "grad_norm": 3.9028871059417725,
      "learning_rate": 0.0001555764910500761,
      "loss": 0.1095,
      "step": 3066
    },
    {
      "epoch": 0.22227053665253468,
      "grad_norm": 2.9955403804779053,
      "learning_rate": 0.00015556199724617726,
      "loss": 0.1364,
      "step": 3067
    },
    {
      "epoch": 0.2223430082980034,
      "grad_norm": 2.011740207672119,
      "learning_rate": 0.00015554750344227845,
      "loss": 0.0768,
      "step": 3068
    },
    {
      "epoch": 0.2224154799434721,
      "grad_norm": 4.097280025482178,
      "learning_rate": 0.0001555330096383796,
      "loss": 0.1191,
      "step": 3069
    },
    {
      "epoch": 0.22248795158894083,
      "grad_norm": 2.6921889781951904,
      "learning_rate": 0.00015551851583448076,
      "loss": 0.1053,
      "step": 3070
    },
    {
      "epoch": 0.22256042323440953,
      "grad_norm": 1.9509985446929932,
      "learning_rate": 0.00015550402203058194,
      "loss": 0.1478,
      "step": 3071
    },
    {
      "epoch": 0.22263289487987825,
      "grad_norm": 1.727711796760559,
      "learning_rate": 0.0001554895282266831,
      "loss": 0.0904,
      "step": 3072
    },
    {
      "epoch": 0.22270536652534695,
      "grad_norm": 1.6556376218795776,
      "learning_rate": 0.00015547503442278426,
      "loss": 0.0897,
      "step": 3073
    },
    {
      "epoch": 0.22277783817081567,
      "grad_norm": 0.8658995628356934,
      "learning_rate": 0.00015546054061888544,
      "loss": 0.0399,
      "step": 3074
    },
    {
      "epoch": 0.22285030981628437,
      "grad_norm": 1.5979313850402832,
      "learning_rate": 0.0001554460468149866,
      "loss": 0.0699,
      "step": 3075
    },
    {
      "epoch": 0.2229227814617531,
      "grad_norm": 1.49459969997406,
      "learning_rate": 0.00015543155301108775,
      "loss": 0.1188,
      "step": 3076
    },
    {
      "epoch": 0.2229952531072218,
      "grad_norm": 2.556178331375122,
      "learning_rate": 0.00015541705920718894,
      "loss": 0.0888,
      "step": 3077
    },
    {
      "epoch": 0.22306772475269052,
      "grad_norm": 2.651960849761963,
      "learning_rate": 0.0001554025654032901,
      "loss": 0.2254,
      "step": 3078
    },
    {
      "epoch": 0.2231401963981592,
      "grad_norm": 1.032598853111267,
      "learning_rate": 0.00015538807159939125,
      "loss": 0.0341,
      "step": 3079
    },
    {
      "epoch": 0.22321266804362794,
      "grad_norm": 1.834493637084961,
      "learning_rate": 0.00015537357779549243,
      "loss": 0.044,
      "step": 3080
    },
    {
      "epoch": 0.22328513968909663,
      "grad_norm": 1.653894066810608,
      "learning_rate": 0.0001553590839915936,
      "loss": 0.0572,
      "step": 3081
    },
    {
      "epoch": 0.22335761133456536,
      "grad_norm": 3.610441207885742,
      "learning_rate": 0.00015534459018769477,
      "loss": 0.1217,
      "step": 3082
    },
    {
      "epoch": 0.22343008298003406,
      "grad_norm": 0.9599097371101379,
      "learning_rate": 0.00015533009638379596,
      "loss": 0.0678,
      "step": 3083
    },
    {
      "epoch": 0.22350255462550278,
      "grad_norm": 1.3539704084396362,
      "learning_rate": 0.0001553156025798971,
      "loss": 0.0295,
      "step": 3084
    },
    {
      "epoch": 0.22357502627097148,
      "grad_norm": 2.4551010131835938,
      "learning_rate": 0.00015530110877599827,
      "loss": 0.0624,
      "step": 3085
    },
    {
      "epoch": 0.2236474979164402,
      "grad_norm": 2.405813694000244,
      "learning_rate": 0.00015528661497209945,
      "loss": 0.112,
      "step": 3086
    },
    {
      "epoch": 0.2237199695619089,
      "grad_norm": 2.4544553756713867,
      "learning_rate": 0.0001552721211682006,
      "loss": 0.1267,
      "step": 3087
    },
    {
      "epoch": 0.22379244120737762,
      "grad_norm": 1.0455889701843262,
      "learning_rate": 0.00015525762736430177,
      "loss": 0.057,
      "step": 3088
    },
    {
      "epoch": 0.22386491285284632,
      "grad_norm": 3.758958578109741,
      "learning_rate": 0.00015524313356040295,
      "loss": 0.2622,
      "step": 3089
    },
    {
      "epoch": 0.22393738449831505,
      "grad_norm": 9.45009994506836,
      "learning_rate": 0.0001552286397565041,
      "loss": 0.1691,
      "step": 3090
    },
    {
      "epoch": 0.22400985614378374,
      "grad_norm": 5.286837100982666,
      "learning_rate": 0.00015521414595260526,
      "loss": 0.2882,
      "step": 3091
    },
    {
      "epoch": 0.22408232778925247,
      "grad_norm": 2.262345552444458,
      "learning_rate": 0.00015519965214870645,
      "loss": 0.0623,
      "step": 3092
    },
    {
      "epoch": 0.22415479943472116,
      "grad_norm": 0.9219176173210144,
      "learning_rate": 0.0001551851583448076,
      "loss": 0.0202,
      "step": 3093
    },
    {
      "epoch": 0.2242272710801899,
      "grad_norm": 1.0634998083114624,
      "learning_rate": 0.00015517066454090876,
      "loss": 0.0333,
      "step": 3094
    },
    {
      "epoch": 0.22429974272565859,
      "grad_norm": 2.4265248775482178,
      "learning_rate": 0.00015515617073700994,
      "loss": 0.0939,
      "step": 3095
    },
    {
      "epoch": 0.2243722143711273,
      "grad_norm": 4.872962951660156,
      "learning_rate": 0.0001551416769331111,
      "loss": 0.1238,
      "step": 3096
    },
    {
      "epoch": 0.224444686016596,
      "grad_norm": 7.398514747619629,
      "learning_rate": 0.00015512718312921225,
      "loss": 0.1196,
      "step": 3097
    },
    {
      "epoch": 0.2245171576620647,
      "grad_norm": 4.762068748474121,
      "learning_rate": 0.00015511268932531344,
      "loss": 0.1359,
      "step": 3098
    },
    {
      "epoch": 0.22458962930753343,
      "grad_norm": 1.6379543542861938,
      "learning_rate": 0.0001550981955214146,
      "loss": 0.0943,
      "step": 3099
    },
    {
      "epoch": 0.22466210095300213,
      "grad_norm": 1.8946239948272705,
      "learning_rate": 0.00015508370171751575,
      "loss": 0.0638,
      "step": 3100
    },
    {
      "epoch": 0.22473457259847085,
      "grad_norm": 1.988952875137329,
      "learning_rate": 0.00015506920791361694,
      "loss": 0.058,
      "step": 3101
    },
    {
      "epoch": 0.22480704424393955,
      "grad_norm": 2.2084317207336426,
      "learning_rate": 0.0001550547141097181,
      "loss": 0.1078,
      "step": 3102
    },
    {
      "epoch": 0.22487951588940827,
      "grad_norm": 4.977779388427734,
      "learning_rate": 0.00015504022030581925,
      "loss": 0.0567,
      "step": 3103
    },
    {
      "epoch": 0.22495198753487697,
      "grad_norm": 4.878524303436279,
      "learning_rate": 0.00015502572650192043,
      "loss": 0.1127,
      "step": 3104
    },
    {
      "epoch": 0.2250244591803457,
      "grad_norm": 5.00486421585083,
      "learning_rate": 0.00015501123269802162,
      "loss": 0.0892,
      "step": 3105
    },
    {
      "epoch": 0.2250969308258144,
      "grad_norm": 2.170372486114502,
      "learning_rate": 0.00015499673889412277,
      "loss": 0.1554,
      "step": 3106
    },
    {
      "epoch": 0.22516940247128311,
      "grad_norm": 5.286480903625488,
      "learning_rate": 0.00015498224509022396,
      "loss": 0.1639,
      "step": 3107
    },
    {
      "epoch": 0.2252418741167518,
      "grad_norm": 0.6607525944709778,
      "learning_rate": 0.0001549677512863251,
      "loss": 0.0548,
      "step": 3108
    },
    {
      "epoch": 0.22531434576222054,
      "grad_norm": 1.8903822898864746,
      "learning_rate": 0.00015495325748242627,
      "loss": 0.0865,
      "step": 3109
    },
    {
      "epoch": 0.22538681740768923,
      "grad_norm": 2.0279767513275146,
      "learning_rate": 0.00015493876367852745,
      "loss": 0.0854,
      "step": 3110
    },
    {
      "epoch": 0.22545928905315796,
      "grad_norm": 1.4500279426574707,
      "learning_rate": 0.0001549242698746286,
      "loss": 0.0487,
      "step": 3111
    },
    {
      "epoch": 0.22553176069862665,
      "grad_norm": 2.9112391471862793,
      "learning_rate": 0.00015490977607072976,
      "loss": 0.1144,
      "step": 3112
    },
    {
      "epoch": 0.22560423234409538,
      "grad_norm": 1.8110147714614868,
      "learning_rate": 0.00015489528226683095,
      "loss": 0.1262,
      "step": 3113
    },
    {
      "epoch": 0.22567670398956408,
      "grad_norm": 2.609546184539795,
      "learning_rate": 0.0001548807884629321,
      "loss": 0.0829,
      "step": 3114
    },
    {
      "epoch": 0.2257491756350328,
      "grad_norm": 1.4499369859695435,
      "learning_rate": 0.00015486629465903326,
      "loss": 0.0491,
      "step": 3115
    },
    {
      "epoch": 0.2258216472805015,
      "grad_norm": 1.6704002618789673,
      "learning_rate": 0.00015485180085513444,
      "loss": 0.0352,
      "step": 3116
    },
    {
      "epoch": 0.22589411892597022,
      "grad_norm": 2.0297980308532715,
      "learning_rate": 0.0001548373070512356,
      "loss": 0.1526,
      "step": 3117
    },
    {
      "epoch": 0.22596659057143892,
      "grad_norm": 1.9119887351989746,
      "learning_rate": 0.00015482281324733676,
      "loss": 0.096,
      "step": 3118
    },
    {
      "epoch": 0.22603906221690764,
      "grad_norm": 1.2128633260726929,
      "learning_rate": 0.00015480831944343794,
      "loss": 0.0571,
      "step": 3119
    },
    {
      "epoch": 0.22611153386237634,
      "grad_norm": 1.2171403169631958,
      "learning_rate": 0.0001547938256395391,
      "loss": 0.0775,
      "step": 3120
    },
    {
      "epoch": 0.22618400550784507,
      "grad_norm": 3.0490493774414062,
      "learning_rate": 0.00015477933183564025,
      "loss": 0.1305,
      "step": 3121
    },
    {
      "epoch": 0.22625647715331376,
      "grad_norm": 2.258085250854492,
      "learning_rate": 0.00015476483803174144,
      "loss": 0.1049,
      "step": 3122
    },
    {
      "epoch": 0.2263289487987825,
      "grad_norm": 1.4006046056747437,
      "learning_rate": 0.0001547503442278426,
      "loss": 0.0627,
      "step": 3123
    },
    {
      "epoch": 0.22640142044425118,
      "grad_norm": 1.9551374912261963,
      "learning_rate": 0.00015473585042394375,
      "loss": 0.0937,
      "step": 3124
    },
    {
      "epoch": 0.2264738920897199,
      "grad_norm": 2.446099281311035,
      "learning_rate": 0.00015472135662004493,
      "loss": 0.1002,
      "step": 3125
    },
    {
      "epoch": 0.2265463637351886,
      "grad_norm": 0.6067213416099548,
      "learning_rate": 0.0001547068628161461,
      "loss": 0.0254,
      "step": 3126
    },
    {
      "epoch": 0.22661883538065733,
      "grad_norm": 1.2293012142181396,
      "learning_rate": 0.00015469236901224727,
      "loss": 0.0829,
      "step": 3127
    },
    {
      "epoch": 0.22669130702612603,
      "grad_norm": 0.9678452014923096,
      "learning_rate": 0.00015467787520834843,
      "loss": 0.0173,
      "step": 3128
    },
    {
      "epoch": 0.22676377867159475,
      "grad_norm": 1.6026045083999634,
      "learning_rate": 0.00015466338140444961,
      "loss": 0.0524,
      "step": 3129
    },
    {
      "epoch": 0.22683625031706345,
      "grad_norm": 2.4303390979766846,
      "learning_rate": 0.00015464888760055077,
      "loss": 0.1518,
      "step": 3130
    },
    {
      "epoch": 0.22690872196253217,
      "grad_norm": 3.512646436691284,
      "learning_rate": 0.00015463439379665195,
      "loss": 0.0772,
      "step": 3131
    },
    {
      "epoch": 0.22698119360800087,
      "grad_norm": 1.9757306575775146,
      "learning_rate": 0.0001546198999927531,
      "loss": 0.077,
      "step": 3132
    },
    {
      "epoch": 0.22705366525346957,
      "grad_norm": 2.6379199028015137,
      "learning_rate": 0.00015460540618885427,
      "loss": 0.0867,
      "step": 3133
    },
    {
      "epoch": 0.2271261368989383,
      "grad_norm": 0.17186538875102997,
      "learning_rate": 0.00015459091238495545,
      "loss": 0.0029,
      "step": 3134
    },
    {
      "epoch": 0.227198608544407,
      "grad_norm": 1.2329283952713013,
      "learning_rate": 0.0001545764185810566,
      "loss": 0.0456,
      "step": 3135
    },
    {
      "epoch": 0.2272710801898757,
      "grad_norm": 2.6940195560455322,
      "learning_rate": 0.00015456192477715776,
      "loss": 0.1074,
      "step": 3136
    },
    {
      "epoch": 0.2273435518353444,
      "grad_norm": 6.185295104980469,
      "learning_rate": 0.00015454743097325895,
      "loss": 0.124,
      "step": 3137
    },
    {
      "epoch": 0.22741602348081313,
      "grad_norm": 2.378912925720215,
      "learning_rate": 0.0001545329371693601,
      "loss": 0.0617,
      "step": 3138
    },
    {
      "epoch": 0.22748849512628183,
      "grad_norm": 1.5280207395553589,
      "learning_rate": 0.00015451844336546126,
      "loss": 0.1074,
      "step": 3139
    },
    {
      "epoch": 0.22756096677175056,
      "grad_norm": 2.924093246459961,
      "learning_rate": 0.00015450394956156244,
      "loss": 0.1673,
      "step": 3140
    },
    {
      "epoch": 0.22763343841721925,
      "grad_norm": 4.20170783996582,
      "learning_rate": 0.0001544894557576636,
      "loss": 0.2663,
      "step": 3141
    },
    {
      "epoch": 0.22770591006268798,
      "grad_norm": 9.128886222839355,
      "learning_rate": 0.00015447496195376476,
      "loss": 0.1036,
      "step": 3142
    },
    {
      "epoch": 0.22777838170815667,
      "grad_norm": 0.8884163498878479,
      "learning_rate": 0.00015446046814986594,
      "loss": 0.0721,
      "step": 3143
    },
    {
      "epoch": 0.2278508533536254,
      "grad_norm": 2.061929702758789,
      "learning_rate": 0.0001544459743459671,
      "loss": 0.0626,
      "step": 3144
    },
    {
      "epoch": 0.2279233249990941,
      "grad_norm": 3.416914224624634,
      "learning_rate": 0.00015443148054206825,
      "loss": 0.1648,
      "step": 3145
    },
    {
      "epoch": 0.22799579664456282,
      "grad_norm": 2.226264476776123,
      "learning_rate": 0.00015441698673816944,
      "loss": 0.1666,
      "step": 3146
    },
    {
      "epoch": 0.22806826829003152,
      "grad_norm": 4.302074432373047,
      "learning_rate": 0.0001544024929342706,
      "loss": 0.1723,
      "step": 3147
    },
    {
      "epoch": 0.22814073993550024,
      "grad_norm": 1.9170676469802856,
      "learning_rate": 0.00015438799913037175,
      "loss": 0.1489,
      "step": 3148
    },
    {
      "epoch": 0.22821321158096894,
      "grad_norm": 1.7673275470733643,
      "learning_rate": 0.00015437350532647293,
      "loss": 0.1247,
      "step": 3149
    },
    {
      "epoch": 0.22828568322643766,
      "grad_norm": 0.8272567391395569,
      "learning_rate": 0.0001543590115225741,
      "loss": 0.0313,
      "step": 3150
    },
    {
      "epoch": 0.22835815487190636,
      "grad_norm": 1.9097058773040771,
      "learning_rate": 0.00015434451771867527,
      "loss": 0.0344,
      "step": 3151
    },
    {
      "epoch": 0.22843062651737508,
      "grad_norm": 1.2350860834121704,
      "learning_rate": 0.00015433002391477646,
      "loss": 0.0448,
      "step": 3152
    },
    {
      "epoch": 0.22850309816284378,
      "grad_norm": 1.1810996532440186,
      "learning_rate": 0.00015431553011087761,
      "loss": 0.0954,
      "step": 3153
    },
    {
      "epoch": 0.2285755698083125,
      "grad_norm": 0.9774881601333618,
      "learning_rate": 0.00015430103630697877,
      "loss": 0.0757,
      "step": 3154
    },
    {
      "epoch": 0.2286480414537812,
      "grad_norm": 1.203518033027649,
      "learning_rate": 0.00015428654250307995,
      "loss": 0.0468,
      "step": 3155
    },
    {
      "epoch": 0.22872051309924993,
      "grad_norm": 5.3112263679504395,
      "learning_rate": 0.0001542720486991811,
      "loss": 0.2306,
      "step": 3156
    },
    {
      "epoch": 0.22879298474471862,
      "grad_norm": 0.981231153011322,
      "learning_rate": 0.00015425755489528227,
      "loss": 0.0772,
      "step": 3157
    },
    {
      "epoch": 0.22886545639018735,
      "grad_norm": 1.447721004486084,
      "learning_rate": 0.00015424306109138345,
      "loss": 0.0464,
      "step": 3158
    },
    {
      "epoch": 0.22893792803565605,
      "grad_norm": 2.579254627227783,
      "learning_rate": 0.0001542285672874846,
      "loss": 0.1747,
      "step": 3159
    },
    {
      "epoch": 0.22901039968112477,
      "grad_norm": 1.21382474899292,
      "learning_rate": 0.00015421407348358576,
      "loss": 0.1096,
      "step": 3160
    },
    {
      "epoch": 0.22908287132659347,
      "grad_norm": 3.0824575424194336,
      "learning_rate": 0.00015419957967968695,
      "loss": 0.0506,
      "step": 3161
    },
    {
      "epoch": 0.2291553429720622,
      "grad_norm": 0.9428160786628723,
      "learning_rate": 0.0001541850858757881,
      "loss": 0.0407,
      "step": 3162
    },
    {
      "epoch": 0.2292278146175309,
      "grad_norm": 2.699030876159668,
      "learning_rate": 0.00015417059207188926,
      "loss": 0.0703,
      "step": 3163
    },
    {
      "epoch": 0.22930028626299961,
      "grad_norm": 1.8287310600280762,
      "learning_rate": 0.00015415609826799044,
      "loss": 0.0313,
      "step": 3164
    },
    {
      "epoch": 0.2293727579084683,
      "grad_norm": 1.103076457977295,
      "learning_rate": 0.0001541416044640916,
      "loss": 0.0904,
      "step": 3165
    },
    {
      "epoch": 0.22944522955393704,
      "grad_norm": 4.027413845062256,
      "learning_rate": 0.00015412711066019276,
      "loss": 0.1442,
      "step": 3166
    },
    {
      "epoch": 0.22951770119940573,
      "grad_norm": 2.2634499073028564,
      "learning_rate": 0.00015411261685629394,
      "loss": 0.1369,
      "step": 3167
    },
    {
      "epoch": 0.22959017284487443,
      "grad_norm": 1.489303708076477,
      "learning_rate": 0.0001540981230523951,
      "loss": 0.0789,
      "step": 3168
    },
    {
      "epoch": 0.22966264449034315,
      "grad_norm": 1.6456897258758545,
      "learning_rate": 0.00015408362924849628,
      "loss": 0.0569,
      "step": 3169
    },
    {
      "epoch": 0.22973511613581185,
      "grad_norm": 1.279598355293274,
      "learning_rate": 0.00015406913544459744,
      "loss": 0.0324,
      "step": 3170
    },
    {
      "epoch": 0.22980758778128058,
      "grad_norm": 1.5509921312332153,
      "learning_rate": 0.0001540546416406986,
      "loss": 0.083,
      "step": 3171
    },
    {
      "epoch": 0.22988005942674927,
      "grad_norm": 7.697230815887451,
      "learning_rate": 0.00015404014783679978,
      "loss": 0.0651,
      "step": 3172
    },
    {
      "epoch": 0.229952531072218,
      "grad_norm": 2.503371000289917,
      "learning_rate": 0.00015402565403290093,
      "loss": 0.1198,
      "step": 3173
    },
    {
      "epoch": 0.2300250027176867,
      "grad_norm": 3.3302223682403564,
      "learning_rate": 0.00015401116022900212,
      "loss": 0.0298,
      "step": 3174
    },
    {
      "epoch": 0.23009747436315542,
      "grad_norm": 5.632021903991699,
      "learning_rate": 0.00015399666642510327,
      "loss": 0.1213,
      "step": 3175
    },
    {
      "epoch": 0.23016994600862412,
      "grad_norm": 1.2696197032928467,
      "learning_rate": 0.00015398217262120446,
      "loss": 0.1023,
      "step": 3176
    },
    {
      "epoch": 0.23024241765409284,
      "grad_norm": 3.9827136993408203,
      "learning_rate": 0.00015396767881730561,
      "loss": 0.1424,
      "step": 3177
    },
    {
      "epoch": 0.23031488929956154,
      "grad_norm": 2.034306287765503,
      "learning_rate": 0.0001539531850134068,
      "loss": 0.1732,
      "step": 3178
    },
    {
      "epoch": 0.23038736094503026,
      "grad_norm": 1.0665278434753418,
      "learning_rate": 0.00015393869120950795,
      "loss": 0.0799,
      "step": 3179
    },
    {
      "epoch": 0.23045983259049896,
      "grad_norm": 4.174856662750244,
      "learning_rate": 0.0001539241974056091,
      "loss": 0.1002,
      "step": 3180
    },
    {
      "epoch": 0.23053230423596768,
      "grad_norm": 0.9614624977111816,
      "learning_rate": 0.0001539097036017103,
      "loss": 0.0565,
      "step": 3181
    },
    {
      "epoch": 0.23060477588143638,
      "grad_norm": 3.2149200439453125,
      "learning_rate": 0.00015389520979781145,
      "loss": 0.1063,
      "step": 3182
    },
    {
      "epoch": 0.2306772475269051,
      "grad_norm": 0.9955391883850098,
      "learning_rate": 0.0001538807159939126,
      "loss": 0.1202,
      "step": 3183
    },
    {
      "epoch": 0.2307497191723738,
      "grad_norm": 2.5960187911987305,
      "learning_rate": 0.0001538662221900138,
      "loss": 0.1159,
      "step": 3184
    },
    {
      "epoch": 0.23082219081784253,
      "grad_norm": 2.128969669342041,
      "learning_rate": 0.00015385172838611495,
      "loss": 0.1468,
      "step": 3185
    },
    {
      "epoch": 0.23089466246331122,
      "grad_norm": 1.7326302528381348,
      "learning_rate": 0.0001538372345822161,
      "loss": 0.0552,
      "step": 3186
    },
    {
      "epoch": 0.23096713410877995,
      "grad_norm": 0.7620888948440552,
      "learning_rate": 0.0001538227407783173,
      "loss": 0.0296,
      "step": 3187
    },
    {
      "epoch": 0.23103960575424864,
      "grad_norm": 2.174009323120117,
      "learning_rate": 0.00015380824697441844,
      "loss": 0.1096,
      "step": 3188
    },
    {
      "epoch": 0.23111207739971737,
      "grad_norm": 0.800804078578949,
      "learning_rate": 0.0001537937531705196,
      "loss": 0.0472,
      "step": 3189
    },
    {
      "epoch": 0.23118454904518607,
      "grad_norm": 2.8414201736450195,
      "learning_rate": 0.00015377925936662078,
      "loss": 0.2857,
      "step": 3190
    },
    {
      "epoch": 0.2312570206906548,
      "grad_norm": 3.086043357849121,
      "learning_rate": 0.00015376476556272194,
      "loss": 0.058,
      "step": 3191
    },
    {
      "epoch": 0.2313294923361235,
      "grad_norm": 2.658033847808838,
      "learning_rate": 0.0001537502717588231,
      "loss": 0.0745,
      "step": 3192
    },
    {
      "epoch": 0.2314019639815922,
      "grad_norm": 6.047761917114258,
      "learning_rate": 0.00015373577795492428,
      "loss": 0.2387,
      "step": 3193
    },
    {
      "epoch": 0.2314744356270609,
      "grad_norm": 1.1670405864715576,
      "learning_rate": 0.00015372128415102544,
      "loss": 0.0431,
      "step": 3194
    },
    {
      "epoch": 0.23154690727252963,
      "grad_norm": 2.8268139362335205,
      "learning_rate": 0.0001537067903471266,
      "loss": 0.1724,
      "step": 3195
    },
    {
      "epoch": 0.23161937891799833,
      "grad_norm": 2.293272018432617,
      "learning_rate": 0.00015369229654322778,
      "loss": 0.0805,
      "step": 3196
    },
    {
      "epoch": 0.23169185056346706,
      "grad_norm": 0.5837582945823669,
      "learning_rate": 0.00015367780273932893,
      "loss": 0.0445,
      "step": 3197
    },
    {
      "epoch": 0.23176432220893575,
      "grad_norm": 1.0440188646316528,
      "learning_rate": 0.00015366330893543012,
      "loss": 0.0561,
      "step": 3198
    },
    {
      "epoch": 0.23183679385440448,
      "grad_norm": 1.005989670753479,
      "learning_rate": 0.0001536488151315313,
      "loss": 0.0919,
      "step": 3199
    },
    {
      "epoch": 0.23190926549987317,
      "grad_norm": 0.7798192501068115,
      "learning_rate": 0.00015363432132763246,
      "loss": 0.0524,
      "step": 3200
    },
    {
      "epoch": 0.2319817371453419,
      "grad_norm": 2.6738052368164062,
      "learning_rate": 0.00015361982752373361,
      "loss": 0.0909,
      "step": 3201
    },
    {
      "epoch": 0.2320542087908106,
      "grad_norm": 0.4815628230571747,
      "learning_rate": 0.0001536053337198348,
      "loss": 0.0221,
      "step": 3202
    },
    {
      "epoch": 0.2321266804362793,
      "grad_norm": 0.4164941906929016,
      "learning_rate": 0.00015359083991593595,
      "loss": 0.0119,
      "step": 3203
    },
    {
      "epoch": 0.23219915208174802,
      "grad_norm": 4.63654088973999,
      "learning_rate": 0.0001535763461120371,
      "loss": 0.1826,
      "step": 3204
    },
    {
      "epoch": 0.23227162372721671,
      "grad_norm": 1.4658708572387695,
      "learning_rate": 0.0001535618523081383,
      "loss": 0.0657,
      "step": 3205
    },
    {
      "epoch": 0.23234409537268544,
      "grad_norm": 5.478832244873047,
      "learning_rate": 0.00015354735850423945,
      "loss": 0.0495,
      "step": 3206
    },
    {
      "epoch": 0.23241656701815414,
      "grad_norm": 0.8833270072937012,
      "learning_rate": 0.0001535328647003406,
      "loss": 0.0609,
      "step": 3207
    },
    {
      "epoch": 0.23248903866362286,
      "grad_norm": 1.8885548114776611,
      "learning_rate": 0.0001535183708964418,
      "loss": 0.1843,
      "step": 3208
    },
    {
      "epoch": 0.23256151030909156,
      "grad_norm": 1.5845141410827637,
      "learning_rate": 0.00015350387709254295,
      "loss": 0.0662,
      "step": 3209
    },
    {
      "epoch": 0.23263398195456028,
      "grad_norm": 2.2438290119171143,
      "learning_rate": 0.0001534893832886441,
      "loss": 0.1273,
      "step": 3210
    },
    {
      "epoch": 0.23270645360002898,
      "grad_norm": 2.0383574962615967,
      "learning_rate": 0.0001534748894847453,
      "loss": 0.0878,
      "step": 3211
    },
    {
      "epoch": 0.2327789252454977,
      "grad_norm": 4.154660224914551,
      "learning_rate": 0.00015346039568084644,
      "loss": 0.1698,
      "step": 3212
    },
    {
      "epoch": 0.2328513968909664,
      "grad_norm": 3.115257740020752,
      "learning_rate": 0.0001534459018769476,
      "loss": 0.1865,
      "step": 3213
    },
    {
      "epoch": 0.23292386853643512,
      "grad_norm": 1.343575358390808,
      "learning_rate": 0.00015343140807304878,
      "loss": 0.1156,
      "step": 3214
    },
    {
      "epoch": 0.23299634018190382,
      "grad_norm": 1.1905242204666138,
      "learning_rate": 0.00015341691426914994,
      "loss": 0.0376,
      "step": 3215
    },
    {
      "epoch": 0.23306881182737255,
      "grad_norm": 1.0909672975540161,
      "learning_rate": 0.0001534024204652511,
      "loss": 0.0894,
      "step": 3216
    },
    {
      "epoch": 0.23314128347284124,
      "grad_norm": 2.4749343395233154,
      "learning_rate": 0.00015338792666135228,
      "loss": 0.1636,
      "step": 3217
    },
    {
      "epoch": 0.23321375511830997,
      "grad_norm": 1.009630799293518,
      "learning_rate": 0.00015337343285745344,
      "loss": 0.046,
      "step": 3218
    },
    {
      "epoch": 0.23328622676377866,
      "grad_norm": 2.3022122383117676,
      "learning_rate": 0.00015335893905355462,
      "loss": 0.0582,
      "step": 3219
    },
    {
      "epoch": 0.2333586984092474,
      "grad_norm": 1.2975225448608398,
      "learning_rate": 0.00015334444524965578,
      "loss": 0.045,
      "step": 3220
    },
    {
      "epoch": 0.2334311700547161,
      "grad_norm": 1.5491468906402588,
      "learning_rate": 0.00015332995144575696,
      "loss": 0.0469,
      "step": 3221
    },
    {
      "epoch": 0.2335036417001848,
      "grad_norm": 6.453967094421387,
      "learning_rate": 0.00015331545764185812,
      "loss": 0.0422,
      "step": 3222
    },
    {
      "epoch": 0.2335761133456535,
      "grad_norm": 1.7396436929702759,
      "learning_rate": 0.0001533009638379593,
      "loss": 0.0413,
      "step": 3223
    },
    {
      "epoch": 0.23364858499112223,
      "grad_norm": 2.9861111640930176,
      "learning_rate": 0.00015328647003406046,
      "loss": 0.1491,
      "step": 3224
    },
    {
      "epoch": 0.23372105663659093,
      "grad_norm": 1.445723533630371,
      "learning_rate": 0.0001532719762301616,
      "loss": 0.092,
      "step": 3225
    },
    {
      "epoch": 0.23379352828205965,
      "grad_norm": 1.3700180053710938,
      "learning_rate": 0.0001532574824262628,
      "loss": 0.037,
      "step": 3226
    },
    {
      "epoch": 0.23386599992752835,
      "grad_norm": 0.9160640835762024,
      "learning_rate": 0.00015324298862236395,
      "loss": 0.0207,
      "step": 3227
    },
    {
      "epoch": 0.23393847157299708,
      "grad_norm": 4.799799919128418,
      "learning_rate": 0.0001532284948184651,
      "loss": 0.0557,
      "step": 3228
    },
    {
      "epoch": 0.23401094321846577,
      "grad_norm": 1.9281039237976074,
      "learning_rate": 0.0001532140010145663,
      "loss": 0.0668,
      "step": 3229
    },
    {
      "epoch": 0.2340834148639345,
      "grad_norm": 1.1545214653015137,
      "learning_rate": 0.00015319950721066745,
      "loss": 0.0237,
      "step": 3230
    },
    {
      "epoch": 0.2341558865094032,
      "grad_norm": 2.5200021266937256,
      "learning_rate": 0.0001531850134067686,
      "loss": 0.0585,
      "step": 3231
    },
    {
      "epoch": 0.23422835815487192,
      "grad_norm": 2.8255367279052734,
      "learning_rate": 0.0001531705196028698,
      "loss": 0.1971,
      "step": 3232
    },
    {
      "epoch": 0.23430082980034062,
      "grad_norm": 6.200389385223389,
      "learning_rate": 0.00015315602579897095,
      "loss": 0.1027,
      "step": 3233
    },
    {
      "epoch": 0.23437330144580934,
      "grad_norm": 4.102030277252197,
      "learning_rate": 0.0001531415319950721,
      "loss": 0.1348,
      "step": 3234
    },
    {
      "epoch": 0.23444577309127804,
      "grad_norm": 5.633013725280762,
      "learning_rate": 0.00015312703819117329,
      "loss": 0.1053,
      "step": 3235
    },
    {
      "epoch": 0.23451824473674676,
      "grad_norm": 3.5381810665130615,
      "learning_rate": 0.00015311254438727444,
      "loss": 0.0322,
      "step": 3236
    },
    {
      "epoch": 0.23459071638221546,
      "grad_norm": 1.61327064037323,
      "learning_rate": 0.0001530980505833756,
      "loss": 0.0388,
      "step": 3237
    },
    {
      "epoch": 0.23466318802768416,
      "grad_norm": 1.163419246673584,
      "learning_rate": 0.00015308355677947678,
      "loss": 0.0776,
      "step": 3238
    },
    {
      "epoch": 0.23473565967315288,
      "grad_norm": 1.6884843111038208,
      "learning_rate": 0.00015306906297557794,
      "loss": 0.1687,
      "step": 3239
    },
    {
      "epoch": 0.23480813131862158,
      "grad_norm": 0.8670715093612671,
      "learning_rate": 0.0001530545691716791,
      "loss": 0.0471,
      "step": 3240
    },
    {
      "epoch": 0.2348806029640903,
      "grad_norm": 1.6412909030914307,
      "learning_rate": 0.00015304007536778028,
      "loss": 0.0792,
      "step": 3241
    },
    {
      "epoch": 0.234953074609559,
      "grad_norm": 1.3969076871871948,
      "learning_rate": 0.00015302558156388144,
      "loss": 0.0517,
      "step": 3242
    },
    {
      "epoch": 0.23502554625502772,
      "grad_norm": 4.137848854064941,
      "learning_rate": 0.00015301108775998262,
      "loss": 0.1701,
      "step": 3243
    },
    {
      "epoch": 0.23509801790049642,
      "grad_norm": 3.7132391929626465,
      "learning_rate": 0.00015299659395608378,
      "loss": 0.1366,
      "step": 3244
    },
    {
      "epoch": 0.23517048954596514,
      "grad_norm": 3.6785576343536377,
      "learning_rate": 0.00015298210015218496,
      "loss": 0.1061,
      "step": 3245
    },
    {
      "epoch": 0.23524296119143384,
      "grad_norm": 4.222601413726807,
      "learning_rate": 0.00015296760634828612,
      "loss": 0.0732,
      "step": 3246
    },
    {
      "epoch": 0.23531543283690257,
      "grad_norm": 1.8565728664398193,
      "learning_rate": 0.0001529531125443873,
      "loss": 0.1504,
      "step": 3247
    },
    {
      "epoch": 0.23538790448237126,
      "grad_norm": 3.582298994064331,
      "learning_rate": 0.00015293861874048846,
      "loss": 0.238,
      "step": 3248
    },
    {
      "epoch": 0.23546037612784,
      "grad_norm": 1.6750174760818481,
      "learning_rate": 0.0001529241249365896,
      "loss": 0.033,
      "step": 3249
    },
    {
      "epoch": 0.23553284777330868,
      "grad_norm": 2.273815870285034,
      "learning_rate": 0.0001529096311326908,
      "loss": 0.1753,
      "step": 3250
    },
    {
      "epoch": 0.2356053194187774,
      "grad_norm": 3.0952093601226807,
      "learning_rate": 0.00015289513732879195,
      "loss": 0.0713,
      "step": 3251
    },
    {
      "epoch": 0.2356777910642461,
      "grad_norm": 2.250124216079712,
      "learning_rate": 0.0001528806435248931,
      "loss": 0.1135,
      "step": 3252
    },
    {
      "epoch": 0.23575026270971483,
      "grad_norm": 0.8626754283905029,
      "learning_rate": 0.0001528661497209943,
      "loss": 0.057,
      "step": 3253
    },
    {
      "epoch": 0.23582273435518353,
      "grad_norm": 5.290526390075684,
      "learning_rate": 0.00015285165591709545,
      "loss": 0.1995,
      "step": 3254
    },
    {
      "epoch": 0.23589520600065225,
      "grad_norm": 1.7736458778381348,
      "learning_rate": 0.0001528371621131966,
      "loss": 0.0898,
      "step": 3255
    },
    {
      "epoch": 0.23596767764612095,
      "grad_norm": 2.6795454025268555,
      "learning_rate": 0.0001528226683092978,
      "loss": 0.1168,
      "step": 3256
    },
    {
      "epoch": 0.23604014929158967,
      "grad_norm": 3.6332075595855713,
      "learning_rate": 0.00015280817450539895,
      "loss": 0.1099,
      "step": 3257
    },
    {
      "epoch": 0.23611262093705837,
      "grad_norm": 2.111783266067505,
      "learning_rate": 0.0001527936807015001,
      "loss": 0.104,
      "step": 3258
    },
    {
      "epoch": 0.2361850925825271,
      "grad_norm": 5.654288291931152,
      "learning_rate": 0.00015277918689760129,
      "loss": 0.1424,
      "step": 3259
    },
    {
      "epoch": 0.2362575642279958,
      "grad_norm": 0.7352163195610046,
      "learning_rate": 0.00015276469309370244,
      "loss": 0.0416,
      "step": 3260
    },
    {
      "epoch": 0.23633003587346452,
      "grad_norm": 3.0459487438201904,
      "learning_rate": 0.0001527501992898036,
      "loss": 0.1101,
      "step": 3261
    },
    {
      "epoch": 0.2364025075189332,
      "grad_norm": 0.9257131218910217,
      "learning_rate": 0.00015273570548590478,
      "loss": 0.0402,
      "step": 3262
    },
    {
      "epoch": 0.23647497916440194,
      "grad_norm": 2.92183256149292,
      "learning_rate": 0.00015272121168200594,
      "loss": 0.124,
      "step": 3263
    },
    {
      "epoch": 0.23654745080987064,
      "grad_norm": 0.6782184839248657,
      "learning_rate": 0.0001527067178781071,
      "loss": 0.052,
      "step": 3264
    },
    {
      "epoch": 0.23661992245533936,
      "grad_norm": 1.1104240417480469,
      "learning_rate": 0.00015269222407420828,
      "loss": 0.037,
      "step": 3265
    },
    {
      "epoch": 0.23669239410080806,
      "grad_norm": 1.78925621509552,
      "learning_rate": 0.00015267773027030946,
      "loss": 0.047,
      "step": 3266
    },
    {
      "epoch": 0.23676486574627678,
      "grad_norm": 1.815428614616394,
      "learning_rate": 0.00015266323646641062,
      "loss": 0.0693,
      "step": 3267
    },
    {
      "epoch": 0.23683733739174548,
      "grad_norm": 2.9318556785583496,
      "learning_rate": 0.0001526487426625118,
      "loss": 0.1486,
      "step": 3268
    },
    {
      "epoch": 0.2369098090372142,
      "grad_norm": 1.5798612833023071,
      "learning_rate": 0.00015263424885861296,
      "loss": 0.0691,
      "step": 3269
    },
    {
      "epoch": 0.2369822806826829,
      "grad_norm": 4.064321994781494,
      "learning_rate": 0.00015261975505471412,
      "loss": 0.1437,
      "step": 3270
    },
    {
      "epoch": 0.23705475232815162,
      "grad_norm": 2.1489152908325195,
      "learning_rate": 0.0001526052612508153,
      "loss": 0.1159,
      "step": 3271
    },
    {
      "epoch": 0.23712722397362032,
      "grad_norm": 4.039096832275391,
      "learning_rate": 0.00015259076744691646,
      "loss": 0.1311,
      "step": 3272
    },
    {
      "epoch": 0.23719969561908902,
      "grad_norm": 4.181158542633057,
      "learning_rate": 0.0001525762736430176,
      "loss": 0.1098,
      "step": 3273
    },
    {
      "epoch": 0.23727216726455774,
      "grad_norm": 3.2733733654022217,
      "learning_rate": 0.0001525617798391188,
      "loss": 0.0802,
      "step": 3274
    },
    {
      "epoch": 0.23734463891002644,
      "grad_norm": 1.9102154970169067,
      "learning_rate": 0.00015254728603521995,
      "loss": 0.1529,
      "step": 3275
    },
    {
      "epoch": 0.23741711055549516,
      "grad_norm": 1.322629451751709,
      "learning_rate": 0.0001525327922313211,
      "loss": 0.0547,
      "step": 3276
    },
    {
      "epoch": 0.23748958220096386,
      "grad_norm": 1.367640495300293,
      "learning_rate": 0.0001525182984274223,
      "loss": 0.0202,
      "step": 3277
    },
    {
      "epoch": 0.23756205384643259,
      "grad_norm": 5.29815673828125,
      "learning_rate": 0.00015250380462352345,
      "loss": 0.1584,
      "step": 3278
    },
    {
      "epoch": 0.23763452549190128,
      "grad_norm": 4.5346808433532715,
      "learning_rate": 0.0001524893108196246,
      "loss": 0.1534,
      "step": 3279
    },
    {
      "epoch": 0.23770699713737,
      "grad_norm": 4.636466979980469,
      "learning_rate": 0.0001524748170157258,
      "loss": 0.1144,
      "step": 3280
    },
    {
      "epoch": 0.2377794687828387,
      "grad_norm": 6.550497055053711,
      "learning_rate": 0.00015246032321182695,
      "loss": 0.1123,
      "step": 3281
    },
    {
      "epoch": 0.23785194042830743,
      "grad_norm": 4.717048168182373,
      "learning_rate": 0.0001524458294079281,
      "loss": 0.1494,
      "step": 3282
    },
    {
      "epoch": 0.23792441207377613,
      "grad_norm": 0.5050515532493591,
      "learning_rate": 0.00015243133560402929,
      "loss": 0.0183,
      "step": 3283
    },
    {
      "epoch": 0.23799688371924485,
      "grad_norm": 2.150571346282959,
      "learning_rate": 0.00015241684180013044,
      "loss": 0.1256,
      "step": 3284
    },
    {
      "epoch": 0.23806935536471355,
      "grad_norm": 2.881749153137207,
      "learning_rate": 0.0001524023479962316,
      "loss": 0.2078,
      "step": 3285
    },
    {
      "epoch": 0.23814182701018227,
      "grad_norm": 2.6651151180267334,
      "learning_rate": 0.00015238785419233278,
      "loss": 0.1332,
      "step": 3286
    },
    {
      "epoch": 0.23821429865565097,
      "grad_norm": 1.2504043579101562,
      "learning_rate": 0.00015237336038843394,
      "loss": 0.0994,
      "step": 3287
    },
    {
      "epoch": 0.2382867703011197,
      "grad_norm": 2.634239673614502,
      "learning_rate": 0.00015235886658453512,
      "loss": 0.0823,
      "step": 3288
    },
    {
      "epoch": 0.2383592419465884,
      "grad_norm": 1.0088119506835938,
      "learning_rate": 0.00015234437278063628,
      "loss": 0.0693,
      "step": 3289
    },
    {
      "epoch": 0.23843171359205712,
      "grad_norm": 1.0638487339019775,
      "learning_rate": 0.00015232987897673746,
      "loss": 0.0289,
      "step": 3290
    },
    {
      "epoch": 0.2385041852375258,
      "grad_norm": 3.0299267768859863,
      "learning_rate": 0.00015231538517283862,
      "loss": 0.1612,
      "step": 3291
    },
    {
      "epoch": 0.23857665688299454,
      "grad_norm": 1.7508642673492432,
      "learning_rate": 0.0001523008913689398,
      "loss": 0.1404,
      "step": 3292
    },
    {
      "epoch": 0.23864912852846323,
      "grad_norm": 0.9023568630218506,
      "learning_rate": 0.00015228639756504096,
      "loss": 0.0564,
      "step": 3293
    },
    {
      "epoch": 0.23872160017393196,
      "grad_norm": 3.3123762607574463,
      "learning_rate": 0.00015227190376114212,
      "loss": 0.1309,
      "step": 3294
    },
    {
      "epoch": 0.23879407181940066,
      "grad_norm": 1.1888970136642456,
      "learning_rate": 0.0001522574099572433,
      "loss": 0.036,
      "step": 3295
    },
    {
      "epoch": 0.23886654346486938,
      "grad_norm": 1.334026575088501,
      "learning_rate": 0.00015224291615334446,
      "loss": 0.082,
      "step": 3296
    },
    {
      "epoch": 0.23893901511033808,
      "grad_norm": 1.4827734231948853,
      "learning_rate": 0.0001522284223494456,
      "loss": 0.0667,
      "step": 3297
    },
    {
      "epoch": 0.2390114867558068,
      "grad_norm": 5.818456649780273,
      "learning_rate": 0.0001522139285455468,
      "loss": 0.1826,
      "step": 3298
    },
    {
      "epoch": 0.2390839584012755,
      "grad_norm": 0.8155729174613953,
      "learning_rate": 0.00015219943474164795,
      "loss": 0.0207,
      "step": 3299
    },
    {
      "epoch": 0.23915643004674422,
      "grad_norm": 1.196854591369629,
      "learning_rate": 0.0001521849409377491,
      "loss": 0.1018,
      "step": 3300
    },
    {
      "epoch": 0.23922890169221292,
      "grad_norm": 1.4627448320388794,
      "learning_rate": 0.0001521704471338503,
      "loss": 0.0704,
      "step": 3301
    },
    {
      "epoch": 0.23930137333768164,
      "grad_norm": 1.0898851156234741,
      "learning_rate": 0.00015215595332995145,
      "loss": 0.049,
      "step": 3302
    },
    {
      "epoch": 0.23937384498315034,
      "grad_norm": 1.5316733121871948,
      "learning_rate": 0.0001521414595260526,
      "loss": 0.0868,
      "step": 3303
    },
    {
      "epoch": 0.23944631662861907,
      "grad_norm": 3.2184104919433594,
      "learning_rate": 0.0001521269657221538,
      "loss": 0.1474,
      "step": 3304
    },
    {
      "epoch": 0.23951878827408776,
      "grad_norm": 1.2248222827911377,
      "learning_rate": 0.00015211247191825495,
      "loss": 0.0389,
      "step": 3305
    },
    {
      "epoch": 0.2395912599195565,
      "grad_norm": 3.1412158012390137,
      "learning_rate": 0.0001520979781143561,
      "loss": 0.1042,
      "step": 3306
    },
    {
      "epoch": 0.23966373156502518,
      "grad_norm": 0.48883891105651855,
      "learning_rate": 0.00015208348431045729,
      "loss": 0.0231,
      "step": 3307
    },
    {
      "epoch": 0.23973620321049388,
      "grad_norm": 2.185464382171631,
      "learning_rate": 0.00015206899050655844,
      "loss": 0.1267,
      "step": 3308
    },
    {
      "epoch": 0.2398086748559626,
      "grad_norm": 3.256298542022705,
      "learning_rate": 0.0001520544967026596,
      "loss": 0.1707,
      "step": 3309
    },
    {
      "epoch": 0.2398811465014313,
      "grad_norm": 0.883823037147522,
      "learning_rate": 0.00015204000289876078,
      "loss": 0.0285,
      "step": 3310
    },
    {
      "epoch": 0.23995361814690003,
      "grad_norm": 1.4533034563064575,
      "learning_rate": 0.00015202550909486194,
      "loss": 0.0798,
      "step": 3311
    },
    {
      "epoch": 0.24002608979236872,
      "grad_norm": 1.6578941345214844,
      "learning_rate": 0.00015201101529096312,
      "loss": 0.0644,
      "step": 3312
    },
    {
      "epoch": 0.24009856143783745,
      "grad_norm": 6.303485870361328,
      "learning_rate": 0.00015199652148706428,
      "loss": 0.1003,
      "step": 3313
    },
    {
      "epoch": 0.24017103308330615,
      "grad_norm": 2.4464550018310547,
      "learning_rate": 0.00015198202768316546,
      "loss": 0.0486,
      "step": 3314
    },
    {
      "epoch": 0.24024350472877487,
      "grad_norm": 2.2375524044036865,
      "learning_rate": 0.00015196753387926662,
      "loss": 0.0818,
      "step": 3315
    },
    {
      "epoch": 0.24031597637424357,
      "grad_norm": 1.9446316957473755,
      "learning_rate": 0.0001519530400753678,
      "loss": 0.0946,
      "step": 3316
    },
    {
      "epoch": 0.2403884480197123,
      "grad_norm": 3.1080892086029053,
      "learning_rate": 0.00015193854627146896,
      "loss": 0.1222,
      "step": 3317
    },
    {
      "epoch": 0.240460919665181,
      "grad_norm": 1.7131986618041992,
      "learning_rate": 0.00015192405246757011,
      "loss": 0.1015,
      "step": 3318
    },
    {
      "epoch": 0.2405333913106497,
      "grad_norm": 3.5773699283599854,
      "learning_rate": 0.0001519095586636713,
      "loss": 0.2347,
      "step": 3319
    },
    {
      "epoch": 0.2406058629561184,
      "grad_norm": 2.0245563983917236,
      "learning_rate": 0.00015189506485977246,
      "loss": 0.1594,
      "step": 3320
    },
    {
      "epoch": 0.24067833460158713,
      "grad_norm": 0.8614035248756409,
      "learning_rate": 0.0001518805710558736,
      "loss": 0.0165,
      "step": 3321
    },
    {
      "epoch": 0.24075080624705583,
      "grad_norm": 1.7105209827423096,
      "learning_rate": 0.0001518660772519748,
      "loss": 0.1061,
      "step": 3322
    },
    {
      "epoch": 0.24082327789252456,
      "grad_norm": 1.8698722124099731,
      "learning_rate": 0.00015185158344807595,
      "loss": 0.0803,
      "step": 3323
    },
    {
      "epoch": 0.24089574953799325,
      "grad_norm": 0.9226605296134949,
      "learning_rate": 0.0001518370896441771,
      "loss": 0.0715,
      "step": 3324
    },
    {
      "epoch": 0.24096822118346198,
      "grad_norm": 3.691453218460083,
      "learning_rate": 0.0001518225958402783,
      "loss": 0.2096,
      "step": 3325
    },
    {
      "epoch": 0.24104069282893067,
      "grad_norm": 2.0884974002838135,
      "learning_rate": 0.00015180810203637945,
      "loss": 0.1165,
      "step": 3326
    },
    {
      "epoch": 0.2411131644743994,
      "grad_norm": 2.7491018772125244,
      "learning_rate": 0.0001517936082324806,
      "loss": 0.056,
      "step": 3327
    },
    {
      "epoch": 0.2411856361198681,
      "grad_norm": 0.9684414863586426,
      "learning_rate": 0.0001517791144285818,
      "loss": 0.0569,
      "step": 3328
    },
    {
      "epoch": 0.24125810776533682,
      "grad_norm": 4.166203498840332,
      "learning_rate": 0.00015176462062468294,
      "loss": 0.0773,
      "step": 3329
    },
    {
      "epoch": 0.24133057941080552,
      "grad_norm": 1.6497459411621094,
      "learning_rate": 0.00015175012682078413,
      "loss": 0.0482,
      "step": 3330
    },
    {
      "epoch": 0.24140305105627424,
      "grad_norm": 3.7662413120269775,
      "learning_rate": 0.00015173563301688528,
      "loss": 0.1484,
      "step": 3331
    },
    {
      "epoch": 0.24147552270174294,
      "grad_norm": 3.6166911125183105,
      "learning_rate": 0.00015172113921298644,
      "loss": 0.0961,
      "step": 3332
    },
    {
      "epoch": 0.24154799434721166,
      "grad_norm": 0.538936972618103,
      "learning_rate": 0.00015170664540908762,
      "loss": 0.0244,
      "step": 3333
    },
    {
      "epoch": 0.24162046599268036,
      "grad_norm": 1.1492244005203247,
      "learning_rate": 0.00015169215160518878,
      "loss": 0.0614,
      "step": 3334
    },
    {
      "epoch": 0.24169293763814909,
      "grad_norm": 2.6148784160614014,
      "learning_rate": 0.00015167765780128996,
      "loss": 0.0697,
      "step": 3335
    },
    {
      "epoch": 0.24176540928361778,
      "grad_norm": 2.699007034301758,
      "learning_rate": 0.00015166316399739112,
      "loss": 0.1642,
      "step": 3336
    },
    {
      "epoch": 0.2418378809290865,
      "grad_norm": 1.4175853729248047,
      "learning_rate": 0.0001516486701934923,
      "loss": 0.0305,
      "step": 3337
    },
    {
      "epoch": 0.2419103525745552,
      "grad_norm": 2.31881046295166,
      "learning_rate": 0.00015163417638959346,
      "loss": 0.1246,
      "step": 3338
    },
    {
      "epoch": 0.24198282422002393,
      "grad_norm": 1.4519065618515015,
      "learning_rate": 0.00015161968258569465,
      "loss": 0.0687,
      "step": 3339
    },
    {
      "epoch": 0.24205529586549263,
      "grad_norm": 2.7104268074035645,
      "learning_rate": 0.0001516051887817958,
      "loss": 0.1188,
      "step": 3340
    },
    {
      "epoch": 0.24212776751096132,
      "grad_norm": 2.2811384201049805,
      "learning_rate": 0.00015159069497789696,
      "loss": 0.049,
      "step": 3341
    },
    {
      "epoch": 0.24220023915643005,
      "grad_norm": 1.6591883897781372,
      "learning_rate": 0.00015157620117399814,
      "loss": 0.1001,
      "step": 3342
    },
    {
      "epoch": 0.24227271080189874,
      "grad_norm": 1.6933225393295288,
      "learning_rate": 0.0001515617073700993,
      "loss": 0.0681,
      "step": 3343
    },
    {
      "epoch": 0.24234518244736747,
      "grad_norm": 1.6272835731506348,
      "learning_rate": 0.00015154721356620045,
      "loss": 0.1379,
      "step": 3344
    },
    {
      "epoch": 0.24241765409283617,
      "grad_norm": 0.8426344394683838,
      "learning_rate": 0.00015153271976230164,
      "loss": 0.0125,
      "step": 3345
    },
    {
      "epoch": 0.2424901257383049,
      "grad_norm": 0.7076666355133057,
      "learning_rate": 0.0001515182259584028,
      "loss": 0.0126,
      "step": 3346
    },
    {
      "epoch": 0.2425625973837736,
      "grad_norm": 1.2093807458877563,
      "learning_rate": 0.00015150373215450395,
      "loss": 0.054,
      "step": 3347
    },
    {
      "epoch": 0.2426350690292423,
      "grad_norm": 0.580285370349884,
      "learning_rate": 0.00015148923835060513,
      "loss": 0.0188,
      "step": 3348
    },
    {
      "epoch": 0.242707540674711,
      "grad_norm": 0.848059356212616,
      "learning_rate": 0.0001514747445467063,
      "loss": 0.0599,
      "step": 3349
    },
    {
      "epoch": 0.24278001232017973,
      "grad_norm": 2.5079715251922607,
      "learning_rate": 0.00015146025074280745,
      "loss": 0.0692,
      "step": 3350
    },
    {
      "epoch": 0.24285248396564843,
      "grad_norm": 0.9639308452606201,
      "learning_rate": 0.00015144575693890863,
      "loss": 0.0375,
      "step": 3351
    },
    {
      "epoch": 0.24292495561111715,
      "grad_norm": 1.493806004524231,
      "learning_rate": 0.0001514312631350098,
      "loss": 0.0839,
      "step": 3352
    },
    {
      "epoch": 0.24299742725658585,
      "grad_norm": 3.7835564613342285,
      "learning_rate": 0.00015141676933111094,
      "loss": 0.1433,
      "step": 3353
    },
    {
      "epoch": 0.24306989890205458,
      "grad_norm": 0.7775623202323914,
      "learning_rate": 0.00015140227552721213,
      "loss": 0.0452,
      "step": 3354
    },
    {
      "epoch": 0.24314237054752327,
      "grad_norm": 2.801461935043335,
      "learning_rate": 0.00015138778172331328,
      "loss": 0.0585,
      "step": 3355
    },
    {
      "epoch": 0.243214842192992,
      "grad_norm": 2.724935293197632,
      "learning_rate": 0.00015137328791941444,
      "loss": 0.0613,
      "step": 3356
    },
    {
      "epoch": 0.2432873138384607,
      "grad_norm": 0.7480066418647766,
      "learning_rate": 0.00015135879411551562,
      "loss": 0.0415,
      "step": 3357
    },
    {
      "epoch": 0.24335978548392942,
      "grad_norm": 4.793900012969971,
      "learning_rate": 0.00015134430031161678,
      "loss": 0.175,
      "step": 3358
    },
    {
      "epoch": 0.24343225712939812,
      "grad_norm": 1.489121437072754,
      "learning_rate": 0.00015132980650771796,
      "loss": 0.0646,
      "step": 3359
    },
    {
      "epoch": 0.24350472877486684,
      "grad_norm": 3.142230272293091,
      "learning_rate": 0.00015131531270381912,
      "loss": 0.1856,
      "step": 3360
    },
    {
      "epoch": 0.24357720042033554,
      "grad_norm": 0.5082643628120422,
      "learning_rate": 0.0001513008188999203,
      "loss": 0.0152,
      "step": 3361
    },
    {
      "epoch": 0.24364967206580426,
      "grad_norm": 1.1633245944976807,
      "learning_rate": 0.00015128632509602146,
      "loss": 0.0641,
      "step": 3362
    },
    {
      "epoch": 0.24372214371127296,
      "grad_norm": 5.525934219360352,
      "learning_rate": 0.00015127183129212264,
      "loss": 0.1161,
      "step": 3363
    },
    {
      "epoch": 0.24379461535674168,
      "grad_norm": 4.620271682739258,
      "learning_rate": 0.0001512573374882238,
      "loss": 0.1725,
      "step": 3364
    },
    {
      "epoch": 0.24386708700221038,
      "grad_norm": 1.5632929801940918,
      "learning_rate": 0.00015124284368432496,
      "loss": 0.0588,
      "step": 3365
    },
    {
      "epoch": 0.2439395586476791,
      "grad_norm": 0.5071166157722473,
      "learning_rate": 0.00015122834988042614,
      "loss": 0.0186,
      "step": 3366
    },
    {
      "epoch": 0.2440120302931478,
      "grad_norm": 4.019278526306152,
      "learning_rate": 0.0001512138560765273,
      "loss": 0.2803,
      "step": 3367
    },
    {
      "epoch": 0.24408450193861653,
      "grad_norm": 1.987108826637268,
      "learning_rate": 0.00015119936227262845,
      "loss": 0.1496,
      "step": 3368
    },
    {
      "epoch": 0.24415697358408522,
      "grad_norm": 1.980191946029663,
      "learning_rate": 0.00015118486846872964,
      "loss": 0.0939,
      "step": 3369
    },
    {
      "epoch": 0.24422944522955395,
      "grad_norm": 0.6153913736343384,
      "learning_rate": 0.0001511703746648308,
      "loss": 0.0183,
      "step": 3370
    },
    {
      "epoch": 0.24430191687502265,
      "grad_norm": 2.270709276199341,
      "learning_rate": 0.00015115588086093195,
      "loss": 0.056,
      "step": 3371
    },
    {
      "epoch": 0.24437438852049137,
      "grad_norm": 0.7861217260360718,
      "learning_rate": 0.00015114138705703313,
      "loss": 0.0266,
      "step": 3372
    },
    {
      "epoch": 0.24444686016596007,
      "grad_norm": 4.101675987243652,
      "learning_rate": 0.0001511268932531343,
      "loss": 0.1473,
      "step": 3373
    },
    {
      "epoch": 0.2445193318114288,
      "grad_norm": 3.2345831394195557,
      "learning_rate": 0.00015111239944923545,
      "loss": 0.0361,
      "step": 3374
    },
    {
      "epoch": 0.2445918034568975,
      "grad_norm": 1.8431849479675293,
      "learning_rate": 0.00015109790564533663,
      "loss": 0.1272,
      "step": 3375
    },
    {
      "epoch": 0.24466427510236619,
      "grad_norm": 1.3456145524978638,
      "learning_rate": 0.0001510834118414378,
      "loss": 0.0355,
      "step": 3376
    },
    {
      "epoch": 0.2447367467478349,
      "grad_norm": 4.849013805389404,
      "learning_rate": 0.00015106891803753894,
      "loss": 0.1853,
      "step": 3377
    },
    {
      "epoch": 0.2448092183933036,
      "grad_norm": 1.6068943738937378,
      "learning_rate": 0.00015105442423364013,
      "loss": 0.1017,
      "step": 3378
    },
    {
      "epoch": 0.24488169003877233,
      "grad_norm": 8.45140266418457,
      "learning_rate": 0.00015103993042974128,
      "loss": 0.1206,
      "step": 3379
    },
    {
      "epoch": 0.24495416168424103,
      "grad_norm": 1.599360704421997,
      "learning_rate": 0.00015102543662584244,
      "loss": 0.0704,
      "step": 3380
    },
    {
      "epoch": 0.24502663332970975,
      "grad_norm": 1.102813720703125,
      "learning_rate": 0.00015101094282194362,
      "loss": 0.1126,
      "step": 3381
    },
    {
      "epoch": 0.24509910497517845,
      "grad_norm": 1.7127035856246948,
      "learning_rate": 0.0001509964490180448,
      "loss": 0.1291,
      "step": 3382
    },
    {
      "epoch": 0.24517157662064717,
      "grad_norm": 2.7089571952819824,
      "learning_rate": 0.00015098195521414596,
      "loss": 0.1249,
      "step": 3383
    },
    {
      "epoch": 0.24524404826611587,
      "grad_norm": 2.129164218902588,
      "learning_rate": 0.00015096746141024715,
      "loss": 0.1397,
      "step": 3384
    },
    {
      "epoch": 0.2453165199115846,
      "grad_norm": 0.895976722240448,
      "learning_rate": 0.0001509529676063483,
      "loss": 0.0567,
      "step": 3385
    },
    {
      "epoch": 0.2453889915570533,
      "grad_norm": 2.323362350463867,
      "learning_rate": 0.00015093847380244946,
      "loss": 0.1823,
      "step": 3386
    },
    {
      "epoch": 0.24546146320252202,
      "grad_norm": 0.27558672428131104,
      "learning_rate": 0.00015092397999855064,
      "loss": 0.0172,
      "step": 3387
    },
    {
      "epoch": 0.24553393484799071,
      "grad_norm": 2.8080902099609375,
      "learning_rate": 0.0001509094861946518,
      "loss": 0.1761,
      "step": 3388
    },
    {
      "epoch": 0.24560640649345944,
      "grad_norm": 1.5982565879821777,
      "learning_rate": 0.00015089499239075296,
      "loss": 0.0991,
      "step": 3389
    },
    {
      "epoch": 0.24567887813892814,
      "grad_norm": 1.585533618927002,
      "learning_rate": 0.00015088049858685414,
      "loss": 0.0682,
      "step": 3390
    },
    {
      "epoch": 0.24575134978439686,
      "grad_norm": 0.9317215085029602,
      "learning_rate": 0.0001508660047829553,
      "loss": 0.0547,
      "step": 3391
    },
    {
      "epoch": 0.24582382142986556,
      "grad_norm": 1.142195701599121,
      "learning_rate": 0.00015085151097905645,
      "loss": 0.0363,
      "step": 3392
    },
    {
      "epoch": 0.24589629307533428,
      "grad_norm": 0.6554014682769775,
      "learning_rate": 0.00015083701717515764,
      "loss": 0.0443,
      "step": 3393
    },
    {
      "epoch": 0.24596876472080298,
      "grad_norm": 0.5670879483222961,
      "learning_rate": 0.0001508225233712588,
      "loss": 0.047,
      "step": 3394
    },
    {
      "epoch": 0.2460412363662717,
      "grad_norm": 0.6949446797370911,
      "learning_rate": 0.00015080802956735995,
      "loss": 0.0224,
      "step": 3395
    },
    {
      "epoch": 0.2461137080117404,
      "grad_norm": 1.488804817199707,
      "learning_rate": 0.00015079353576346113,
      "loss": 0.0493,
      "step": 3396
    },
    {
      "epoch": 0.24618617965720913,
      "grad_norm": 2.1525607109069824,
      "learning_rate": 0.0001507790419595623,
      "loss": 0.127,
      "step": 3397
    },
    {
      "epoch": 0.24625865130267782,
      "grad_norm": 1.1819342374801636,
      "learning_rate": 0.00015076454815566345,
      "loss": 0.0497,
      "step": 3398
    },
    {
      "epoch": 0.24633112294814655,
      "grad_norm": 1.7427327632904053,
      "learning_rate": 0.00015075005435176463,
      "loss": 0.13,
      "step": 3399
    },
    {
      "epoch": 0.24640359459361524,
      "grad_norm": 3.1467196941375732,
      "learning_rate": 0.0001507355605478658,
      "loss": 0.1828,
      "step": 3400
    },
    {
      "epoch": 0.24647606623908397,
      "grad_norm": 1.658534049987793,
      "learning_rate": 0.00015072106674396694,
      "loss": 0.1127,
      "step": 3401
    },
    {
      "epoch": 0.24654853788455267,
      "grad_norm": 2.1723392009735107,
      "learning_rate": 0.00015070657294006813,
      "loss": 0.138,
      "step": 3402
    },
    {
      "epoch": 0.2466210095300214,
      "grad_norm": 0.8311641216278076,
      "learning_rate": 0.00015069207913616928,
      "loss": 0.0487,
      "step": 3403
    },
    {
      "epoch": 0.2466934811754901,
      "grad_norm": 0.45634207129478455,
      "learning_rate": 0.00015067758533227047,
      "loss": 0.0454,
      "step": 3404
    },
    {
      "epoch": 0.2467659528209588,
      "grad_norm": 0.8333228826522827,
      "learning_rate": 0.00015066309152837162,
      "loss": 0.0707,
      "step": 3405
    },
    {
      "epoch": 0.2468384244664275,
      "grad_norm": 1.0739620923995972,
      "learning_rate": 0.0001506485977244728,
      "loss": 0.0453,
      "step": 3406
    },
    {
      "epoch": 0.24691089611189623,
      "grad_norm": 1.377049446105957,
      "learning_rate": 0.00015063410392057396,
      "loss": 0.055,
      "step": 3407
    },
    {
      "epoch": 0.24698336775736493,
      "grad_norm": 1.2730379104614258,
      "learning_rate": 0.00015061961011667515,
      "loss": 0.0741,
      "step": 3408
    },
    {
      "epoch": 0.24705583940283365,
      "grad_norm": 1.8506721258163452,
      "learning_rate": 0.0001506051163127763,
      "loss": 0.165,
      "step": 3409
    },
    {
      "epoch": 0.24712831104830235,
      "grad_norm": 1.1810472011566162,
      "learning_rate": 0.00015059062250887746,
      "loss": 0.0838,
      "step": 3410
    },
    {
      "epoch": 0.24720078269377105,
      "grad_norm": 2.2900571823120117,
      "learning_rate": 0.00015057612870497864,
      "loss": 0.0891,
      "step": 3411
    },
    {
      "epoch": 0.24727325433923977,
      "grad_norm": 2.8513948917388916,
      "learning_rate": 0.0001505616349010798,
      "loss": 0.0796,
      "step": 3412
    },
    {
      "epoch": 0.24734572598470847,
      "grad_norm": 1.9619910717010498,
      "learning_rate": 0.00015054714109718096,
      "loss": 0.1149,
      "step": 3413
    },
    {
      "epoch": 0.2474181976301772,
      "grad_norm": 0.865727961063385,
      "learning_rate": 0.00015053264729328214,
      "loss": 0.0838,
      "step": 3414
    },
    {
      "epoch": 0.2474906692756459,
      "grad_norm": 2.913830518722534,
      "learning_rate": 0.0001505181534893833,
      "loss": 0.0801,
      "step": 3415
    },
    {
      "epoch": 0.24756314092111462,
      "grad_norm": 1.0264005661010742,
      "learning_rate": 0.00015050365968548445,
      "loss": 0.0611,
      "step": 3416
    },
    {
      "epoch": 0.2476356125665833,
      "grad_norm": 1.0865693092346191,
      "learning_rate": 0.00015048916588158564,
      "loss": 0.0593,
      "step": 3417
    },
    {
      "epoch": 0.24770808421205204,
      "grad_norm": 0.9146007299423218,
      "learning_rate": 0.0001504746720776868,
      "loss": 0.0345,
      "step": 3418
    },
    {
      "epoch": 0.24778055585752073,
      "grad_norm": 3.360562801361084,
      "learning_rate": 0.00015046017827378795,
      "loss": 0.0952,
      "step": 3419
    },
    {
      "epoch": 0.24785302750298946,
      "grad_norm": 3.6536905765533447,
      "learning_rate": 0.00015044568446988913,
      "loss": 0.1102,
      "step": 3420
    },
    {
      "epoch": 0.24792549914845816,
      "grad_norm": 1.943433403968811,
      "learning_rate": 0.0001504311906659903,
      "loss": 0.1355,
      "step": 3421
    },
    {
      "epoch": 0.24799797079392688,
      "grad_norm": 1.408643126487732,
      "learning_rate": 0.00015041669686209145,
      "loss": 0.0549,
      "step": 3422
    },
    {
      "epoch": 0.24807044243939558,
      "grad_norm": 3.4291820526123047,
      "learning_rate": 0.00015040220305819263,
      "loss": 0.1557,
      "step": 3423
    },
    {
      "epoch": 0.2481429140848643,
      "grad_norm": 2.3802812099456787,
      "learning_rate": 0.0001503877092542938,
      "loss": 0.1576,
      "step": 3424
    },
    {
      "epoch": 0.248215385730333,
      "grad_norm": 1.3118205070495605,
      "learning_rate": 0.00015037321545039494,
      "loss": 0.0772,
      "step": 3425
    },
    {
      "epoch": 0.24828785737580172,
      "grad_norm": 2.2973155975341797,
      "learning_rate": 0.00015035872164649613,
      "loss": 0.1133,
      "step": 3426
    },
    {
      "epoch": 0.24836032902127042,
      "grad_norm": 3.329432487487793,
      "learning_rate": 0.00015034422784259728,
      "loss": 0.1364,
      "step": 3427
    },
    {
      "epoch": 0.24843280066673915,
      "grad_norm": 1.7336633205413818,
      "learning_rate": 0.00015032973403869847,
      "loss": 0.1118,
      "step": 3428
    },
    {
      "epoch": 0.24850527231220784,
      "grad_norm": 0.30884474515914917,
      "learning_rate": 0.00015031524023479965,
      "loss": 0.0084,
      "step": 3429
    },
    {
      "epoch": 0.24857774395767657,
      "grad_norm": 3.2083346843719482,
      "learning_rate": 0.0001503007464309008,
      "loss": 0.1341,
      "step": 3430
    },
    {
      "epoch": 0.24865021560314526,
      "grad_norm": 1.994902491569519,
      "learning_rate": 0.00015028625262700196,
      "loss": 0.0485,
      "step": 3431
    },
    {
      "epoch": 0.248722687248614,
      "grad_norm": 6.14385986328125,
      "learning_rate": 0.00015027175882310315,
      "loss": 0.0408,
      "step": 3432
    },
    {
      "epoch": 0.24879515889408269,
      "grad_norm": 1.2693531513214111,
      "learning_rate": 0.0001502572650192043,
      "loss": 0.0867,
      "step": 3433
    },
    {
      "epoch": 0.2488676305395514,
      "grad_norm": 1.5512945652008057,
      "learning_rate": 0.00015024277121530546,
      "loss": 0.0885,
      "step": 3434
    },
    {
      "epoch": 0.2489401021850201,
      "grad_norm": 3.4360406398773193,
      "learning_rate": 0.00015022827741140664,
      "loss": 0.0637,
      "step": 3435
    },
    {
      "epoch": 0.24901257383048883,
      "grad_norm": 0.8746065497398376,
      "learning_rate": 0.0001502137836075078,
      "loss": 0.0607,
      "step": 3436
    },
    {
      "epoch": 0.24908504547595753,
      "grad_norm": 2.061164379119873,
      "learning_rate": 0.00015019928980360896,
      "loss": 0.073,
      "step": 3437
    },
    {
      "epoch": 0.24915751712142625,
      "grad_norm": 1.6461071968078613,
      "learning_rate": 0.00015018479599971014,
      "loss": 0.0493,
      "step": 3438
    },
    {
      "epoch": 0.24922998876689495,
      "grad_norm": 1.0060323476791382,
      "learning_rate": 0.0001501703021958113,
      "loss": 0.037,
      "step": 3439
    },
    {
      "epoch": 0.24930246041236367,
      "grad_norm": 1.4369635581970215,
      "learning_rate": 0.00015015580839191245,
      "loss": 0.0899,
      "step": 3440
    },
    {
      "epoch": 0.24937493205783237,
      "grad_norm": 1.3755991458892822,
      "learning_rate": 0.00015014131458801364,
      "loss": 0.0657,
      "step": 3441
    },
    {
      "epoch": 0.2494474037033011,
      "grad_norm": 1.1112284660339355,
      "learning_rate": 0.0001501268207841148,
      "loss": 0.0496,
      "step": 3442
    },
    {
      "epoch": 0.2495198753487698,
      "grad_norm": 2.903754472732544,
      "learning_rate": 0.00015011232698021595,
      "loss": 0.0565,
      "step": 3443
    },
    {
      "epoch": 0.24959234699423852,
      "grad_norm": 2.9755513668060303,
      "learning_rate": 0.00015009783317631713,
      "loss": 0.1414,
      "step": 3444
    },
    {
      "epoch": 0.24966481863970721,
      "grad_norm": 1.2932472229003906,
      "learning_rate": 0.0001500833393724183,
      "loss": 0.0674,
      "step": 3445
    },
    {
      "epoch": 0.2497372902851759,
      "grad_norm": 1.4118820428848267,
      "learning_rate": 0.00015006884556851945,
      "loss": 0.1103,
      "step": 3446
    },
    {
      "epoch": 0.24980976193064464,
      "grad_norm": 4.512496471405029,
      "learning_rate": 0.00015005435176462063,
      "loss": 0.1687,
      "step": 3447
    },
    {
      "epoch": 0.24988223357611333,
      "grad_norm": 1.1095268726348877,
      "learning_rate": 0.00015003985796072179,
      "loss": 0.0564,
      "step": 3448
    },
    {
      "epoch": 0.24995470522158206,
      "grad_norm": 1.7007746696472168,
      "learning_rate": 0.00015002536415682294,
      "loss": 0.0337,
      "step": 3449
    },
    {
      "epoch": 0.2500271768670508,
      "grad_norm": 0.8243526816368103,
      "learning_rate": 0.00015001087035292413,
      "loss": 0.0576,
      "step": 3450
    },
    {
      "epoch": 0.2500996485125195,
      "grad_norm": 1.5926873683929443,
      "learning_rate": 0.0001499963765490253,
      "loss": 0.0401,
      "step": 3451
    },
    {
      "epoch": 0.2501721201579882,
      "grad_norm": 1.266147494316101,
      "learning_rate": 0.00014998188274512647,
      "loss": 0.0799,
      "step": 3452
    },
    {
      "epoch": 0.2502445918034569,
      "grad_norm": 1.4918464422225952,
      "learning_rate": 0.00014996738894122765,
      "loss": 0.1139,
      "step": 3453
    },
    {
      "epoch": 0.2503170634489256,
      "grad_norm": 0.7262272238731384,
      "learning_rate": 0.0001499528951373288,
      "loss": 0.051,
      "step": 3454
    },
    {
      "epoch": 0.2503895350943943,
      "grad_norm": 1.3673683404922485,
      "learning_rate": 0.00014993840133342996,
      "loss": 0.1223,
      "step": 3455
    },
    {
      "epoch": 0.250462006739863,
      "grad_norm": 0.5448102355003357,
      "learning_rate": 0.00014992390752953115,
      "loss": 0.0264,
      "step": 3456
    },
    {
      "epoch": 0.2505344783853317,
      "grad_norm": 1.4118785858154297,
      "learning_rate": 0.0001499094137256323,
      "loss": 0.0763,
      "step": 3457
    },
    {
      "epoch": 0.25060695003080047,
      "grad_norm": 0.5670624375343323,
      "learning_rate": 0.00014989491992173346,
      "loss": 0.0435,
      "step": 3458
    },
    {
      "epoch": 0.25067942167626917,
      "grad_norm": 4.180376052856445,
      "learning_rate": 0.00014988042611783464,
      "loss": 0.0669,
      "step": 3459
    },
    {
      "epoch": 0.25075189332173786,
      "grad_norm": 1.493212103843689,
      "learning_rate": 0.0001498659323139358,
      "loss": 0.0381,
      "step": 3460
    },
    {
      "epoch": 0.25082436496720656,
      "grad_norm": 2.984018087387085,
      "learning_rate": 0.00014985143851003696,
      "loss": 0.1317,
      "step": 3461
    },
    {
      "epoch": 0.2508968366126753,
      "grad_norm": 4.2441558837890625,
      "learning_rate": 0.00014983694470613814,
      "loss": 0.3223,
      "step": 3462
    },
    {
      "epoch": 0.250969308258144,
      "grad_norm": 3.8589916229248047,
      "learning_rate": 0.0001498224509022393,
      "loss": 0.1587,
      "step": 3463
    },
    {
      "epoch": 0.2510417799036127,
      "grad_norm": 0.9524838328361511,
      "learning_rate": 0.00014980795709834045,
      "loss": 0.0513,
      "step": 3464
    },
    {
      "epoch": 0.2511142515490814,
      "grad_norm": 2.6657118797302246,
      "learning_rate": 0.00014979346329444164,
      "loss": 0.121,
      "step": 3465
    },
    {
      "epoch": 0.25118672319455015,
      "grad_norm": 1.8020093441009521,
      "learning_rate": 0.0001497789694905428,
      "loss": 0.1056,
      "step": 3466
    },
    {
      "epoch": 0.25125919484001885,
      "grad_norm": 1.996648907661438,
      "learning_rate": 0.00014976447568664395,
      "loss": 0.0262,
      "step": 3467
    },
    {
      "epoch": 0.25133166648548755,
      "grad_norm": 2.3021678924560547,
      "learning_rate": 0.00014974998188274513,
      "loss": 0.0765,
      "step": 3468
    },
    {
      "epoch": 0.25140413813095625,
      "grad_norm": 0.31025880575180054,
      "learning_rate": 0.0001497354880788463,
      "loss": 0.0102,
      "step": 3469
    },
    {
      "epoch": 0.251476609776425,
      "grad_norm": 1.6246002912521362,
      "learning_rate": 0.00014972099427494745,
      "loss": 0.044,
      "step": 3470
    },
    {
      "epoch": 0.2515490814218937,
      "grad_norm": 12.59139633178711,
      "learning_rate": 0.00014970650047104863,
      "loss": 0.1176,
      "step": 3471
    },
    {
      "epoch": 0.2516215530673624,
      "grad_norm": 1.2374504804611206,
      "learning_rate": 0.00014969200666714979,
      "loss": 0.0358,
      "step": 3472
    },
    {
      "epoch": 0.2516940247128311,
      "grad_norm": 4.675734519958496,
      "learning_rate": 0.00014967751286325097,
      "loss": 0.0489,
      "step": 3473
    },
    {
      "epoch": 0.25176649635829984,
      "grad_norm": 3.258256196975708,
      "learning_rate": 0.00014966301905935213,
      "loss": 0.1887,
      "step": 3474
    },
    {
      "epoch": 0.25183896800376854,
      "grad_norm": 1.5206377506256104,
      "learning_rate": 0.0001496485252554533,
      "loss": 0.0601,
      "step": 3475
    },
    {
      "epoch": 0.25191143964923723,
      "grad_norm": 1.654890775680542,
      "learning_rate": 0.00014963403145155447,
      "loss": 0.0808,
      "step": 3476
    },
    {
      "epoch": 0.25198391129470593,
      "grad_norm": 5.835735321044922,
      "learning_rate": 0.00014961953764765565,
      "loss": 0.2445,
      "step": 3477
    },
    {
      "epoch": 0.2520563829401747,
      "grad_norm": 2.8179450035095215,
      "learning_rate": 0.0001496050438437568,
      "loss": 0.1312,
      "step": 3478
    },
    {
      "epoch": 0.2521288545856434,
      "grad_norm": 1.7268762588500977,
      "learning_rate": 0.00014959055003985796,
      "loss": 0.0858,
      "step": 3479
    },
    {
      "epoch": 0.2522013262311121,
      "grad_norm": 2.2568209171295166,
      "learning_rate": 0.00014957605623595915,
      "loss": 0.0753,
      "step": 3480
    },
    {
      "epoch": 0.2522737978765808,
      "grad_norm": 1.2416473627090454,
      "learning_rate": 0.0001495615624320603,
      "loss": 0.0331,
      "step": 3481
    },
    {
      "epoch": 0.25234626952204947,
      "grad_norm": 1.0287460088729858,
      "learning_rate": 0.00014954706862816146,
      "loss": 0.0833,
      "step": 3482
    },
    {
      "epoch": 0.2524187411675182,
      "grad_norm": 2.3750264644622803,
      "learning_rate": 0.00014953257482426264,
      "loss": 0.1403,
      "step": 3483
    },
    {
      "epoch": 0.2524912128129869,
      "grad_norm": 0.5622336864471436,
      "learning_rate": 0.0001495180810203638,
      "loss": 0.0148,
      "step": 3484
    },
    {
      "epoch": 0.2525636844584556,
      "grad_norm": 2.551913022994995,
      "learning_rate": 0.00014950358721646496,
      "loss": 0.1569,
      "step": 3485
    },
    {
      "epoch": 0.2526361561039243,
      "grad_norm": 1.0763448476791382,
      "learning_rate": 0.00014948909341256614,
      "loss": 0.0703,
      "step": 3486
    },
    {
      "epoch": 0.25270862774939307,
      "grad_norm": 1.5008314847946167,
      "learning_rate": 0.0001494745996086673,
      "loss": 0.0671,
      "step": 3487
    },
    {
      "epoch": 0.25278109939486176,
      "grad_norm": 2.8477272987365723,
      "learning_rate": 0.00014946010580476845,
      "loss": 0.0912,
      "step": 3488
    },
    {
      "epoch": 0.25285357104033046,
      "grad_norm": 1.0032329559326172,
      "learning_rate": 0.00014944561200086964,
      "loss": 0.0318,
      "step": 3489
    },
    {
      "epoch": 0.25292604268579916,
      "grad_norm": 3.2508959770202637,
      "learning_rate": 0.0001494311181969708,
      "loss": 0.1101,
      "step": 3490
    },
    {
      "epoch": 0.2529985143312679,
      "grad_norm": 0.6419294476509094,
      "learning_rate": 0.00014941662439307195,
      "loss": 0.054,
      "step": 3491
    },
    {
      "epoch": 0.2530709859767366,
      "grad_norm": 3.7708847522735596,
      "learning_rate": 0.00014940213058917313,
      "loss": 0.0695,
      "step": 3492
    },
    {
      "epoch": 0.2531434576222053,
      "grad_norm": 7.153858184814453,
      "learning_rate": 0.0001493876367852743,
      "loss": 0.0762,
      "step": 3493
    },
    {
      "epoch": 0.253215929267674,
      "grad_norm": 0.7502964735031128,
      "learning_rate": 0.00014937314298137547,
      "loss": 0.0404,
      "step": 3494
    },
    {
      "epoch": 0.25328840091314275,
      "grad_norm": 3.5361926555633545,
      "learning_rate": 0.00014935864917747663,
      "loss": 0.0567,
      "step": 3495
    },
    {
      "epoch": 0.25336087255861145,
      "grad_norm": 1.5356014966964722,
      "learning_rate": 0.00014934415537357779,
      "loss": 0.0652,
      "step": 3496
    },
    {
      "epoch": 0.25343334420408015,
      "grad_norm": 1.0282025337219238,
      "learning_rate": 0.00014932966156967897,
      "loss": 0.043,
      "step": 3497
    },
    {
      "epoch": 0.25350581584954884,
      "grad_norm": 0.7636952996253967,
      "learning_rate": 0.00014931516776578015,
      "loss": 0.0546,
      "step": 3498
    },
    {
      "epoch": 0.2535782874950176,
      "grad_norm": 1.5171868801116943,
      "learning_rate": 0.0001493006739618813,
      "loss": 0.1335,
      "step": 3499
    },
    {
      "epoch": 0.2536507591404863,
      "grad_norm": 4.897678852081299,
      "learning_rate": 0.0001492861801579825,
      "loss": 0.1255,
      "step": 3500
    },
    {
      "epoch": 0.253723230785955,
      "grad_norm": 5.991415500640869,
      "learning_rate": 0.00014927168635408365,
      "loss": 0.096,
      "step": 3501
    },
    {
      "epoch": 0.2537957024314237,
      "grad_norm": 1.6702978610992432,
      "learning_rate": 0.0001492571925501848,
      "loss": 0.0113,
      "step": 3502
    },
    {
      "epoch": 0.25386817407689244,
      "grad_norm": 5.589145660400391,
      "learning_rate": 0.000149242698746286,
      "loss": 0.0962,
      "step": 3503
    },
    {
      "epoch": 0.25394064572236114,
      "grad_norm": 3.4616103172302246,
      "learning_rate": 0.00014922820494238715,
      "loss": 0.0442,
      "step": 3504
    },
    {
      "epoch": 0.25401311736782983,
      "grad_norm": 4.557753086090088,
      "learning_rate": 0.0001492137111384883,
      "loss": 0.0238,
      "step": 3505
    },
    {
      "epoch": 0.25408558901329853,
      "grad_norm": 1.5377991199493408,
      "learning_rate": 0.00014919921733458949,
      "loss": 0.0483,
      "step": 3506
    },
    {
      "epoch": 0.2541580606587673,
      "grad_norm": 5.589317321777344,
      "learning_rate": 0.00014918472353069064,
      "loss": 0.1131,
      "step": 3507
    },
    {
      "epoch": 0.254230532304236,
      "grad_norm": 3.3616507053375244,
      "learning_rate": 0.0001491702297267918,
      "loss": 0.0759,
      "step": 3508
    },
    {
      "epoch": 0.2543030039497047,
      "grad_norm": 4.727691173553467,
      "learning_rate": 0.00014915573592289298,
      "loss": 0.0648,
      "step": 3509
    },
    {
      "epoch": 0.2543754755951734,
      "grad_norm": 2.9811060428619385,
      "learning_rate": 0.00014914124211899414,
      "loss": 0.2621,
      "step": 3510
    },
    {
      "epoch": 0.2544479472406421,
      "grad_norm": 2.600843906402588,
      "learning_rate": 0.0001491267483150953,
      "loss": 0.102,
      "step": 3511
    },
    {
      "epoch": 0.2545204188861108,
      "grad_norm": 1.1135164499282837,
      "learning_rate": 0.00014911225451119648,
      "loss": 0.0596,
      "step": 3512
    },
    {
      "epoch": 0.2545928905315795,
      "grad_norm": 1.756097435951233,
      "learning_rate": 0.00014909776070729764,
      "loss": 0.1475,
      "step": 3513
    },
    {
      "epoch": 0.2546653621770482,
      "grad_norm": 1.5448983907699585,
      "learning_rate": 0.0001490832669033988,
      "loss": 0.0727,
      "step": 3514
    },
    {
      "epoch": 0.2547378338225169,
      "grad_norm": 2.017639636993408,
      "learning_rate": 0.00014906877309949998,
      "loss": 0.0708,
      "step": 3515
    },
    {
      "epoch": 0.25481030546798566,
      "grad_norm": 6.858598232269287,
      "learning_rate": 0.00014905427929560113,
      "loss": 0.287,
      "step": 3516
    },
    {
      "epoch": 0.25488277711345436,
      "grad_norm": 3.803053140640259,
      "learning_rate": 0.0001490397854917023,
      "loss": 0.1457,
      "step": 3517
    },
    {
      "epoch": 0.25495524875892306,
      "grad_norm": 4.627501487731934,
      "learning_rate": 0.00014902529168780347,
      "loss": 0.0267,
      "step": 3518
    },
    {
      "epoch": 0.25502772040439176,
      "grad_norm": 4.103227615356445,
      "learning_rate": 0.00014901079788390463,
      "loss": 0.0305,
      "step": 3519
    },
    {
      "epoch": 0.2551001920498605,
      "grad_norm": 1.4754236936569214,
      "learning_rate": 0.0001489963040800058,
      "loss": 0.1184,
      "step": 3520
    },
    {
      "epoch": 0.2551726636953292,
      "grad_norm": 1.346161961555481,
      "learning_rate": 0.00014898181027610697,
      "loss": 0.0339,
      "step": 3521
    },
    {
      "epoch": 0.2552451353407979,
      "grad_norm": 1.1860345602035522,
      "learning_rate": 0.00014896731647220815,
      "loss": 0.0161,
      "step": 3522
    },
    {
      "epoch": 0.2553176069862666,
      "grad_norm": 3.226515531539917,
      "learning_rate": 0.0001489528226683093,
      "loss": 0.1213,
      "step": 3523
    },
    {
      "epoch": 0.25539007863173535,
      "grad_norm": 2.019272804260254,
      "learning_rate": 0.0001489383288644105,
      "loss": 0.0971,
      "step": 3524
    },
    {
      "epoch": 0.25546255027720405,
      "grad_norm": 2.977532148361206,
      "learning_rate": 0.00014892383506051165,
      "loss": 0.1388,
      "step": 3525
    },
    {
      "epoch": 0.25553502192267274,
      "grad_norm": 1.7143210172653198,
      "learning_rate": 0.0001489093412566128,
      "loss": 0.1259,
      "step": 3526
    },
    {
      "epoch": 0.25560749356814144,
      "grad_norm": 0.47812750935554504,
      "learning_rate": 0.000148894847452714,
      "loss": 0.0441,
      "step": 3527
    },
    {
      "epoch": 0.2556799652136102,
      "grad_norm": 1.8717881441116333,
      "learning_rate": 0.00014888035364881515,
      "loss": 0.0703,
      "step": 3528
    },
    {
      "epoch": 0.2557524368590789,
      "grad_norm": 1.7988301515579224,
      "learning_rate": 0.0001488658598449163,
      "loss": 0.1011,
      "step": 3529
    },
    {
      "epoch": 0.2558249085045476,
      "grad_norm": 1.8854252099990845,
      "learning_rate": 0.00014885136604101749,
      "loss": 0.1191,
      "step": 3530
    },
    {
      "epoch": 0.2558973801500163,
      "grad_norm": 2.339625597000122,
      "learning_rate": 0.00014883687223711864,
      "loss": 0.0748,
      "step": 3531
    },
    {
      "epoch": 0.25596985179548504,
      "grad_norm": 2.095427989959717,
      "learning_rate": 0.0001488223784332198,
      "loss": 0.1417,
      "step": 3532
    },
    {
      "epoch": 0.25604232344095373,
      "grad_norm": 3.6058430671691895,
      "learning_rate": 0.00014880788462932098,
      "loss": 0.158,
      "step": 3533
    },
    {
      "epoch": 0.25611479508642243,
      "grad_norm": 2.236576795578003,
      "learning_rate": 0.00014879339082542214,
      "loss": 0.0567,
      "step": 3534
    },
    {
      "epoch": 0.25618726673189113,
      "grad_norm": 1.5095406770706177,
      "learning_rate": 0.0001487788970215233,
      "loss": 0.102,
      "step": 3535
    },
    {
      "epoch": 0.2562597383773599,
      "grad_norm": 1.8774274587631226,
      "learning_rate": 0.00014876440321762448,
      "loss": 0.1016,
      "step": 3536
    },
    {
      "epoch": 0.2563322100228286,
      "grad_norm": 1.9160853624343872,
      "learning_rate": 0.00014874990941372563,
      "loss": 0.0804,
      "step": 3537
    },
    {
      "epoch": 0.2564046816682973,
      "grad_norm": 2.1076388359069824,
      "learning_rate": 0.0001487354156098268,
      "loss": 0.0624,
      "step": 3538
    },
    {
      "epoch": 0.25647715331376597,
      "grad_norm": 1.8263736963272095,
      "learning_rate": 0.00014872092180592798,
      "loss": 0.0808,
      "step": 3539
    },
    {
      "epoch": 0.2565496249592347,
      "grad_norm": 2.446763753890991,
      "learning_rate": 0.00014870642800202913,
      "loss": 0.1044,
      "step": 3540
    },
    {
      "epoch": 0.2566220966047034,
      "grad_norm": 1.3782092332839966,
      "learning_rate": 0.0001486919341981303,
      "loss": 0.0546,
      "step": 3541
    },
    {
      "epoch": 0.2566945682501721,
      "grad_norm": 4.33615779876709,
      "learning_rate": 0.00014867744039423147,
      "loss": 0.2053,
      "step": 3542
    },
    {
      "epoch": 0.2567670398956408,
      "grad_norm": 2.3890247344970703,
      "learning_rate": 0.00014866294659033263,
      "loss": 0.0652,
      "step": 3543
    },
    {
      "epoch": 0.25683951154110957,
      "grad_norm": 0.785000741481781,
      "learning_rate": 0.0001486484527864338,
      "loss": 0.0252,
      "step": 3544
    },
    {
      "epoch": 0.25691198318657826,
      "grad_norm": 2.4959895610809326,
      "learning_rate": 0.000148633958982535,
      "loss": 0.0964,
      "step": 3545
    },
    {
      "epoch": 0.25698445483204696,
      "grad_norm": 1.3390438556671143,
      "learning_rate": 0.00014861946517863615,
      "loss": 0.0939,
      "step": 3546
    },
    {
      "epoch": 0.25705692647751566,
      "grad_norm": 1.3846235275268555,
      "learning_rate": 0.0001486049713747373,
      "loss": 0.078,
      "step": 3547
    },
    {
      "epoch": 0.2571293981229844,
      "grad_norm": 1.3631911277770996,
      "learning_rate": 0.0001485904775708385,
      "loss": 0.0641,
      "step": 3548
    },
    {
      "epoch": 0.2572018697684531,
      "grad_norm": 1.2997405529022217,
      "learning_rate": 0.00014857598376693965,
      "loss": 0.0594,
      "step": 3549
    },
    {
      "epoch": 0.2572743414139218,
      "grad_norm": 4.248258113861084,
      "learning_rate": 0.0001485614899630408,
      "loss": 0.3321,
      "step": 3550
    },
    {
      "epoch": 0.2573468130593905,
      "grad_norm": 3.186124086380005,
      "learning_rate": 0.000148546996159142,
      "loss": 0.1332,
      "step": 3551
    },
    {
      "epoch": 0.2574192847048592,
      "grad_norm": 3.2311480045318604,
      "learning_rate": 0.00014853250235524314,
      "loss": 0.112,
      "step": 3552
    },
    {
      "epoch": 0.25749175635032795,
      "grad_norm": 2.606741189956665,
      "learning_rate": 0.0001485180085513443,
      "loss": 0.1424,
      "step": 3553
    },
    {
      "epoch": 0.25756422799579665,
      "grad_norm": 0.9945389032363892,
      "learning_rate": 0.00014850351474744548,
      "loss": 0.0393,
      "step": 3554
    },
    {
      "epoch": 0.25763669964126534,
      "grad_norm": 0.2695501744747162,
      "learning_rate": 0.00014848902094354664,
      "loss": 0.0046,
      "step": 3555
    },
    {
      "epoch": 0.25770917128673404,
      "grad_norm": 4.296133518218994,
      "learning_rate": 0.0001484745271396478,
      "loss": 0.148,
      "step": 3556
    },
    {
      "epoch": 0.2577816429322028,
      "grad_norm": 1.139575481414795,
      "learning_rate": 0.00014846003333574898,
      "loss": 0.0444,
      "step": 3557
    },
    {
      "epoch": 0.2578541145776715,
      "grad_norm": 0.623100757598877,
      "learning_rate": 0.00014844553953185014,
      "loss": 0.0272,
      "step": 3558
    },
    {
      "epoch": 0.2579265862231402,
      "grad_norm": 5.874107360839844,
      "learning_rate": 0.0001484310457279513,
      "loss": 0.0809,
      "step": 3559
    },
    {
      "epoch": 0.2579990578686089,
      "grad_norm": 3.6858322620391846,
      "learning_rate": 0.00014841655192405248,
      "loss": 0.0964,
      "step": 3560
    },
    {
      "epoch": 0.25807152951407764,
      "grad_norm": 3.156189203262329,
      "learning_rate": 0.00014840205812015363,
      "loss": 0.0853,
      "step": 3561
    },
    {
      "epoch": 0.25814400115954633,
      "grad_norm": 2.0201051235198975,
      "learning_rate": 0.0001483875643162548,
      "loss": 0.0529,
      "step": 3562
    },
    {
      "epoch": 0.25821647280501503,
      "grad_norm": 1.678167700767517,
      "learning_rate": 0.00014837307051235597,
      "loss": 0.0548,
      "step": 3563
    },
    {
      "epoch": 0.2582889444504837,
      "grad_norm": 1.2989252805709839,
      "learning_rate": 0.00014835857670845713,
      "loss": 0.0448,
      "step": 3564
    },
    {
      "epoch": 0.2583614160959525,
      "grad_norm": 1.5962096452713013,
      "learning_rate": 0.00014834408290455831,
      "loss": 0.0785,
      "step": 3565
    },
    {
      "epoch": 0.2584338877414212,
      "grad_norm": 0.5362985730171204,
      "learning_rate": 0.00014832958910065947,
      "loss": 0.0326,
      "step": 3566
    },
    {
      "epoch": 0.2585063593868899,
      "grad_norm": 2.675233840942383,
      "learning_rate": 0.00014831509529676065,
      "loss": 0.0457,
      "step": 3567
    },
    {
      "epoch": 0.25857883103235857,
      "grad_norm": 1.219462513923645,
      "learning_rate": 0.0001483006014928618,
      "loss": 0.0807,
      "step": 3568
    },
    {
      "epoch": 0.2586513026778273,
      "grad_norm": 1.3610635995864868,
      "learning_rate": 0.000148286107688963,
      "loss": 0.0468,
      "step": 3569
    },
    {
      "epoch": 0.258723774323296,
      "grad_norm": 1.7949669361114502,
      "learning_rate": 0.00014827161388506415,
      "loss": 0.0654,
      "step": 3570
    },
    {
      "epoch": 0.2587962459687647,
      "grad_norm": 0.8440501689910889,
      "learning_rate": 0.0001482571200811653,
      "loss": 0.0225,
      "step": 3571
    },
    {
      "epoch": 0.2588687176142334,
      "grad_norm": 3.116586685180664,
      "learning_rate": 0.0001482426262772665,
      "loss": 0.0937,
      "step": 3572
    },
    {
      "epoch": 0.25894118925970216,
      "grad_norm": 4.30549955368042,
      "learning_rate": 0.00014822813247336765,
      "loss": 0.1569,
      "step": 3573
    },
    {
      "epoch": 0.25901366090517086,
      "grad_norm": 1.2189643383026123,
      "learning_rate": 0.0001482136386694688,
      "loss": 0.068,
      "step": 3574
    },
    {
      "epoch": 0.25908613255063956,
      "grad_norm": 1.7264049053192139,
      "learning_rate": 0.00014819914486557,
      "loss": 0.0283,
      "step": 3575
    },
    {
      "epoch": 0.25915860419610826,
      "grad_norm": 5.5063886642456055,
      "learning_rate": 0.00014818465106167114,
      "loss": 0.1302,
      "step": 3576
    },
    {
      "epoch": 0.259231075841577,
      "grad_norm": 3.558378219604492,
      "learning_rate": 0.0001481701572577723,
      "loss": 0.1232,
      "step": 3577
    },
    {
      "epoch": 0.2593035474870457,
      "grad_norm": 0.9542403817176819,
      "learning_rate": 0.00014815566345387348,
      "loss": 0.0565,
      "step": 3578
    },
    {
      "epoch": 0.2593760191325144,
      "grad_norm": 0.6906246542930603,
      "learning_rate": 0.00014814116964997464,
      "loss": 0.031,
      "step": 3579
    },
    {
      "epoch": 0.2594484907779831,
      "grad_norm": 2.339475631713867,
      "learning_rate": 0.0001481266758460758,
      "loss": 0.1778,
      "step": 3580
    },
    {
      "epoch": 0.25952096242345185,
      "grad_norm": 1.4652925729751587,
      "learning_rate": 0.00014811218204217698,
      "loss": 0.0571,
      "step": 3581
    },
    {
      "epoch": 0.25959343406892055,
      "grad_norm": 1.1407055854797363,
      "learning_rate": 0.00014809768823827814,
      "loss": 0.0754,
      "step": 3582
    },
    {
      "epoch": 0.25966590571438924,
      "grad_norm": 3.047102451324463,
      "learning_rate": 0.0001480831944343793,
      "loss": 0.0749,
      "step": 3583
    },
    {
      "epoch": 0.25973837735985794,
      "grad_norm": 1.2121280431747437,
      "learning_rate": 0.00014806870063048048,
      "loss": 0.0337,
      "step": 3584
    },
    {
      "epoch": 0.25981084900532664,
      "grad_norm": 1.631181001663208,
      "learning_rate": 0.00014805420682658163,
      "loss": 0.0502,
      "step": 3585
    },
    {
      "epoch": 0.2598833206507954,
      "grad_norm": 3.3879587650299072,
      "learning_rate": 0.0001480397130226828,
      "loss": 0.1106,
      "step": 3586
    },
    {
      "epoch": 0.2599557922962641,
      "grad_norm": 2.645441770553589,
      "learning_rate": 0.00014802521921878397,
      "loss": 0.101,
      "step": 3587
    },
    {
      "epoch": 0.2600282639417328,
      "grad_norm": 3.192857503890991,
      "learning_rate": 0.00014801072541488513,
      "loss": 0.126,
      "step": 3588
    },
    {
      "epoch": 0.2601007355872015,
      "grad_norm": 1.0218443870544434,
      "learning_rate": 0.00014799623161098631,
      "loss": 0.0731,
      "step": 3589
    },
    {
      "epoch": 0.26017320723267023,
      "grad_norm": 0.660965085029602,
      "learning_rate": 0.00014798173780708747,
      "loss": 0.0175,
      "step": 3590
    },
    {
      "epoch": 0.26024567887813893,
      "grad_norm": 1.0819787979125977,
      "learning_rate": 0.00014796724400318865,
      "loss": 0.0748,
      "step": 3591
    },
    {
      "epoch": 0.2603181505236076,
      "grad_norm": 3.2015960216522217,
      "learning_rate": 0.0001479527501992898,
      "loss": 0.2051,
      "step": 3592
    },
    {
      "epoch": 0.2603906221690763,
      "grad_norm": 1.210806965827942,
      "learning_rate": 0.000147938256395391,
      "loss": 0.029,
      "step": 3593
    },
    {
      "epoch": 0.2604630938145451,
      "grad_norm": 1.577540397644043,
      "learning_rate": 0.00014792376259149215,
      "loss": 0.0646,
      "step": 3594
    },
    {
      "epoch": 0.2605355654600138,
      "grad_norm": 0.801550567150116,
      "learning_rate": 0.0001479092687875933,
      "loss": 0.0445,
      "step": 3595
    },
    {
      "epoch": 0.26060803710548247,
      "grad_norm": 0.7159741520881653,
      "learning_rate": 0.0001478947749836945,
      "loss": 0.0774,
      "step": 3596
    },
    {
      "epoch": 0.26068050875095117,
      "grad_norm": 0.8042230606079102,
      "learning_rate": 0.00014788028117979565,
      "loss": 0.0699,
      "step": 3597
    },
    {
      "epoch": 0.2607529803964199,
      "grad_norm": 1.0057615041732788,
      "learning_rate": 0.0001478657873758968,
      "loss": 0.0263,
      "step": 3598
    },
    {
      "epoch": 0.2608254520418886,
      "grad_norm": 2.2344069480895996,
      "learning_rate": 0.000147851293571998,
      "loss": 0.0326,
      "step": 3599
    },
    {
      "epoch": 0.2608979236873573,
      "grad_norm": 2.112053871154785,
      "learning_rate": 0.00014783679976809914,
      "loss": 0.0631,
      "step": 3600
    },
    {
      "epoch": 0.260970395332826,
      "grad_norm": 1.5345689058303833,
      "learning_rate": 0.0001478223059642003,
      "loss": 0.0368,
      "step": 3601
    },
    {
      "epoch": 0.26104286697829476,
      "grad_norm": 1.4149309396743774,
      "learning_rate": 0.00014780781216030148,
      "loss": 0.0701,
      "step": 3602
    },
    {
      "epoch": 0.26111533862376346,
      "grad_norm": 0.6960694789886475,
      "learning_rate": 0.00014779331835640264,
      "loss": 0.0325,
      "step": 3603
    },
    {
      "epoch": 0.26118781026923216,
      "grad_norm": 1.4866888523101807,
      "learning_rate": 0.0001477788245525038,
      "loss": 0.0375,
      "step": 3604
    },
    {
      "epoch": 0.26126028191470085,
      "grad_norm": 1.1485813856124878,
      "learning_rate": 0.00014776433074860498,
      "loss": 0.0688,
      "step": 3605
    },
    {
      "epoch": 0.2613327535601696,
      "grad_norm": 1.5652793645858765,
      "learning_rate": 0.00014774983694470614,
      "loss": 0.101,
      "step": 3606
    },
    {
      "epoch": 0.2614052252056383,
      "grad_norm": 1.023525595664978,
      "learning_rate": 0.0001477353431408073,
      "loss": 0.0111,
      "step": 3607
    },
    {
      "epoch": 0.261477696851107,
      "grad_norm": 2.815937042236328,
      "learning_rate": 0.00014772084933690848,
      "loss": 0.1005,
      "step": 3608
    },
    {
      "epoch": 0.2615501684965757,
      "grad_norm": 1.38056218624115,
      "learning_rate": 0.00014770635553300963,
      "loss": 0.0698,
      "step": 3609
    },
    {
      "epoch": 0.26162264014204445,
      "grad_norm": 1.3760141134262085,
      "learning_rate": 0.0001476918617291108,
      "loss": 0.1271,
      "step": 3610
    },
    {
      "epoch": 0.26169511178751315,
      "grad_norm": 3.5511527061462402,
      "learning_rate": 0.00014767736792521197,
      "loss": 0.0979,
      "step": 3611
    },
    {
      "epoch": 0.26176758343298184,
      "grad_norm": 5.99786901473999,
      "learning_rate": 0.00014766287412131316,
      "loss": 0.1251,
      "step": 3612
    },
    {
      "epoch": 0.26184005507845054,
      "grad_norm": 2.827143669128418,
      "learning_rate": 0.00014764838031741431,
      "loss": 0.058,
      "step": 3613
    },
    {
      "epoch": 0.2619125267239193,
      "grad_norm": 1.0060406923294067,
      "learning_rate": 0.0001476338865135155,
      "loss": 0.0469,
      "step": 3614
    },
    {
      "epoch": 0.261984998369388,
      "grad_norm": 4.743847370147705,
      "learning_rate": 0.00014761939270961665,
      "loss": 0.1119,
      "step": 3615
    },
    {
      "epoch": 0.2620574700148567,
      "grad_norm": 2.078294515609741,
      "learning_rate": 0.0001476048989057178,
      "loss": 0.107,
      "step": 3616
    },
    {
      "epoch": 0.2621299416603254,
      "grad_norm": 2.7692832946777344,
      "learning_rate": 0.000147590405101819,
      "loss": 0.1205,
      "step": 3617
    },
    {
      "epoch": 0.26220241330579414,
      "grad_norm": 2.4488136768341064,
      "learning_rate": 0.00014757591129792015,
      "loss": 0.0676,
      "step": 3618
    },
    {
      "epoch": 0.26227488495126283,
      "grad_norm": 2.239806652069092,
      "learning_rate": 0.0001475614174940213,
      "loss": 0.1953,
      "step": 3619
    },
    {
      "epoch": 0.26234735659673153,
      "grad_norm": 1.3456065654754639,
      "learning_rate": 0.0001475469236901225,
      "loss": 0.0366,
      "step": 3620
    },
    {
      "epoch": 0.2624198282422002,
      "grad_norm": 3.170940637588501,
      "learning_rate": 0.00014753242988622365,
      "loss": 0.1656,
      "step": 3621
    },
    {
      "epoch": 0.2624922998876689,
      "grad_norm": 1.1903482675552368,
      "learning_rate": 0.0001475179360823248,
      "loss": 0.0587,
      "step": 3622
    },
    {
      "epoch": 0.2625647715331377,
      "grad_norm": 2.861666440963745,
      "learning_rate": 0.000147503442278426,
      "loss": 0.0427,
      "step": 3623
    },
    {
      "epoch": 0.26263724317860637,
      "grad_norm": 1.4120910167694092,
      "learning_rate": 0.00014748894847452714,
      "loss": 0.0651,
      "step": 3624
    },
    {
      "epoch": 0.26270971482407507,
      "grad_norm": 0.311968594789505,
      "learning_rate": 0.0001474744546706283,
      "loss": 0.0052,
      "step": 3625
    },
    {
      "epoch": 0.26278218646954377,
      "grad_norm": 8.71433162689209,
      "learning_rate": 0.00014745996086672948,
      "loss": 0.1402,
      "step": 3626
    },
    {
      "epoch": 0.2628546581150125,
      "grad_norm": 1.9240351915359497,
      "learning_rate": 0.00014744546706283064,
      "loss": 0.076,
      "step": 3627
    },
    {
      "epoch": 0.2629271297604812,
      "grad_norm": 0.8398791551589966,
      "learning_rate": 0.0001474309732589318,
      "loss": 0.0684,
      "step": 3628
    },
    {
      "epoch": 0.2629996014059499,
      "grad_norm": 3.458589553833008,
      "learning_rate": 0.00014741647945503298,
      "loss": 0.1966,
      "step": 3629
    },
    {
      "epoch": 0.2630720730514186,
      "grad_norm": 3.845242500305176,
      "learning_rate": 0.00014740198565113414,
      "loss": 0.1707,
      "step": 3630
    },
    {
      "epoch": 0.26314454469688736,
      "grad_norm": 2.1087794303894043,
      "learning_rate": 0.0001473874918472353,
      "loss": 0.052,
      "step": 3631
    },
    {
      "epoch": 0.26321701634235606,
      "grad_norm": 0.9042068719863892,
      "learning_rate": 0.00014737299804333648,
      "loss": 0.0901,
      "step": 3632
    },
    {
      "epoch": 0.26328948798782476,
      "grad_norm": 0.458658903837204,
      "learning_rate": 0.00014735850423943763,
      "loss": 0.0206,
      "step": 3633
    },
    {
      "epoch": 0.26336195963329345,
      "grad_norm": 0.6340630054473877,
      "learning_rate": 0.00014734401043553882,
      "loss": 0.0276,
      "step": 3634
    },
    {
      "epoch": 0.2634344312787622,
      "grad_norm": 0.8647485971450806,
      "learning_rate": 0.00014732951663163997,
      "loss": 0.0581,
      "step": 3635
    },
    {
      "epoch": 0.2635069029242309,
      "grad_norm": 2.9081387519836426,
      "learning_rate": 0.00014731502282774116,
      "loss": 0.0845,
      "step": 3636
    },
    {
      "epoch": 0.2635793745696996,
      "grad_norm": 2.720754623413086,
      "learning_rate": 0.0001473005290238423,
      "loss": 0.1921,
      "step": 3637
    },
    {
      "epoch": 0.2636518462151683,
      "grad_norm": 1.9088990688323975,
      "learning_rate": 0.0001472860352199435,
      "loss": 0.0577,
      "step": 3638
    },
    {
      "epoch": 0.26372431786063705,
      "grad_norm": 2.0688958168029785,
      "learning_rate": 0.00014727154141604465,
      "loss": 0.0884,
      "step": 3639
    },
    {
      "epoch": 0.26379678950610574,
      "grad_norm": 1.001740574836731,
      "learning_rate": 0.0001472570476121458,
      "loss": 0.0673,
      "step": 3640
    },
    {
      "epoch": 0.26386926115157444,
      "grad_norm": 1.3062270879745483,
      "learning_rate": 0.000147242553808247,
      "loss": 0.0487,
      "step": 3641
    },
    {
      "epoch": 0.26394173279704314,
      "grad_norm": 5.172676086425781,
      "learning_rate": 0.00014722806000434815,
      "loss": 0.1349,
      "step": 3642
    },
    {
      "epoch": 0.2640142044425119,
      "grad_norm": 2.5909690856933594,
      "learning_rate": 0.0001472135662004493,
      "loss": 0.0795,
      "step": 3643
    },
    {
      "epoch": 0.2640866760879806,
      "grad_norm": 1.5634571313858032,
      "learning_rate": 0.0001471990723965505,
      "loss": 0.0753,
      "step": 3644
    },
    {
      "epoch": 0.2641591477334493,
      "grad_norm": 1.1362491846084595,
      "learning_rate": 0.00014718457859265165,
      "loss": 0.0336,
      "step": 3645
    },
    {
      "epoch": 0.264231619378918,
      "grad_norm": 1.6038568019866943,
      "learning_rate": 0.0001471700847887528,
      "loss": 0.062,
      "step": 3646
    },
    {
      "epoch": 0.26430409102438673,
      "grad_norm": 1.6049126386642456,
      "learning_rate": 0.000147155590984854,
      "loss": 0.0921,
      "step": 3647
    },
    {
      "epoch": 0.26437656266985543,
      "grad_norm": 1.7791452407836914,
      "learning_rate": 0.00014714109718095514,
      "loss": 0.0549,
      "step": 3648
    },
    {
      "epoch": 0.2644490343153241,
      "grad_norm": 0.4917774498462677,
      "learning_rate": 0.0001471266033770563,
      "loss": 0.018,
      "step": 3649
    },
    {
      "epoch": 0.2645215059607928,
      "grad_norm": 5.335105895996094,
      "learning_rate": 0.00014711210957315748,
      "loss": 0.2408,
      "step": 3650
    },
    {
      "epoch": 0.2645939776062616,
      "grad_norm": 0.8766303062438965,
      "learning_rate": 0.00014709761576925864,
      "loss": 0.0639,
      "step": 3651
    },
    {
      "epoch": 0.2646664492517303,
      "grad_norm": 0.8749645948410034,
      "learning_rate": 0.0001470831219653598,
      "loss": 0.0701,
      "step": 3652
    },
    {
      "epoch": 0.26473892089719897,
      "grad_norm": 2.6453890800476074,
      "learning_rate": 0.00014706862816146098,
      "loss": 0.1404,
      "step": 3653
    },
    {
      "epoch": 0.26481139254266767,
      "grad_norm": 1.5130503177642822,
      "learning_rate": 0.00014705413435756214,
      "loss": 0.1181,
      "step": 3654
    },
    {
      "epoch": 0.26488386418813636,
      "grad_norm": 2.3749852180480957,
      "learning_rate": 0.00014703964055366332,
      "loss": 0.063,
      "step": 3655
    },
    {
      "epoch": 0.2649563358336051,
      "grad_norm": 0.6985965967178345,
      "learning_rate": 0.00014702514674976448,
      "loss": 0.0455,
      "step": 3656
    },
    {
      "epoch": 0.2650288074790738,
      "grad_norm": 0.8959426283836365,
      "learning_rate": 0.00014701065294586563,
      "loss": 0.0505,
      "step": 3657
    },
    {
      "epoch": 0.2651012791245425,
      "grad_norm": 2.174246311187744,
      "learning_rate": 0.00014699615914196682,
      "loss": 0.0711,
      "step": 3658
    },
    {
      "epoch": 0.2651737507700112,
      "grad_norm": 1.3125654458999634,
      "learning_rate": 0.00014698166533806797,
      "loss": 0.0351,
      "step": 3659
    },
    {
      "epoch": 0.26524622241547996,
      "grad_norm": 6.812685012817383,
      "learning_rate": 0.00014696717153416916,
      "loss": 0.1717,
      "step": 3660
    },
    {
      "epoch": 0.26531869406094866,
      "grad_norm": 2.057697296142578,
      "learning_rate": 0.00014695267773027034,
      "loss": 0.0782,
      "step": 3661
    },
    {
      "epoch": 0.26539116570641735,
      "grad_norm": 1.516039490699768,
      "learning_rate": 0.0001469381839263715,
      "loss": 0.0348,
      "step": 3662
    },
    {
      "epoch": 0.26546363735188605,
      "grad_norm": 4.263140678405762,
      "learning_rate": 0.00014692369012247265,
      "loss": 0.1165,
      "step": 3663
    },
    {
      "epoch": 0.2655361089973548,
      "grad_norm": 7.06815242767334,
      "learning_rate": 0.00014690919631857384,
      "loss": 0.2437,
      "step": 3664
    },
    {
      "epoch": 0.2656085806428235,
      "grad_norm": 3.2551305294036865,
      "learning_rate": 0.000146894702514675,
      "loss": 0.129,
      "step": 3665
    },
    {
      "epoch": 0.2656810522882922,
      "grad_norm": 6.260554313659668,
      "learning_rate": 0.00014688020871077615,
      "loss": 0.0758,
      "step": 3666
    },
    {
      "epoch": 0.2657535239337609,
      "grad_norm": 0.7088811993598938,
      "learning_rate": 0.00014686571490687733,
      "loss": 0.0134,
      "step": 3667
    },
    {
      "epoch": 0.26582599557922965,
      "grad_norm": 1.4922938346862793,
      "learning_rate": 0.0001468512211029785,
      "loss": 0.0269,
      "step": 3668
    },
    {
      "epoch": 0.26589846722469834,
      "grad_norm": 1.0722154378890991,
      "learning_rate": 0.00014683672729907965,
      "loss": 0.1128,
      "step": 3669
    },
    {
      "epoch": 0.26597093887016704,
      "grad_norm": 4.606974124908447,
      "learning_rate": 0.00014682223349518083,
      "loss": 0.1087,
      "step": 3670
    },
    {
      "epoch": 0.26604341051563574,
      "grad_norm": 1.3150088787078857,
      "learning_rate": 0.00014680773969128199,
      "loss": 0.0517,
      "step": 3671
    },
    {
      "epoch": 0.2661158821611045,
      "grad_norm": 3.8779385089874268,
      "learning_rate": 0.00014679324588738314,
      "loss": 0.3207,
      "step": 3672
    },
    {
      "epoch": 0.2661883538065732,
      "grad_norm": 2.8126001358032227,
      "learning_rate": 0.00014677875208348433,
      "loss": 0.0949,
      "step": 3673
    },
    {
      "epoch": 0.2662608254520419,
      "grad_norm": 2.023754358291626,
      "learning_rate": 0.00014676425827958548,
      "loss": 0.1509,
      "step": 3674
    },
    {
      "epoch": 0.2663332970975106,
      "grad_norm": 6.047685146331787,
      "learning_rate": 0.00014674976447568664,
      "loss": 0.163,
      "step": 3675
    },
    {
      "epoch": 0.26640576874297933,
      "grad_norm": 3.561222553253174,
      "learning_rate": 0.00014673527067178782,
      "loss": 0.0805,
      "step": 3676
    },
    {
      "epoch": 0.26647824038844803,
      "grad_norm": 0.9461691975593567,
      "learning_rate": 0.00014672077686788898,
      "loss": 0.0827,
      "step": 3677
    },
    {
      "epoch": 0.2665507120339167,
      "grad_norm": 1.1283752918243408,
      "learning_rate": 0.00014670628306399014,
      "loss": 0.048,
      "step": 3678
    },
    {
      "epoch": 0.2666231836793854,
      "grad_norm": 2.2979867458343506,
      "learning_rate": 0.00014669178926009132,
      "loss": 0.0924,
      "step": 3679
    },
    {
      "epoch": 0.2666956553248542,
      "grad_norm": 0.8020358681678772,
      "learning_rate": 0.00014667729545619248,
      "loss": 0.1102,
      "step": 3680
    },
    {
      "epoch": 0.26676812697032287,
      "grad_norm": 0.788636326789856,
      "learning_rate": 0.00014666280165229366,
      "loss": 0.0911,
      "step": 3681
    },
    {
      "epoch": 0.26684059861579157,
      "grad_norm": 2.6175482273101807,
      "learning_rate": 0.00014664830784839482,
      "loss": 0.0888,
      "step": 3682
    },
    {
      "epoch": 0.26691307026126027,
      "grad_norm": 0.5392648577690125,
      "learning_rate": 0.000146633814044496,
      "loss": 0.0249,
      "step": 3683
    },
    {
      "epoch": 0.266985541906729,
      "grad_norm": 3.1069788932800293,
      "learning_rate": 0.00014661932024059716,
      "loss": 0.1393,
      "step": 3684
    },
    {
      "epoch": 0.2670580135521977,
      "grad_norm": 1.7549693584442139,
      "learning_rate": 0.00014660482643669834,
      "loss": 0.0814,
      "step": 3685
    },
    {
      "epoch": 0.2671304851976664,
      "grad_norm": 0.8478889465332031,
      "learning_rate": 0.0001465903326327995,
      "loss": 0.0246,
      "step": 3686
    },
    {
      "epoch": 0.2672029568431351,
      "grad_norm": 0.7126715183258057,
      "learning_rate": 0.00014657583882890065,
      "loss": 0.0801,
      "step": 3687
    },
    {
      "epoch": 0.26727542848860386,
      "grad_norm": 1.3685593605041504,
      "learning_rate": 0.00014656134502500184,
      "loss": 0.1026,
      "step": 3688
    },
    {
      "epoch": 0.26734790013407256,
      "grad_norm": 2.5635929107666016,
      "learning_rate": 0.000146546851221103,
      "loss": 0.1878,
      "step": 3689
    },
    {
      "epoch": 0.26742037177954125,
      "grad_norm": 3.698821544647217,
      "learning_rate": 0.00014653235741720415,
      "loss": 0.0967,
      "step": 3690
    },
    {
      "epoch": 0.26749284342500995,
      "grad_norm": 4.450935363769531,
      "learning_rate": 0.00014651786361330533,
      "loss": 0.243,
      "step": 3691
    },
    {
      "epoch": 0.26756531507047865,
      "grad_norm": 3.3269388675689697,
      "learning_rate": 0.0001465033698094065,
      "loss": 0.1413,
      "step": 3692
    },
    {
      "epoch": 0.2676377867159474,
      "grad_norm": 5.741732597351074,
      "learning_rate": 0.00014648887600550765,
      "loss": 0.1224,
      "step": 3693
    },
    {
      "epoch": 0.2677102583614161,
      "grad_norm": 1.1343884468078613,
      "learning_rate": 0.00014647438220160883,
      "loss": 0.0886,
      "step": 3694
    },
    {
      "epoch": 0.2677827300068848,
      "grad_norm": 1.3471776247024536,
      "learning_rate": 0.00014645988839770999,
      "loss": 0.0725,
      "step": 3695
    },
    {
      "epoch": 0.2678552016523535,
      "grad_norm": 2.5388948917388916,
      "learning_rate": 0.00014644539459381114,
      "loss": 0.0838,
      "step": 3696
    },
    {
      "epoch": 0.26792767329782224,
      "grad_norm": 1.2768595218658447,
      "learning_rate": 0.00014643090078991233,
      "loss": 0.0818,
      "step": 3697
    },
    {
      "epoch": 0.26800014494329094,
      "grad_norm": 2.1354620456695557,
      "learning_rate": 0.00014641640698601348,
      "loss": 0.0798,
      "step": 3698
    },
    {
      "epoch": 0.26807261658875964,
      "grad_norm": 0.5599550008773804,
      "learning_rate": 0.00014640191318211464,
      "loss": 0.0361,
      "step": 3699
    },
    {
      "epoch": 0.26814508823422833,
      "grad_norm": 1.120066523551941,
      "learning_rate": 0.00014638741937821582,
      "loss": 0.0424,
      "step": 3700
    },
    {
      "epoch": 0.2682175598796971,
      "grad_norm": 1.9709949493408203,
      "learning_rate": 0.00014637292557431698,
      "loss": 0.083,
      "step": 3701
    },
    {
      "epoch": 0.2682900315251658,
      "grad_norm": 4.572483062744141,
      "learning_rate": 0.00014635843177041814,
      "loss": 0.2746,
      "step": 3702
    },
    {
      "epoch": 0.2683625031706345,
      "grad_norm": 7.865817070007324,
      "learning_rate": 0.00014634393796651932,
      "loss": 0.0969,
      "step": 3703
    },
    {
      "epoch": 0.2684349748161032,
      "grad_norm": 0.734636127948761,
      "learning_rate": 0.00014632944416262048,
      "loss": 0.0279,
      "step": 3704
    },
    {
      "epoch": 0.26850744646157193,
      "grad_norm": 0.5831279158592224,
      "learning_rate": 0.00014631495035872166,
      "loss": 0.0299,
      "step": 3705
    },
    {
      "epoch": 0.2685799181070406,
      "grad_norm": 2.760366916656494,
      "learning_rate": 0.00014630045655482282,
      "loss": 0.1642,
      "step": 3706
    },
    {
      "epoch": 0.2686523897525093,
      "grad_norm": 1.9242091178894043,
      "learning_rate": 0.000146285962750924,
      "loss": 0.1101,
      "step": 3707
    },
    {
      "epoch": 0.268724861397978,
      "grad_norm": 1.1112079620361328,
      "learning_rate": 0.00014627146894702516,
      "loss": 0.0624,
      "step": 3708
    },
    {
      "epoch": 0.2687973330434468,
      "grad_norm": 1.2319698333740234,
      "learning_rate": 0.00014625697514312634,
      "loss": 0.0484,
      "step": 3709
    },
    {
      "epoch": 0.26886980468891547,
      "grad_norm": 3.142911434173584,
      "learning_rate": 0.0001462424813392275,
      "loss": 0.0682,
      "step": 3710
    },
    {
      "epoch": 0.26894227633438417,
      "grad_norm": 3.9186573028564453,
      "learning_rate": 0.00014622798753532865,
      "loss": 0.0765,
      "step": 3711
    },
    {
      "epoch": 0.26901474797985286,
      "grad_norm": 1.8046637773513794,
      "learning_rate": 0.00014621349373142984,
      "loss": 0.0796,
      "step": 3712
    },
    {
      "epoch": 0.2690872196253216,
      "grad_norm": 1.7592521905899048,
      "learning_rate": 0.000146198999927531,
      "loss": 0.1117,
      "step": 3713
    },
    {
      "epoch": 0.2691596912707903,
      "grad_norm": 3.0050222873687744,
      "learning_rate": 0.00014618450612363215,
      "loss": 0.1315,
      "step": 3714
    },
    {
      "epoch": 0.269232162916259,
      "grad_norm": 1.543285608291626,
      "learning_rate": 0.00014617001231973333,
      "loss": 0.0764,
      "step": 3715
    },
    {
      "epoch": 0.2693046345617277,
      "grad_norm": 1.7216548919677734,
      "learning_rate": 0.0001461555185158345,
      "loss": 0.0746,
      "step": 3716
    },
    {
      "epoch": 0.26937710620719646,
      "grad_norm": 0.8479487895965576,
      "learning_rate": 0.00014614102471193565,
      "loss": 0.0434,
      "step": 3717
    },
    {
      "epoch": 0.26944957785266516,
      "grad_norm": 1.163912296295166,
      "learning_rate": 0.00014612653090803683,
      "loss": 0.0265,
      "step": 3718
    },
    {
      "epoch": 0.26952204949813385,
      "grad_norm": 2.5356245040893555,
      "learning_rate": 0.00014611203710413799,
      "loss": 0.0487,
      "step": 3719
    },
    {
      "epoch": 0.26959452114360255,
      "grad_norm": 0.640126645565033,
      "learning_rate": 0.00014609754330023914,
      "loss": 0.0395,
      "step": 3720
    },
    {
      "epoch": 0.2696669927890713,
      "grad_norm": 1.6948219537734985,
      "learning_rate": 0.00014608304949634033,
      "loss": 0.0519,
      "step": 3721
    },
    {
      "epoch": 0.26973946443454,
      "grad_norm": 1.6091371774673462,
      "learning_rate": 0.00014606855569244148,
      "loss": 0.0684,
      "step": 3722
    },
    {
      "epoch": 0.2698119360800087,
      "grad_norm": 0.525577187538147,
      "learning_rate": 0.00014605406188854264,
      "loss": 0.0418,
      "step": 3723
    },
    {
      "epoch": 0.2698844077254774,
      "grad_norm": 0.9853134751319885,
      "learning_rate": 0.00014603956808464382,
      "loss": 0.0465,
      "step": 3724
    },
    {
      "epoch": 0.2699568793709461,
      "grad_norm": 0.9515277147293091,
      "learning_rate": 0.00014602507428074498,
      "loss": 0.0372,
      "step": 3725
    },
    {
      "epoch": 0.27002935101641484,
      "grad_norm": 2.232717752456665,
      "learning_rate": 0.00014601058047684614,
      "loss": 0.0792,
      "step": 3726
    },
    {
      "epoch": 0.27010182266188354,
      "grad_norm": 1.5803611278533936,
      "learning_rate": 0.00014599608667294732,
      "loss": 0.0757,
      "step": 3727
    },
    {
      "epoch": 0.27017429430735224,
      "grad_norm": 1.9927610158920288,
      "learning_rate": 0.0001459815928690485,
      "loss": 0.0659,
      "step": 3728
    },
    {
      "epoch": 0.27024676595282093,
      "grad_norm": 0.452431857585907,
      "learning_rate": 0.00014596709906514966,
      "loss": 0.0189,
      "step": 3729
    },
    {
      "epoch": 0.2703192375982897,
      "grad_norm": 7.988786220550537,
      "learning_rate": 0.00014595260526125084,
      "loss": 0.0469,
      "step": 3730
    },
    {
      "epoch": 0.2703917092437584,
      "grad_norm": 5.664959907531738,
      "learning_rate": 0.000145938111457352,
      "loss": 0.0939,
      "step": 3731
    },
    {
      "epoch": 0.2704641808892271,
      "grad_norm": 6.39124870300293,
      "learning_rate": 0.00014592361765345316,
      "loss": 0.0473,
      "step": 3732
    },
    {
      "epoch": 0.2705366525346958,
      "grad_norm": 0.874747633934021,
      "learning_rate": 0.00014590912384955434,
      "loss": 0.0381,
      "step": 3733
    },
    {
      "epoch": 0.27060912418016453,
      "grad_norm": 0.49146196246147156,
      "learning_rate": 0.0001458946300456555,
      "loss": 0.0218,
      "step": 3734
    },
    {
      "epoch": 0.2706815958256332,
      "grad_norm": 3.5926685333251953,
      "learning_rate": 0.00014588013624175665,
      "loss": 0.1432,
      "step": 3735
    },
    {
      "epoch": 0.2707540674711019,
      "grad_norm": 4.945797443389893,
      "learning_rate": 0.00014586564243785784,
      "loss": 0.0894,
      "step": 3736
    },
    {
      "epoch": 0.2708265391165706,
      "grad_norm": 0.6575477719306946,
      "learning_rate": 0.000145851148633959,
      "loss": 0.0152,
      "step": 3737
    },
    {
      "epoch": 0.27089901076203937,
      "grad_norm": 4.691531658172607,
      "learning_rate": 0.00014583665483006015,
      "loss": 0.2022,
      "step": 3738
    },
    {
      "epoch": 0.27097148240750807,
      "grad_norm": 2.6676666736602783,
      "learning_rate": 0.00014582216102616133,
      "loss": 0.1734,
      "step": 3739
    },
    {
      "epoch": 0.27104395405297677,
      "grad_norm": 0.3137180805206299,
      "learning_rate": 0.0001458076672222625,
      "loss": 0.0085,
      "step": 3740
    },
    {
      "epoch": 0.27111642569844546,
      "grad_norm": 2.4275333881378174,
      "learning_rate": 0.00014579317341836365,
      "loss": 0.0636,
      "step": 3741
    },
    {
      "epoch": 0.2711888973439142,
      "grad_norm": 0.9974201321601868,
      "learning_rate": 0.00014577867961446483,
      "loss": 0.0455,
      "step": 3742
    },
    {
      "epoch": 0.2712613689893829,
      "grad_norm": 4.8410420417785645,
      "learning_rate": 0.00014576418581056599,
      "loss": 0.101,
      "step": 3743
    },
    {
      "epoch": 0.2713338406348516,
      "grad_norm": 8.120672225952148,
      "learning_rate": 0.00014574969200666714,
      "loss": 0.1048,
      "step": 3744
    },
    {
      "epoch": 0.2714063122803203,
      "grad_norm": 0.7975614666938782,
      "learning_rate": 0.00014573519820276833,
      "loss": 0.0296,
      "step": 3745
    },
    {
      "epoch": 0.27147878392578906,
      "grad_norm": 1.328237771987915,
      "learning_rate": 0.00014572070439886948,
      "loss": 0.0373,
      "step": 3746
    },
    {
      "epoch": 0.27155125557125775,
      "grad_norm": 1.098032832145691,
      "learning_rate": 0.00014570621059497064,
      "loss": 0.0506,
      "step": 3747
    },
    {
      "epoch": 0.27162372721672645,
      "grad_norm": 1.547111988067627,
      "learning_rate": 0.00014569171679107182,
      "loss": 0.0688,
      "step": 3748
    },
    {
      "epoch": 0.27169619886219515,
      "grad_norm": 0.8327585458755493,
      "learning_rate": 0.00014567722298717298,
      "loss": 0.0543,
      "step": 3749
    },
    {
      "epoch": 0.2717686705076639,
      "grad_norm": 3.6612324714660645,
      "learning_rate": 0.00014566272918327416,
      "loss": 0.0471,
      "step": 3750
    },
    {
      "epoch": 0.2718411421531326,
      "grad_norm": 5.243351936340332,
      "learning_rate": 0.00014564823537937532,
      "loss": 0.0564,
      "step": 3751
    },
    {
      "epoch": 0.2719136137986013,
      "grad_norm": 0.9679908752441406,
      "learning_rate": 0.0001456337415754765,
      "loss": 0.0696,
      "step": 3752
    },
    {
      "epoch": 0.27198608544407,
      "grad_norm": 9.038076400756836,
      "learning_rate": 0.00014561924777157766,
      "loss": 0.0675,
      "step": 3753
    },
    {
      "epoch": 0.27205855708953874,
      "grad_norm": 1.0080453157424927,
      "learning_rate": 0.00014560475396767884,
      "loss": 0.0233,
      "step": 3754
    },
    {
      "epoch": 0.27213102873500744,
      "grad_norm": 3.171834945678711,
      "learning_rate": 0.00014559026016378,
      "loss": 0.2295,
      "step": 3755
    },
    {
      "epoch": 0.27220350038047614,
      "grad_norm": 7.622982978820801,
      "learning_rate": 0.00014557576635988115,
      "loss": 0.2052,
      "step": 3756
    },
    {
      "epoch": 0.27227597202594483,
      "grad_norm": 3.206179141998291,
      "learning_rate": 0.00014556127255598234,
      "loss": 0.1676,
      "step": 3757
    },
    {
      "epoch": 0.2723484436714136,
      "grad_norm": 0.39477041363716125,
      "learning_rate": 0.0001455467787520835,
      "loss": 0.0069,
      "step": 3758
    },
    {
      "epoch": 0.2724209153168823,
      "grad_norm": 1.460988998413086,
      "learning_rate": 0.00014553228494818465,
      "loss": 0.0842,
      "step": 3759
    },
    {
      "epoch": 0.272493386962351,
      "grad_norm": 3.1348037719726562,
      "learning_rate": 0.00014551779114428584,
      "loss": 0.0946,
      "step": 3760
    },
    {
      "epoch": 0.2725658586078197,
      "grad_norm": 2.0550570487976074,
      "learning_rate": 0.000145503297340387,
      "loss": 0.1606,
      "step": 3761
    },
    {
      "epoch": 0.2726383302532884,
      "grad_norm": 2.650452136993408,
      "learning_rate": 0.00014548880353648815,
      "loss": 0.1844,
      "step": 3762
    },
    {
      "epoch": 0.2727108018987571,
      "grad_norm": 1.125017523765564,
      "learning_rate": 0.00014547430973258933,
      "loss": 0.0927,
      "step": 3763
    },
    {
      "epoch": 0.2727832735442258,
      "grad_norm": 2.1042895317077637,
      "learning_rate": 0.0001454598159286905,
      "loss": 0.0829,
      "step": 3764
    },
    {
      "epoch": 0.2728557451896945,
      "grad_norm": 3.447990894317627,
      "learning_rate": 0.00014544532212479164,
      "loss": 0.1021,
      "step": 3765
    },
    {
      "epoch": 0.2729282168351632,
      "grad_norm": 0.7536026835441589,
      "learning_rate": 0.00014543082832089283,
      "loss": 0.0202,
      "step": 3766
    },
    {
      "epoch": 0.27300068848063197,
      "grad_norm": 0.919706404209137,
      "learning_rate": 0.00014541633451699398,
      "loss": 0.04,
      "step": 3767
    },
    {
      "epoch": 0.27307316012610067,
      "grad_norm": 1.642770767211914,
      "learning_rate": 0.00014540184071309514,
      "loss": 0.0423,
      "step": 3768
    },
    {
      "epoch": 0.27314563177156936,
      "grad_norm": 0.6594184041023254,
      "learning_rate": 0.00014538734690919632,
      "loss": 0.018,
      "step": 3769
    },
    {
      "epoch": 0.27321810341703806,
      "grad_norm": 4.122265338897705,
      "learning_rate": 0.00014537285310529748,
      "loss": 0.1516,
      "step": 3770
    },
    {
      "epoch": 0.2732905750625068,
      "grad_norm": 1.2406941652297974,
      "learning_rate": 0.00014535835930139864,
      "loss": 0.0761,
      "step": 3771
    },
    {
      "epoch": 0.2733630467079755,
      "grad_norm": 1.2954827547073364,
      "learning_rate": 0.00014534386549749982,
      "loss": 0.0528,
      "step": 3772
    },
    {
      "epoch": 0.2734355183534442,
      "grad_norm": 3.3700716495513916,
      "learning_rate": 0.00014532937169360098,
      "loss": 0.0903,
      "step": 3773
    },
    {
      "epoch": 0.2735079899989129,
      "grad_norm": 1.1086982488632202,
      "learning_rate": 0.00014531487788970216,
      "loss": 0.0618,
      "step": 3774
    },
    {
      "epoch": 0.27358046164438166,
      "grad_norm": 1.243322730064392,
      "learning_rate": 0.00014530038408580334,
      "loss": 0.0348,
      "step": 3775
    },
    {
      "epoch": 0.27365293328985035,
      "grad_norm": 1.0003917217254639,
      "learning_rate": 0.0001452858902819045,
      "loss": 0.0761,
      "step": 3776
    },
    {
      "epoch": 0.27372540493531905,
      "grad_norm": 0.8613985776901245,
      "learning_rate": 0.00014527139647800566,
      "loss": 0.0496,
      "step": 3777
    },
    {
      "epoch": 0.27379787658078775,
      "grad_norm": 2.54840087890625,
      "learning_rate": 0.00014525690267410684,
      "loss": 0.1566,
      "step": 3778
    },
    {
      "epoch": 0.2738703482262565,
      "grad_norm": 1.040614128112793,
      "learning_rate": 0.000145242408870208,
      "loss": 0.1205,
      "step": 3779
    },
    {
      "epoch": 0.2739428198717252,
      "grad_norm": 1.5640759468078613,
      "learning_rate": 0.00014522791506630915,
      "loss": 0.0209,
      "step": 3780
    },
    {
      "epoch": 0.2740152915171939,
      "grad_norm": 1.070711374282837,
      "learning_rate": 0.00014521342126241034,
      "loss": 0.0735,
      "step": 3781
    },
    {
      "epoch": 0.2740877631626626,
      "grad_norm": 2.17223858833313,
      "learning_rate": 0.0001451989274585115,
      "loss": 0.1011,
      "step": 3782
    },
    {
      "epoch": 0.27416023480813134,
      "grad_norm": 0.8815562725067139,
      "learning_rate": 0.00014518443365461265,
      "loss": 0.0446,
      "step": 3783
    },
    {
      "epoch": 0.27423270645360004,
      "grad_norm": 2.362788438796997,
      "learning_rate": 0.00014516993985071383,
      "loss": 0.0622,
      "step": 3784
    },
    {
      "epoch": 0.27430517809906874,
      "grad_norm": 0.8247526288032532,
      "learning_rate": 0.000145155446046815,
      "loss": 0.0267,
      "step": 3785
    },
    {
      "epoch": 0.27437764974453743,
      "grad_norm": 1.7325369119644165,
      "learning_rate": 0.00014514095224291615,
      "loss": 0.0508,
      "step": 3786
    },
    {
      "epoch": 0.2744501213900062,
      "grad_norm": 2.2520809173583984,
      "learning_rate": 0.00014512645843901733,
      "loss": 0.0742,
      "step": 3787
    },
    {
      "epoch": 0.2745225930354749,
      "grad_norm": 1.0249104499816895,
      "learning_rate": 0.0001451119646351185,
      "loss": 0.0169,
      "step": 3788
    },
    {
      "epoch": 0.2745950646809436,
      "grad_norm": 1.4017298221588135,
      "learning_rate": 0.00014509747083121964,
      "loss": 0.0921,
      "step": 3789
    },
    {
      "epoch": 0.2746675363264123,
      "grad_norm": 3.038130044937134,
      "learning_rate": 0.00014508297702732083,
      "loss": 0.0679,
      "step": 3790
    },
    {
      "epoch": 0.27474000797188103,
      "grad_norm": 3.613403797149658,
      "learning_rate": 0.00014506848322342198,
      "loss": 0.1786,
      "step": 3791
    },
    {
      "epoch": 0.2748124796173497,
      "grad_norm": 2.4694859981536865,
      "learning_rate": 0.00014505398941952314,
      "loss": 0.1762,
      "step": 3792
    },
    {
      "epoch": 0.2748849512628184,
      "grad_norm": 2.223855495452881,
      "learning_rate": 0.00014503949561562432,
      "loss": 0.0924,
      "step": 3793
    },
    {
      "epoch": 0.2749574229082871,
      "grad_norm": 3.3269431591033936,
      "learning_rate": 0.00014502500181172548,
      "loss": 0.2258,
      "step": 3794
    },
    {
      "epoch": 0.2750298945537558,
      "grad_norm": 1.8706704378128052,
      "learning_rate": 0.00014501050800782666,
      "loss": 0.0925,
      "step": 3795
    },
    {
      "epoch": 0.27510236619922457,
      "grad_norm": 1.611616611480713,
      "learning_rate": 0.00014499601420392782,
      "loss": 0.1542,
      "step": 3796
    },
    {
      "epoch": 0.27517483784469327,
      "grad_norm": 0.8933471441268921,
      "learning_rate": 0.000144981520400029,
      "loss": 0.0328,
      "step": 3797
    },
    {
      "epoch": 0.27524730949016196,
      "grad_norm": 2.5080857276916504,
      "learning_rate": 0.00014496702659613016,
      "loss": 0.2004,
      "step": 3798
    },
    {
      "epoch": 0.27531978113563066,
      "grad_norm": 0.5698952674865723,
      "learning_rate": 0.00014495253279223134,
      "loss": 0.0213,
      "step": 3799
    },
    {
      "epoch": 0.2753922527810994,
      "grad_norm": 1.438828945159912,
      "learning_rate": 0.0001449380389883325,
      "loss": 0.1301,
      "step": 3800
    },
    {
      "epoch": 0.2754647244265681,
      "grad_norm": 1.2395111322402954,
      "learning_rate": 0.00014492354518443366,
      "loss": 0.1357,
      "step": 3801
    },
    {
      "epoch": 0.2755371960720368,
      "grad_norm": 1.1977002620697021,
      "learning_rate": 0.00014490905138053484,
      "loss": 0.0889,
      "step": 3802
    },
    {
      "epoch": 0.2756096677175055,
      "grad_norm": 0.9064057469367981,
      "learning_rate": 0.000144894557576636,
      "loss": 0.0288,
      "step": 3803
    },
    {
      "epoch": 0.27568213936297425,
      "grad_norm": 0.4844646751880646,
      "learning_rate": 0.00014488006377273715,
      "loss": 0.026,
      "step": 3804
    },
    {
      "epoch": 0.27575461100844295,
      "grad_norm": 1.0509672164916992,
      "learning_rate": 0.00014486556996883834,
      "loss": 0.0638,
      "step": 3805
    },
    {
      "epoch": 0.27582708265391165,
      "grad_norm": 1.003980040550232,
      "learning_rate": 0.0001448510761649395,
      "loss": 0.0689,
      "step": 3806
    },
    {
      "epoch": 0.27589955429938035,
      "grad_norm": 0.6448007225990295,
      "learning_rate": 0.00014483658236104065,
      "loss": 0.0488,
      "step": 3807
    },
    {
      "epoch": 0.2759720259448491,
      "grad_norm": 1.8797533512115479,
      "learning_rate": 0.00014482208855714183,
      "loss": 0.1,
      "step": 3808
    },
    {
      "epoch": 0.2760444975903178,
      "grad_norm": 8.097715377807617,
      "learning_rate": 0.000144807594753243,
      "loss": 0.1737,
      "step": 3809
    },
    {
      "epoch": 0.2761169692357865,
      "grad_norm": 0.3730844557285309,
      "learning_rate": 0.00014479310094934415,
      "loss": 0.0225,
      "step": 3810
    },
    {
      "epoch": 0.2761894408812552,
      "grad_norm": 3.1333537101745605,
      "learning_rate": 0.00014477860714544533,
      "loss": 0.1299,
      "step": 3811
    },
    {
      "epoch": 0.27626191252672394,
      "grad_norm": 1.053828239440918,
      "learning_rate": 0.0001447641133415465,
      "loss": 0.0658,
      "step": 3812
    },
    {
      "epoch": 0.27633438417219264,
      "grad_norm": 3.300898313522339,
      "learning_rate": 0.00014474961953764764,
      "loss": 0.1121,
      "step": 3813
    },
    {
      "epoch": 0.27640685581766133,
      "grad_norm": 0.6923996210098267,
      "learning_rate": 0.00014473512573374883,
      "loss": 0.0427,
      "step": 3814
    },
    {
      "epoch": 0.27647932746313003,
      "grad_norm": 1.5662835836410522,
      "learning_rate": 0.00014472063192984998,
      "loss": 0.1052,
      "step": 3815
    },
    {
      "epoch": 0.2765517991085988,
      "grad_norm": 0.6898585557937622,
      "learning_rate": 0.00014470613812595114,
      "loss": 0.019,
      "step": 3816
    },
    {
      "epoch": 0.2766242707540675,
      "grad_norm": 2.516936779022217,
      "learning_rate": 0.00014469164432205232,
      "loss": 0.1381,
      "step": 3817
    },
    {
      "epoch": 0.2766967423995362,
      "grad_norm": 2.2183737754821777,
      "learning_rate": 0.00014467715051815348,
      "loss": 0.0992,
      "step": 3818
    },
    {
      "epoch": 0.2767692140450049,
      "grad_norm": 2.538844347000122,
      "learning_rate": 0.00014466265671425466,
      "loss": 0.0989,
      "step": 3819
    },
    {
      "epoch": 0.2768416856904736,
      "grad_norm": 1.0759515762329102,
      "learning_rate": 0.00014464816291035582,
      "loss": 0.0563,
      "step": 3820
    },
    {
      "epoch": 0.2769141573359423,
      "grad_norm": 1.4012892246246338,
      "learning_rate": 0.000144633669106457,
      "loss": 0.0904,
      "step": 3821
    },
    {
      "epoch": 0.276986628981411,
      "grad_norm": 3.037738084793091,
      "learning_rate": 0.0001446191753025582,
      "loss": 0.1709,
      "step": 3822
    },
    {
      "epoch": 0.2770591006268797,
      "grad_norm": 2.657456874847412,
      "learning_rate": 0.00014460468149865934,
      "loss": 0.0975,
      "step": 3823
    },
    {
      "epoch": 0.27713157227234847,
      "grad_norm": 1.6087254285812378,
      "learning_rate": 0.0001445901876947605,
      "loss": 0.0483,
      "step": 3824
    },
    {
      "epoch": 0.27720404391781717,
      "grad_norm": 2.156928062438965,
      "learning_rate": 0.00014457569389086168,
      "loss": 0.0745,
      "step": 3825
    },
    {
      "epoch": 0.27727651556328586,
      "grad_norm": 4.634500980377197,
      "learning_rate": 0.00014456120008696284,
      "loss": 0.1295,
      "step": 3826
    },
    {
      "epoch": 0.27734898720875456,
      "grad_norm": 1.1860229969024658,
      "learning_rate": 0.000144546706283064,
      "loss": 0.0387,
      "step": 3827
    },
    {
      "epoch": 0.2774214588542233,
      "grad_norm": 0.7208093404769897,
      "learning_rate": 0.00014453221247916518,
      "loss": 0.036,
      "step": 3828
    },
    {
      "epoch": 0.277493930499692,
      "grad_norm": 4.225613117218018,
      "learning_rate": 0.00014451771867526634,
      "loss": 0.18,
      "step": 3829
    },
    {
      "epoch": 0.2775664021451607,
      "grad_norm": 3.271300792694092,
      "learning_rate": 0.0001445032248713675,
      "loss": 0.1589,
      "step": 3830
    },
    {
      "epoch": 0.2776388737906294,
      "grad_norm": 2.3842010498046875,
      "learning_rate": 0.00014448873106746868,
      "loss": 0.1559,
      "step": 3831
    },
    {
      "epoch": 0.2777113454360981,
      "grad_norm": 0.873140275478363,
      "learning_rate": 0.00014447423726356983,
      "loss": 0.0485,
      "step": 3832
    },
    {
      "epoch": 0.27778381708156685,
      "grad_norm": 1.2569959163665771,
      "learning_rate": 0.000144459743459671,
      "loss": 0.0392,
      "step": 3833
    },
    {
      "epoch": 0.27785628872703555,
      "grad_norm": 2.0605528354644775,
      "learning_rate": 0.00014444524965577217,
      "loss": 0.0734,
      "step": 3834
    },
    {
      "epoch": 0.27792876037250425,
      "grad_norm": 2.75606632232666,
      "learning_rate": 0.00014443075585187333,
      "loss": 0.1017,
      "step": 3835
    },
    {
      "epoch": 0.27800123201797294,
      "grad_norm": 1.0913714170455933,
      "learning_rate": 0.0001444162620479745,
      "loss": 0.0325,
      "step": 3836
    },
    {
      "epoch": 0.2780737036634417,
      "grad_norm": 0.6863417625427246,
      "learning_rate": 0.00014440176824407567,
      "loss": 0.01,
      "step": 3837
    },
    {
      "epoch": 0.2781461753089104,
      "grad_norm": 1.8542814254760742,
      "learning_rate": 0.00014438727444017683,
      "loss": 0.0754,
      "step": 3838
    },
    {
      "epoch": 0.2782186469543791,
      "grad_norm": 3.3745105266571045,
      "learning_rate": 0.00014437278063627798,
      "loss": 0.1379,
      "step": 3839
    },
    {
      "epoch": 0.2782911185998478,
      "grad_norm": 0.7807537317276001,
      "learning_rate": 0.00014435828683237917,
      "loss": 0.0206,
      "step": 3840
    },
    {
      "epoch": 0.27836359024531654,
      "grad_norm": 3.566471576690674,
      "learning_rate": 0.00014434379302848032,
      "loss": 0.0982,
      "step": 3841
    },
    {
      "epoch": 0.27843606189078524,
      "grad_norm": 3.4646081924438477,
      "learning_rate": 0.00014432929922458148,
      "loss": 0.1418,
      "step": 3842
    },
    {
      "epoch": 0.27850853353625393,
      "grad_norm": 2.348304510116577,
      "learning_rate": 0.00014431480542068266,
      "loss": 0.2123,
      "step": 3843
    },
    {
      "epoch": 0.27858100518172263,
      "grad_norm": 4.034048080444336,
      "learning_rate": 0.00014430031161678385,
      "loss": 0.1164,
      "step": 3844
    },
    {
      "epoch": 0.2786534768271914,
      "grad_norm": 3.2889623641967773,
      "learning_rate": 0.000144285817812885,
      "loss": 0.0606,
      "step": 3845
    },
    {
      "epoch": 0.2787259484726601,
      "grad_norm": 2.478947877883911,
      "learning_rate": 0.0001442713240089862,
      "loss": 0.1108,
      "step": 3846
    },
    {
      "epoch": 0.2787984201181288,
      "grad_norm": 1.2427759170532227,
      "learning_rate": 0.00014425683020508734,
      "loss": 0.0715,
      "step": 3847
    },
    {
      "epoch": 0.2788708917635975,
      "grad_norm": 1.4508171081542969,
      "learning_rate": 0.0001442423364011885,
      "loss": 0.1412,
      "step": 3848
    },
    {
      "epoch": 0.2789433634090662,
      "grad_norm": 1.068549633026123,
      "learning_rate": 0.00014422784259728968,
      "loss": 0.0705,
      "step": 3849
    },
    {
      "epoch": 0.2790158350545349,
      "grad_norm": 1.8950024843215942,
      "learning_rate": 0.00014421334879339084,
      "loss": 0.1315,
      "step": 3850
    },
    {
      "epoch": 0.2790883067000036,
      "grad_norm": 2.20599627494812,
      "learning_rate": 0.000144198854989492,
      "loss": 0.0558,
      "step": 3851
    },
    {
      "epoch": 0.2791607783454723,
      "grad_norm": 3.8152546882629395,
      "learning_rate": 0.00014418436118559318,
      "loss": 0.1035,
      "step": 3852
    },
    {
      "epoch": 0.27923324999094107,
      "grad_norm": 1.307779312133789,
      "learning_rate": 0.00014416986738169434,
      "loss": 0.085,
      "step": 3853
    },
    {
      "epoch": 0.27930572163640977,
      "grad_norm": 1.6625721454620361,
      "learning_rate": 0.0001441553735777955,
      "loss": 0.0374,
      "step": 3854
    },
    {
      "epoch": 0.27937819328187846,
      "grad_norm": 3.848773717880249,
      "learning_rate": 0.00014414087977389668,
      "loss": 0.1293,
      "step": 3855
    },
    {
      "epoch": 0.27945066492734716,
      "grad_norm": 0.7655242681503296,
      "learning_rate": 0.00014412638596999783,
      "loss": 0.0534,
      "step": 3856
    },
    {
      "epoch": 0.2795231365728159,
      "grad_norm": 2.8898136615753174,
      "learning_rate": 0.000144111892166099,
      "loss": 0.1173,
      "step": 3857
    },
    {
      "epoch": 0.2795956082182846,
      "grad_norm": 1.428554892539978,
      "learning_rate": 0.00014409739836220017,
      "loss": 0.0737,
      "step": 3858
    },
    {
      "epoch": 0.2796680798637533,
      "grad_norm": 4.337907314300537,
      "learning_rate": 0.00014408290455830133,
      "loss": 0.1452,
      "step": 3859
    },
    {
      "epoch": 0.279740551509222,
      "grad_norm": 1.8509814739227295,
      "learning_rate": 0.0001440684107544025,
      "loss": 0.067,
      "step": 3860
    },
    {
      "epoch": 0.27981302315469075,
      "grad_norm": 4.177830696105957,
      "learning_rate": 0.00014405391695050367,
      "loss": 0.0816,
      "step": 3861
    },
    {
      "epoch": 0.27988549480015945,
      "grad_norm": 3.6782262325286865,
      "learning_rate": 0.00014403942314660483,
      "loss": 0.1328,
      "step": 3862
    },
    {
      "epoch": 0.27995796644562815,
      "grad_norm": 3.663799285888672,
      "learning_rate": 0.00014402492934270598,
      "loss": 0.1375,
      "step": 3863
    },
    {
      "epoch": 0.28003043809109684,
      "grad_norm": 6.0349249839782715,
      "learning_rate": 0.00014401043553880717,
      "loss": 0.1032,
      "step": 3864
    },
    {
      "epoch": 0.28010290973656554,
      "grad_norm": 2.8937015533447266,
      "learning_rate": 0.00014399594173490832,
      "loss": 0.1186,
      "step": 3865
    },
    {
      "epoch": 0.2801753813820343,
      "grad_norm": 2.840083122253418,
      "learning_rate": 0.0001439814479310095,
      "loss": 0.0269,
      "step": 3866
    },
    {
      "epoch": 0.280247853027503,
      "grad_norm": 1.7762759923934937,
      "learning_rate": 0.00014396695412711066,
      "loss": 0.0925,
      "step": 3867
    },
    {
      "epoch": 0.2803203246729717,
      "grad_norm": 1.0943355560302734,
      "learning_rate": 0.00014395246032321185,
      "loss": 0.1013,
      "step": 3868
    },
    {
      "epoch": 0.2803927963184404,
      "grad_norm": 1.5979145765304565,
      "learning_rate": 0.000143937966519313,
      "loss": 0.0372,
      "step": 3869
    },
    {
      "epoch": 0.28046526796390914,
      "grad_norm": 1.2812621593475342,
      "learning_rate": 0.0001439234727154142,
      "loss": 0.1319,
      "step": 3870
    },
    {
      "epoch": 0.28053773960937783,
      "grad_norm": 1.7809240818023682,
      "learning_rate": 0.00014390897891151534,
      "loss": 0.0398,
      "step": 3871
    },
    {
      "epoch": 0.28061021125484653,
      "grad_norm": 0.7912048101425171,
      "learning_rate": 0.0001438944851076165,
      "loss": 0.0733,
      "step": 3872
    },
    {
      "epoch": 0.28068268290031523,
      "grad_norm": 3.2497031688690186,
      "learning_rate": 0.00014387999130371768,
      "loss": 0.2076,
      "step": 3873
    },
    {
      "epoch": 0.280755154545784,
      "grad_norm": 0.459710955619812,
      "learning_rate": 0.00014386549749981884,
      "loss": 0.0275,
      "step": 3874
    },
    {
      "epoch": 0.2808276261912527,
      "grad_norm": 2.6775405406951904,
      "learning_rate": 0.00014385100369592,
      "loss": 0.1895,
      "step": 3875
    },
    {
      "epoch": 0.2809000978367214,
      "grad_norm": 1.5407744646072388,
      "learning_rate": 0.00014383650989202118,
      "loss": 0.0464,
      "step": 3876
    },
    {
      "epoch": 0.28097256948219007,
      "grad_norm": 2.927595853805542,
      "learning_rate": 0.00014382201608812234,
      "loss": 0.1502,
      "step": 3877
    },
    {
      "epoch": 0.2810450411276588,
      "grad_norm": 0.8707779049873352,
      "learning_rate": 0.0001438075222842235,
      "loss": 0.0608,
      "step": 3878
    },
    {
      "epoch": 0.2811175127731275,
      "grad_norm": 0.9336594939231873,
      "learning_rate": 0.00014379302848032468,
      "loss": 0.0677,
      "step": 3879
    },
    {
      "epoch": 0.2811899844185962,
      "grad_norm": 0.7600298523902893,
      "learning_rate": 0.00014377853467642583,
      "loss": 0.0227,
      "step": 3880
    },
    {
      "epoch": 0.2812624560640649,
      "grad_norm": 0.9782384634017944,
      "learning_rate": 0.000143764040872527,
      "loss": 0.1071,
      "step": 3881
    },
    {
      "epoch": 0.28133492770953367,
      "grad_norm": 1.1901684999465942,
      "learning_rate": 0.00014374954706862817,
      "loss": 0.113,
      "step": 3882
    },
    {
      "epoch": 0.28140739935500236,
      "grad_norm": 3.0152201652526855,
      "learning_rate": 0.00014373505326472933,
      "loss": 0.1931,
      "step": 3883
    },
    {
      "epoch": 0.28147987100047106,
      "grad_norm": 0.8070743680000305,
      "learning_rate": 0.00014372055946083049,
      "loss": 0.0258,
      "step": 3884
    },
    {
      "epoch": 0.28155234264593976,
      "grad_norm": 2.4574098587036133,
      "learning_rate": 0.00014370606565693167,
      "loss": 0.1242,
      "step": 3885
    },
    {
      "epoch": 0.2816248142914085,
      "grad_norm": 0.8952910900115967,
      "learning_rate": 0.00014369157185303283,
      "loss": 0.0662,
      "step": 3886
    },
    {
      "epoch": 0.2816972859368772,
      "grad_norm": 0.5876597762107849,
      "learning_rate": 0.00014367707804913398,
      "loss": 0.0574,
      "step": 3887
    },
    {
      "epoch": 0.2817697575823459,
      "grad_norm": 1.3105173110961914,
      "learning_rate": 0.00014366258424523517,
      "loss": 0.0609,
      "step": 3888
    },
    {
      "epoch": 0.2818422292278146,
      "grad_norm": 0.8341556191444397,
      "learning_rate": 0.00014364809044133632,
      "loss": 0.0646,
      "step": 3889
    },
    {
      "epoch": 0.28191470087328335,
      "grad_norm": 0.9822377562522888,
      "learning_rate": 0.0001436335966374375,
      "loss": 0.0533,
      "step": 3890
    },
    {
      "epoch": 0.28198717251875205,
      "grad_norm": 1.398328423500061,
      "learning_rate": 0.0001436191028335387,
      "loss": 0.0643,
      "step": 3891
    },
    {
      "epoch": 0.28205964416422075,
      "grad_norm": 1.7801992893218994,
      "learning_rate": 0.00014360460902963985,
      "loss": 0.1537,
      "step": 3892
    },
    {
      "epoch": 0.28213211580968944,
      "grad_norm": 1.1266605854034424,
      "learning_rate": 0.000143590115225741,
      "loss": 0.0197,
      "step": 3893
    },
    {
      "epoch": 0.2822045874551582,
      "grad_norm": 2.272815704345703,
      "learning_rate": 0.0001435756214218422,
      "loss": 0.1542,
      "step": 3894
    },
    {
      "epoch": 0.2822770591006269,
      "grad_norm": 1.0623703002929688,
      "learning_rate": 0.00014356112761794334,
      "loss": 0.0722,
      "step": 3895
    },
    {
      "epoch": 0.2823495307460956,
      "grad_norm": 1.2882249355316162,
      "learning_rate": 0.0001435466338140445,
      "loss": 0.0565,
      "step": 3896
    },
    {
      "epoch": 0.2824220023915643,
      "grad_norm": 1.8458226919174194,
      "learning_rate": 0.00014353214001014568,
      "loss": 0.087,
      "step": 3897
    },
    {
      "epoch": 0.282494474037033,
      "grad_norm": 1.4154679775238037,
      "learning_rate": 0.00014351764620624684,
      "loss": 0.1115,
      "step": 3898
    },
    {
      "epoch": 0.28256694568250174,
      "grad_norm": 0.9414328932762146,
      "learning_rate": 0.000143503152402348,
      "loss": 0.0606,
      "step": 3899
    },
    {
      "epoch": 0.28263941732797043,
      "grad_norm": 5.554140090942383,
      "learning_rate": 0.00014348865859844918,
      "loss": 0.1536,
      "step": 3900
    },
    {
      "epoch": 0.28271188897343913,
      "grad_norm": 2.3299877643585205,
      "learning_rate": 0.00014347416479455034,
      "loss": 0.0378,
      "step": 3901
    },
    {
      "epoch": 0.2827843606189078,
      "grad_norm": 1.1836857795715332,
      "learning_rate": 0.0001434596709906515,
      "loss": 0.0831,
      "step": 3902
    },
    {
      "epoch": 0.2828568322643766,
      "grad_norm": 1.4831106662750244,
      "learning_rate": 0.00014344517718675268,
      "loss": 0.1511,
      "step": 3903
    },
    {
      "epoch": 0.2829293039098453,
      "grad_norm": 0.9121438264846802,
      "learning_rate": 0.00014343068338285383,
      "loss": 0.0265,
      "step": 3904
    },
    {
      "epoch": 0.283001775555314,
      "grad_norm": 1.7987065315246582,
      "learning_rate": 0.000143416189578955,
      "loss": 0.0609,
      "step": 3905
    },
    {
      "epoch": 0.28307424720078267,
      "grad_norm": 1.145553708076477,
      "learning_rate": 0.00014340169577505617,
      "loss": 0.0272,
      "step": 3906
    },
    {
      "epoch": 0.2831467188462514,
      "grad_norm": 0.5803369879722595,
      "learning_rate": 0.00014338720197115733,
      "loss": 0.0243,
      "step": 3907
    },
    {
      "epoch": 0.2832191904917201,
      "grad_norm": 2.566502571105957,
      "learning_rate": 0.00014337270816725849,
      "loss": 0.1701,
      "step": 3908
    },
    {
      "epoch": 0.2832916621371888,
      "grad_norm": 1.0465387105941772,
      "learning_rate": 0.00014335821436335967,
      "loss": 0.0207,
      "step": 3909
    },
    {
      "epoch": 0.2833641337826575,
      "grad_norm": 0.7208538055419922,
      "learning_rate": 0.00014334372055946083,
      "loss": 0.0256,
      "step": 3910
    },
    {
      "epoch": 0.28343660542812626,
      "grad_norm": 1.7048600912094116,
      "learning_rate": 0.000143329226755562,
      "loss": 0.0254,
      "step": 3911
    },
    {
      "epoch": 0.28350907707359496,
      "grad_norm": 1.6802606582641602,
      "learning_rate": 0.00014331473295166317,
      "loss": 0.091,
      "step": 3912
    },
    {
      "epoch": 0.28358154871906366,
      "grad_norm": 1.224237322807312,
      "learning_rate": 0.00014330023914776435,
      "loss": 0.0912,
      "step": 3913
    },
    {
      "epoch": 0.28365402036453236,
      "grad_norm": 2.714002847671509,
      "learning_rate": 0.0001432857453438655,
      "loss": 0.1267,
      "step": 3914
    },
    {
      "epoch": 0.2837264920100011,
      "grad_norm": 2.7040891647338867,
      "learning_rate": 0.0001432712515399667,
      "loss": 0.1094,
      "step": 3915
    },
    {
      "epoch": 0.2837989636554698,
      "grad_norm": 1.5833288431167603,
      "learning_rate": 0.00014325675773606785,
      "loss": 0.0857,
      "step": 3916
    },
    {
      "epoch": 0.2838714353009385,
      "grad_norm": 1.281467318534851,
      "learning_rate": 0.000143242263932169,
      "loss": 0.1185,
      "step": 3917
    },
    {
      "epoch": 0.2839439069464072,
      "grad_norm": 2.266254425048828,
      "learning_rate": 0.00014322777012827019,
      "loss": 0.0749,
      "step": 3918
    },
    {
      "epoch": 0.28401637859187595,
      "grad_norm": 0.6653261780738831,
      "learning_rate": 0.00014321327632437134,
      "loss": 0.0522,
      "step": 3919
    },
    {
      "epoch": 0.28408885023734465,
      "grad_norm": 1.3082716464996338,
      "learning_rate": 0.0001431987825204725,
      "loss": 0.0129,
      "step": 3920
    },
    {
      "epoch": 0.28416132188281334,
      "grad_norm": 3.6382577419281006,
      "learning_rate": 0.00014318428871657368,
      "loss": 0.0792,
      "step": 3921
    },
    {
      "epoch": 0.28423379352828204,
      "grad_norm": 0.3995676338672638,
      "learning_rate": 0.00014316979491267484,
      "loss": 0.0045,
      "step": 3922
    },
    {
      "epoch": 0.2843062651737508,
      "grad_norm": 0.6443598866462708,
      "learning_rate": 0.000143155301108776,
      "loss": 0.0479,
      "step": 3923
    },
    {
      "epoch": 0.2843787368192195,
      "grad_norm": 1.2267917394638062,
      "learning_rate": 0.00014314080730487718,
      "loss": 0.0479,
      "step": 3924
    },
    {
      "epoch": 0.2844512084646882,
      "grad_norm": 3.0466415882110596,
      "learning_rate": 0.00014312631350097834,
      "loss": 0.1666,
      "step": 3925
    },
    {
      "epoch": 0.2845236801101569,
      "grad_norm": 0.9805502891540527,
      "learning_rate": 0.0001431118196970795,
      "loss": 0.1185,
      "step": 3926
    },
    {
      "epoch": 0.28459615175562564,
      "grad_norm": 0.9875369668006897,
      "learning_rate": 0.00014309732589318068,
      "loss": 0.0662,
      "step": 3927
    },
    {
      "epoch": 0.28466862340109433,
      "grad_norm": 0.9924613237380981,
      "learning_rate": 0.00014308283208928183,
      "loss": 0.0989,
      "step": 3928
    },
    {
      "epoch": 0.28474109504656303,
      "grad_norm": 2.389934539794922,
      "learning_rate": 0.000143068338285383,
      "loss": 0.2175,
      "step": 3929
    },
    {
      "epoch": 0.2848135666920317,
      "grad_norm": 4.341465950012207,
      "learning_rate": 0.00014305384448148417,
      "loss": 0.1854,
      "step": 3930
    },
    {
      "epoch": 0.2848860383375005,
      "grad_norm": 1.079526424407959,
      "learning_rate": 0.00014303935067758533,
      "loss": 0.1198,
      "step": 3931
    },
    {
      "epoch": 0.2849585099829692,
      "grad_norm": 0.5750483274459839,
      "learning_rate": 0.00014302485687368649,
      "loss": 0.0445,
      "step": 3932
    },
    {
      "epoch": 0.2850309816284379,
      "grad_norm": 1.0388340950012207,
      "learning_rate": 0.00014301036306978767,
      "loss": 0.0747,
      "step": 3933
    },
    {
      "epoch": 0.28510345327390657,
      "grad_norm": 0.722304105758667,
      "learning_rate": 0.00014299586926588883,
      "loss": 0.0391,
      "step": 3934
    },
    {
      "epoch": 0.28517592491937527,
      "grad_norm": 1.2990496158599854,
      "learning_rate": 0.00014298137546199,
      "loss": 0.0427,
      "step": 3935
    },
    {
      "epoch": 0.285248396564844,
      "grad_norm": 5.082513332366943,
      "learning_rate": 0.00014296688165809117,
      "loss": 0.0742,
      "step": 3936
    },
    {
      "epoch": 0.2853208682103127,
      "grad_norm": 4.112176895141602,
      "learning_rate": 0.00014295238785419235,
      "loss": 0.1631,
      "step": 3937
    },
    {
      "epoch": 0.2853933398557814,
      "grad_norm": 3.349039077758789,
      "learning_rate": 0.0001429378940502935,
      "loss": 0.098,
      "step": 3938
    },
    {
      "epoch": 0.2854658115012501,
      "grad_norm": 3.5264058113098145,
      "learning_rate": 0.0001429234002463947,
      "loss": 0.1367,
      "step": 3939
    },
    {
      "epoch": 0.28553828314671886,
      "grad_norm": 3.478588819503784,
      "learning_rate": 0.00014290890644249585,
      "loss": 0.2212,
      "step": 3940
    },
    {
      "epoch": 0.28561075479218756,
      "grad_norm": 1.0245342254638672,
      "learning_rate": 0.000142894412638597,
      "loss": 0.0328,
      "step": 3941
    },
    {
      "epoch": 0.28568322643765626,
      "grad_norm": 2.1289398670196533,
      "learning_rate": 0.00014287991883469819,
      "loss": 0.0957,
      "step": 3942
    },
    {
      "epoch": 0.28575569808312495,
      "grad_norm": 3.8412375450134277,
      "learning_rate": 0.00014286542503079934,
      "loss": 0.0423,
      "step": 3943
    },
    {
      "epoch": 0.2858281697285937,
      "grad_norm": 0.9373006224632263,
      "learning_rate": 0.0001428509312269005,
      "loss": 0.0582,
      "step": 3944
    },
    {
      "epoch": 0.2859006413740624,
      "grad_norm": 1.7975636720657349,
      "learning_rate": 0.00014283643742300168,
      "loss": 0.1054,
      "step": 3945
    },
    {
      "epoch": 0.2859731130195311,
      "grad_norm": 1.5985280275344849,
      "learning_rate": 0.00014282194361910284,
      "loss": 0.0747,
      "step": 3946
    },
    {
      "epoch": 0.2860455846649998,
      "grad_norm": 0.8383982181549072,
      "learning_rate": 0.000142807449815204,
      "loss": 0.02,
      "step": 3947
    },
    {
      "epoch": 0.28611805631046855,
      "grad_norm": 1.9146246910095215,
      "learning_rate": 0.00014279295601130518,
      "loss": 0.068,
      "step": 3948
    },
    {
      "epoch": 0.28619052795593725,
      "grad_norm": 2.1473686695098877,
      "learning_rate": 0.00014277846220740634,
      "loss": 0.1198,
      "step": 3949
    },
    {
      "epoch": 0.28626299960140594,
      "grad_norm": 1.055611491203308,
      "learning_rate": 0.0001427639684035075,
      "loss": 0.0637,
      "step": 3950
    },
    {
      "epoch": 0.28633547124687464,
      "grad_norm": 0.39554139971733093,
      "learning_rate": 0.00014274947459960868,
      "loss": 0.0057,
      "step": 3951
    },
    {
      "epoch": 0.2864079428923434,
      "grad_norm": 1.6719146966934204,
      "learning_rate": 0.00014273498079570983,
      "loss": 0.1252,
      "step": 3952
    },
    {
      "epoch": 0.2864804145378121,
      "grad_norm": 1.3950932025909424,
      "learning_rate": 0.000142720486991811,
      "loss": 0.0895,
      "step": 3953
    },
    {
      "epoch": 0.2865528861832808,
      "grad_norm": 2.0040957927703857,
      "learning_rate": 0.00014270599318791217,
      "loss": 0.1034,
      "step": 3954
    },
    {
      "epoch": 0.2866253578287495,
      "grad_norm": 0.8462116718292236,
      "learning_rate": 0.00014269149938401333,
      "loss": 0.0384,
      "step": 3955
    },
    {
      "epoch": 0.28669782947421824,
      "grad_norm": 0.676335871219635,
      "learning_rate": 0.00014267700558011448,
      "loss": 0.0366,
      "step": 3956
    },
    {
      "epoch": 0.28677030111968693,
      "grad_norm": 1.3013417720794678,
      "learning_rate": 0.00014266251177621567,
      "loss": 0.08,
      "step": 3957
    },
    {
      "epoch": 0.28684277276515563,
      "grad_norm": 0.7998930811882019,
      "learning_rate": 0.00014264801797231685,
      "loss": 0.047,
      "step": 3958
    },
    {
      "epoch": 0.2869152444106243,
      "grad_norm": 2.6906192302703857,
      "learning_rate": 0.000142633524168418,
      "loss": 0.1008,
      "step": 3959
    },
    {
      "epoch": 0.2869877160560931,
      "grad_norm": 3.4940345287323,
      "learning_rate": 0.0001426190303645192,
      "loss": 0.0994,
      "step": 3960
    },
    {
      "epoch": 0.2870601877015618,
      "grad_norm": 1.4554591178894043,
      "learning_rate": 0.00014260453656062035,
      "loss": 0.0735,
      "step": 3961
    },
    {
      "epoch": 0.28713265934703047,
      "grad_norm": 1.8025912046432495,
      "learning_rate": 0.0001425900427567215,
      "loss": 0.0384,
      "step": 3962
    },
    {
      "epoch": 0.28720513099249917,
      "grad_norm": 0.587388277053833,
      "learning_rate": 0.0001425755489528227,
      "loss": 0.0185,
      "step": 3963
    },
    {
      "epoch": 0.2872776026379679,
      "grad_norm": 1.9895962476730347,
      "learning_rate": 0.00014256105514892385,
      "loss": 0.0887,
      "step": 3964
    },
    {
      "epoch": 0.2873500742834366,
      "grad_norm": 2.5986690521240234,
      "learning_rate": 0.000142546561345025,
      "loss": 0.1038,
      "step": 3965
    },
    {
      "epoch": 0.2874225459289053,
      "grad_norm": 1.6122946739196777,
      "learning_rate": 0.00014253206754112619,
      "loss": 0.0949,
      "step": 3966
    },
    {
      "epoch": 0.287495017574374,
      "grad_norm": 3.8767828941345215,
      "learning_rate": 0.00014251757373722734,
      "loss": 0.2951,
      "step": 3967
    },
    {
      "epoch": 0.2875674892198427,
      "grad_norm": 1.4921296834945679,
      "learning_rate": 0.0001425030799333285,
      "loss": 0.0209,
      "step": 3968
    },
    {
      "epoch": 0.28763996086531146,
      "grad_norm": 1.0474824905395508,
      "learning_rate": 0.00014248858612942968,
      "loss": 0.0406,
      "step": 3969
    },
    {
      "epoch": 0.28771243251078016,
      "grad_norm": 2.3183586597442627,
      "learning_rate": 0.00014247409232553084,
      "loss": 0.1437,
      "step": 3970
    },
    {
      "epoch": 0.28778490415624886,
      "grad_norm": 0.789788544178009,
      "learning_rate": 0.000142459598521632,
      "loss": 0.0302,
      "step": 3971
    },
    {
      "epoch": 0.28785737580171755,
      "grad_norm": 0.7271677255630493,
      "learning_rate": 0.00014244510471773318,
      "loss": 0.026,
      "step": 3972
    },
    {
      "epoch": 0.2879298474471863,
      "grad_norm": 0.8477612137794495,
      "learning_rate": 0.00014243061091383433,
      "loss": 0.043,
      "step": 3973
    },
    {
      "epoch": 0.288002319092655,
      "grad_norm": 2.4201290607452393,
      "learning_rate": 0.0001424161171099355,
      "loss": 0.1348,
      "step": 3974
    },
    {
      "epoch": 0.2880747907381237,
      "grad_norm": 3.6975371837615967,
      "learning_rate": 0.00014240162330603667,
      "loss": 0.2024,
      "step": 3975
    },
    {
      "epoch": 0.2881472623835924,
      "grad_norm": 1.4108597040176392,
      "learning_rate": 0.00014238712950213783,
      "loss": 0.0434,
      "step": 3976
    },
    {
      "epoch": 0.28821973402906115,
      "grad_norm": 1.3261865377426147,
      "learning_rate": 0.000142372635698239,
      "loss": 0.0671,
      "step": 3977
    },
    {
      "epoch": 0.28829220567452984,
      "grad_norm": 2.322155237197876,
      "learning_rate": 0.00014235814189434017,
      "loss": 0.1629,
      "step": 3978
    },
    {
      "epoch": 0.28836467731999854,
      "grad_norm": 1.5896557569503784,
      "learning_rate": 0.00014234364809044133,
      "loss": 0.0647,
      "step": 3979
    },
    {
      "epoch": 0.28843714896546724,
      "grad_norm": 0.6063269972801208,
      "learning_rate": 0.0001423291542865425,
      "loss": 0.0484,
      "step": 3980
    },
    {
      "epoch": 0.288509620610936,
      "grad_norm": 0.9121752381324768,
      "learning_rate": 0.00014231466048264367,
      "loss": 0.0384,
      "step": 3981
    },
    {
      "epoch": 0.2885820922564047,
      "grad_norm": 2.120882272720337,
      "learning_rate": 0.00014230016667874485,
      "loss": 0.1013,
      "step": 3982
    },
    {
      "epoch": 0.2886545639018734,
      "grad_norm": 1.8514013290405273,
      "learning_rate": 0.000142285672874846,
      "loss": 0.0893,
      "step": 3983
    },
    {
      "epoch": 0.2887270355473421,
      "grad_norm": 3.274352788925171,
      "learning_rate": 0.0001422711790709472,
      "loss": 0.1136,
      "step": 3984
    },
    {
      "epoch": 0.28879950719281083,
      "grad_norm": 1.6320703029632568,
      "learning_rate": 0.00014225668526704835,
      "loss": 0.0735,
      "step": 3985
    },
    {
      "epoch": 0.28887197883827953,
      "grad_norm": 0.4575583338737488,
      "learning_rate": 0.00014224219146314953,
      "loss": 0.0242,
      "step": 3986
    },
    {
      "epoch": 0.2889444504837482,
      "grad_norm": 2.0467491149902344,
      "learning_rate": 0.0001422276976592507,
      "loss": 0.0773,
      "step": 3987
    },
    {
      "epoch": 0.2890169221292169,
      "grad_norm": 1.7432254552841187,
      "learning_rate": 0.00014221320385535184,
      "loss": 0.0872,
      "step": 3988
    },
    {
      "epoch": 0.2890893937746857,
      "grad_norm": 4.6840434074401855,
      "learning_rate": 0.00014219871005145303,
      "loss": 0.1102,
      "step": 3989
    },
    {
      "epoch": 0.2891618654201544,
      "grad_norm": 0.5819520354270935,
      "learning_rate": 0.00014218421624755418,
      "loss": 0.04,
      "step": 3990
    },
    {
      "epoch": 0.28923433706562307,
      "grad_norm": 1.9656740427017212,
      "learning_rate": 0.00014216972244365534,
      "loss": 0.0358,
      "step": 3991
    },
    {
      "epoch": 0.28930680871109177,
      "grad_norm": 1.489305853843689,
      "learning_rate": 0.00014215522863975652,
      "loss": 0.0737,
      "step": 3992
    },
    {
      "epoch": 0.2893792803565605,
      "grad_norm": 2.5386407375335693,
      "learning_rate": 0.00014214073483585768,
      "loss": 0.1407,
      "step": 3993
    },
    {
      "epoch": 0.2894517520020292,
      "grad_norm": 3.5398242473602295,
      "learning_rate": 0.00014212624103195884,
      "loss": 0.1304,
      "step": 3994
    },
    {
      "epoch": 0.2895242236474979,
      "grad_norm": 1.9511574506759644,
      "learning_rate": 0.00014211174722806002,
      "loss": 0.1233,
      "step": 3995
    },
    {
      "epoch": 0.2895966952929666,
      "grad_norm": 1.6105046272277832,
      "learning_rate": 0.00014209725342416118,
      "loss": 0.0789,
      "step": 3996
    },
    {
      "epoch": 0.28966916693843536,
      "grad_norm": 2.4799437522888184,
      "learning_rate": 0.00014208275962026233,
      "loss": 0.0289,
      "step": 3997
    },
    {
      "epoch": 0.28974163858390406,
      "grad_norm": 5.660634517669678,
      "learning_rate": 0.00014206826581636352,
      "loss": 0.2375,
      "step": 3998
    },
    {
      "epoch": 0.28981411022937276,
      "grad_norm": 1.8583894968032837,
      "learning_rate": 0.00014205377201246467,
      "loss": 0.0403,
      "step": 3999
    },
    {
      "epoch": 0.28988658187484145,
      "grad_norm": 3.5373873710632324,
      "learning_rate": 0.00014203927820856583,
      "loss": 0.1514,
      "step": 4000
    },
    {
      "epoch": 0.2899590535203102,
      "grad_norm": 0.7954727411270142,
      "learning_rate": 0.00014202478440466701,
      "loss": 0.0474,
      "step": 4001
    },
    {
      "epoch": 0.2900315251657789,
      "grad_norm": 0.3982660174369812,
      "learning_rate": 0.00014201029060076817,
      "loss": 0.0266,
      "step": 4002
    },
    {
      "epoch": 0.2901039968112476,
      "grad_norm": 1.6737905740737915,
      "learning_rate": 0.00014199579679686933,
      "loss": 0.0708,
      "step": 4003
    },
    {
      "epoch": 0.2901764684567163,
      "grad_norm": 0.7754551768302917,
      "learning_rate": 0.0001419813029929705,
      "loss": 0.0493,
      "step": 4004
    },
    {
      "epoch": 0.290248940102185,
      "grad_norm": 2.380730152130127,
      "learning_rate": 0.00014196680918907167,
      "loss": 0.0324,
      "step": 4005
    },
    {
      "epoch": 0.29032141174765375,
      "grad_norm": 2.0074405670166016,
      "learning_rate": 0.00014195231538517285,
      "loss": 0.0341,
      "step": 4006
    },
    {
      "epoch": 0.29039388339312244,
      "grad_norm": 3.2423834800720215,
      "learning_rate": 0.00014193782158127403,
      "loss": 0.184,
      "step": 4007
    },
    {
      "epoch": 0.29046635503859114,
      "grad_norm": 1.4360063076019287,
      "learning_rate": 0.0001419233277773752,
      "loss": 0.078,
      "step": 4008
    },
    {
      "epoch": 0.29053882668405984,
      "grad_norm": 0.7474132776260376,
      "learning_rate": 0.00014190883397347635,
      "loss": 0.0083,
      "step": 4009
    },
    {
      "epoch": 0.2906112983295286,
      "grad_norm": 1.7819924354553223,
      "learning_rate": 0.00014189434016957753,
      "loss": 0.0879,
      "step": 4010
    },
    {
      "epoch": 0.2906837699749973,
      "grad_norm": 2.146479845046997,
      "learning_rate": 0.0001418798463656787,
      "loss": 0.0801,
      "step": 4011
    },
    {
      "epoch": 0.290756241620466,
      "grad_norm": 1.547210693359375,
      "learning_rate": 0.00014186535256177984,
      "loss": 0.1356,
      "step": 4012
    },
    {
      "epoch": 0.2908287132659347,
      "grad_norm": 1.7463433742523193,
      "learning_rate": 0.00014185085875788103,
      "loss": 0.0921,
      "step": 4013
    },
    {
      "epoch": 0.29090118491140343,
      "grad_norm": 0.8899944424629211,
      "learning_rate": 0.00014183636495398218,
      "loss": 0.033,
      "step": 4014
    },
    {
      "epoch": 0.29097365655687213,
      "grad_norm": 1.9619596004486084,
      "learning_rate": 0.00014182187115008334,
      "loss": 0.1051,
      "step": 4015
    },
    {
      "epoch": 0.2910461282023408,
      "grad_norm": 3.8349294662475586,
      "learning_rate": 0.00014180737734618452,
      "loss": 0.1097,
      "step": 4016
    },
    {
      "epoch": 0.2911185998478095,
      "grad_norm": 5.715522766113281,
      "learning_rate": 0.00014179288354228568,
      "loss": 0.1853,
      "step": 4017
    },
    {
      "epoch": 0.2911910714932783,
      "grad_norm": 3.062389850616455,
      "learning_rate": 0.00014177838973838684,
      "loss": 0.0401,
      "step": 4018
    },
    {
      "epoch": 0.29126354313874697,
      "grad_norm": 1.302032470703125,
      "learning_rate": 0.00014176389593448802,
      "loss": 0.0327,
      "step": 4019
    },
    {
      "epoch": 0.29133601478421567,
      "grad_norm": 0.976023256778717,
      "learning_rate": 0.00014174940213058918,
      "loss": 0.0431,
      "step": 4020
    },
    {
      "epoch": 0.29140848642968437,
      "grad_norm": 4.592096328735352,
      "learning_rate": 0.00014173490832669033,
      "loss": 0.1235,
      "step": 4021
    },
    {
      "epoch": 0.2914809580751531,
      "grad_norm": 0.5396727323532104,
      "learning_rate": 0.00014172041452279152,
      "loss": 0.0206,
      "step": 4022
    },
    {
      "epoch": 0.2915534297206218,
      "grad_norm": 3.479802131652832,
      "learning_rate": 0.00014170592071889267,
      "loss": 0.1029,
      "step": 4023
    },
    {
      "epoch": 0.2916259013660905,
      "grad_norm": 1.8998887538909912,
      "learning_rate": 0.00014169142691499383,
      "loss": 0.0462,
      "step": 4024
    },
    {
      "epoch": 0.2916983730115592,
      "grad_norm": 0.8560043573379517,
      "learning_rate": 0.00014167693311109501,
      "loss": 0.0655,
      "step": 4025
    },
    {
      "epoch": 0.29177084465702796,
      "grad_norm": 0.9632948040962219,
      "learning_rate": 0.00014166243930719617,
      "loss": 0.0409,
      "step": 4026
    },
    {
      "epoch": 0.29184331630249666,
      "grad_norm": 1.5048846006393433,
      "learning_rate": 0.00014164794550329735,
      "loss": 0.06,
      "step": 4027
    },
    {
      "epoch": 0.29191578794796536,
      "grad_norm": 3.4960689544677734,
      "learning_rate": 0.0001416334516993985,
      "loss": 0.0951,
      "step": 4028
    },
    {
      "epoch": 0.29198825959343405,
      "grad_norm": 1.0997501611709595,
      "learning_rate": 0.0001416189578954997,
      "loss": 0.0846,
      "step": 4029
    },
    {
      "epoch": 0.2920607312389028,
      "grad_norm": 3.5756630897521973,
      "learning_rate": 0.00014160446409160085,
      "loss": 0.2209,
      "step": 4030
    },
    {
      "epoch": 0.2921332028843715,
      "grad_norm": 2.3241825103759766,
      "learning_rate": 0.00014158997028770203,
      "loss": 0.0571,
      "step": 4031
    },
    {
      "epoch": 0.2922056745298402,
      "grad_norm": 0.6442422866821289,
      "learning_rate": 0.0001415754764838032,
      "loss": 0.0268,
      "step": 4032
    },
    {
      "epoch": 0.2922781461753089,
      "grad_norm": 2.4420769214630127,
      "learning_rate": 0.00014156098267990435,
      "loss": 0.0387,
      "step": 4033
    },
    {
      "epoch": 0.29235061782077765,
      "grad_norm": 1.3733054399490356,
      "learning_rate": 0.00014154648887600553,
      "loss": 0.0971,
      "step": 4034
    },
    {
      "epoch": 0.29242308946624634,
      "grad_norm": 6.9219841957092285,
      "learning_rate": 0.0001415319950721067,
      "loss": 0.204,
      "step": 4035
    },
    {
      "epoch": 0.29249556111171504,
      "grad_norm": 2.2270703315734863,
      "learning_rate": 0.00014151750126820784,
      "loss": 0.1885,
      "step": 4036
    },
    {
      "epoch": 0.29256803275718374,
      "grad_norm": 3.007153034210205,
      "learning_rate": 0.00014150300746430903,
      "loss": 0.0878,
      "step": 4037
    },
    {
      "epoch": 0.29264050440265243,
      "grad_norm": 1.9208199977874756,
      "learning_rate": 0.00014148851366041018,
      "loss": 0.1006,
      "step": 4038
    },
    {
      "epoch": 0.2927129760481212,
      "grad_norm": 1.3458528518676758,
      "learning_rate": 0.00014147401985651134,
      "loss": 0.0822,
      "step": 4039
    },
    {
      "epoch": 0.2927854476935899,
      "grad_norm": 1.2670952081680298,
      "learning_rate": 0.00014145952605261252,
      "loss": 0.1032,
      "step": 4040
    },
    {
      "epoch": 0.2928579193390586,
      "grad_norm": 0.5820179581642151,
      "learning_rate": 0.00014144503224871368,
      "loss": 0.0199,
      "step": 4041
    },
    {
      "epoch": 0.2929303909845273,
      "grad_norm": 3.9297897815704346,
      "learning_rate": 0.00014143053844481484,
      "loss": 0.0801,
      "step": 4042
    },
    {
      "epoch": 0.29300286262999603,
      "grad_norm": 2.538975477218628,
      "learning_rate": 0.00014141604464091602,
      "loss": 0.1324,
      "step": 4043
    },
    {
      "epoch": 0.2930753342754647,
      "grad_norm": 1.7877373695373535,
      "learning_rate": 0.00014140155083701718,
      "loss": 0.1351,
      "step": 4044
    },
    {
      "epoch": 0.2931478059209334,
      "grad_norm": 2.113511085510254,
      "learning_rate": 0.00014138705703311833,
      "loss": 0.0809,
      "step": 4045
    },
    {
      "epoch": 0.2932202775664021,
      "grad_norm": 2.5582897663116455,
      "learning_rate": 0.00014137256322921952,
      "loss": 0.0569,
      "step": 4046
    },
    {
      "epoch": 0.2932927492118709,
      "grad_norm": 1.5863585472106934,
      "learning_rate": 0.00014135806942532067,
      "loss": 0.106,
      "step": 4047
    },
    {
      "epoch": 0.29336522085733957,
      "grad_norm": 2.7137322425842285,
      "learning_rate": 0.00014134357562142183,
      "loss": 0.2458,
      "step": 4048
    },
    {
      "epoch": 0.29343769250280827,
      "grad_norm": 1.1568654775619507,
      "learning_rate": 0.00014132908181752301,
      "loss": 0.0273,
      "step": 4049
    },
    {
      "epoch": 0.29351016414827696,
      "grad_norm": 2.012531280517578,
      "learning_rate": 0.00014131458801362417,
      "loss": 0.0949,
      "step": 4050
    },
    {
      "epoch": 0.2935826357937457,
      "grad_norm": 3.191696882247925,
      "learning_rate": 0.00014130009420972535,
      "loss": 0.1649,
      "step": 4051
    },
    {
      "epoch": 0.2936551074392144,
      "grad_norm": 4.41822624206543,
      "learning_rate": 0.0001412856004058265,
      "loss": 0.1768,
      "step": 4052
    },
    {
      "epoch": 0.2937275790846831,
      "grad_norm": 1.483180046081543,
      "learning_rate": 0.0001412711066019277,
      "loss": 0.024,
      "step": 4053
    },
    {
      "epoch": 0.2938000507301518,
      "grad_norm": 1.2067664861679077,
      "learning_rate": 0.00014125661279802885,
      "loss": 0.0513,
      "step": 4054
    },
    {
      "epoch": 0.29387252237562056,
      "grad_norm": 1.7695156335830688,
      "learning_rate": 0.00014124211899413003,
      "loss": 0.0575,
      "step": 4055
    },
    {
      "epoch": 0.29394499402108926,
      "grad_norm": 2.022998094558716,
      "learning_rate": 0.0001412276251902312,
      "loss": 0.0481,
      "step": 4056
    },
    {
      "epoch": 0.29401746566655795,
      "grad_norm": 6.128429412841797,
      "learning_rate": 0.00014121313138633235,
      "loss": 0.2464,
      "step": 4057
    },
    {
      "epoch": 0.29408993731202665,
      "grad_norm": 1.2053505182266235,
      "learning_rate": 0.00014119863758243353,
      "loss": 0.0239,
      "step": 4058
    },
    {
      "epoch": 0.2941624089574954,
      "grad_norm": 2.30311918258667,
      "learning_rate": 0.0001411841437785347,
      "loss": 0.0862,
      "step": 4059
    },
    {
      "epoch": 0.2942348806029641,
      "grad_norm": 2.6712777614593506,
      "learning_rate": 0.00014116964997463584,
      "loss": 0.0803,
      "step": 4060
    },
    {
      "epoch": 0.2943073522484328,
      "grad_norm": 1.4201244115829468,
      "learning_rate": 0.00014115515617073703,
      "loss": 0.053,
      "step": 4061
    },
    {
      "epoch": 0.2943798238939015,
      "grad_norm": 2.278148889541626,
      "learning_rate": 0.00014114066236683818,
      "loss": 0.0977,
      "step": 4062
    },
    {
      "epoch": 0.29445229553937025,
      "grad_norm": 2.9265291690826416,
      "learning_rate": 0.00014112616856293934,
      "loss": 0.0587,
      "step": 4063
    },
    {
      "epoch": 0.29452476718483894,
      "grad_norm": 2.358590602874756,
      "learning_rate": 0.00014111167475904052,
      "loss": 0.1286,
      "step": 4064
    },
    {
      "epoch": 0.29459723883030764,
      "grad_norm": 1.8679319620132446,
      "learning_rate": 0.00014109718095514168,
      "loss": 0.0356,
      "step": 4065
    },
    {
      "epoch": 0.29466971047577634,
      "grad_norm": 2.309286117553711,
      "learning_rate": 0.00014108268715124284,
      "loss": 0.0479,
      "step": 4066
    },
    {
      "epoch": 0.2947421821212451,
      "grad_norm": 1.8290538787841797,
      "learning_rate": 0.00014106819334734402,
      "loss": 0.1896,
      "step": 4067
    },
    {
      "epoch": 0.2948146537667138,
      "grad_norm": 2.5866901874542236,
      "learning_rate": 0.00014105369954344518,
      "loss": 0.1642,
      "step": 4068
    },
    {
      "epoch": 0.2948871254121825,
      "grad_norm": 2.24873423576355,
      "learning_rate": 0.00014103920573954633,
      "loss": 0.1424,
      "step": 4069
    },
    {
      "epoch": 0.2949595970576512,
      "grad_norm": 2.194153070449829,
      "learning_rate": 0.00014102471193564752,
      "loss": 0.1202,
      "step": 4070
    },
    {
      "epoch": 0.29503206870311993,
      "grad_norm": 3.1287429332733154,
      "learning_rate": 0.00014101021813174867,
      "loss": 0.0819,
      "step": 4071
    },
    {
      "epoch": 0.29510454034858863,
      "grad_norm": 1.502469539642334,
      "learning_rate": 0.00014099572432784983,
      "loss": 0.0613,
      "step": 4072
    },
    {
      "epoch": 0.2951770119940573,
      "grad_norm": 1.6776195764541626,
      "learning_rate": 0.000140981230523951,
      "loss": 0.0672,
      "step": 4073
    },
    {
      "epoch": 0.295249483639526,
      "grad_norm": 1.487191081047058,
      "learning_rate": 0.0001409667367200522,
      "loss": 0.0458,
      "step": 4074
    },
    {
      "epoch": 0.2953219552849947,
      "grad_norm": 1.5450518131256104,
      "learning_rate": 0.00014095224291615335,
      "loss": 0.0711,
      "step": 4075
    },
    {
      "epoch": 0.29539442693046347,
      "grad_norm": 1.6416280269622803,
      "learning_rate": 0.00014093774911225454,
      "loss": 0.1759,
      "step": 4076
    },
    {
      "epoch": 0.29546689857593217,
      "grad_norm": 1.3997687101364136,
      "learning_rate": 0.0001409232553083557,
      "loss": 0.0574,
      "step": 4077
    },
    {
      "epoch": 0.29553937022140087,
      "grad_norm": 1.06857168674469,
      "learning_rate": 0.00014090876150445685,
      "loss": 0.0938,
      "step": 4078
    },
    {
      "epoch": 0.29561184186686956,
      "grad_norm": 0.6562754511833191,
      "learning_rate": 0.00014089426770055803,
      "loss": 0.0297,
      "step": 4079
    },
    {
      "epoch": 0.2956843135123383,
      "grad_norm": 5.713514804840088,
      "learning_rate": 0.0001408797738966592,
      "loss": 0.1744,
      "step": 4080
    },
    {
      "epoch": 0.295756785157807,
      "grad_norm": 1.672719955444336,
      "learning_rate": 0.00014086528009276035,
      "loss": 0.0548,
      "step": 4081
    },
    {
      "epoch": 0.2958292568032757,
      "grad_norm": 0.9768772721290588,
      "learning_rate": 0.00014085078628886153,
      "loss": 0.0658,
      "step": 4082
    },
    {
      "epoch": 0.2959017284487444,
      "grad_norm": 3.080934524536133,
      "learning_rate": 0.0001408362924849627,
      "loss": 0.0375,
      "step": 4083
    },
    {
      "epoch": 0.29597420009421316,
      "grad_norm": 0.8033443689346313,
      "learning_rate": 0.00014082179868106384,
      "loss": 0.0897,
      "step": 4084
    },
    {
      "epoch": 0.29604667173968185,
      "grad_norm": 2.591977834701538,
      "learning_rate": 0.00014080730487716503,
      "loss": 0.1473,
      "step": 4085
    },
    {
      "epoch": 0.29611914338515055,
      "grad_norm": 3.095641613006592,
      "learning_rate": 0.00014079281107326618,
      "loss": 0.194,
      "step": 4086
    },
    {
      "epoch": 0.29619161503061925,
      "grad_norm": 1.1294291019439697,
      "learning_rate": 0.00014077831726936734,
      "loss": 0.0593,
      "step": 4087
    },
    {
      "epoch": 0.296264086676088,
      "grad_norm": 0.6728200316429138,
      "learning_rate": 0.00014076382346546852,
      "loss": 0.0254,
      "step": 4088
    },
    {
      "epoch": 0.2963365583215567,
      "grad_norm": 2.4095335006713867,
      "learning_rate": 0.00014074932966156968,
      "loss": 0.2653,
      "step": 4089
    },
    {
      "epoch": 0.2964090299670254,
      "grad_norm": 1.2332689762115479,
      "learning_rate": 0.00014073483585767084,
      "loss": 0.0475,
      "step": 4090
    },
    {
      "epoch": 0.2964815016124941,
      "grad_norm": 0.34759461879730225,
      "learning_rate": 0.00014072034205377202,
      "loss": 0.0282,
      "step": 4091
    },
    {
      "epoch": 0.29655397325796284,
      "grad_norm": 1.0119645595550537,
      "learning_rate": 0.00014070584824987318,
      "loss": 0.0639,
      "step": 4092
    },
    {
      "epoch": 0.29662644490343154,
      "grad_norm": 0.8384896516799927,
      "learning_rate": 0.00014069135444597433,
      "loss": 0.0198,
      "step": 4093
    },
    {
      "epoch": 0.29669891654890024,
      "grad_norm": 1.3277223110198975,
      "learning_rate": 0.00014067686064207552,
      "loss": 0.0402,
      "step": 4094
    },
    {
      "epoch": 0.29677138819436893,
      "grad_norm": 2.422835111618042,
      "learning_rate": 0.00014066236683817667,
      "loss": 0.0476,
      "step": 4095
    },
    {
      "epoch": 0.2968438598398377,
      "grad_norm": 0.5184153318405151,
      "learning_rate": 0.00014064787303427786,
      "loss": 0.0202,
      "step": 4096
    },
    {
      "epoch": 0.2969163314853064,
      "grad_norm": 1.3597054481506348,
      "learning_rate": 0.000140633379230379,
      "loss": 0.0412,
      "step": 4097
    },
    {
      "epoch": 0.2969888031307751,
      "grad_norm": 0.6549736857414246,
      "learning_rate": 0.0001406188854264802,
      "loss": 0.0041,
      "step": 4098
    },
    {
      "epoch": 0.2970612747762438,
      "grad_norm": 2.768310308456421,
      "learning_rate": 0.00014060439162258135,
      "loss": 0.064,
      "step": 4099
    },
    {
      "epoch": 0.29713374642171253,
      "grad_norm": 1.0636438131332397,
      "learning_rate": 0.00014058989781868254,
      "loss": 0.0718,
      "step": 4100
    },
    {
      "epoch": 0.2972062180671812,
      "grad_norm": 1.4319428205490112,
      "learning_rate": 0.0001405754040147837,
      "loss": 0.0558,
      "step": 4101
    },
    {
      "epoch": 0.2972786897126499,
      "grad_norm": 0.7976477742195129,
      "learning_rate": 0.00014056091021088485,
      "loss": 0.0314,
      "step": 4102
    },
    {
      "epoch": 0.2973511613581186,
      "grad_norm": 0.7088959813117981,
      "learning_rate": 0.00014054641640698603,
      "loss": 0.0126,
      "step": 4103
    },
    {
      "epoch": 0.2974236330035874,
      "grad_norm": 1.6919821500778198,
      "learning_rate": 0.0001405319226030872,
      "loss": 0.1089,
      "step": 4104
    },
    {
      "epoch": 0.29749610464905607,
      "grad_norm": 3.4696013927459717,
      "learning_rate": 0.00014051742879918835,
      "loss": 0.1504,
      "step": 4105
    },
    {
      "epoch": 0.29756857629452477,
      "grad_norm": 0.8736355304718018,
      "learning_rate": 0.00014050293499528953,
      "loss": 0.0133,
      "step": 4106
    },
    {
      "epoch": 0.29764104793999346,
      "grad_norm": 1.3347042798995972,
      "learning_rate": 0.00014048844119139069,
      "loss": 0.0621,
      "step": 4107
    },
    {
      "epoch": 0.29771351958546216,
      "grad_norm": 2.150161027908325,
      "learning_rate": 0.00014047394738749184,
      "loss": 0.0325,
      "step": 4108
    },
    {
      "epoch": 0.2977859912309309,
      "grad_norm": 3.916360855102539,
      "learning_rate": 0.00014045945358359303,
      "loss": 0.1964,
      "step": 4109
    },
    {
      "epoch": 0.2978584628763996,
      "grad_norm": 3.0665011405944824,
      "learning_rate": 0.00014044495977969418,
      "loss": 0.1971,
      "step": 4110
    },
    {
      "epoch": 0.2979309345218683,
      "grad_norm": 3.1119797229766846,
      "learning_rate": 0.00014043046597579534,
      "loss": 0.122,
      "step": 4111
    },
    {
      "epoch": 0.298003406167337,
      "grad_norm": 4.505470275878906,
      "learning_rate": 0.00014041597217189652,
      "loss": 0.0814,
      "step": 4112
    },
    {
      "epoch": 0.29807587781280576,
      "grad_norm": 1.9813247919082642,
      "learning_rate": 0.00014040147836799768,
      "loss": 0.1485,
      "step": 4113
    },
    {
      "epoch": 0.29814834945827445,
      "grad_norm": 2.89668869972229,
      "learning_rate": 0.00014038698456409884,
      "loss": 0.1379,
      "step": 4114
    },
    {
      "epoch": 0.29822082110374315,
      "grad_norm": 3.6026952266693115,
      "learning_rate": 0.00014037249076020002,
      "loss": 0.1171,
      "step": 4115
    },
    {
      "epoch": 0.29829329274921185,
      "grad_norm": 1.2835801839828491,
      "learning_rate": 0.00014035799695630118,
      "loss": 0.0761,
      "step": 4116
    },
    {
      "epoch": 0.2983657643946806,
      "grad_norm": 1.6853975057601929,
      "learning_rate": 0.00014034350315240233,
      "loss": 0.1397,
      "step": 4117
    },
    {
      "epoch": 0.2984382360401493,
      "grad_norm": 2.7200093269348145,
      "learning_rate": 0.00014032900934850352,
      "loss": 0.1715,
      "step": 4118
    },
    {
      "epoch": 0.298510707685618,
      "grad_norm": 1.209068775177002,
      "learning_rate": 0.00014031451554460467,
      "loss": 0.0769,
      "step": 4119
    },
    {
      "epoch": 0.2985831793310867,
      "grad_norm": 2.8723690509796143,
      "learning_rate": 0.00014030002174070586,
      "loss": 0.1353,
      "step": 4120
    },
    {
      "epoch": 0.29865565097655544,
      "grad_norm": 2.188478469848633,
      "learning_rate": 0.00014028552793680704,
      "loss": 0.0565,
      "step": 4121
    },
    {
      "epoch": 0.29872812262202414,
      "grad_norm": 1.1815279722213745,
      "learning_rate": 0.0001402710341329082,
      "loss": 0.0659,
      "step": 4122
    },
    {
      "epoch": 0.29880059426749284,
      "grad_norm": 2.597501754760742,
      "learning_rate": 0.00014025654032900935,
      "loss": 0.1382,
      "step": 4123
    },
    {
      "epoch": 0.29887306591296153,
      "grad_norm": 0.8787816166877747,
      "learning_rate": 0.00014024204652511054,
      "loss": 0.0454,
      "step": 4124
    },
    {
      "epoch": 0.2989455375584303,
      "grad_norm": 4.704958438873291,
      "learning_rate": 0.0001402275527212117,
      "loss": 0.1027,
      "step": 4125
    },
    {
      "epoch": 0.299018009203899,
      "grad_norm": 2.9102325439453125,
      "learning_rate": 0.00014021305891731285,
      "loss": 0.1949,
      "step": 4126
    },
    {
      "epoch": 0.2990904808493677,
      "grad_norm": 4.336623191833496,
      "learning_rate": 0.00014019856511341403,
      "loss": 0.1042,
      "step": 4127
    },
    {
      "epoch": 0.2991629524948364,
      "grad_norm": 1.6954758167266846,
      "learning_rate": 0.0001401840713095152,
      "loss": 0.0812,
      "step": 4128
    },
    {
      "epoch": 0.29923542414030513,
      "grad_norm": 1.3669673204421997,
      "learning_rate": 0.00014016957750561635,
      "loss": 0.1047,
      "step": 4129
    },
    {
      "epoch": 0.2993078957857738,
      "grad_norm": 1.359988808631897,
      "learning_rate": 0.00014015508370171753,
      "loss": 0.0808,
      "step": 4130
    },
    {
      "epoch": 0.2993803674312425,
      "grad_norm": 0.9938555955886841,
      "learning_rate": 0.00014014058989781869,
      "loss": 0.0715,
      "step": 4131
    },
    {
      "epoch": 0.2994528390767112,
      "grad_norm": 1.0473934412002563,
      "learning_rate": 0.00014012609609391984,
      "loss": 0.065,
      "step": 4132
    },
    {
      "epoch": 0.29952531072217997,
      "grad_norm": 0.9772869348526001,
      "learning_rate": 0.00014011160229002103,
      "loss": 0.0956,
      "step": 4133
    },
    {
      "epoch": 0.29959778236764867,
      "grad_norm": 0.8445690274238586,
      "learning_rate": 0.00014009710848612218,
      "loss": 0.0381,
      "step": 4134
    },
    {
      "epoch": 0.29967025401311737,
      "grad_norm": 0.47604086995124817,
      "learning_rate": 0.00014008261468222334,
      "loss": 0.0325,
      "step": 4135
    },
    {
      "epoch": 0.29974272565858606,
      "grad_norm": 0.8821952939033508,
      "learning_rate": 0.00014006812087832452,
      "loss": 0.0561,
      "step": 4136
    },
    {
      "epoch": 0.2998151973040548,
      "grad_norm": 3.321481227874756,
      "learning_rate": 0.00014005362707442568,
      "loss": 0.1654,
      "step": 4137
    },
    {
      "epoch": 0.2998876689495235,
      "grad_norm": 0.7662927508354187,
      "learning_rate": 0.00014003913327052684,
      "loss": 0.0359,
      "step": 4138
    },
    {
      "epoch": 0.2999601405949922,
      "grad_norm": 1.2455456256866455,
      "learning_rate": 0.00014002463946662802,
      "loss": 0.0355,
      "step": 4139
    },
    {
      "epoch": 0.3000326122404609,
      "grad_norm": 3.9392569065093994,
      "learning_rate": 0.00014001014566272918,
      "loss": 0.0714,
      "step": 4140
    },
    {
      "epoch": 0.30010508388592966,
      "grad_norm": 1.218479037284851,
      "learning_rate": 0.00013999565185883036,
      "loss": 0.0373,
      "step": 4141
    },
    {
      "epoch": 0.30017755553139835,
      "grad_norm": 3.0775842666625977,
      "learning_rate": 0.00013998115805493152,
      "loss": 0.0573,
      "step": 4142
    },
    {
      "epoch": 0.30025002717686705,
      "grad_norm": 3.755621910095215,
      "learning_rate": 0.0001399666642510327,
      "loss": 0.1425,
      "step": 4143
    },
    {
      "epoch": 0.30032249882233575,
      "grad_norm": 0.9650608897209167,
      "learning_rate": 0.00013995217044713386,
      "loss": 0.0431,
      "step": 4144
    },
    {
      "epoch": 0.30039497046780445,
      "grad_norm": 2.619204521179199,
      "learning_rate": 0.00013993767664323504,
      "loss": 0.101,
      "step": 4145
    },
    {
      "epoch": 0.3004674421132732,
      "grad_norm": 4.048067569732666,
      "learning_rate": 0.0001399231828393362,
      "loss": 0.2148,
      "step": 4146
    },
    {
      "epoch": 0.3005399137587419,
      "grad_norm": 3.718017816543579,
      "learning_rate": 0.00013990868903543738,
      "loss": 0.1307,
      "step": 4147
    },
    {
      "epoch": 0.3006123854042106,
      "grad_norm": 2.5674965381622314,
      "learning_rate": 0.00013989419523153854,
      "loss": 0.1565,
      "step": 4148
    },
    {
      "epoch": 0.3006848570496793,
      "grad_norm": 1.049802303314209,
      "learning_rate": 0.0001398797014276397,
      "loss": 0.0522,
      "step": 4149
    },
    {
      "epoch": 0.30075732869514804,
      "grad_norm": 1.1215709447860718,
      "learning_rate": 0.00013986520762374088,
      "loss": 0.0725,
      "step": 4150
    },
    {
      "epoch": 0.30082980034061674,
      "grad_norm": 2.9829723834991455,
      "learning_rate": 0.00013985071381984203,
      "loss": 0.0839,
      "step": 4151
    },
    {
      "epoch": 0.30090227198608543,
      "grad_norm": 0.9630555510520935,
      "learning_rate": 0.0001398362200159432,
      "loss": 0.085,
      "step": 4152
    },
    {
      "epoch": 0.30097474363155413,
      "grad_norm": 0.6764822602272034,
      "learning_rate": 0.00013982172621204437,
      "loss": 0.0302,
      "step": 4153
    },
    {
      "epoch": 0.3010472152770229,
      "grad_norm": 0.42651620507240295,
      "learning_rate": 0.00013980723240814553,
      "loss": 0.027,
      "step": 4154
    },
    {
      "epoch": 0.3011196869224916,
      "grad_norm": 1.8196920156478882,
      "learning_rate": 0.00013979273860424669,
      "loss": 0.0799,
      "step": 4155
    },
    {
      "epoch": 0.3011921585679603,
      "grad_norm": 1.4844303131103516,
      "learning_rate": 0.00013977824480034787,
      "loss": 0.0776,
      "step": 4156
    },
    {
      "epoch": 0.301264630213429,
      "grad_norm": 2.9130518436431885,
      "learning_rate": 0.00013976375099644903,
      "loss": 0.0829,
      "step": 4157
    },
    {
      "epoch": 0.3013371018588977,
      "grad_norm": 0.549075186252594,
      "learning_rate": 0.00013974925719255018,
      "loss": 0.0397,
      "step": 4158
    },
    {
      "epoch": 0.3014095735043664,
      "grad_norm": 1.0777804851531982,
      "learning_rate": 0.00013973476338865137,
      "loss": 0.088,
      "step": 4159
    },
    {
      "epoch": 0.3014820451498351,
      "grad_norm": 3.5051562786102295,
      "learning_rate": 0.00013972026958475252,
      "loss": 0.0786,
      "step": 4160
    },
    {
      "epoch": 0.3015545167953038,
      "grad_norm": 3.2511463165283203,
      "learning_rate": 0.00013970577578085368,
      "loss": 0.1254,
      "step": 4161
    },
    {
      "epoch": 0.30162698844077257,
      "grad_norm": 0.704035222530365,
      "learning_rate": 0.00013969128197695486,
      "loss": 0.0219,
      "step": 4162
    },
    {
      "epoch": 0.30169946008624127,
      "grad_norm": 2.7733397483825684,
      "learning_rate": 0.00013967678817305602,
      "loss": 0.0933,
      "step": 4163
    },
    {
      "epoch": 0.30177193173170996,
      "grad_norm": 2.6187455654144287,
      "learning_rate": 0.00013966229436915718,
      "loss": 0.1224,
      "step": 4164
    },
    {
      "epoch": 0.30184440337717866,
      "grad_norm": 0.8723596930503845,
      "learning_rate": 0.00013964780056525836,
      "loss": 0.0985,
      "step": 4165
    },
    {
      "epoch": 0.3019168750226474,
      "grad_norm": 3.30465030670166,
      "learning_rate": 0.00013963330676135952,
      "loss": 0.2177,
      "step": 4166
    },
    {
      "epoch": 0.3019893466681161,
      "grad_norm": 1.239537000656128,
      "learning_rate": 0.0001396188129574607,
      "loss": 0.0823,
      "step": 4167
    },
    {
      "epoch": 0.3020618183135848,
      "grad_norm": 0.44028058648109436,
      "learning_rate": 0.00013960431915356188,
      "loss": 0.0381,
      "step": 4168
    },
    {
      "epoch": 0.3021342899590535,
      "grad_norm": 1.6331589221954346,
      "learning_rate": 0.00013958982534966304,
      "loss": 0.1386,
      "step": 4169
    },
    {
      "epoch": 0.30220676160452226,
      "grad_norm": 2.3605189323425293,
      "learning_rate": 0.0001395753315457642,
      "loss": 0.0803,
      "step": 4170
    },
    {
      "epoch": 0.30227923324999095,
      "grad_norm": 1.4016903638839722,
      "learning_rate": 0.00013956083774186538,
      "loss": 0.1011,
      "step": 4171
    },
    {
      "epoch": 0.30235170489545965,
      "grad_norm": 2.231985569000244,
      "learning_rate": 0.00013954634393796654,
      "loss": 0.1175,
      "step": 4172
    },
    {
      "epoch": 0.30242417654092835,
      "grad_norm": 0.7341736555099487,
      "learning_rate": 0.0001395318501340677,
      "loss": 0.0235,
      "step": 4173
    },
    {
      "epoch": 0.3024966481863971,
      "grad_norm": 0.894536554813385,
      "learning_rate": 0.00013951735633016888,
      "loss": 0.1122,
      "step": 4174
    },
    {
      "epoch": 0.3025691198318658,
      "grad_norm": 1.177341103553772,
      "learning_rate": 0.00013950286252627003,
      "loss": 0.0477,
      "step": 4175
    },
    {
      "epoch": 0.3026415914773345,
      "grad_norm": 0.5766676068305969,
      "learning_rate": 0.0001394883687223712,
      "loss": 0.0599,
      "step": 4176
    },
    {
      "epoch": 0.3027140631228032,
      "grad_norm": 1.6717479228973389,
      "learning_rate": 0.00013947387491847237,
      "loss": 0.1309,
      "step": 4177
    },
    {
      "epoch": 0.3027865347682719,
      "grad_norm": 0.5036557912826538,
      "learning_rate": 0.00013945938111457353,
      "loss": 0.0115,
      "step": 4178
    },
    {
      "epoch": 0.30285900641374064,
      "grad_norm": 3.016563892364502,
      "learning_rate": 0.00013944488731067468,
      "loss": 0.1207,
      "step": 4179
    },
    {
      "epoch": 0.30293147805920934,
      "grad_norm": 0.6099810004234314,
      "learning_rate": 0.00013943039350677587,
      "loss": 0.0273,
      "step": 4180
    },
    {
      "epoch": 0.30300394970467803,
      "grad_norm": 6.78793478012085,
      "learning_rate": 0.00013941589970287703,
      "loss": 0.162,
      "step": 4181
    },
    {
      "epoch": 0.30307642135014673,
      "grad_norm": 3.6471192836761475,
      "learning_rate": 0.00013940140589897818,
      "loss": 0.2058,
      "step": 4182
    },
    {
      "epoch": 0.3031488929956155,
      "grad_norm": 8.624221801757812,
      "learning_rate": 0.00013938691209507937,
      "loss": 0.2372,
      "step": 4183
    },
    {
      "epoch": 0.3032213646410842,
      "grad_norm": 1.1815359592437744,
      "learning_rate": 0.00013937241829118052,
      "loss": 0.0529,
      "step": 4184
    },
    {
      "epoch": 0.3032938362865529,
      "grad_norm": 2.470883846282959,
      "learning_rate": 0.00013935792448728168,
      "loss": 0.1445,
      "step": 4185
    },
    {
      "epoch": 0.3033663079320216,
      "grad_norm": 2.253887414932251,
      "learning_rate": 0.00013934343068338286,
      "loss": 0.0911,
      "step": 4186
    },
    {
      "epoch": 0.3034387795774903,
      "grad_norm": 2.6862354278564453,
      "learning_rate": 0.00013932893687948402,
      "loss": 0.1594,
      "step": 4187
    },
    {
      "epoch": 0.303511251222959,
      "grad_norm": 0.9341241717338562,
      "learning_rate": 0.00013931444307558517,
      "loss": 0.0881,
      "step": 4188
    },
    {
      "epoch": 0.3035837228684277,
      "grad_norm": 0.7575125098228455,
      "learning_rate": 0.00013929994927168636,
      "loss": 0.0613,
      "step": 4189
    },
    {
      "epoch": 0.3036561945138964,
      "grad_norm": 0.915825605392456,
      "learning_rate": 0.00013928545546778754,
      "loss": 0.0309,
      "step": 4190
    },
    {
      "epoch": 0.30372866615936517,
      "grad_norm": 0.549966037273407,
      "learning_rate": 0.0001392709616638887,
      "loss": 0.0372,
      "step": 4191
    },
    {
      "epoch": 0.30380113780483387,
      "grad_norm": 0.843572199344635,
      "learning_rate": 0.00013925646785998988,
      "loss": 0.0367,
      "step": 4192
    },
    {
      "epoch": 0.30387360945030256,
      "grad_norm": 0.645851731300354,
      "learning_rate": 0.00013924197405609104,
      "loss": 0.0251,
      "step": 4193
    },
    {
      "epoch": 0.30394608109577126,
      "grad_norm": 0.6711270809173584,
      "learning_rate": 0.0001392274802521922,
      "loss": 0.065,
      "step": 4194
    },
    {
      "epoch": 0.30401855274124,
      "grad_norm": 1.2955516576766968,
      "learning_rate": 0.00013921298644829338,
      "loss": 0.0557,
      "step": 4195
    },
    {
      "epoch": 0.3040910243867087,
      "grad_norm": 1.2826464176177979,
      "learning_rate": 0.00013919849264439453,
      "loss": 0.1253,
      "step": 4196
    },
    {
      "epoch": 0.3041634960321774,
      "grad_norm": 0.7887303829193115,
      "learning_rate": 0.0001391839988404957,
      "loss": 0.0479,
      "step": 4197
    },
    {
      "epoch": 0.3042359676776461,
      "grad_norm": 2.9531373977661133,
      "learning_rate": 0.00013916950503659688,
      "loss": 0.1026,
      "step": 4198
    },
    {
      "epoch": 0.30430843932311485,
      "grad_norm": 1.9306600093841553,
      "learning_rate": 0.00013915501123269803,
      "loss": 0.1194,
      "step": 4199
    },
    {
      "epoch": 0.30438091096858355,
      "grad_norm": 0.8667159080505371,
      "learning_rate": 0.0001391405174287992,
      "loss": 0.0232,
      "step": 4200
    },
    {
      "epoch": 0.30445338261405225,
      "grad_norm": 3.582801103591919,
      "learning_rate": 0.00013912602362490037,
      "loss": 0.0607,
      "step": 4201
    },
    {
      "epoch": 0.30452585425952094,
      "grad_norm": 4.028736591339111,
      "learning_rate": 0.00013911152982100153,
      "loss": 0.0702,
      "step": 4202
    },
    {
      "epoch": 0.3045983259049897,
      "grad_norm": 0.16445523500442505,
      "learning_rate": 0.00013909703601710268,
      "loss": 0.0017,
      "step": 4203
    },
    {
      "epoch": 0.3046707975504584,
      "grad_norm": 2.5851480960845947,
      "learning_rate": 0.00013908254221320387,
      "loss": 0.0629,
      "step": 4204
    },
    {
      "epoch": 0.3047432691959271,
      "grad_norm": 1.4797178506851196,
      "learning_rate": 0.00013906804840930502,
      "loss": 0.1243,
      "step": 4205
    },
    {
      "epoch": 0.3048157408413958,
      "grad_norm": 1.6027107238769531,
      "learning_rate": 0.00013905355460540618,
      "loss": 0.0237,
      "step": 4206
    },
    {
      "epoch": 0.30488821248686454,
      "grad_norm": 1.5140748023986816,
      "learning_rate": 0.00013903906080150736,
      "loss": 0.0522,
      "step": 4207
    },
    {
      "epoch": 0.30496068413233324,
      "grad_norm": 4.417464256286621,
      "learning_rate": 0.00013902456699760852,
      "loss": 0.1705,
      "step": 4208
    },
    {
      "epoch": 0.30503315577780193,
      "grad_norm": 0.7231544852256775,
      "learning_rate": 0.00013901007319370968,
      "loss": 0.0197,
      "step": 4209
    },
    {
      "epoch": 0.30510562742327063,
      "grad_norm": 2.0887956619262695,
      "learning_rate": 0.00013899557938981086,
      "loss": 0.1037,
      "step": 4210
    },
    {
      "epoch": 0.30517809906873933,
      "grad_norm": 0.7435898780822754,
      "learning_rate": 0.00013898108558591202,
      "loss": 0.0356,
      "step": 4211
    },
    {
      "epoch": 0.3052505707142081,
      "grad_norm": 2.0431277751922607,
      "learning_rate": 0.0001389665917820132,
      "loss": 0.0679,
      "step": 4212
    },
    {
      "epoch": 0.3053230423596768,
      "grad_norm": 4.429169178009033,
      "learning_rate": 0.00013895209797811436,
      "loss": 0.0874,
      "step": 4213
    },
    {
      "epoch": 0.3053955140051455,
      "grad_norm": 1.2316102981567383,
      "learning_rate": 0.00013893760417421554,
      "loss": 0.0362,
      "step": 4214
    },
    {
      "epoch": 0.30546798565061417,
      "grad_norm": 2.9751036167144775,
      "learning_rate": 0.0001389231103703167,
      "loss": 0.0447,
      "step": 4215
    },
    {
      "epoch": 0.3055404572960829,
      "grad_norm": 0.7007616758346558,
      "learning_rate": 0.00013890861656641788,
      "loss": 0.026,
      "step": 4216
    },
    {
      "epoch": 0.3056129289415516,
      "grad_norm": 0.7226802706718445,
      "learning_rate": 0.00013889412276251904,
      "loss": 0.0356,
      "step": 4217
    },
    {
      "epoch": 0.3056854005870203,
      "grad_norm": 1.2301188707351685,
      "learning_rate": 0.0001388796289586202,
      "loss": 0.0824,
      "step": 4218
    },
    {
      "epoch": 0.305757872232489,
      "grad_norm": 1.9037790298461914,
      "learning_rate": 0.00013886513515472138,
      "loss": 0.0708,
      "step": 4219
    },
    {
      "epoch": 0.30583034387795777,
      "grad_norm": 1.138347864151001,
      "learning_rate": 0.00013885064135082253,
      "loss": 0.0497,
      "step": 4220
    },
    {
      "epoch": 0.30590281552342646,
      "grad_norm": 3.035775899887085,
      "learning_rate": 0.0001388361475469237,
      "loss": 0.1075,
      "step": 4221
    },
    {
      "epoch": 0.30597528716889516,
      "grad_norm": 0.6676719188690186,
      "learning_rate": 0.00013882165374302487,
      "loss": 0.0356,
      "step": 4222
    },
    {
      "epoch": 0.30604775881436386,
      "grad_norm": 5.842602729797363,
      "learning_rate": 0.00013880715993912603,
      "loss": 0.1087,
      "step": 4223
    },
    {
      "epoch": 0.3061202304598326,
      "grad_norm": 1.3964205980300903,
      "learning_rate": 0.0001387926661352272,
      "loss": 0.0445,
      "step": 4224
    },
    {
      "epoch": 0.3061927021053013,
      "grad_norm": 0.92926424741745,
      "learning_rate": 0.00013877817233132837,
      "loss": 0.0348,
      "step": 4225
    },
    {
      "epoch": 0.30626517375077,
      "grad_norm": 0.7721614241600037,
      "learning_rate": 0.00013876367852742953,
      "loss": 0.0571,
      "step": 4226
    },
    {
      "epoch": 0.3063376453962387,
      "grad_norm": 2.242093086242676,
      "learning_rate": 0.00013874918472353068,
      "loss": 0.1333,
      "step": 4227
    },
    {
      "epoch": 0.30641011704170745,
      "grad_norm": 2.4168033599853516,
      "learning_rate": 0.00013873469091963187,
      "loss": 0.0161,
      "step": 4228
    },
    {
      "epoch": 0.30648258868717615,
      "grad_norm": 4.297688007354736,
      "learning_rate": 0.00013872019711573302,
      "loss": 0.1254,
      "step": 4229
    },
    {
      "epoch": 0.30655506033264485,
      "grad_norm": 1.7874385118484497,
      "learning_rate": 0.00013870570331183418,
      "loss": 0.0887,
      "step": 4230
    },
    {
      "epoch": 0.30662753197811354,
      "grad_norm": 1.9663457870483398,
      "learning_rate": 0.00013869120950793536,
      "loss": 0.0938,
      "step": 4231
    },
    {
      "epoch": 0.3067000036235823,
      "grad_norm": 1.9943222999572754,
      "learning_rate": 0.00013867671570403652,
      "loss": 0.0524,
      "step": 4232
    },
    {
      "epoch": 0.306772475269051,
      "grad_norm": 0.808431088924408,
      "learning_rate": 0.00013866222190013768,
      "loss": 0.0488,
      "step": 4233
    },
    {
      "epoch": 0.3068449469145197,
      "grad_norm": 1.5181469917297363,
      "learning_rate": 0.00013864772809623886,
      "loss": 0.0366,
      "step": 4234
    },
    {
      "epoch": 0.3069174185599884,
      "grad_norm": 3.6643149852752686,
      "learning_rate": 0.00013863323429234002,
      "loss": 0.1813,
      "step": 4235
    },
    {
      "epoch": 0.30698989020545714,
      "grad_norm": 2.249605417251587,
      "learning_rate": 0.0001386187404884412,
      "loss": 0.126,
      "step": 4236
    },
    {
      "epoch": 0.30706236185092584,
      "grad_norm": 4.509246349334717,
      "learning_rate": 0.00013860424668454238,
      "loss": 0.1559,
      "step": 4237
    },
    {
      "epoch": 0.30713483349639453,
      "grad_norm": 2.478419780731201,
      "learning_rate": 0.00013858975288064354,
      "loss": 0.1472,
      "step": 4238
    },
    {
      "epoch": 0.30720730514186323,
      "grad_norm": 0.16353155672550201,
      "learning_rate": 0.0001385752590767447,
      "loss": 0.0019,
      "step": 4239
    },
    {
      "epoch": 0.307279776787332,
      "grad_norm": 1.913051724433899,
      "learning_rate": 0.00013856076527284588,
      "loss": 0.0909,
      "step": 4240
    },
    {
      "epoch": 0.3073522484328007,
      "grad_norm": 0.8544118404388428,
      "learning_rate": 0.00013854627146894704,
      "loss": 0.0711,
      "step": 4241
    },
    {
      "epoch": 0.3074247200782694,
      "grad_norm": 3.7321701049804688,
      "learning_rate": 0.0001385317776650482,
      "loss": 0.1151,
      "step": 4242
    },
    {
      "epoch": 0.3074971917237381,
      "grad_norm": 0.8280377984046936,
      "learning_rate": 0.00013851728386114938,
      "loss": 0.0325,
      "step": 4243
    },
    {
      "epoch": 0.3075696633692068,
      "grad_norm": 1.3250317573547363,
      "learning_rate": 0.00013850279005725053,
      "loss": 0.0434,
      "step": 4244
    },
    {
      "epoch": 0.3076421350146755,
      "grad_norm": 1.7862887382507324,
      "learning_rate": 0.0001384882962533517,
      "loss": 0.0655,
      "step": 4245
    },
    {
      "epoch": 0.3077146066601442,
      "grad_norm": 0.8901339173316956,
      "learning_rate": 0.00013847380244945287,
      "loss": 0.0186,
      "step": 4246
    },
    {
      "epoch": 0.3077870783056129,
      "grad_norm": 1.708519697189331,
      "learning_rate": 0.00013845930864555403,
      "loss": 0.1199,
      "step": 4247
    },
    {
      "epoch": 0.3078595499510816,
      "grad_norm": 2.094054698944092,
      "learning_rate": 0.0001384448148416552,
      "loss": 0.0595,
      "step": 4248
    },
    {
      "epoch": 0.30793202159655036,
      "grad_norm": 1.2659319639205933,
      "learning_rate": 0.00013843032103775637,
      "loss": 0.0773,
      "step": 4249
    },
    {
      "epoch": 0.30800449324201906,
      "grad_norm": 4.587681293487549,
      "learning_rate": 0.00013841582723385753,
      "loss": 0.2125,
      "step": 4250
    },
    {
      "epoch": 0.30807696488748776,
      "grad_norm": 0.9556794762611389,
      "learning_rate": 0.00013840133342995868,
      "loss": 0.072,
      "step": 4251
    },
    {
      "epoch": 0.30814943653295646,
      "grad_norm": 1.0015207529067993,
      "learning_rate": 0.00013838683962605987,
      "loss": 0.0361,
      "step": 4252
    },
    {
      "epoch": 0.3082219081784252,
      "grad_norm": 0.49480196833610535,
      "learning_rate": 0.00013837234582216102,
      "loss": 0.0124,
      "step": 4253
    },
    {
      "epoch": 0.3082943798238939,
      "grad_norm": 1.309831142425537,
      "learning_rate": 0.00013835785201826218,
      "loss": 0.0606,
      "step": 4254
    },
    {
      "epoch": 0.3083668514693626,
      "grad_norm": 0.8737406134605408,
      "learning_rate": 0.00013834335821436336,
      "loss": 0.0672,
      "step": 4255
    },
    {
      "epoch": 0.3084393231148313,
      "grad_norm": 0.9506343603134155,
      "learning_rate": 0.00013832886441046452,
      "loss": 0.0585,
      "step": 4256
    },
    {
      "epoch": 0.30851179476030005,
      "grad_norm": 1.7119354009628296,
      "learning_rate": 0.0001383143706065657,
      "loss": 0.1279,
      "step": 4257
    },
    {
      "epoch": 0.30858426640576875,
      "grad_norm": 3.0123965740203857,
      "learning_rate": 0.00013829987680266686,
      "loss": 0.1364,
      "step": 4258
    },
    {
      "epoch": 0.30865673805123744,
      "grad_norm": 0.37832242250442505,
      "learning_rate": 0.00013828538299876804,
      "loss": 0.0233,
      "step": 4259
    },
    {
      "epoch": 0.30872920969670614,
      "grad_norm": 2.610759735107422,
      "learning_rate": 0.0001382708891948692,
      "loss": 0.153,
      "step": 4260
    },
    {
      "epoch": 0.3088016813421749,
      "grad_norm": 2.608349323272705,
      "learning_rate": 0.00013825639539097038,
      "loss": 0.0824,
      "step": 4261
    },
    {
      "epoch": 0.3088741529876436,
      "grad_norm": 0.5612375140190125,
      "learning_rate": 0.00013824190158707154,
      "loss": 0.0387,
      "step": 4262
    },
    {
      "epoch": 0.3089466246331123,
      "grad_norm": 2.627089023590088,
      "learning_rate": 0.0001382274077831727,
      "loss": 0.0779,
      "step": 4263
    },
    {
      "epoch": 0.309019096278581,
      "grad_norm": 1.5700513124465942,
      "learning_rate": 0.00013821291397927388,
      "loss": 0.1448,
      "step": 4264
    },
    {
      "epoch": 0.30909156792404974,
      "grad_norm": 0.7434777021408081,
      "learning_rate": 0.00013819842017537504,
      "loss": 0.054,
      "step": 4265
    },
    {
      "epoch": 0.30916403956951843,
      "grad_norm": 0.9186266660690308,
      "learning_rate": 0.0001381839263714762,
      "loss": 0.0527,
      "step": 4266
    },
    {
      "epoch": 0.30923651121498713,
      "grad_norm": 5.806856632232666,
      "learning_rate": 0.00013816943256757738,
      "loss": 0.1272,
      "step": 4267
    },
    {
      "epoch": 0.30930898286045583,
      "grad_norm": 1.0189532041549683,
      "learning_rate": 0.00013815493876367853,
      "loss": 0.0636,
      "step": 4268
    },
    {
      "epoch": 0.3093814545059246,
      "grad_norm": 0.6348406672477722,
      "learning_rate": 0.0001381404449597797,
      "loss": 0.0352,
      "step": 4269
    },
    {
      "epoch": 0.3094539261513933,
      "grad_norm": 1.5271832942962646,
      "learning_rate": 0.00013812595115588087,
      "loss": 0.0284,
      "step": 4270
    },
    {
      "epoch": 0.309526397796862,
      "grad_norm": 1.8513619899749756,
      "learning_rate": 0.00013811145735198203,
      "loss": 0.066,
      "step": 4271
    },
    {
      "epoch": 0.30959886944233067,
      "grad_norm": 2.574160099029541,
      "learning_rate": 0.0001380969635480832,
      "loss": 0.0481,
      "step": 4272
    },
    {
      "epoch": 0.3096713410877994,
      "grad_norm": 1.7366694211959839,
      "learning_rate": 0.00013808246974418437,
      "loss": 0.1314,
      "step": 4273
    },
    {
      "epoch": 0.3097438127332681,
      "grad_norm": 1.8054778575897217,
      "learning_rate": 0.00013806797594028553,
      "loss": 0.0803,
      "step": 4274
    },
    {
      "epoch": 0.3098162843787368,
      "grad_norm": 0.2680200934410095,
      "learning_rate": 0.00013805348213638668,
      "loss": 0.0213,
      "step": 4275
    },
    {
      "epoch": 0.3098887560242055,
      "grad_norm": 1.9484021663665771,
      "learning_rate": 0.00013803898833248787,
      "loss": 0.0568,
      "step": 4276
    },
    {
      "epoch": 0.30996122766967427,
      "grad_norm": 1.7304108142852783,
      "learning_rate": 0.00013802449452858902,
      "loss": 0.0721,
      "step": 4277
    },
    {
      "epoch": 0.31003369931514296,
      "grad_norm": 2.153494358062744,
      "learning_rate": 0.00013801000072469018,
      "loss": 0.0858,
      "step": 4278
    },
    {
      "epoch": 0.31010617096061166,
      "grad_norm": 1.766728401184082,
      "learning_rate": 0.00013799550692079136,
      "loss": 0.0371,
      "step": 4279
    },
    {
      "epoch": 0.31017864260608036,
      "grad_norm": 0.935591995716095,
      "learning_rate": 0.00013798101311689252,
      "loss": 0.0655,
      "step": 4280
    },
    {
      "epoch": 0.31025111425154905,
      "grad_norm": 1.4671719074249268,
      "learning_rate": 0.0001379665193129937,
      "loss": 0.0406,
      "step": 4281
    },
    {
      "epoch": 0.3103235858970178,
      "grad_norm": 2.263014078140259,
      "learning_rate": 0.00013795202550909486,
      "loss": 0.1462,
      "step": 4282
    },
    {
      "epoch": 0.3103960575424865,
      "grad_norm": 1.5706182718276978,
      "learning_rate": 0.00013793753170519604,
      "loss": 0.0468,
      "step": 4283
    },
    {
      "epoch": 0.3104685291879552,
      "grad_norm": 6.014066219329834,
      "learning_rate": 0.0001379230379012972,
      "loss": 0.1666,
      "step": 4284
    },
    {
      "epoch": 0.3105410008334239,
      "grad_norm": 0.898227870464325,
      "learning_rate": 0.00013790854409739838,
      "loss": 0.0613,
      "step": 4285
    },
    {
      "epoch": 0.31061347247889265,
      "grad_norm": 0.9240279793739319,
      "learning_rate": 0.00013789405029349954,
      "loss": 0.0281,
      "step": 4286
    },
    {
      "epoch": 0.31068594412436135,
      "grad_norm": 1.3425722122192383,
      "learning_rate": 0.0001378795564896007,
      "loss": 0.1178,
      "step": 4287
    },
    {
      "epoch": 0.31075841576983004,
      "grad_norm": 2.987920045852661,
      "learning_rate": 0.00013786506268570188,
      "loss": 0.0751,
      "step": 4288
    },
    {
      "epoch": 0.31083088741529874,
      "grad_norm": 1.1995681524276733,
      "learning_rate": 0.00013785056888180304,
      "loss": 0.051,
      "step": 4289
    },
    {
      "epoch": 0.3109033590607675,
      "grad_norm": 2.327038526535034,
      "learning_rate": 0.0001378360750779042,
      "loss": 0.1569,
      "step": 4290
    },
    {
      "epoch": 0.3109758307062362,
      "grad_norm": 1.3176801204681396,
      "learning_rate": 0.00013782158127400538,
      "loss": 0.0589,
      "step": 4291
    },
    {
      "epoch": 0.3110483023517049,
      "grad_norm": 2.421835422515869,
      "learning_rate": 0.00013780708747010653,
      "loss": 0.0682,
      "step": 4292
    },
    {
      "epoch": 0.3111207739971736,
      "grad_norm": 2.2938499450683594,
      "learning_rate": 0.0001377925936662077,
      "loss": 0.1111,
      "step": 4293
    },
    {
      "epoch": 0.31119324564264234,
      "grad_norm": 2.6876351833343506,
      "learning_rate": 0.00013777809986230887,
      "loss": 0.0496,
      "step": 4294
    },
    {
      "epoch": 0.31126571728811103,
      "grad_norm": 1.3036184310913086,
      "learning_rate": 0.00013776360605841003,
      "loss": 0.1413,
      "step": 4295
    },
    {
      "epoch": 0.31133818893357973,
      "grad_norm": 1.0190902948379517,
      "learning_rate": 0.00013774911225451119,
      "loss": 0.039,
      "step": 4296
    },
    {
      "epoch": 0.3114106605790484,
      "grad_norm": 2.3090579509735107,
      "learning_rate": 0.00013773461845061237,
      "loss": 0.0612,
      "step": 4297
    },
    {
      "epoch": 0.3114831322245172,
      "grad_norm": 2.386789083480835,
      "learning_rate": 0.00013772012464671353,
      "loss": 0.0736,
      "step": 4298
    },
    {
      "epoch": 0.3115556038699859,
      "grad_norm": 2.834937334060669,
      "learning_rate": 0.00013770563084281468,
      "loss": 0.0819,
      "step": 4299
    },
    {
      "epoch": 0.3116280755154546,
      "grad_norm": 4.892210960388184,
      "learning_rate": 0.00013769113703891587,
      "loss": 0.1851,
      "step": 4300
    },
    {
      "epoch": 0.31170054716092327,
      "grad_norm": 3.1522412300109863,
      "learning_rate": 0.00013767664323501702,
      "loss": 0.1375,
      "step": 4301
    },
    {
      "epoch": 0.311773018806392,
      "grad_norm": 1.6320831775665283,
      "learning_rate": 0.00013766214943111818,
      "loss": 0.079,
      "step": 4302
    },
    {
      "epoch": 0.3118454904518607,
      "grad_norm": 1.2736899852752686,
      "learning_rate": 0.00013764765562721936,
      "loss": 0.0839,
      "step": 4303
    },
    {
      "epoch": 0.3119179620973294,
      "grad_norm": 2.171149969100952,
      "learning_rate": 0.00013763316182332055,
      "loss": 0.1516,
      "step": 4304
    },
    {
      "epoch": 0.3119904337427981,
      "grad_norm": 1.5518126487731934,
      "learning_rate": 0.0001376186680194217,
      "loss": 0.0741,
      "step": 4305
    },
    {
      "epoch": 0.31206290538826686,
      "grad_norm": 2.1865456104278564,
      "learning_rate": 0.0001376041742155229,
      "loss": 0.0874,
      "step": 4306
    },
    {
      "epoch": 0.31213537703373556,
      "grad_norm": 2.130173921585083,
      "learning_rate": 0.00013758968041162404,
      "loss": 0.0476,
      "step": 4307
    },
    {
      "epoch": 0.31220784867920426,
      "grad_norm": 0.9077187776565552,
      "learning_rate": 0.00013757518660772523,
      "loss": 0.0865,
      "step": 4308
    },
    {
      "epoch": 0.31228032032467296,
      "grad_norm": 1.769396424293518,
      "learning_rate": 0.00013756069280382638,
      "loss": 0.0553,
      "step": 4309
    },
    {
      "epoch": 0.3123527919701417,
      "grad_norm": 0.9821685552597046,
      "learning_rate": 0.00013754619899992754,
      "loss": 0.109,
      "step": 4310
    },
    {
      "epoch": 0.3124252636156104,
      "grad_norm": 2.411824941635132,
      "learning_rate": 0.00013753170519602872,
      "loss": 0.1461,
      "step": 4311
    },
    {
      "epoch": 0.3124977352610791,
      "grad_norm": 2.322293996810913,
      "learning_rate": 0.00013751721139212988,
      "loss": 0.0383,
      "step": 4312
    },
    {
      "epoch": 0.3125702069065478,
      "grad_norm": 3.6450841426849365,
      "learning_rate": 0.00013750271758823104,
      "loss": 0.1602,
      "step": 4313
    },
    {
      "epoch": 0.31264267855201655,
      "grad_norm": 0.7361690998077393,
      "learning_rate": 0.00013748822378433222,
      "loss": 0.0849,
      "step": 4314
    },
    {
      "epoch": 0.31271515019748525,
      "grad_norm": 0.8497464656829834,
      "learning_rate": 0.00013747372998043338,
      "loss": 0.0863,
      "step": 4315
    },
    {
      "epoch": 0.31278762184295394,
      "grad_norm": 1.0253448486328125,
      "learning_rate": 0.00013745923617653453,
      "loss": 0.0534,
      "step": 4316
    },
    {
      "epoch": 0.31286009348842264,
      "grad_norm": 0.7068461179733276,
      "learning_rate": 0.00013744474237263572,
      "loss": 0.0777,
      "step": 4317
    },
    {
      "epoch": 0.31293256513389134,
      "grad_norm": 1.4352500438690186,
      "learning_rate": 0.00013743024856873687,
      "loss": 0.0641,
      "step": 4318
    },
    {
      "epoch": 0.3130050367793601,
      "grad_norm": 3.4190807342529297,
      "learning_rate": 0.00013741575476483803,
      "loss": 0.0724,
      "step": 4319
    },
    {
      "epoch": 0.3130775084248288,
      "grad_norm": 1.389967441558838,
      "learning_rate": 0.0001374012609609392,
      "loss": 0.0698,
      "step": 4320
    },
    {
      "epoch": 0.3131499800702975,
      "grad_norm": 2.189018487930298,
      "learning_rate": 0.00013738676715704037,
      "loss": 0.1251,
      "step": 4321
    },
    {
      "epoch": 0.3132224517157662,
      "grad_norm": 0.5310906171798706,
      "learning_rate": 0.00013737227335314153,
      "loss": 0.0324,
      "step": 4322
    },
    {
      "epoch": 0.31329492336123493,
      "grad_norm": 0.6914539933204651,
      "learning_rate": 0.0001373577795492427,
      "loss": 0.0296,
      "step": 4323
    },
    {
      "epoch": 0.31336739500670363,
      "grad_norm": 1.9963011741638184,
      "learning_rate": 0.00013734328574534387,
      "loss": 0.1371,
      "step": 4324
    },
    {
      "epoch": 0.3134398666521723,
      "grad_norm": 1.6441056728363037,
      "learning_rate": 0.00013732879194144502,
      "loss": 0.1015,
      "step": 4325
    },
    {
      "epoch": 0.313512338297641,
      "grad_norm": 1.4513932466506958,
      "learning_rate": 0.0001373142981375462,
      "loss": 0.0585,
      "step": 4326
    },
    {
      "epoch": 0.3135848099431098,
      "grad_norm": 1.3843992948532104,
      "learning_rate": 0.00013729980433364736,
      "loss": 0.0898,
      "step": 4327
    },
    {
      "epoch": 0.3136572815885785,
      "grad_norm": 0.999222993850708,
      "learning_rate": 0.00013728531052974855,
      "loss": 0.0418,
      "step": 4328
    },
    {
      "epoch": 0.31372975323404717,
      "grad_norm": 0.8505780696868896,
      "learning_rate": 0.0001372708167258497,
      "loss": 0.108,
      "step": 4329
    },
    {
      "epoch": 0.31380222487951587,
      "grad_norm": 1.3797746896743774,
      "learning_rate": 0.00013725632292195089,
      "loss": 0.0515,
      "step": 4330
    },
    {
      "epoch": 0.3138746965249846,
      "grad_norm": 3.3451507091522217,
      "learning_rate": 0.00013724182911805204,
      "loss": 0.1769,
      "step": 4331
    },
    {
      "epoch": 0.3139471681704533,
      "grad_norm": 3.139657735824585,
      "learning_rate": 0.00013722733531415323,
      "loss": 0.0328,
      "step": 4332
    },
    {
      "epoch": 0.314019639815922,
      "grad_norm": 0.735847532749176,
      "learning_rate": 0.00013721284151025438,
      "loss": 0.0511,
      "step": 4333
    },
    {
      "epoch": 0.3140921114613907,
      "grad_norm": 1.7801744937896729,
      "learning_rate": 0.00013719834770635554,
      "loss": 0.0648,
      "step": 4334
    },
    {
      "epoch": 0.31416458310685946,
      "grad_norm": 1.6908578872680664,
      "learning_rate": 0.00013718385390245672,
      "loss": 0.0514,
      "step": 4335
    },
    {
      "epoch": 0.31423705475232816,
      "grad_norm": 1.3273755311965942,
      "learning_rate": 0.00013716936009855788,
      "loss": 0.0837,
      "step": 4336
    },
    {
      "epoch": 0.31430952639779686,
      "grad_norm": 3.958156108856201,
      "learning_rate": 0.00013715486629465904,
      "loss": 0.2109,
      "step": 4337
    },
    {
      "epoch": 0.31438199804326555,
      "grad_norm": 6.821872234344482,
      "learning_rate": 0.00013714037249076022,
      "loss": 0.2172,
      "step": 4338
    },
    {
      "epoch": 0.3144544696887343,
      "grad_norm": 1.9135183095932007,
      "learning_rate": 0.00013712587868686138,
      "loss": 0.0945,
      "step": 4339
    },
    {
      "epoch": 0.314526941334203,
      "grad_norm": 4.645795822143555,
      "learning_rate": 0.00013711138488296253,
      "loss": 0.1359,
      "step": 4340
    },
    {
      "epoch": 0.3145994129796717,
      "grad_norm": 1.1336146593093872,
      "learning_rate": 0.00013709689107906372,
      "loss": 0.0443,
      "step": 4341
    },
    {
      "epoch": 0.3146718846251404,
      "grad_norm": 0.9191692471504211,
      "learning_rate": 0.00013708239727516487,
      "loss": 0.0548,
      "step": 4342
    },
    {
      "epoch": 0.31474435627060915,
      "grad_norm": 3.2770001888275146,
      "learning_rate": 0.00013706790347126603,
      "loss": 0.0993,
      "step": 4343
    },
    {
      "epoch": 0.31481682791607785,
      "grad_norm": 1.767501711845398,
      "learning_rate": 0.0001370534096673672,
      "loss": 0.0919,
      "step": 4344
    },
    {
      "epoch": 0.31488929956154654,
      "grad_norm": 3.7896792888641357,
      "learning_rate": 0.00013703891586346837,
      "loss": 0.1806,
      "step": 4345
    },
    {
      "epoch": 0.31496177120701524,
      "grad_norm": 1.9810112714767456,
      "learning_rate": 0.00013702442205956953,
      "loss": 0.0555,
      "step": 4346
    },
    {
      "epoch": 0.315034242852484,
      "grad_norm": 0.79969322681427,
      "learning_rate": 0.0001370099282556707,
      "loss": 0.0401,
      "step": 4347
    },
    {
      "epoch": 0.3151067144979527,
      "grad_norm": 3.20373272895813,
      "learning_rate": 0.00013699543445177187,
      "loss": 0.2046,
      "step": 4348
    },
    {
      "epoch": 0.3151791861434214,
      "grad_norm": 1.2022329568862915,
      "learning_rate": 0.00013698094064787302,
      "loss": 0.0952,
      "step": 4349
    },
    {
      "epoch": 0.3152516577888901,
      "grad_norm": 6.1111979484558105,
      "learning_rate": 0.0001369664468439742,
      "loss": 0.1185,
      "step": 4350
    },
    {
      "epoch": 0.3153241294343588,
      "grad_norm": 2.68853497505188,
      "learning_rate": 0.0001369519530400754,
      "loss": 0.0999,
      "step": 4351
    },
    {
      "epoch": 0.31539660107982753,
      "grad_norm": 1.9448981285095215,
      "learning_rate": 0.00013693745923617655,
      "loss": 0.1278,
      "step": 4352
    },
    {
      "epoch": 0.31546907272529623,
      "grad_norm": 5.201650142669678,
      "learning_rate": 0.00013692296543227773,
      "loss": 0.0784,
      "step": 4353
    },
    {
      "epoch": 0.3155415443707649,
      "grad_norm": 1.6522856950759888,
      "learning_rate": 0.00013690847162837889,
      "loss": 0.0945,
      "step": 4354
    },
    {
      "epoch": 0.3156140160162336,
      "grad_norm": 1.3095452785491943,
      "learning_rate": 0.00013689397782448004,
      "loss": 0.0886,
      "step": 4355
    },
    {
      "epoch": 0.3156864876617024,
      "grad_norm": 1.116988182067871,
      "learning_rate": 0.00013687948402058123,
      "loss": 0.0666,
      "step": 4356
    },
    {
      "epoch": 0.31575895930717107,
      "grad_norm": 1.6752067804336548,
      "learning_rate": 0.00013686499021668238,
      "loss": 0.0873,
      "step": 4357
    },
    {
      "epoch": 0.31583143095263977,
      "grad_norm": 0.9524573087692261,
      "learning_rate": 0.00013685049641278354,
      "loss": 0.0703,
      "step": 4358
    },
    {
      "epoch": 0.31590390259810847,
      "grad_norm": 1.1399916410446167,
      "learning_rate": 0.00013683600260888472,
      "loss": 0.0408,
      "step": 4359
    },
    {
      "epoch": 0.3159763742435772,
      "grad_norm": 5.2675700187683105,
      "learning_rate": 0.00013682150880498588,
      "loss": 0.1245,
      "step": 4360
    },
    {
      "epoch": 0.3160488458890459,
      "grad_norm": 0.5679008364677429,
      "learning_rate": 0.00013680701500108704,
      "loss": 0.0298,
      "step": 4361
    },
    {
      "epoch": 0.3161213175345146,
      "grad_norm": 0.5317927598953247,
      "learning_rate": 0.00013679252119718822,
      "loss": 0.0439,
      "step": 4362
    },
    {
      "epoch": 0.3161937891799833,
      "grad_norm": 0.6006423234939575,
      "learning_rate": 0.00013677802739328938,
      "loss": 0.089,
      "step": 4363
    },
    {
      "epoch": 0.31626626082545206,
      "grad_norm": 3.722372055053711,
      "learning_rate": 0.00013676353358939053,
      "loss": 0.0907,
      "step": 4364
    },
    {
      "epoch": 0.31633873247092076,
      "grad_norm": 2.373380184173584,
      "learning_rate": 0.00013674903978549172,
      "loss": 0.0711,
      "step": 4365
    },
    {
      "epoch": 0.31641120411638946,
      "grad_norm": 4.064864635467529,
      "learning_rate": 0.00013673454598159287,
      "loss": 0.1672,
      "step": 4366
    },
    {
      "epoch": 0.31648367576185815,
      "grad_norm": 0.6241242289543152,
      "learning_rate": 0.00013672005217769403,
      "loss": 0.0167,
      "step": 4367
    },
    {
      "epoch": 0.3165561474073269,
      "grad_norm": 3.462486982345581,
      "learning_rate": 0.0001367055583737952,
      "loss": 0.0521,
      "step": 4368
    },
    {
      "epoch": 0.3166286190527956,
      "grad_norm": 2.7845969200134277,
      "learning_rate": 0.00013669106456989637,
      "loss": 0.0544,
      "step": 4369
    },
    {
      "epoch": 0.3167010906982643,
      "grad_norm": 1.8989677429199219,
      "learning_rate": 0.00013667657076599753,
      "loss": 0.0721,
      "step": 4370
    },
    {
      "epoch": 0.316773562343733,
      "grad_norm": 0.7369182109832764,
      "learning_rate": 0.0001366620769620987,
      "loss": 0.0503,
      "step": 4371
    },
    {
      "epoch": 0.31684603398920175,
      "grad_norm": 1.4571125507354736,
      "learning_rate": 0.00013664758315819987,
      "loss": 0.0324,
      "step": 4372
    },
    {
      "epoch": 0.31691850563467044,
      "grad_norm": 1.953115701675415,
      "learning_rate": 0.00013663308935430105,
      "loss": 0.0363,
      "step": 4373
    },
    {
      "epoch": 0.31699097728013914,
      "grad_norm": 1.3782050609588623,
      "learning_rate": 0.0001366185955504022,
      "loss": 0.105,
      "step": 4374
    },
    {
      "epoch": 0.31706344892560784,
      "grad_norm": 2.5579142570495605,
      "learning_rate": 0.0001366041017465034,
      "loss": 0.1115,
      "step": 4375
    },
    {
      "epoch": 0.3171359205710766,
      "grad_norm": 0.8076615333557129,
      "learning_rate": 0.00013658960794260455,
      "loss": 0.0391,
      "step": 4376
    },
    {
      "epoch": 0.3172083922165453,
      "grad_norm": 1.735858678817749,
      "learning_rate": 0.00013657511413870573,
      "loss": 0.047,
      "step": 4377
    },
    {
      "epoch": 0.317280863862014,
      "grad_norm": 1.511110782623291,
      "learning_rate": 0.00013656062033480689,
      "loss": 0.0347,
      "step": 4378
    },
    {
      "epoch": 0.3173533355074827,
      "grad_norm": 2.8871216773986816,
      "learning_rate": 0.00013654612653090804,
      "loss": 0.1553,
      "step": 4379
    },
    {
      "epoch": 0.31742580715295143,
      "grad_norm": 0.7255018949508667,
      "learning_rate": 0.00013653163272700923,
      "loss": 0.0313,
      "step": 4380
    },
    {
      "epoch": 0.31749827879842013,
      "grad_norm": 1.2789630889892578,
      "learning_rate": 0.00013651713892311038,
      "loss": 0.0617,
      "step": 4381
    },
    {
      "epoch": 0.3175707504438888,
      "grad_norm": 2.1334476470947266,
      "learning_rate": 0.00013650264511921154,
      "loss": 0.1387,
      "step": 4382
    },
    {
      "epoch": 0.3176432220893575,
      "grad_norm": 1.126943826675415,
      "learning_rate": 0.00013648815131531272,
      "loss": 0.0555,
      "step": 4383
    },
    {
      "epoch": 0.3177156937348263,
      "grad_norm": 0.7272164225578308,
      "learning_rate": 0.00013647365751141388,
      "loss": 0.0154,
      "step": 4384
    },
    {
      "epoch": 0.317788165380295,
      "grad_norm": 2.164891004562378,
      "learning_rate": 0.00013645916370751504,
      "loss": 0.0514,
      "step": 4385
    },
    {
      "epoch": 0.31786063702576367,
      "grad_norm": 2.3363490104675293,
      "learning_rate": 0.00013644466990361622,
      "loss": 0.0922,
      "step": 4386
    },
    {
      "epoch": 0.31793310867123237,
      "grad_norm": 0.9051724076271057,
      "learning_rate": 0.00013643017609971738,
      "loss": 0.0479,
      "step": 4387
    },
    {
      "epoch": 0.31800558031670106,
      "grad_norm": 1.2367165088653564,
      "learning_rate": 0.00013641568229581853,
      "loss": 0.0581,
      "step": 4388
    },
    {
      "epoch": 0.3180780519621698,
      "grad_norm": 1.6605972051620483,
      "learning_rate": 0.00013640118849191972,
      "loss": 0.0516,
      "step": 4389
    },
    {
      "epoch": 0.3181505236076385,
      "grad_norm": 1.2765666246414185,
      "learning_rate": 0.00013638669468802087,
      "loss": 0.0724,
      "step": 4390
    },
    {
      "epoch": 0.3182229952531072,
      "grad_norm": 4.691551208496094,
      "learning_rate": 0.00013637220088412203,
      "loss": 0.1511,
      "step": 4391
    },
    {
      "epoch": 0.3182954668985759,
      "grad_norm": 3.6198246479034424,
      "learning_rate": 0.0001363577070802232,
      "loss": 0.105,
      "step": 4392
    },
    {
      "epoch": 0.31836793854404466,
      "grad_norm": 5.046623229980469,
      "learning_rate": 0.00013634321327632437,
      "loss": 0.2251,
      "step": 4393
    },
    {
      "epoch": 0.31844041018951336,
      "grad_norm": 0.9207944273948669,
      "learning_rate": 0.00013632871947242552,
      "loss": 0.0382,
      "step": 4394
    },
    {
      "epoch": 0.31851288183498205,
      "grad_norm": 1.8935022354125977,
      "learning_rate": 0.0001363142256685267,
      "loss": 0.0644,
      "step": 4395
    },
    {
      "epoch": 0.31858535348045075,
      "grad_norm": 0.853624165058136,
      "learning_rate": 0.00013629973186462786,
      "loss": 0.0587,
      "step": 4396
    },
    {
      "epoch": 0.3186578251259195,
      "grad_norm": 1.3886300325393677,
      "learning_rate": 0.00013628523806072905,
      "loss": 0.0666,
      "step": 4397
    },
    {
      "epoch": 0.3187302967713882,
      "grad_norm": 0.7625412344932556,
      "learning_rate": 0.0001362707442568302,
      "loss": 0.034,
      "step": 4398
    },
    {
      "epoch": 0.3188027684168569,
      "grad_norm": 1.4980177879333496,
      "learning_rate": 0.0001362562504529314,
      "loss": 0.101,
      "step": 4399
    },
    {
      "epoch": 0.3188752400623256,
      "grad_norm": 1.071972370147705,
      "learning_rate": 0.00013624175664903255,
      "loss": 0.0733,
      "step": 4400
    },
    {
      "epoch": 0.31894771170779435,
      "grad_norm": 3.083580255508423,
      "learning_rate": 0.00013622726284513373,
      "loss": 0.0851,
      "step": 4401
    },
    {
      "epoch": 0.31902018335326304,
      "grad_norm": 1.9085708856582642,
      "learning_rate": 0.00013621276904123489,
      "loss": 0.0412,
      "step": 4402
    },
    {
      "epoch": 0.31909265499873174,
      "grad_norm": 3.114356279373169,
      "learning_rate": 0.00013619827523733604,
      "loss": 0.0964,
      "step": 4403
    },
    {
      "epoch": 0.31916512664420044,
      "grad_norm": 0.27401280403137207,
      "learning_rate": 0.00013618378143343723,
      "loss": 0.0062,
      "step": 4404
    },
    {
      "epoch": 0.3192375982896692,
      "grad_norm": 1.2765856981277466,
      "learning_rate": 0.00013616928762953838,
      "loss": 0.0787,
      "step": 4405
    },
    {
      "epoch": 0.3193100699351379,
      "grad_norm": 2.266993761062622,
      "learning_rate": 0.00013615479382563954,
      "loss": 0.0515,
      "step": 4406
    },
    {
      "epoch": 0.3193825415806066,
      "grad_norm": 3.0299673080444336,
      "learning_rate": 0.00013614030002174072,
      "loss": 0.1486,
      "step": 4407
    },
    {
      "epoch": 0.3194550132260753,
      "grad_norm": 0.8506748676300049,
      "learning_rate": 0.00013612580621784188,
      "loss": 0.0288,
      "step": 4408
    },
    {
      "epoch": 0.31952748487154403,
      "grad_norm": 2.3454513549804688,
      "learning_rate": 0.00013611131241394303,
      "loss": 0.1209,
      "step": 4409
    },
    {
      "epoch": 0.31959995651701273,
      "grad_norm": 7.462140083312988,
      "learning_rate": 0.00013609681861004422,
      "loss": 0.0729,
      "step": 4410
    },
    {
      "epoch": 0.3196724281624814,
      "grad_norm": 0.42932912707328796,
      "learning_rate": 0.00013608232480614537,
      "loss": 0.0054,
      "step": 4411
    },
    {
      "epoch": 0.3197448998079501,
      "grad_norm": 5.470800876617432,
      "learning_rate": 0.00013606783100224653,
      "loss": 0.0568,
      "step": 4412
    },
    {
      "epoch": 0.3198173714534189,
      "grad_norm": 3.315734386444092,
      "learning_rate": 0.00013605333719834771,
      "loss": 0.0943,
      "step": 4413
    },
    {
      "epoch": 0.31988984309888757,
      "grad_norm": 3.382585048675537,
      "learning_rate": 0.00013603884339444887,
      "loss": 0.1683,
      "step": 4414
    },
    {
      "epoch": 0.31996231474435627,
      "grad_norm": 0.495254784822464,
      "learning_rate": 0.00013602434959055003,
      "loss": 0.02,
      "step": 4415
    },
    {
      "epoch": 0.32003478638982497,
      "grad_norm": 0.8195750713348389,
      "learning_rate": 0.0001360098557866512,
      "loss": 0.0313,
      "step": 4416
    },
    {
      "epoch": 0.3201072580352937,
      "grad_norm": 2.2810680866241455,
      "learning_rate": 0.00013599536198275237,
      "loss": 0.128,
      "step": 4417
    },
    {
      "epoch": 0.3201797296807624,
      "grad_norm": 0.8146130442619324,
      "learning_rate": 0.00013598086817885352,
      "loss": 0.0342,
      "step": 4418
    },
    {
      "epoch": 0.3202522013262311,
      "grad_norm": 0.8278922438621521,
      "learning_rate": 0.0001359663743749547,
      "loss": 0.0402,
      "step": 4419
    },
    {
      "epoch": 0.3203246729716998,
      "grad_norm": 5.14215087890625,
      "learning_rate": 0.0001359518805710559,
      "loss": 0.0417,
      "step": 4420
    },
    {
      "epoch": 0.3203971446171685,
      "grad_norm": 3.8730080127716064,
      "learning_rate": 0.00013593738676715705,
      "loss": 0.2306,
      "step": 4421
    },
    {
      "epoch": 0.32046961626263726,
      "grad_norm": 2.322275400161743,
      "learning_rate": 0.00013592289296325823,
      "loss": 0.1798,
      "step": 4422
    },
    {
      "epoch": 0.32054208790810595,
      "grad_norm": 1.8799442052841187,
      "learning_rate": 0.0001359083991593594,
      "loss": 0.0873,
      "step": 4423
    },
    {
      "epoch": 0.32061455955357465,
      "grad_norm": 0.5157938599586487,
      "learning_rate": 0.00013589390535546054,
      "loss": 0.0409,
      "step": 4424
    },
    {
      "epoch": 0.32068703119904335,
      "grad_norm": 1.8333837985992432,
      "learning_rate": 0.00013587941155156173,
      "loss": 0.0407,
      "step": 4425
    },
    {
      "epoch": 0.3207595028445121,
      "grad_norm": 0.9729204177856445,
      "learning_rate": 0.00013586491774766288,
      "loss": 0.0571,
      "step": 4426
    },
    {
      "epoch": 0.3208319744899808,
      "grad_norm": 0.7714840173721313,
      "learning_rate": 0.00013585042394376404,
      "loss": 0.0351,
      "step": 4427
    },
    {
      "epoch": 0.3209044461354495,
      "grad_norm": 2.481505870819092,
      "learning_rate": 0.00013583593013986522,
      "loss": 0.0561,
      "step": 4428
    },
    {
      "epoch": 0.3209769177809182,
      "grad_norm": 1.0148500204086304,
      "learning_rate": 0.00013582143633596638,
      "loss": 0.049,
      "step": 4429
    },
    {
      "epoch": 0.32104938942638694,
      "grad_norm": 1.9384220838546753,
      "learning_rate": 0.00013580694253206754,
      "loss": 0.1274,
      "step": 4430
    },
    {
      "epoch": 0.32112186107185564,
      "grad_norm": 2.2615013122558594,
      "learning_rate": 0.00013579244872816872,
      "loss": 0.0659,
      "step": 4431
    },
    {
      "epoch": 0.32119433271732434,
      "grad_norm": 1.8677504062652588,
      "learning_rate": 0.00013577795492426988,
      "loss": 0.0367,
      "step": 4432
    },
    {
      "epoch": 0.32126680436279303,
      "grad_norm": 1.0792114734649658,
      "learning_rate": 0.00013576346112037103,
      "loss": 0.0573,
      "step": 4433
    },
    {
      "epoch": 0.3213392760082618,
      "grad_norm": 0.6524178385734558,
      "learning_rate": 0.00013574896731647222,
      "loss": 0.0333,
      "step": 4434
    },
    {
      "epoch": 0.3214117476537305,
      "grad_norm": 0.8903523683547974,
      "learning_rate": 0.00013573447351257337,
      "loss": 0.0299,
      "step": 4435
    },
    {
      "epoch": 0.3214842192991992,
      "grad_norm": 2.3541903495788574,
      "learning_rate": 0.00013571997970867453,
      "loss": 0.0338,
      "step": 4436
    },
    {
      "epoch": 0.3215566909446679,
      "grad_norm": 2.651787042617798,
      "learning_rate": 0.00013570548590477571,
      "loss": 0.0811,
      "step": 4437
    },
    {
      "epoch": 0.32162916259013663,
      "grad_norm": 3.267880439758301,
      "learning_rate": 0.00013569099210087687,
      "loss": 0.0897,
      "step": 4438
    },
    {
      "epoch": 0.3217016342356053,
      "grad_norm": 3.3493812084198,
      "learning_rate": 0.00013567649829697803,
      "loss": 0.1178,
      "step": 4439
    },
    {
      "epoch": 0.321774105881074,
      "grad_norm": 3.17555832862854,
      "learning_rate": 0.0001356620044930792,
      "loss": 0.1075,
      "step": 4440
    },
    {
      "epoch": 0.3218465775265427,
      "grad_norm": 0.20612558722496033,
      "learning_rate": 0.00013564751068918037,
      "loss": 0.0033,
      "step": 4441
    },
    {
      "epoch": 0.3219190491720115,
      "grad_norm": 3.9139325618743896,
      "learning_rate": 0.00013563301688528155,
      "loss": 0.0837,
      "step": 4442
    },
    {
      "epoch": 0.32199152081748017,
      "grad_norm": 1.7585335969924927,
      "learning_rate": 0.0001356185230813827,
      "loss": 0.0836,
      "step": 4443
    },
    {
      "epoch": 0.32206399246294887,
      "grad_norm": 2.767561435699463,
      "learning_rate": 0.0001356040292774839,
      "loss": 0.0696,
      "step": 4444
    },
    {
      "epoch": 0.32213646410841756,
      "grad_norm": 1.04204523563385,
      "learning_rate": 0.00013558953547358505,
      "loss": 0.0433,
      "step": 4445
    },
    {
      "epoch": 0.3222089357538863,
      "grad_norm": 2.64660382270813,
      "learning_rate": 0.00013557504166968623,
      "loss": 0.0176,
      "step": 4446
    },
    {
      "epoch": 0.322281407399355,
      "grad_norm": 4.242690563201904,
      "learning_rate": 0.0001355605478657874,
      "loss": 0.0748,
      "step": 4447
    },
    {
      "epoch": 0.3223538790448237,
      "grad_norm": 3.4215824604034424,
      "learning_rate": 0.00013554605406188854,
      "loss": 0.0927,
      "step": 4448
    },
    {
      "epoch": 0.3224263506902924,
      "grad_norm": 6.446061134338379,
      "learning_rate": 0.00013553156025798973,
      "loss": 0.1858,
      "step": 4449
    },
    {
      "epoch": 0.32249882233576116,
      "grad_norm": 1.4818161725997925,
      "learning_rate": 0.00013551706645409088,
      "loss": 0.0813,
      "step": 4450
    },
    {
      "epoch": 0.32257129398122986,
      "grad_norm": 2.5392134189605713,
      "learning_rate": 0.00013550257265019204,
      "loss": 0.1422,
      "step": 4451
    },
    {
      "epoch": 0.32264376562669855,
      "grad_norm": 1.8534801006317139,
      "learning_rate": 0.00013548807884629322,
      "loss": 0.1213,
      "step": 4452
    },
    {
      "epoch": 0.32271623727216725,
      "grad_norm": 2.709108352661133,
      "learning_rate": 0.00013547358504239438,
      "loss": 0.0591,
      "step": 4453
    },
    {
      "epoch": 0.322788708917636,
      "grad_norm": 2.654902458190918,
      "learning_rate": 0.00013545909123849554,
      "loss": 0.0565,
      "step": 4454
    },
    {
      "epoch": 0.3228611805631047,
      "grad_norm": 2.6751956939697266,
      "learning_rate": 0.00013544459743459672,
      "loss": 0.0362,
      "step": 4455
    },
    {
      "epoch": 0.3229336522085734,
      "grad_norm": 2.1654725074768066,
      "learning_rate": 0.00013543010363069788,
      "loss": 0.1219,
      "step": 4456
    },
    {
      "epoch": 0.3230061238540421,
      "grad_norm": 1.9949592351913452,
      "learning_rate": 0.00013541560982679903,
      "loss": 0.1322,
      "step": 4457
    },
    {
      "epoch": 0.3230785954995108,
      "grad_norm": 1.3102055788040161,
      "learning_rate": 0.00013540111602290022,
      "loss": 0.0794,
      "step": 4458
    },
    {
      "epoch": 0.32315106714497954,
      "grad_norm": 2.216488838195801,
      "learning_rate": 0.00013538662221900137,
      "loss": 0.1836,
      "step": 4459
    },
    {
      "epoch": 0.32322353879044824,
      "grad_norm": 0.7627164125442505,
      "learning_rate": 0.00013537212841510253,
      "loss": 0.0629,
      "step": 4460
    },
    {
      "epoch": 0.32329601043591694,
      "grad_norm": 0.7970724105834961,
      "learning_rate": 0.00013535763461120371,
      "loss": 0.0475,
      "step": 4461
    },
    {
      "epoch": 0.32336848208138563,
      "grad_norm": 1.3820812702178955,
      "learning_rate": 0.00013534314080730487,
      "loss": 0.0536,
      "step": 4462
    },
    {
      "epoch": 0.3234409537268544,
      "grad_norm": 0.9722176790237427,
      "learning_rate": 0.00013532864700340603,
      "loss": 0.1501,
      "step": 4463
    },
    {
      "epoch": 0.3235134253723231,
      "grad_norm": 0.9277364015579224,
      "learning_rate": 0.0001353141531995072,
      "loss": 0.0802,
      "step": 4464
    },
    {
      "epoch": 0.3235858970177918,
      "grad_norm": 1.156995415687561,
      "learning_rate": 0.00013529965939560837,
      "loss": 0.0635,
      "step": 4465
    },
    {
      "epoch": 0.3236583686632605,
      "grad_norm": 2.234830856323242,
      "learning_rate": 0.00013528516559170955,
      "loss": 0.1484,
      "step": 4466
    },
    {
      "epoch": 0.32373084030872923,
      "grad_norm": 0.92824786901474,
      "learning_rate": 0.00013527067178781073,
      "loss": 0.024,
      "step": 4467
    },
    {
      "epoch": 0.3238033119541979,
      "grad_norm": 2.4012579917907715,
      "learning_rate": 0.0001352561779839119,
      "loss": 0.0764,
      "step": 4468
    },
    {
      "epoch": 0.3238757835996666,
      "grad_norm": 2.461902141571045,
      "learning_rate": 0.00013524168418001307,
      "loss": 0.0669,
      "step": 4469
    },
    {
      "epoch": 0.3239482552451353,
      "grad_norm": 0.9968600869178772,
      "learning_rate": 0.00013522719037611423,
      "loss": 0.0549,
      "step": 4470
    },
    {
      "epoch": 0.32402072689060407,
      "grad_norm": 1.929274559020996,
      "learning_rate": 0.0001352126965722154,
      "loss": 0.071,
      "step": 4471
    },
    {
      "epoch": 0.32409319853607277,
      "grad_norm": 2.878969430923462,
      "learning_rate": 0.00013519820276831657,
      "loss": 0.0273,
      "step": 4472
    },
    {
      "epoch": 0.32416567018154147,
      "grad_norm": 1.2762587070465088,
      "learning_rate": 0.00013518370896441773,
      "loss": 0.0599,
      "step": 4473
    },
    {
      "epoch": 0.32423814182701016,
      "grad_norm": 1.1701316833496094,
      "learning_rate": 0.00013516921516051888,
      "loss": 0.113,
      "step": 4474
    },
    {
      "epoch": 0.3243106134724789,
      "grad_norm": 1.5304187536239624,
      "learning_rate": 0.00013515472135662007,
      "loss": 0.0387,
      "step": 4475
    },
    {
      "epoch": 0.3243830851179476,
      "grad_norm": 0.5792485475540161,
      "learning_rate": 0.00013514022755272122,
      "loss": 0.0214,
      "step": 4476
    },
    {
      "epoch": 0.3244555567634163,
      "grad_norm": 1.4608750343322754,
      "learning_rate": 0.00013512573374882238,
      "loss": 0.052,
      "step": 4477
    },
    {
      "epoch": 0.324528028408885,
      "grad_norm": 1.1640300750732422,
      "learning_rate": 0.00013511123994492356,
      "loss": 0.0689,
      "step": 4478
    },
    {
      "epoch": 0.32460050005435376,
      "grad_norm": 2.3529438972473145,
      "learning_rate": 0.00013509674614102472,
      "loss": 0.0366,
      "step": 4479
    },
    {
      "epoch": 0.32467297169982245,
      "grad_norm": 1.3352620601654053,
      "learning_rate": 0.00013508225233712588,
      "loss": 0.0583,
      "step": 4480
    },
    {
      "epoch": 0.32474544334529115,
      "grad_norm": 1.0216666460037231,
      "learning_rate": 0.00013506775853322706,
      "loss": 0.0674,
      "step": 4481
    },
    {
      "epoch": 0.32481791499075985,
      "grad_norm": 2.0202274322509766,
      "learning_rate": 0.00013505326472932822,
      "loss": 0.1216,
      "step": 4482
    },
    {
      "epoch": 0.3248903866362286,
      "grad_norm": 2.6885316371917725,
      "learning_rate": 0.00013503877092542937,
      "loss": 0.1334,
      "step": 4483
    },
    {
      "epoch": 0.3249628582816973,
      "grad_norm": 3.8373184204101562,
      "learning_rate": 0.00013502427712153056,
      "loss": 0.078,
      "step": 4484
    },
    {
      "epoch": 0.325035329927166,
      "grad_norm": 0.8128508925437927,
      "learning_rate": 0.00013500978331763171,
      "loss": 0.0619,
      "step": 4485
    },
    {
      "epoch": 0.3251078015726347,
      "grad_norm": 21.757606506347656,
      "learning_rate": 0.00013499528951373287,
      "loss": 0.0933,
      "step": 4486
    },
    {
      "epoch": 0.32518027321810344,
      "grad_norm": 2.161924362182617,
      "learning_rate": 0.00013498079570983405,
      "loss": 0.0944,
      "step": 4487
    },
    {
      "epoch": 0.32525274486357214,
      "grad_norm": 0.5846811532974243,
      "learning_rate": 0.0001349663019059352,
      "loss": 0.0208,
      "step": 4488
    },
    {
      "epoch": 0.32532521650904084,
      "grad_norm": 2.0510613918304443,
      "learning_rate": 0.0001349518081020364,
      "loss": 0.1037,
      "step": 4489
    },
    {
      "epoch": 0.32539768815450953,
      "grad_norm": 1.651193380355835,
      "learning_rate": 0.00013493731429813755,
      "loss": 0.098,
      "step": 4490
    },
    {
      "epoch": 0.32547015979997823,
      "grad_norm": 3.474503993988037,
      "learning_rate": 0.00013492282049423873,
      "loss": 0.1109,
      "step": 4491
    },
    {
      "epoch": 0.325542631445447,
      "grad_norm": 2.264821767807007,
      "learning_rate": 0.0001349083266903399,
      "loss": 0.1008,
      "step": 4492
    },
    {
      "epoch": 0.3256151030909157,
      "grad_norm": 0.6502141356468201,
      "learning_rate": 0.00013489383288644107,
      "loss": 0.0404,
      "step": 4493
    },
    {
      "epoch": 0.3256875747363844,
      "grad_norm": 1.2302517890930176,
      "learning_rate": 0.00013487933908254223,
      "loss": 0.0705,
      "step": 4494
    },
    {
      "epoch": 0.3257600463818531,
      "grad_norm": 0.8582626581192017,
      "learning_rate": 0.0001348648452786434,
      "loss": 0.0292,
      "step": 4495
    },
    {
      "epoch": 0.3258325180273218,
      "grad_norm": 1.338357925415039,
      "learning_rate": 0.00013485035147474457,
      "loss": 0.0643,
      "step": 4496
    },
    {
      "epoch": 0.3259049896727905,
      "grad_norm": 1.4187370538711548,
      "learning_rate": 0.00013483585767084573,
      "loss": 0.0714,
      "step": 4497
    },
    {
      "epoch": 0.3259774613182592,
      "grad_norm": 0.851382315158844,
      "learning_rate": 0.00013482136386694688,
      "loss": 0.0393,
      "step": 4498
    },
    {
      "epoch": 0.3260499329637279,
      "grad_norm": 0.6694838404655457,
      "learning_rate": 0.00013480687006304807,
      "loss": 0.0535,
      "step": 4499
    },
    {
      "epoch": 0.32612240460919667,
      "grad_norm": 3.6185715198516846,
      "learning_rate": 0.00013479237625914922,
      "loss": 0.1718,
      "step": 4500
    },
    {
      "epoch": 0.32619487625466537,
      "grad_norm": 1.3764008283615112,
      "learning_rate": 0.00013477788245525038,
      "loss": 0.0744,
      "step": 4501
    },
    {
      "epoch": 0.32626734790013406,
      "grad_norm": 2.4523911476135254,
      "learning_rate": 0.00013476338865135156,
      "loss": 0.194,
      "step": 4502
    },
    {
      "epoch": 0.32633981954560276,
      "grad_norm": 0.8087218999862671,
      "learning_rate": 0.00013474889484745272,
      "loss": 0.0238,
      "step": 4503
    },
    {
      "epoch": 0.3264122911910715,
      "grad_norm": 1.2402303218841553,
      "learning_rate": 0.00013473440104355388,
      "loss": 0.0478,
      "step": 4504
    },
    {
      "epoch": 0.3264847628365402,
      "grad_norm": 2.4432618618011475,
      "learning_rate": 0.00013471990723965506,
      "loss": 0.0248,
      "step": 4505
    },
    {
      "epoch": 0.3265572344820089,
      "grad_norm": 0.7724368572235107,
      "learning_rate": 0.00013470541343575622,
      "loss": 0.0282,
      "step": 4506
    },
    {
      "epoch": 0.3266297061274776,
      "grad_norm": 1.883737325668335,
      "learning_rate": 0.00013469091963185737,
      "loss": 0.1798,
      "step": 4507
    },
    {
      "epoch": 0.32670217777294636,
      "grad_norm": 1.1068423986434937,
      "learning_rate": 0.00013467642582795856,
      "loss": 0.0479,
      "step": 4508
    },
    {
      "epoch": 0.32677464941841505,
      "grad_norm": 1.4642915725708008,
      "learning_rate": 0.0001346619320240597,
      "loss": 0.0705,
      "step": 4509
    },
    {
      "epoch": 0.32684712106388375,
      "grad_norm": 0.6892443299293518,
      "learning_rate": 0.00013464743822016087,
      "loss": 0.1005,
      "step": 4510
    },
    {
      "epoch": 0.32691959270935245,
      "grad_norm": 1.6891673803329468,
      "learning_rate": 0.00013463294441626205,
      "loss": 0.0628,
      "step": 4511
    },
    {
      "epoch": 0.3269920643548212,
      "grad_norm": 0.8605892658233643,
      "learning_rate": 0.0001346184506123632,
      "loss": 0.0357,
      "step": 4512
    },
    {
      "epoch": 0.3270645360002899,
      "grad_norm": 1.0285089015960693,
      "learning_rate": 0.0001346039568084644,
      "loss": 0.0708,
      "step": 4513
    },
    {
      "epoch": 0.3271370076457586,
      "grad_norm": 3.4725701808929443,
      "learning_rate": 0.00013458946300456558,
      "loss": 0.2122,
      "step": 4514
    },
    {
      "epoch": 0.3272094792912273,
      "grad_norm": 1.6349072456359863,
      "learning_rate": 0.00013457496920066673,
      "loss": 0.0709,
      "step": 4515
    },
    {
      "epoch": 0.32728195093669604,
      "grad_norm": 3.596844434738159,
      "learning_rate": 0.0001345604753967679,
      "loss": 0.136,
      "step": 4516
    },
    {
      "epoch": 0.32735442258216474,
      "grad_norm": 1.5547189712524414,
      "learning_rate": 0.00013454598159286907,
      "loss": 0.0628,
      "step": 4517
    },
    {
      "epoch": 0.32742689422763344,
      "grad_norm": 1.6658523082733154,
      "learning_rate": 0.00013453148778897023,
      "loss": 0.091,
      "step": 4518
    },
    {
      "epoch": 0.32749936587310213,
      "grad_norm": 2.03732967376709,
      "learning_rate": 0.0001345169939850714,
      "loss": 0.0941,
      "step": 4519
    },
    {
      "epoch": 0.3275718375185709,
      "grad_norm": 0.9045955538749695,
      "learning_rate": 0.00013450250018117257,
      "loss": 0.0401,
      "step": 4520
    },
    {
      "epoch": 0.3276443091640396,
      "grad_norm": 0.7190199494361877,
      "learning_rate": 0.00013448800637727373,
      "loss": 0.0413,
      "step": 4521
    },
    {
      "epoch": 0.3277167808095083,
      "grad_norm": 3.0420823097229004,
      "learning_rate": 0.00013447351257337488,
      "loss": 0.0694,
      "step": 4522
    },
    {
      "epoch": 0.327789252454977,
      "grad_norm": 0.9951088428497314,
      "learning_rate": 0.00013445901876947607,
      "loss": 0.0286,
      "step": 4523
    },
    {
      "epoch": 0.32786172410044573,
      "grad_norm": 1.7677087783813477,
      "learning_rate": 0.00013444452496557722,
      "loss": 0.1125,
      "step": 4524
    },
    {
      "epoch": 0.3279341957459144,
      "grad_norm": 0.4729143977165222,
      "learning_rate": 0.00013443003116167838,
      "loss": 0.0116,
      "step": 4525
    },
    {
      "epoch": 0.3280066673913831,
      "grad_norm": 1.2604347467422485,
      "learning_rate": 0.00013441553735777956,
      "loss": 0.0465,
      "step": 4526
    },
    {
      "epoch": 0.3280791390368518,
      "grad_norm": 1.5881465673446655,
      "learning_rate": 0.00013440104355388072,
      "loss": 0.0357,
      "step": 4527
    },
    {
      "epoch": 0.3281516106823205,
      "grad_norm": 1.954868197441101,
      "learning_rate": 0.00013438654974998188,
      "loss": 0.1926,
      "step": 4528
    },
    {
      "epoch": 0.32822408232778927,
      "grad_norm": 0.5053938031196594,
      "learning_rate": 0.00013437205594608306,
      "loss": 0.0238,
      "step": 4529
    },
    {
      "epoch": 0.32829655397325797,
      "grad_norm": 1.565908432006836,
      "learning_rate": 0.00013435756214218422,
      "loss": 0.0756,
      "step": 4530
    },
    {
      "epoch": 0.32836902561872666,
      "grad_norm": 1.2029038667678833,
      "learning_rate": 0.00013434306833828537,
      "loss": 0.0447,
      "step": 4531
    },
    {
      "epoch": 0.32844149726419536,
      "grad_norm": 2.0916550159454346,
      "learning_rate": 0.00013432857453438656,
      "loss": 0.0502,
      "step": 4532
    },
    {
      "epoch": 0.3285139689096641,
      "grad_norm": 0.530471920967102,
      "learning_rate": 0.0001343140807304877,
      "loss": 0.0111,
      "step": 4533
    },
    {
      "epoch": 0.3285864405551328,
      "grad_norm": 0.9429653882980347,
      "learning_rate": 0.00013429958692658887,
      "loss": 0.0503,
      "step": 4534
    },
    {
      "epoch": 0.3286589122006015,
      "grad_norm": 3.8107118606567383,
      "learning_rate": 0.00013428509312269005,
      "loss": 0.1118,
      "step": 4535
    },
    {
      "epoch": 0.3287313838460702,
      "grad_norm": 1.4407374858856201,
      "learning_rate": 0.00013427059931879124,
      "loss": 0.0758,
      "step": 4536
    },
    {
      "epoch": 0.32880385549153895,
      "grad_norm": 0.32879945635795593,
      "learning_rate": 0.0001342561055148924,
      "loss": 0.0106,
      "step": 4537
    },
    {
      "epoch": 0.32887632713700765,
      "grad_norm": 2.450531005859375,
      "learning_rate": 0.00013424161171099358,
      "loss": 0.06,
      "step": 4538
    },
    {
      "epoch": 0.32894879878247635,
      "grad_norm": 1.3725779056549072,
      "learning_rate": 0.00013422711790709473,
      "loss": 0.1087,
      "step": 4539
    },
    {
      "epoch": 0.32902127042794505,
      "grad_norm": 2.166905164718628,
      "learning_rate": 0.0001342126241031959,
      "loss": 0.098,
      "step": 4540
    },
    {
      "epoch": 0.3290937420734138,
      "grad_norm": 0.9116429686546326,
      "learning_rate": 0.00013419813029929707,
      "loss": 0.0872,
      "step": 4541
    },
    {
      "epoch": 0.3291662137188825,
      "grad_norm": 3.4853708744049072,
      "learning_rate": 0.00013418363649539823,
      "loss": 0.0869,
      "step": 4542
    },
    {
      "epoch": 0.3292386853643512,
      "grad_norm": 1.263282060623169,
      "learning_rate": 0.00013416914269149939,
      "loss": 0.0692,
      "step": 4543
    },
    {
      "epoch": 0.3293111570098199,
      "grad_norm": 0.7844039797782898,
      "learning_rate": 0.00013415464888760057,
      "loss": 0.0638,
      "step": 4544
    },
    {
      "epoch": 0.32938362865528864,
      "grad_norm": 0.6706308722496033,
      "learning_rate": 0.00013414015508370173,
      "loss": 0.0173,
      "step": 4545
    },
    {
      "epoch": 0.32945610030075734,
      "grad_norm": 0.6957987546920776,
      "learning_rate": 0.00013412566127980288,
      "loss": 0.0416,
      "step": 4546
    },
    {
      "epoch": 0.32952857194622603,
      "grad_norm": 1.5920394659042358,
      "learning_rate": 0.00013411116747590407,
      "loss": 0.0601,
      "step": 4547
    },
    {
      "epoch": 0.32960104359169473,
      "grad_norm": 1.1624886989593506,
      "learning_rate": 0.00013409667367200522,
      "loss": 0.0337,
      "step": 4548
    },
    {
      "epoch": 0.3296735152371635,
      "grad_norm": 1.6282950639724731,
      "learning_rate": 0.00013408217986810638,
      "loss": 0.0226,
      "step": 4549
    },
    {
      "epoch": 0.3297459868826322,
      "grad_norm": 2.2077810764312744,
      "learning_rate": 0.00013406768606420756,
      "loss": 0.063,
      "step": 4550
    },
    {
      "epoch": 0.3298184585281009,
      "grad_norm": 0.8338733911514282,
      "learning_rate": 0.00013405319226030872,
      "loss": 0.0625,
      "step": 4551
    },
    {
      "epoch": 0.3298909301735696,
      "grad_norm": 1.0316270589828491,
      "learning_rate": 0.00013403869845640988,
      "loss": 0.0511,
      "step": 4552
    },
    {
      "epoch": 0.3299634018190383,
      "grad_norm": 1.9366627931594849,
      "learning_rate": 0.00013402420465251106,
      "loss": 0.0512,
      "step": 4553
    },
    {
      "epoch": 0.330035873464507,
      "grad_norm": 0.6140490770339966,
      "learning_rate": 0.00013400971084861222,
      "loss": 0.0433,
      "step": 4554
    },
    {
      "epoch": 0.3301083451099757,
      "grad_norm": 1.4421876668930054,
      "learning_rate": 0.00013399521704471337,
      "loss": 0.0971,
      "step": 4555
    },
    {
      "epoch": 0.3301808167554444,
      "grad_norm": 0.627957820892334,
      "learning_rate": 0.00013398072324081456,
      "loss": 0.0204,
      "step": 4556
    },
    {
      "epoch": 0.33025328840091317,
      "grad_norm": 6.684861183166504,
      "learning_rate": 0.0001339662294369157,
      "loss": 0.1831,
      "step": 4557
    },
    {
      "epoch": 0.33032576004638187,
      "grad_norm": 1.0657029151916504,
      "learning_rate": 0.0001339517356330169,
      "loss": 0.0288,
      "step": 4558
    },
    {
      "epoch": 0.33039823169185056,
      "grad_norm": 3.7467055320739746,
      "learning_rate": 0.00013393724182911805,
      "loss": 0.0804,
      "step": 4559
    },
    {
      "epoch": 0.33047070333731926,
      "grad_norm": 2.883533000946045,
      "learning_rate": 0.00013392274802521924,
      "loss": 0.0716,
      "step": 4560
    },
    {
      "epoch": 0.33054317498278796,
      "grad_norm": 4.970081806182861,
      "learning_rate": 0.0001339082542213204,
      "loss": 0.0517,
      "step": 4561
    },
    {
      "epoch": 0.3306156466282567,
      "grad_norm": 0.4022134244441986,
      "learning_rate": 0.00013389376041742158,
      "loss": 0.0428,
      "step": 4562
    },
    {
      "epoch": 0.3306881182737254,
      "grad_norm": 1.2662723064422607,
      "learning_rate": 0.00013387926661352273,
      "loss": 0.0587,
      "step": 4563
    },
    {
      "epoch": 0.3307605899191941,
      "grad_norm": 5.204892158508301,
      "learning_rate": 0.0001338647728096239,
      "loss": 0.0972,
      "step": 4564
    },
    {
      "epoch": 0.3308330615646628,
      "grad_norm": 1.1567960977554321,
      "learning_rate": 0.00013385027900572507,
      "loss": 0.0596,
      "step": 4565
    },
    {
      "epoch": 0.33090553321013155,
      "grad_norm": 1.7175649404525757,
      "learning_rate": 0.00013383578520182623,
      "loss": 0.0661,
      "step": 4566
    },
    {
      "epoch": 0.33097800485560025,
      "grad_norm": 0.5757002234458923,
      "learning_rate": 0.00013382129139792739,
      "loss": 0.0044,
      "step": 4567
    },
    {
      "epoch": 0.33105047650106895,
      "grad_norm": 0.16787679493427277,
      "learning_rate": 0.00013380679759402857,
      "loss": 0.0046,
      "step": 4568
    },
    {
      "epoch": 0.33112294814653764,
      "grad_norm": 2.254473924636841,
      "learning_rate": 0.00013379230379012973,
      "loss": 0.1391,
      "step": 4569
    },
    {
      "epoch": 0.3311954197920064,
      "grad_norm": 1.5532678365707397,
      "learning_rate": 0.00013377780998623088,
      "loss": 0.0659,
      "step": 4570
    },
    {
      "epoch": 0.3312678914374751,
      "grad_norm": 1.3327274322509766,
      "learning_rate": 0.00013376331618233207,
      "loss": 0.0646,
      "step": 4571
    },
    {
      "epoch": 0.3313403630829438,
      "grad_norm": 0.5264719128608704,
      "learning_rate": 0.00013374882237843322,
      "loss": 0.0257,
      "step": 4572
    },
    {
      "epoch": 0.3314128347284125,
      "grad_norm": 1.4298474788665771,
      "learning_rate": 0.00013373432857453438,
      "loss": 0.0455,
      "step": 4573
    },
    {
      "epoch": 0.33148530637388124,
      "grad_norm": 0.6463721990585327,
      "learning_rate": 0.00013371983477063556,
      "loss": 0.0424,
      "step": 4574
    },
    {
      "epoch": 0.33155777801934994,
      "grad_norm": 2.5838351249694824,
      "learning_rate": 0.00013370534096673672,
      "loss": 0.1894,
      "step": 4575
    },
    {
      "epoch": 0.33163024966481863,
      "grad_norm": 1.0198571681976318,
      "learning_rate": 0.00013369084716283788,
      "loss": 0.0438,
      "step": 4576
    },
    {
      "epoch": 0.33170272131028733,
      "grad_norm": 1.024668574333191,
      "learning_rate": 0.00013367635335893906,
      "loss": 0.0344,
      "step": 4577
    },
    {
      "epoch": 0.3317751929557561,
      "grad_norm": 5.808221817016602,
      "learning_rate": 0.00013366185955504022,
      "loss": 0.1652,
      "step": 4578
    },
    {
      "epoch": 0.3318476646012248,
      "grad_norm": 6.288876056671143,
      "learning_rate": 0.00013364736575114137,
      "loss": 0.1109,
      "step": 4579
    },
    {
      "epoch": 0.3319201362466935,
      "grad_norm": 1.6156097650527954,
      "learning_rate": 0.00013363287194724256,
      "loss": 0.0861,
      "step": 4580
    },
    {
      "epoch": 0.3319926078921622,
      "grad_norm": 2.5989537239074707,
      "learning_rate": 0.0001336183781433437,
      "loss": 0.05,
      "step": 4581
    },
    {
      "epoch": 0.3320650795376309,
      "grad_norm": 2.6034607887268066,
      "learning_rate": 0.0001336038843394449,
      "loss": 0.101,
      "step": 4582
    },
    {
      "epoch": 0.3321375511830996,
      "grad_norm": 1.9475361108779907,
      "learning_rate": 0.00013358939053554608,
      "loss": 0.0455,
      "step": 4583
    },
    {
      "epoch": 0.3322100228285683,
      "grad_norm": 2.390329599380493,
      "learning_rate": 0.00013357489673164724,
      "loss": 0.1164,
      "step": 4584
    },
    {
      "epoch": 0.332282494474037,
      "grad_norm": 2.5233235359191895,
      "learning_rate": 0.0001335604029277484,
      "loss": 0.0821,
      "step": 4585
    },
    {
      "epoch": 0.33235496611950577,
      "grad_norm": 4.174028396606445,
      "learning_rate": 0.00013354590912384958,
      "loss": 0.0995,
      "step": 4586
    },
    {
      "epoch": 0.33242743776497446,
      "grad_norm": 2.0944554805755615,
      "learning_rate": 0.00013353141531995073,
      "loss": 0.0658,
      "step": 4587
    },
    {
      "epoch": 0.33249990941044316,
      "grad_norm": 3.166339635848999,
      "learning_rate": 0.0001335169215160519,
      "loss": 0.0551,
      "step": 4588
    },
    {
      "epoch": 0.33257238105591186,
      "grad_norm": 1.4859977960586548,
      "learning_rate": 0.00013350242771215307,
      "loss": 0.0484,
      "step": 4589
    },
    {
      "epoch": 0.3326448527013806,
      "grad_norm": 1.2801704406738281,
      "learning_rate": 0.00013348793390825423,
      "loss": 0.0806,
      "step": 4590
    },
    {
      "epoch": 0.3327173243468493,
      "grad_norm": 2.772278070449829,
      "learning_rate": 0.00013347344010435539,
      "loss": 0.1796,
      "step": 4591
    },
    {
      "epoch": 0.332789795992318,
      "grad_norm": 3.1568052768707275,
      "learning_rate": 0.00013345894630045657,
      "loss": 0.084,
      "step": 4592
    },
    {
      "epoch": 0.3328622676377867,
      "grad_norm": 1.1171891689300537,
      "learning_rate": 0.00013344445249655773,
      "loss": 0.1175,
      "step": 4593
    },
    {
      "epoch": 0.3329347392832554,
      "grad_norm": 0.6463767290115356,
      "learning_rate": 0.00013342995869265888,
      "loss": 0.0356,
      "step": 4594
    },
    {
      "epoch": 0.33300721092872415,
      "grad_norm": 1.38920259475708,
      "learning_rate": 0.00013341546488876007,
      "loss": 0.0823,
      "step": 4595
    },
    {
      "epoch": 0.33307968257419285,
      "grad_norm": 1.872042179107666,
      "learning_rate": 0.00013340097108486122,
      "loss": 0.0549,
      "step": 4596
    },
    {
      "epoch": 0.33315215421966154,
      "grad_norm": 1.7024959325790405,
      "learning_rate": 0.00013338647728096238,
      "loss": 0.091,
      "step": 4597
    },
    {
      "epoch": 0.33322462586513024,
      "grad_norm": 0.9980034828186035,
      "learning_rate": 0.00013337198347706356,
      "loss": 0.0631,
      "step": 4598
    },
    {
      "epoch": 0.333297097510599,
      "grad_norm": 1.1702942848205566,
      "learning_rate": 0.00013335748967316472,
      "loss": 0.0871,
      "step": 4599
    },
    {
      "epoch": 0.3333695691560677,
      "grad_norm": 1.887771725654602,
      "learning_rate": 0.00013334299586926587,
      "loss": 0.1244,
      "step": 4600
    },
    {
      "epoch": 0.3334420408015364,
      "grad_norm": 0.230390265583992,
      "learning_rate": 0.00013332850206536706,
      "loss": 0.0042,
      "step": 4601
    },
    {
      "epoch": 0.3335145124470051,
      "grad_norm": 0.9115427136421204,
      "learning_rate": 0.00013331400826146822,
      "loss": 0.0287,
      "step": 4602
    },
    {
      "epoch": 0.33358698409247384,
      "grad_norm": 1.499324917793274,
      "learning_rate": 0.0001332995144575694,
      "loss": 0.0471,
      "step": 4603
    },
    {
      "epoch": 0.33365945573794253,
      "grad_norm": 0.5791704654693604,
      "learning_rate": 0.00013328502065367056,
      "loss": 0.015,
      "step": 4604
    },
    {
      "epoch": 0.33373192738341123,
      "grad_norm": 1.332939624786377,
      "learning_rate": 0.00013327052684977174,
      "loss": 0.0504,
      "step": 4605
    },
    {
      "epoch": 0.33380439902887993,
      "grad_norm": 1.870908498764038,
      "learning_rate": 0.0001332560330458729,
      "loss": 0.1687,
      "step": 4606
    },
    {
      "epoch": 0.3338768706743487,
      "grad_norm": 4.139340877532959,
      "learning_rate": 0.00013324153924197408,
      "loss": 0.123,
      "step": 4607
    },
    {
      "epoch": 0.3339493423198174,
      "grad_norm": 1.1088025569915771,
      "learning_rate": 0.00013322704543807524,
      "loss": 0.0862,
      "step": 4608
    },
    {
      "epoch": 0.3340218139652861,
      "grad_norm": 1.639930009841919,
      "learning_rate": 0.0001332125516341764,
      "loss": 0.0825,
      "step": 4609
    },
    {
      "epoch": 0.33409428561075477,
      "grad_norm": 1.58303701877594,
      "learning_rate": 0.00013319805783027758,
      "loss": 0.0867,
      "step": 4610
    },
    {
      "epoch": 0.3341667572562235,
      "grad_norm": 3.179596424102783,
      "learning_rate": 0.00013318356402637873,
      "loss": 0.1552,
      "step": 4611
    },
    {
      "epoch": 0.3342392289016922,
      "grad_norm": 2.9044597148895264,
      "learning_rate": 0.0001331690702224799,
      "loss": 0.0473,
      "step": 4612
    },
    {
      "epoch": 0.3343117005471609,
      "grad_norm": 1.383755087852478,
      "learning_rate": 0.00013315457641858107,
      "loss": 0.1101,
      "step": 4613
    },
    {
      "epoch": 0.3343841721926296,
      "grad_norm": 0.4338253438472748,
      "learning_rate": 0.00013314008261468223,
      "loss": 0.0125,
      "step": 4614
    },
    {
      "epoch": 0.33445664383809837,
      "grad_norm": 0.48642250895500183,
      "learning_rate": 0.00013312558881078338,
      "loss": 0.0358,
      "step": 4615
    },
    {
      "epoch": 0.33452911548356706,
      "grad_norm": 1.8636142015457153,
      "learning_rate": 0.00013311109500688457,
      "loss": 0.1072,
      "step": 4616
    },
    {
      "epoch": 0.33460158712903576,
      "grad_norm": 0.737680971622467,
      "learning_rate": 0.00013309660120298572,
      "loss": 0.0426,
      "step": 4617
    },
    {
      "epoch": 0.33467405877450446,
      "grad_norm": 1.4522438049316406,
      "learning_rate": 0.00013308210739908688,
      "loss": 0.113,
      "step": 4618
    },
    {
      "epoch": 0.3347465304199732,
      "grad_norm": 1.3938676118850708,
      "learning_rate": 0.00013306761359518807,
      "loss": 0.0809,
      "step": 4619
    },
    {
      "epoch": 0.3348190020654419,
      "grad_norm": 0.9729528427124023,
      "learning_rate": 0.00013305311979128922,
      "loss": 0.0416,
      "step": 4620
    },
    {
      "epoch": 0.3348914737109106,
      "grad_norm": 0.9890134930610657,
      "learning_rate": 0.00013303862598739038,
      "loss": 0.0462,
      "step": 4621
    },
    {
      "epoch": 0.3349639453563793,
      "grad_norm": 1.3572372198104858,
      "learning_rate": 0.00013302413218349156,
      "loss": 0.0531,
      "step": 4622
    },
    {
      "epoch": 0.33503641700184805,
      "grad_norm": 2.191229820251465,
      "learning_rate": 0.00013300963837959272,
      "loss": 0.2459,
      "step": 4623
    },
    {
      "epoch": 0.33510888864731675,
      "grad_norm": 1.713066816329956,
      "learning_rate": 0.00013299514457569387,
      "loss": 0.0713,
      "step": 4624
    },
    {
      "epoch": 0.33518136029278545,
      "grad_norm": 0.44497278332710266,
      "learning_rate": 0.00013298065077179506,
      "loss": 0.0155,
      "step": 4625
    },
    {
      "epoch": 0.33525383193825414,
      "grad_norm": 0.14692282676696777,
      "learning_rate": 0.00013296615696789621,
      "loss": 0.0037,
      "step": 4626
    },
    {
      "epoch": 0.3353263035837229,
      "grad_norm": 2.3603174686431885,
      "learning_rate": 0.0001329516631639974,
      "loss": 0.1202,
      "step": 4627
    },
    {
      "epoch": 0.3353987752291916,
      "grad_norm": 2.3269221782684326,
      "learning_rate": 0.00013293716936009855,
      "loss": 0.076,
      "step": 4628
    },
    {
      "epoch": 0.3354712468746603,
      "grad_norm": 1.650607705116272,
      "learning_rate": 0.00013292267555619974,
      "loss": 0.0878,
      "step": 4629
    },
    {
      "epoch": 0.335543718520129,
      "grad_norm": 2.13256573677063,
      "learning_rate": 0.00013290818175230092,
      "loss": 0.0849,
      "step": 4630
    },
    {
      "epoch": 0.3356161901655977,
      "grad_norm": 3.0198631286621094,
      "learning_rate": 0.00013289368794840208,
      "loss": 0.1163,
      "step": 4631
    },
    {
      "epoch": 0.33568866181106644,
      "grad_norm": 6.70053243637085,
      "learning_rate": 0.00013287919414450323,
      "loss": 0.2607,
      "step": 4632
    },
    {
      "epoch": 0.33576113345653513,
      "grad_norm": 1.2309010028839111,
      "learning_rate": 0.00013286470034060442,
      "loss": 0.07,
      "step": 4633
    },
    {
      "epoch": 0.33583360510200383,
      "grad_norm": 4.237293243408203,
      "learning_rate": 0.00013285020653670557,
      "loss": 0.1214,
      "step": 4634
    },
    {
      "epoch": 0.3359060767474725,
      "grad_norm": 1.727226972579956,
      "learning_rate": 0.00013283571273280673,
      "loss": 0.0873,
      "step": 4635
    },
    {
      "epoch": 0.3359785483929413,
      "grad_norm": 0.8657090663909912,
      "learning_rate": 0.00013282121892890792,
      "loss": 0.0622,
      "step": 4636
    },
    {
      "epoch": 0.33605102003841,
      "grad_norm": 0.5633729696273804,
      "learning_rate": 0.00013280672512500907,
      "loss": 0.0458,
      "step": 4637
    },
    {
      "epoch": 0.3361234916838787,
      "grad_norm": 0.5990113019943237,
      "learning_rate": 0.00013279223132111023,
      "loss": 0.0639,
      "step": 4638
    },
    {
      "epoch": 0.33619596332934737,
      "grad_norm": 1.4650508165359497,
      "learning_rate": 0.0001327777375172114,
      "loss": 0.115,
      "step": 4639
    },
    {
      "epoch": 0.3362684349748161,
      "grad_norm": 1.4414438009262085,
      "learning_rate": 0.00013276324371331257,
      "loss": 0.0801,
      "step": 4640
    },
    {
      "epoch": 0.3363409066202848,
      "grad_norm": 1.308968186378479,
      "learning_rate": 0.00013274874990941372,
      "loss": 0.0694,
      "step": 4641
    },
    {
      "epoch": 0.3364133782657535,
      "grad_norm": 1.9783556461334229,
      "learning_rate": 0.0001327342561055149,
      "loss": 0.0375,
      "step": 4642
    },
    {
      "epoch": 0.3364858499112222,
      "grad_norm": 2.5804879665374756,
      "learning_rate": 0.00013271976230161606,
      "loss": 0.0794,
      "step": 4643
    },
    {
      "epoch": 0.33655832155669096,
      "grad_norm": 1.0885329246520996,
      "learning_rate": 0.00013270526849771722,
      "loss": 0.0676,
      "step": 4644
    },
    {
      "epoch": 0.33663079320215966,
      "grad_norm": 0.24765826761722565,
      "learning_rate": 0.0001326907746938184,
      "loss": 0.0253,
      "step": 4645
    },
    {
      "epoch": 0.33670326484762836,
      "grad_norm": 1.5783215761184692,
      "learning_rate": 0.00013267628088991956,
      "loss": 0.0931,
      "step": 4646
    },
    {
      "epoch": 0.33677573649309706,
      "grad_norm": 15.173866271972656,
      "learning_rate": 0.00013266178708602072,
      "loss": 0.1035,
      "step": 4647
    },
    {
      "epoch": 0.3368482081385658,
      "grad_norm": 1.8057483434677124,
      "learning_rate": 0.0001326472932821219,
      "loss": 0.1434,
      "step": 4648
    },
    {
      "epoch": 0.3369206797840345,
      "grad_norm": 0.8417805433273315,
      "learning_rate": 0.00013263279947822306,
      "loss": 0.0292,
      "step": 4649
    },
    {
      "epoch": 0.3369931514295032,
      "grad_norm": 0.8474997878074646,
      "learning_rate": 0.00013261830567432424,
      "loss": 0.0389,
      "step": 4650
    },
    {
      "epoch": 0.3370656230749719,
      "grad_norm": 6.266390323638916,
      "learning_rate": 0.0001326038118704254,
      "loss": 0.2133,
      "step": 4651
    },
    {
      "epoch": 0.33713809472044065,
      "grad_norm": 1.3440508842468262,
      "learning_rate": 0.00013258931806652658,
      "loss": 0.1152,
      "step": 4652
    },
    {
      "epoch": 0.33721056636590935,
      "grad_norm": 0.30153095722198486,
      "learning_rate": 0.00013257482426262774,
      "loss": 0.0265,
      "step": 4653
    },
    {
      "epoch": 0.33728303801137804,
      "grad_norm": 0.8898652195930481,
      "learning_rate": 0.00013256033045872892,
      "loss": 0.0829,
      "step": 4654
    },
    {
      "epoch": 0.33735550965684674,
      "grad_norm": 0.56281977891922,
      "learning_rate": 0.00013254583665483008,
      "loss": 0.0395,
      "step": 4655
    },
    {
      "epoch": 0.3374279813023155,
      "grad_norm": 1.134522795677185,
      "learning_rate": 0.00013253134285093123,
      "loss": 0.0624,
      "step": 4656
    },
    {
      "epoch": 0.3375004529477842,
      "grad_norm": 2.576493740081787,
      "learning_rate": 0.00013251684904703242,
      "loss": 0.1641,
      "step": 4657
    },
    {
      "epoch": 0.3375729245932529,
      "grad_norm": 4.294224262237549,
      "learning_rate": 0.00013250235524313357,
      "loss": 0.3334,
      "step": 4658
    },
    {
      "epoch": 0.3376453962387216,
      "grad_norm": 1.225784420967102,
      "learning_rate": 0.00013248786143923473,
      "loss": 0.0425,
      "step": 4659
    },
    {
      "epoch": 0.33771786788419034,
      "grad_norm": 1.6209566593170166,
      "learning_rate": 0.00013247336763533591,
      "loss": 0.0525,
      "step": 4660
    },
    {
      "epoch": 0.33779033952965903,
      "grad_norm": 1.5356780290603638,
      "learning_rate": 0.00013245887383143707,
      "loss": 0.0584,
      "step": 4661
    },
    {
      "epoch": 0.33786281117512773,
      "grad_norm": 3.2607014179229736,
      "learning_rate": 0.00013244438002753823,
      "loss": 0.1386,
      "step": 4662
    },
    {
      "epoch": 0.3379352828205964,
      "grad_norm": 2.2947261333465576,
      "learning_rate": 0.0001324298862236394,
      "loss": 0.1564,
      "step": 4663
    },
    {
      "epoch": 0.3380077544660651,
      "grad_norm": 1.1942789554595947,
      "learning_rate": 0.00013241539241974057,
      "loss": 0.0632,
      "step": 4664
    },
    {
      "epoch": 0.3380802261115339,
      "grad_norm": 3.595374822616577,
      "learning_rate": 0.00013240089861584172,
      "loss": 0.0761,
      "step": 4665
    },
    {
      "epoch": 0.3381526977570026,
      "grad_norm": 1.4661979675292969,
      "learning_rate": 0.0001323864048119429,
      "loss": 0.0351,
      "step": 4666
    },
    {
      "epoch": 0.33822516940247127,
      "grad_norm": 3.1686229705810547,
      "learning_rate": 0.00013237191100804406,
      "loss": 0.2095,
      "step": 4667
    },
    {
      "epoch": 0.33829764104793997,
      "grad_norm": 2.2079529762268066,
      "learning_rate": 0.00013235741720414522,
      "loss": 0.0743,
      "step": 4668
    },
    {
      "epoch": 0.3383701126934087,
      "grad_norm": 0.763917863368988,
      "learning_rate": 0.0001323429234002464,
      "loss": 0.0408,
      "step": 4669
    },
    {
      "epoch": 0.3384425843388774,
      "grad_norm": 0.6708998084068298,
      "learning_rate": 0.00013232842959634756,
      "loss": 0.0442,
      "step": 4670
    },
    {
      "epoch": 0.3385150559843461,
      "grad_norm": 1.0171014070510864,
      "learning_rate": 0.00013231393579244872,
      "loss": 0.0376,
      "step": 4671
    },
    {
      "epoch": 0.3385875276298148,
      "grad_norm": 1.6941193342208862,
      "learning_rate": 0.0001322994419885499,
      "loss": 0.0727,
      "step": 4672
    },
    {
      "epoch": 0.33865999927528356,
      "grad_norm": 1.018787145614624,
      "learning_rate": 0.00013228494818465106,
      "loss": 0.0566,
      "step": 4673
    },
    {
      "epoch": 0.33873247092075226,
      "grad_norm": 2.2273051738739014,
      "learning_rate": 0.00013227045438075224,
      "loss": 0.0239,
      "step": 4674
    },
    {
      "epoch": 0.33880494256622096,
      "grad_norm": 0.7990014553070068,
      "learning_rate": 0.0001322559605768534,
      "loss": 0.0355,
      "step": 4675
    },
    {
      "epoch": 0.33887741421168965,
      "grad_norm": 2.1372711658477783,
      "learning_rate": 0.00013224146677295458,
      "loss": 0.0547,
      "step": 4676
    },
    {
      "epoch": 0.3389498858571584,
      "grad_norm": 1.1669224500656128,
      "learning_rate": 0.00013222697296905574,
      "loss": 0.0344,
      "step": 4677
    },
    {
      "epoch": 0.3390223575026271,
      "grad_norm": 0.5744873285293579,
      "learning_rate": 0.00013221247916515692,
      "loss": 0.0489,
      "step": 4678
    },
    {
      "epoch": 0.3390948291480958,
      "grad_norm": 0.3517707288265228,
      "learning_rate": 0.00013219798536125808,
      "loss": 0.0203,
      "step": 4679
    },
    {
      "epoch": 0.3391673007935645,
      "grad_norm": 0.15450553596019745,
      "learning_rate": 0.00013218349155735923,
      "loss": 0.0052,
      "step": 4680
    },
    {
      "epoch": 0.33923977243903325,
      "grad_norm": 4.499577045440674,
      "learning_rate": 0.00013216899775346042,
      "loss": 0.1361,
      "step": 4681
    },
    {
      "epoch": 0.33931224408450195,
      "grad_norm": 1.076971411705017,
      "learning_rate": 0.00013215450394956157,
      "loss": 0.046,
      "step": 4682
    },
    {
      "epoch": 0.33938471572997064,
      "grad_norm": 2.4145820140838623,
      "learning_rate": 0.00013214001014566273,
      "loss": 0.0184,
      "step": 4683
    },
    {
      "epoch": 0.33945718737543934,
      "grad_norm": 0.1150667741894722,
      "learning_rate": 0.00013212551634176391,
      "loss": 0.002,
      "step": 4684
    },
    {
      "epoch": 0.3395296590209081,
      "grad_norm": 0.8393023610115051,
      "learning_rate": 0.00013211102253786507,
      "loss": 0.049,
      "step": 4685
    },
    {
      "epoch": 0.3396021306663768,
      "grad_norm": 3.0601186752319336,
      "learning_rate": 0.00013209652873396623,
      "loss": 0.0546,
      "step": 4686
    },
    {
      "epoch": 0.3396746023118455,
      "grad_norm": 1.4782757759094238,
      "learning_rate": 0.0001320820349300674,
      "loss": 0.0615,
      "step": 4687
    },
    {
      "epoch": 0.3397470739573142,
      "grad_norm": 1.0740903615951538,
      "learning_rate": 0.00013206754112616857,
      "loss": 0.0469,
      "step": 4688
    },
    {
      "epoch": 0.33981954560278294,
      "grad_norm": 1.7293635606765747,
      "learning_rate": 0.00013205304732226972,
      "loss": 0.0429,
      "step": 4689
    },
    {
      "epoch": 0.33989201724825163,
      "grad_norm": 1.3179378509521484,
      "learning_rate": 0.0001320385535183709,
      "loss": 0.0743,
      "step": 4690
    },
    {
      "epoch": 0.33996448889372033,
      "grad_norm": 0.5219012498855591,
      "learning_rate": 0.00013202405971447206,
      "loss": 0.0126,
      "step": 4691
    },
    {
      "epoch": 0.340036960539189,
      "grad_norm": 5.4850616455078125,
      "learning_rate": 0.00013200956591057322,
      "loss": 0.173,
      "step": 4692
    },
    {
      "epoch": 0.3401094321846578,
      "grad_norm": 1.160189151763916,
      "learning_rate": 0.0001319950721066744,
      "loss": 0.0668,
      "step": 4693
    },
    {
      "epoch": 0.3401819038301265,
      "grad_norm": 3.6272501945495605,
      "learning_rate": 0.00013198057830277556,
      "loss": 0.1102,
      "step": 4694
    },
    {
      "epoch": 0.34025437547559517,
      "grad_norm": 1.1614128351211548,
      "learning_rate": 0.00013196608449887672,
      "loss": 0.0862,
      "step": 4695
    },
    {
      "epoch": 0.34032684712106387,
      "grad_norm": 0.710016131401062,
      "learning_rate": 0.0001319515906949779,
      "loss": 0.045,
      "step": 4696
    },
    {
      "epoch": 0.3403993187665326,
      "grad_norm": 1.2083262205123901,
      "learning_rate": 0.00013193709689107908,
      "loss": 0.0534,
      "step": 4697
    },
    {
      "epoch": 0.3404717904120013,
      "grad_norm": 1.2751197814941406,
      "learning_rate": 0.00013192260308718024,
      "loss": 0.0622,
      "step": 4698
    },
    {
      "epoch": 0.34054426205747,
      "grad_norm": 3.886629104614258,
      "learning_rate": 0.00013190810928328142,
      "loss": 0.1004,
      "step": 4699
    },
    {
      "epoch": 0.3406167337029387,
      "grad_norm": 2.0856547355651855,
      "learning_rate": 0.00013189361547938258,
      "loss": 0.0767,
      "step": 4700
    },
    {
      "epoch": 0.3406892053484074,
      "grad_norm": 3.506456136703491,
      "learning_rate": 0.00013187912167548374,
      "loss": 0.058,
      "step": 4701
    },
    {
      "epoch": 0.34076167699387616,
      "grad_norm": 1.7742120027542114,
      "learning_rate": 0.00013186462787158492,
      "loss": 0.0666,
      "step": 4702
    },
    {
      "epoch": 0.34083414863934486,
      "grad_norm": 5.407727241516113,
      "learning_rate": 0.00013185013406768608,
      "loss": 0.1755,
      "step": 4703
    },
    {
      "epoch": 0.34090662028481356,
      "grad_norm": 0.4546695053577423,
      "learning_rate": 0.00013183564026378723,
      "loss": 0.0273,
      "step": 4704
    },
    {
      "epoch": 0.34097909193028225,
      "grad_norm": 1.2224763631820679,
      "learning_rate": 0.00013182114645988842,
      "loss": 0.0201,
      "step": 4705
    },
    {
      "epoch": 0.341051563575751,
      "grad_norm": 7.876001358032227,
      "learning_rate": 0.00013180665265598957,
      "loss": 0.1515,
      "step": 4706
    },
    {
      "epoch": 0.3411240352212197,
      "grad_norm": 1.695513129234314,
      "learning_rate": 0.00013179215885209073,
      "loss": 0.163,
      "step": 4707
    },
    {
      "epoch": 0.3411965068666884,
      "grad_norm": 4.005650520324707,
      "learning_rate": 0.00013177766504819191,
      "loss": 0.0401,
      "step": 4708
    },
    {
      "epoch": 0.3412689785121571,
      "grad_norm": 1.5354541540145874,
      "learning_rate": 0.00013176317124429307,
      "loss": 0.0296,
      "step": 4709
    },
    {
      "epoch": 0.34134145015762585,
      "grad_norm": 1.7064969539642334,
      "learning_rate": 0.00013174867744039423,
      "loss": 0.1618,
      "step": 4710
    },
    {
      "epoch": 0.34141392180309454,
      "grad_norm": 1.0262607336044312,
      "learning_rate": 0.0001317341836364954,
      "loss": 0.0598,
      "step": 4711
    },
    {
      "epoch": 0.34148639344856324,
      "grad_norm": 1.6982612609863281,
      "learning_rate": 0.00013171968983259657,
      "loss": 0.0445,
      "step": 4712
    },
    {
      "epoch": 0.34155886509403194,
      "grad_norm": 1.3302377462387085,
      "learning_rate": 0.00013170519602869772,
      "loss": 0.0532,
      "step": 4713
    },
    {
      "epoch": 0.3416313367395007,
      "grad_norm": 0.9481587409973145,
      "learning_rate": 0.0001316907022247989,
      "loss": 0.0302,
      "step": 4714
    },
    {
      "epoch": 0.3417038083849694,
      "grad_norm": 5.910229682922363,
      "learning_rate": 0.00013167620842090006,
      "loss": 0.336,
      "step": 4715
    },
    {
      "epoch": 0.3417762800304381,
      "grad_norm": 1.7568788528442383,
      "learning_rate": 0.00013166171461700122,
      "loss": 0.1241,
      "step": 4716
    },
    {
      "epoch": 0.3418487516759068,
      "grad_norm": 0.6596182584762573,
      "learning_rate": 0.0001316472208131024,
      "loss": 0.0194,
      "step": 4717
    },
    {
      "epoch": 0.34192122332137553,
      "grad_norm": 1.5085209608078003,
      "learning_rate": 0.00013163272700920356,
      "loss": 0.0667,
      "step": 4718
    },
    {
      "epoch": 0.34199369496684423,
      "grad_norm": 1.263981580734253,
      "learning_rate": 0.00013161823320530474,
      "loss": 0.0638,
      "step": 4719
    },
    {
      "epoch": 0.3420661666123129,
      "grad_norm": 0.37047451734542847,
      "learning_rate": 0.0001316037394014059,
      "loss": 0.0194,
      "step": 4720
    },
    {
      "epoch": 0.3421386382577816,
      "grad_norm": 1.5861141681671143,
      "learning_rate": 0.00013158924559750708,
      "loss": 0.1027,
      "step": 4721
    },
    {
      "epoch": 0.3422111099032504,
      "grad_norm": 1.218405842781067,
      "learning_rate": 0.00013157475179360824,
      "loss": 0.0919,
      "step": 4722
    },
    {
      "epoch": 0.3422835815487191,
      "grad_norm": 1.7363373041152954,
      "learning_rate": 0.00013156025798970942,
      "loss": 0.1055,
      "step": 4723
    },
    {
      "epoch": 0.34235605319418777,
      "grad_norm": 0.6985335350036621,
      "learning_rate": 0.00013154576418581058,
      "loss": 0.0207,
      "step": 4724
    },
    {
      "epoch": 0.34242852483965647,
      "grad_norm": 2.4717350006103516,
      "learning_rate": 0.00013153127038191174,
      "loss": 0.0677,
      "step": 4725
    },
    {
      "epoch": 0.3425009964851252,
      "grad_norm": 1.9540318250656128,
      "learning_rate": 0.00013151677657801292,
      "loss": 0.0806,
      "step": 4726
    },
    {
      "epoch": 0.3425734681305939,
      "grad_norm": 0.6668552756309509,
      "learning_rate": 0.00013150228277411408,
      "loss": 0.0281,
      "step": 4727
    },
    {
      "epoch": 0.3426459397760626,
      "grad_norm": 1.7984079122543335,
      "learning_rate": 0.00013148778897021523,
      "loss": 0.121,
      "step": 4728
    },
    {
      "epoch": 0.3427184114215313,
      "grad_norm": 0.8398221135139465,
      "learning_rate": 0.00013147329516631642,
      "loss": 0.0469,
      "step": 4729
    },
    {
      "epoch": 0.34279088306700006,
      "grad_norm": 1.2333928346633911,
      "learning_rate": 0.00013145880136241757,
      "loss": 0.0893,
      "step": 4730
    },
    {
      "epoch": 0.34286335471246876,
      "grad_norm": 2.6815497875213623,
      "learning_rate": 0.00013144430755851873,
      "loss": 0.1548,
      "step": 4731
    },
    {
      "epoch": 0.34293582635793746,
      "grad_norm": 1.41488778591156,
      "learning_rate": 0.0001314298137546199,
      "loss": 0.0864,
      "step": 4732
    },
    {
      "epoch": 0.34300829800340615,
      "grad_norm": 1.3640631437301636,
      "learning_rate": 0.00013141531995072107,
      "loss": 0.0629,
      "step": 4733
    },
    {
      "epoch": 0.34308076964887485,
      "grad_norm": 2.4532291889190674,
      "learning_rate": 0.00013140082614682223,
      "loss": 0.0685,
      "step": 4734
    },
    {
      "epoch": 0.3431532412943436,
      "grad_norm": 1.0027880668640137,
      "learning_rate": 0.0001313863323429234,
      "loss": 0.0173,
      "step": 4735
    },
    {
      "epoch": 0.3432257129398123,
      "grad_norm": 0.6414278149604797,
      "learning_rate": 0.00013137183853902457,
      "loss": 0.0228,
      "step": 4736
    },
    {
      "epoch": 0.343298184585281,
      "grad_norm": 1.2734251022338867,
      "learning_rate": 0.00013135734473512572,
      "loss": 0.1105,
      "step": 4737
    },
    {
      "epoch": 0.3433706562307497,
      "grad_norm": 2.4715054035186768,
      "learning_rate": 0.0001313428509312269,
      "loss": 0.0832,
      "step": 4738
    },
    {
      "epoch": 0.34344312787621845,
      "grad_norm": 1.11232328414917,
      "learning_rate": 0.00013132835712732806,
      "loss": 0.0502,
      "step": 4739
    },
    {
      "epoch": 0.34351559952168714,
      "grad_norm": 1.408779501914978,
      "learning_rate": 0.00013131386332342922,
      "loss": 0.0573,
      "step": 4740
    },
    {
      "epoch": 0.34358807116715584,
      "grad_norm": 2.059335708618164,
      "learning_rate": 0.0001312993695195304,
      "loss": 0.0501,
      "step": 4741
    },
    {
      "epoch": 0.34366054281262454,
      "grad_norm": 2.9745681285858154,
      "learning_rate": 0.00013128487571563156,
      "loss": 0.1541,
      "step": 4742
    },
    {
      "epoch": 0.3437330144580933,
      "grad_norm": 1.9143133163452148,
      "learning_rate": 0.00013127038191173274,
      "loss": 0.1527,
      "step": 4743
    },
    {
      "epoch": 0.343805486103562,
      "grad_norm": 1.7208138704299927,
      "learning_rate": 0.0001312558881078339,
      "loss": 0.1294,
      "step": 4744
    },
    {
      "epoch": 0.3438779577490307,
      "grad_norm": 2.2156801223754883,
      "learning_rate": 0.00013124139430393508,
      "loss": 0.1123,
      "step": 4745
    },
    {
      "epoch": 0.3439504293944994,
      "grad_norm": 0.47962403297424316,
      "learning_rate": 0.00013122690050003624,
      "loss": 0.0319,
      "step": 4746
    },
    {
      "epoch": 0.34402290103996813,
      "grad_norm": 2.110447883605957,
      "learning_rate": 0.00013121240669613742,
      "loss": 0.1104,
      "step": 4747
    },
    {
      "epoch": 0.34409537268543683,
      "grad_norm": 1.4290679693222046,
      "learning_rate": 0.00013119791289223858,
      "loss": 0.0952,
      "step": 4748
    },
    {
      "epoch": 0.3441678443309055,
      "grad_norm": 0.9920172691345215,
      "learning_rate": 0.00013118341908833974,
      "loss": 0.0818,
      "step": 4749
    },
    {
      "epoch": 0.3442403159763742,
      "grad_norm": 0.8899763226509094,
      "learning_rate": 0.00013116892528444092,
      "loss": 0.0763,
      "step": 4750
    },
    {
      "epoch": 0.344312787621843,
      "grad_norm": 3.220216989517212,
      "learning_rate": 0.00013115443148054208,
      "loss": 0.1036,
      "step": 4751
    },
    {
      "epoch": 0.34438525926731167,
      "grad_norm": 0.8168413639068604,
      "learning_rate": 0.00013113993767664323,
      "loss": 0.0352,
      "step": 4752
    },
    {
      "epoch": 0.34445773091278037,
      "grad_norm": 1.6345691680908203,
      "learning_rate": 0.00013112544387274442,
      "loss": 0.1448,
      "step": 4753
    },
    {
      "epoch": 0.34453020255824907,
      "grad_norm": 0.963886022567749,
      "learning_rate": 0.00013111095006884557,
      "loss": 0.0631,
      "step": 4754
    },
    {
      "epoch": 0.3446026742037178,
      "grad_norm": 3.5453264713287354,
      "learning_rate": 0.00013109645626494673,
      "loss": 0.0781,
      "step": 4755
    },
    {
      "epoch": 0.3446751458491865,
      "grad_norm": 1.8838601112365723,
      "learning_rate": 0.0001310819624610479,
      "loss": 0.1116,
      "step": 4756
    },
    {
      "epoch": 0.3447476174946552,
      "grad_norm": 1.5941945314407349,
      "learning_rate": 0.00013106746865714907,
      "loss": 0.099,
      "step": 4757
    },
    {
      "epoch": 0.3448200891401239,
      "grad_norm": 1.3599872589111328,
      "learning_rate": 0.00013105297485325023,
      "loss": 0.065,
      "step": 4758
    },
    {
      "epoch": 0.34489256078559266,
      "grad_norm": 0.9989520907402039,
      "learning_rate": 0.0001310384810493514,
      "loss": 0.0992,
      "step": 4759
    },
    {
      "epoch": 0.34496503243106136,
      "grad_norm": 1.411827802658081,
      "learning_rate": 0.00013102398724545257,
      "loss": 0.0583,
      "step": 4760
    },
    {
      "epoch": 0.34503750407653005,
      "grad_norm": 1.9768575429916382,
      "learning_rate": 0.00013100949344155372,
      "loss": 0.1346,
      "step": 4761
    },
    {
      "epoch": 0.34510997572199875,
      "grad_norm": 0.2859083414077759,
      "learning_rate": 0.0001309949996376549,
      "loss": 0.0186,
      "step": 4762
    },
    {
      "epoch": 0.3451824473674675,
      "grad_norm": 5.418248653411865,
      "learning_rate": 0.00013098050583375606,
      "loss": 0.159,
      "step": 4763
    },
    {
      "epoch": 0.3452549190129362,
      "grad_norm": 0.4874376058578491,
      "learning_rate": 0.00013096601202985722,
      "loss": 0.031,
      "step": 4764
    },
    {
      "epoch": 0.3453273906584049,
      "grad_norm": 0.4877395033836365,
      "learning_rate": 0.0001309515182259584,
      "loss": 0.0226,
      "step": 4765
    },
    {
      "epoch": 0.3453998623038736,
      "grad_norm": 0.8457269668579102,
      "learning_rate": 0.00013093702442205959,
      "loss": 0.0286,
      "step": 4766
    },
    {
      "epoch": 0.34547233394934235,
      "grad_norm": 2.3388233184814453,
      "learning_rate": 0.00013092253061816074,
      "loss": 0.0768,
      "step": 4767
    },
    {
      "epoch": 0.34554480559481104,
      "grad_norm": 1.3136273622512817,
      "learning_rate": 0.00013090803681426193,
      "loss": 0.129,
      "step": 4768
    },
    {
      "epoch": 0.34561727724027974,
      "grad_norm": 1.0127379894256592,
      "learning_rate": 0.00013089354301036308,
      "loss": 0.0776,
      "step": 4769
    },
    {
      "epoch": 0.34568974888574844,
      "grad_norm": 3.5032951831817627,
      "learning_rate": 0.00013087904920646424,
      "loss": 0.1177,
      "step": 4770
    },
    {
      "epoch": 0.34576222053121713,
      "grad_norm": 5.373010635375977,
      "learning_rate": 0.00013086455540256542,
      "loss": 0.0293,
      "step": 4771
    },
    {
      "epoch": 0.3458346921766859,
      "grad_norm": 1.9887468814849854,
      "learning_rate": 0.00013085006159866658,
      "loss": 0.0835,
      "step": 4772
    },
    {
      "epoch": 0.3459071638221546,
      "grad_norm": 0.9840341210365295,
      "learning_rate": 0.00013083556779476774,
      "loss": 0.0623,
      "step": 4773
    },
    {
      "epoch": 0.3459796354676233,
      "grad_norm": 2.2628326416015625,
      "learning_rate": 0.00013082107399086892,
      "loss": 0.0974,
      "step": 4774
    },
    {
      "epoch": 0.346052107113092,
      "grad_norm": 1.4698318243026733,
      "learning_rate": 0.00013080658018697008,
      "loss": 0.0678,
      "step": 4775
    },
    {
      "epoch": 0.34612457875856073,
      "grad_norm": 2.344876527786255,
      "learning_rate": 0.00013079208638307123,
      "loss": 0.087,
      "step": 4776
    },
    {
      "epoch": 0.3461970504040294,
      "grad_norm": 1.0757756233215332,
      "learning_rate": 0.00013077759257917242,
      "loss": 0.0668,
      "step": 4777
    },
    {
      "epoch": 0.3462695220494981,
      "grad_norm": 1.725582242012024,
      "learning_rate": 0.00013076309877527357,
      "loss": 0.0612,
      "step": 4778
    },
    {
      "epoch": 0.3463419936949668,
      "grad_norm": 2.044708490371704,
      "learning_rate": 0.00013074860497137473,
      "loss": 0.0668,
      "step": 4779
    },
    {
      "epoch": 0.3464144653404356,
      "grad_norm": 1.8360779285430908,
      "learning_rate": 0.0001307341111674759,
      "loss": 0.0427,
      "step": 4780
    },
    {
      "epoch": 0.34648693698590427,
      "grad_norm": 1.1595748662948608,
      "learning_rate": 0.00013071961736357707,
      "loss": 0.0874,
      "step": 4781
    },
    {
      "epoch": 0.34655940863137297,
      "grad_norm": 1.3882383108139038,
      "learning_rate": 0.00013070512355967823,
      "loss": 0.0519,
      "step": 4782
    },
    {
      "epoch": 0.34663188027684166,
      "grad_norm": 2.0610759258270264,
      "learning_rate": 0.0001306906297557794,
      "loss": 0.1101,
      "step": 4783
    },
    {
      "epoch": 0.3467043519223104,
      "grad_norm": 0.4079003632068634,
      "learning_rate": 0.00013067613595188057,
      "loss": 0.0101,
      "step": 4784
    },
    {
      "epoch": 0.3467768235677791,
      "grad_norm": 4.379890441894531,
      "learning_rate": 0.00013066164214798172,
      "loss": 0.0716,
      "step": 4785
    },
    {
      "epoch": 0.3468492952132478,
      "grad_norm": 4.668567657470703,
      "learning_rate": 0.0001306471483440829,
      "loss": 0.3189,
      "step": 4786
    },
    {
      "epoch": 0.3469217668587165,
      "grad_norm": 0.8305966854095459,
      "learning_rate": 0.00013063265454018406,
      "loss": 0.0282,
      "step": 4787
    },
    {
      "epoch": 0.34699423850418526,
      "grad_norm": 1.4867219924926758,
      "learning_rate": 0.00013061816073628525,
      "loss": 0.0405,
      "step": 4788
    },
    {
      "epoch": 0.34706671014965396,
      "grad_norm": 1.6058270931243896,
      "learning_rate": 0.0001306036669323864,
      "loss": 0.0512,
      "step": 4789
    },
    {
      "epoch": 0.34713918179512265,
      "grad_norm": 1.6573411226272583,
      "learning_rate": 0.00013058917312848759,
      "loss": 0.0882,
      "step": 4790
    },
    {
      "epoch": 0.34721165344059135,
      "grad_norm": 3.05165958404541,
      "learning_rate": 0.00013057467932458874,
      "loss": 0.1652,
      "step": 4791
    },
    {
      "epoch": 0.3472841250860601,
      "grad_norm": 3.9451682567596436,
      "learning_rate": 0.00013056018552068993,
      "loss": 0.0448,
      "step": 4792
    },
    {
      "epoch": 0.3473565967315288,
      "grad_norm": 0.31259360909461975,
      "learning_rate": 0.00013054569171679108,
      "loss": 0.004,
      "step": 4793
    },
    {
      "epoch": 0.3474290683769975,
      "grad_norm": 1.0292843580245972,
      "learning_rate": 0.00013053119791289227,
      "loss": 0.0822,
      "step": 4794
    },
    {
      "epoch": 0.3475015400224662,
      "grad_norm": 1.2286655902862549,
      "learning_rate": 0.00013051670410899342,
      "loss": 0.0766,
      "step": 4795
    },
    {
      "epoch": 0.34757401166793495,
      "grad_norm": 1.775889277458191,
      "learning_rate": 0.00013050221030509458,
      "loss": 0.0385,
      "step": 4796
    },
    {
      "epoch": 0.34764648331340364,
      "grad_norm": 0.9184211492538452,
      "learning_rate": 0.00013048771650119576,
      "loss": 0.0743,
      "step": 4797
    },
    {
      "epoch": 0.34771895495887234,
      "grad_norm": 6.178076267242432,
      "learning_rate": 0.00013047322269729692,
      "loss": 0.2588,
      "step": 4798
    },
    {
      "epoch": 0.34779142660434104,
      "grad_norm": 0.5042405128479004,
      "learning_rate": 0.00013045872889339808,
      "loss": 0.0263,
      "step": 4799
    },
    {
      "epoch": 0.3478638982498098,
      "grad_norm": 1.584989070892334,
      "learning_rate": 0.00013044423508949926,
      "loss": 0.0733,
      "step": 4800
    },
    {
      "epoch": 0.3479363698952785,
      "grad_norm": 1.787662148475647,
      "learning_rate": 0.00013042974128560042,
      "loss": 0.0615,
      "step": 4801
    },
    {
      "epoch": 0.3480088415407472,
      "grad_norm": 1.5491890907287598,
      "learning_rate": 0.00013041524748170157,
      "loss": 0.0676,
      "step": 4802
    },
    {
      "epoch": 0.3480813131862159,
      "grad_norm": 1.6126528978347778,
      "learning_rate": 0.00013040075367780276,
      "loss": 0.0455,
      "step": 4803
    },
    {
      "epoch": 0.3481537848316846,
      "grad_norm": 1.9682477712631226,
      "learning_rate": 0.0001303862598739039,
      "loss": 0.063,
      "step": 4804
    },
    {
      "epoch": 0.34822625647715333,
      "grad_norm": 1.2719298601150513,
      "learning_rate": 0.00013037176607000507,
      "loss": 0.0188,
      "step": 4805
    },
    {
      "epoch": 0.348298728122622,
      "grad_norm": 2.597388982772827,
      "learning_rate": 0.00013035727226610625,
      "loss": 0.0499,
      "step": 4806
    },
    {
      "epoch": 0.3483711997680907,
      "grad_norm": 2.033848524093628,
      "learning_rate": 0.0001303427784622074,
      "loss": 0.0996,
      "step": 4807
    },
    {
      "epoch": 0.3484436714135594,
      "grad_norm": 1.232617974281311,
      "learning_rate": 0.00013032828465830857,
      "loss": 0.0671,
      "step": 4808
    },
    {
      "epoch": 0.34851614305902817,
      "grad_norm": 2.431744337081909,
      "learning_rate": 0.00013031379085440975,
      "loss": 0.0174,
      "step": 4809
    },
    {
      "epoch": 0.34858861470449687,
      "grad_norm": 1.437800645828247,
      "learning_rate": 0.0001302992970505109,
      "loss": 0.0873,
      "step": 4810
    },
    {
      "epoch": 0.34866108634996557,
      "grad_norm": 1.0328600406646729,
      "learning_rate": 0.00013028480324661206,
      "loss": 0.0456,
      "step": 4811
    },
    {
      "epoch": 0.34873355799543426,
      "grad_norm": 3.3910071849823,
      "learning_rate": 0.00013027030944271325,
      "loss": 0.0938,
      "step": 4812
    },
    {
      "epoch": 0.348806029640903,
      "grad_norm": 0.8740528225898743,
      "learning_rate": 0.00013025581563881443,
      "loss": 0.0512,
      "step": 4813
    },
    {
      "epoch": 0.3488785012863717,
      "grad_norm": 3.157627820968628,
      "learning_rate": 0.00013024132183491559,
      "loss": 0.1711,
      "step": 4814
    },
    {
      "epoch": 0.3489509729318404,
      "grad_norm": 2.137519359588623,
      "learning_rate": 0.00013022682803101677,
      "loss": 0.0879,
      "step": 4815
    },
    {
      "epoch": 0.3490234445773091,
      "grad_norm": 1.3784856796264648,
      "learning_rate": 0.00013021233422711793,
      "loss": 0.0543,
      "step": 4816
    },
    {
      "epoch": 0.34909591622277786,
      "grad_norm": 1.5210171937942505,
      "learning_rate": 0.00013019784042321908,
      "loss": 0.0513,
      "step": 4817
    },
    {
      "epoch": 0.34916838786824655,
      "grad_norm": 0.7518796324729919,
      "learning_rate": 0.00013018334661932027,
      "loss": 0.086,
      "step": 4818
    },
    {
      "epoch": 0.34924085951371525,
      "grad_norm": 1.4200491905212402,
      "learning_rate": 0.00013016885281542142,
      "loss": 0.0559,
      "step": 4819
    },
    {
      "epoch": 0.34931333115918395,
      "grad_norm": 1.625598669052124,
      "learning_rate": 0.00013015435901152258,
      "loss": 0.0316,
      "step": 4820
    },
    {
      "epoch": 0.3493858028046527,
      "grad_norm": 0.6975436210632324,
      "learning_rate": 0.00013013986520762376,
      "loss": 0.0365,
      "step": 4821
    },
    {
      "epoch": 0.3494582744501214,
      "grad_norm": 4.809573173522949,
      "learning_rate": 0.00013012537140372492,
      "loss": 0.1951,
      "step": 4822
    },
    {
      "epoch": 0.3495307460955901,
      "grad_norm": 0.6194565296173096,
      "learning_rate": 0.00013011087759982608,
      "loss": 0.0176,
      "step": 4823
    },
    {
      "epoch": 0.3496032177410588,
      "grad_norm": 2.400818109512329,
      "learning_rate": 0.00013009638379592726,
      "loss": 0.1223,
      "step": 4824
    },
    {
      "epoch": 0.34967568938652754,
      "grad_norm": 0.6704185009002686,
      "learning_rate": 0.00013008188999202842,
      "loss": 0.0466,
      "step": 4825
    },
    {
      "epoch": 0.34974816103199624,
      "grad_norm": 0.9972292184829712,
      "learning_rate": 0.00013006739618812957,
      "loss": 0.0626,
      "step": 4826
    },
    {
      "epoch": 0.34982063267746494,
      "grad_norm": 0.40704426169395447,
      "learning_rate": 0.00013005290238423076,
      "loss": 0.0321,
      "step": 4827
    },
    {
      "epoch": 0.34989310432293363,
      "grad_norm": 0.5842971205711365,
      "learning_rate": 0.0001300384085803319,
      "loss": 0.021,
      "step": 4828
    },
    {
      "epoch": 0.3499655759684024,
      "grad_norm": 0.6007791757583618,
      "learning_rate": 0.00013002391477643307,
      "loss": 0.0096,
      "step": 4829
    },
    {
      "epoch": 0.3500380476138711,
      "grad_norm": 4.346740245819092,
      "learning_rate": 0.00013000942097253425,
      "loss": 0.047,
      "step": 4830
    },
    {
      "epoch": 0.3501105192593398,
      "grad_norm": 1.190488576889038,
      "learning_rate": 0.0001299949271686354,
      "loss": 0.0832,
      "step": 4831
    },
    {
      "epoch": 0.3501829909048085,
      "grad_norm": 2.8713901042938232,
      "learning_rate": 0.00012998043336473656,
      "loss": 0.0726,
      "step": 4832
    },
    {
      "epoch": 0.35025546255027723,
      "grad_norm": 1.9806848764419556,
      "learning_rate": 0.00012996593956083775,
      "loss": 0.1068,
      "step": 4833
    },
    {
      "epoch": 0.3503279341957459,
      "grad_norm": 0.39329421520233154,
      "learning_rate": 0.0001299514457569389,
      "loss": 0.0269,
      "step": 4834
    },
    {
      "epoch": 0.3504004058412146,
      "grad_norm": 8.680891990661621,
      "learning_rate": 0.0001299369519530401,
      "loss": 0.0742,
      "step": 4835
    },
    {
      "epoch": 0.3504728774866833,
      "grad_norm": 1.9065077304840088,
      "learning_rate": 0.00012992245814914124,
      "loss": 0.0222,
      "step": 4836
    },
    {
      "epoch": 0.3505453491321521,
      "grad_norm": 9.78757095336914,
      "learning_rate": 0.00012990796434524243,
      "loss": 0.0684,
      "step": 4837
    },
    {
      "epoch": 0.35061782077762077,
      "grad_norm": 2.9514715671539307,
      "learning_rate": 0.00012989347054134359,
      "loss": 0.2196,
      "step": 4838
    },
    {
      "epoch": 0.35069029242308947,
      "grad_norm": 2.5215601921081543,
      "learning_rate": 0.00012987897673744477,
      "loss": 0.0797,
      "step": 4839
    },
    {
      "epoch": 0.35076276406855816,
      "grad_norm": 1.944093942642212,
      "learning_rate": 0.00012986448293354593,
      "loss": 0.1084,
      "step": 4840
    },
    {
      "epoch": 0.35083523571402686,
      "grad_norm": 1.8690658807754517,
      "learning_rate": 0.00012984998912964708,
      "loss": 0.0519,
      "step": 4841
    },
    {
      "epoch": 0.3509077073594956,
      "grad_norm": 1.53272545337677,
      "learning_rate": 0.00012983549532574827,
      "loss": 0.0463,
      "step": 4842
    },
    {
      "epoch": 0.3509801790049643,
      "grad_norm": 1.1580172777175903,
      "learning_rate": 0.00012982100152184942,
      "loss": 0.0626,
      "step": 4843
    },
    {
      "epoch": 0.351052650650433,
      "grad_norm": 2.1286487579345703,
      "learning_rate": 0.00012980650771795058,
      "loss": 0.0563,
      "step": 4844
    },
    {
      "epoch": 0.3511251222959017,
      "grad_norm": 0.3040391504764557,
      "learning_rate": 0.00012979201391405176,
      "loss": 0.0136,
      "step": 4845
    },
    {
      "epoch": 0.35119759394137046,
      "grad_norm": 1.4997256994247437,
      "learning_rate": 0.00012977752011015292,
      "loss": 0.0315,
      "step": 4846
    },
    {
      "epoch": 0.35127006558683915,
      "grad_norm": 0.17554232478141785,
      "learning_rate": 0.00012976302630625407,
      "loss": 0.0085,
      "step": 4847
    },
    {
      "epoch": 0.35134253723230785,
      "grad_norm": 0.783859372138977,
      "learning_rate": 0.00012974853250235526,
      "loss": 0.0351,
      "step": 4848
    },
    {
      "epoch": 0.35141500887777655,
      "grad_norm": 2.0172054767608643,
      "learning_rate": 0.00012973403869845641,
      "loss": 0.0405,
      "step": 4849
    },
    {
      "epoch": 0.3514874805232453,
      "grad_norm": 2.2115278244018555,
      "learning_rate": 0.00012971954489455757,
      "loss": 0.071,
      "step": 4850
    },
    {
      "epoch": 0.351559952168714,
      "grad_norm": 0.35190311074256897,
      "learning_rate": 0.00012970505109065875,
      "loss": 0.0026,
      "step": 4851
    },
    {
      "epoch": 0.3516324238141827,
      "grad_norm": 2.420572519302368,
      "learning_rate": 0.0001296905572867599,
      "loss": 0.1626,
      "step": 4852
    },
    {
      "epoch": 0.3517048954596514,
      "grad_norm": 0.6494912505149841,
      "learning_rate": 0.00012967606348286107,
      "loss": 0.0153,
      "step": 4853
    },
    {
      "epoch": 0.35177736710512014,
      "grad_norm": 1.3911832571029663,
      "learning_rate": 0.00012966156967896225,
      "loss": 0.0741,
      "step": 4854
    },
    {
      "epoch": 0.35184983875058884,
      "grad_norm": 4.487668037414551,
      "learning_rate": 0.0001296470758750634,
      "loss": 0.0907,
      "step": 4855
    },
    {
      "epoch": 0.35192231039605754,
      "grad_norm": 7.326256275177002,
      "learning_rate": 0.00012963258207116456,
      "loss": 0.1225,
      "step": 4856
    },
    {
      "epoch": 0.35199478204152623,
      "grad_norm": 2.5012736320495605,
      "learning_rate": 0.00012961808826726575,
      "loss": 0.1031,
      "step": 4857
    },
    {
      "epoch": 0.352067253686995,
      "grad_norm": 2.168780565261841,
      "learning_rate": 0.0001296035944633669,
      "loss": 0.0887,
      "step": 4858
    },
    {
      "epoch": 0.3521397253324637,
      "grad_norm": 1.5010356903076172,
      "learning_rate": 0.0001295891006594681,
      "loss": 0.1006,
      "step": 4859
    },
    {
      "epoch": 0.3522121969779324,
      "grad_norm": 3.4694015979766846,
      "learning_rate": 0.00012957460685556927,
      "loss": 0.1634,
      "step": 4860
    },
    {
      "epoch": 0.3522846686234011,
      "grad_norm": 2.346564531326294,
      "learning_rate": 0.00012956011305167043,
      "loss": 0.0499,
      "step": 4861
    },
    {
      "epoch": 0.35235714026886983,
      "grad_norm": 1.5086462497711182,
      "learning_rate": 0.00012954561924777158,
      "loss": 0.1017,
      "step": 4862
    },
    {
      "epoch": 0.3524296119143385,
      "grad_norm": 1.1722215414047241,
      "learning_rate": 0.00012953112544387277,
      "loss": 0.0556,
      "step": 4863
    },
    {
      "epoch": 0.3525020835598072,
      "grad_norm": 2.947326421737671,
      "learning_rate": 0.00012951663163997392,
      "loss": 0.1169,
      "step": 4864
    },
    {
      "epoch": 0.3525745552052759,
      "grad_norm": 1.38137686252594,
      "learning_rate": 0.00012950213783607508,
      "loss": 0.0864,
      "step": 4865
    },
    {
      "epoch": 0.35264702685074467,
      "grad_norm": 3.233553409576416,
      "learning_rate": 0.00012948764403217626,
      "loss": 0.0488,
      "step": 4866
    },
    {
      "epoch": 0.35271949849621337,
      "grad_norm": 1.0570961236953735,
      "learning_rate": 0.00012947315022827742,
      "loss": 0.0684,
      "step": 4867
    },
    {
      "epoch": 0.35279197014168207,
      "grad_norm": 2.000880241394043,
      "learning_rate": 0.00012945865642437858,
      "loss": 0.0405,
      "step": 4868
    },
    {
      "epoch": 0.35286444178715076,
      "grad_norm": 0.8869467973709106,
      "learning_rate": 0.00012944416262047976,
      "loss": 0.0221,
      "step": 4869
    },
    {
      "epoch": 0.3529369134326195,
      "grad_norm": 1.493960976600647,
      "learning_rate": 0.00012942966881658092,
      "loss": 0.1209,
      "step": 4870
    },
    {
      "epoch": 0.3530093850780882,
      "grad_norm": 1.7191089391708374,
      "learning_rate": 0.00012941517501268207,
      "loss": 0.0669,
      "step": 4871
    },
    {
      "epoch": 0.3530818567235569,
      "grad_norm": 2.845470905303955,
      "learning_rate": 0.00012940068120878326,
      "loss": 0.0891,
      "step": 4872
    },
    {
      "epoch": 0.3531543283690256,
      "grad_norm": 2.794980049133301,
      "learning_rate": 0.00012938618740488441,
      "loss": 0.0571,
      "step": 4873
    },
    {
      "epoch": 0.3532268000144943,
      "grad_norm": 0.9313615560531616,
      "learning_rate": 0.00012937169360098557,
      "loss": 0.0223,
      "step": 4874
    },
    {
      "epoch": 0.35329927165996305,
      "grad_norm": 0.5957874655723572,
      "learning_rate": 0.00012935719979708675,
      "loss": 0.0261,
      "step": 4875
    },
    {
      "epoch": 0.35337174330543175,
      "grad_norm": 0.8671910166740417,
      "learning_rate": 0.0001293427059931879,
      "loss": 0.0456,
      "step": 4876
    },
    {
      "epoch": 0.35344421495090045,
      "grad_norm": 2.3339738845825195,
      "learning_rate": 0.00012932821218928907,
      "loss": 0.0448,
      "step": 4877
    },
    {
      "epoch": 0.35351668659636915,
      "grad_norm": 0.31767019629478455,
      "learning_rate": 0.00012931371838539025,
      "loss": 0.0208,
      "step": 4878
    },
    {
      "epoch": 0.3535891582418379,
      "grad_norm": 0.6229513883590698,
      "learning_rate": 0.0001292992245814914,
      "loss": 0.015,
      "step": 4879
    },
    {
      "epoch": 0.3536616298873066,
      "grad_norm": 1.9942526817321777,
      "learning_rate": 0.0001292847307775926,
      "loss": 0.1395,
      "step": 4880
    },
    {
      "epoch": 0.3537341015327753,
      "grad_norm": 0.6448583006858826,
      "learning_rate": 0.00012927023697369375,
      "loss": 0.0334,
      "step": 4881
    },
    {
      "epoch": 0.353806573178244,
      "grad_norm": 2.5125832557678223,
      "learning_rate": 0.00012925574316979493,
      "loss": 0.1131,
      "step": 4882
    },
    {
      "epoch": 0.35387904482371274,
      "grad_norm": 7.824975967407227,
      "learning_rate": 0.0001292412493658961,
      "loss": 0.0841,
      "step": 4883
    },
    {
      "epoch": 0.35395151646918144,
      "grad_norm": 0.4687654674053192,
      "learning_rate": 0.00012922675556199727,
      "loss": 0.034,
      "step": 4884
    },
    {
      "epoch": 0.35402398811465013,
      "grad_norm": 5.369009494781494,
      "learning_rate": 0.00012921226175809843,
      "loss": 0.1525,
      "step": 4885
    },
    {
      "epoch": 0.35409645976011883,
      "grad_norm": 1.299033284187317,
      "learning_rate": 0.00012919776795419958,
      "loss": 0.0369,
      "step": 4886
    },
    {
      "epoch": 0.3541689314055876,
      "grad_norm": 0.7054987549781799,
      "learning_rate": 0.00012918327415030077,
      "loss": 0.0245,
      "step": 4887
    },
    {
      "epoch": 0.3542414030510563,
      "grad_norm": 1.0505975484848022,
      "learning_rate": 0.00012916878034640192,
      "loss": 0.0444,
      "step": 4888
    },
    {
      "epoch": 0.354313874696525,
      "grad_norm": 2.4332778453826904,
      "learning_rate": 0.00012915428654250308,
      "loss": 0.0858,
      "step": 4889
    },
    {
      "epoch": 0.3543863463419937,
      "grad_norm": 3.102769374847412,
      "learning_rate": 0.00012913979273860426,
      "loss": 0.1017,
      "step": 4890
    },
    {
      "epoch": 0.3544588179874624,
      "grad_norm": 1.5880687236785889,
      "learning_rate": 0.00012912529893470542,
      "loss": 0.1244,
      "step": 4891
    },
    {
      "epoch": 0.3545312896329311,
      "grad_norm": 1.599632978439331,
      "learning_rate": 0.00012911080513080658,
      "loss": 0.0763,
      "step": 4892
    },
    {
      "epoch": 0.3546037612783998,
      "grad_norm": 2.0751793384552,
      "learning_rate": 0.00012909631132690776,
      "loss": 0.0912,
      "step": 4893
    },
    {
      "epoch": 0.3546762329238685,
      "grad_norm": 6.434521198272705,
      "learning_rate": 0.00012908181752300892,
      "loss": 0.2425,
      "step": 4894
    },
    {
      "epoch": 0.35474870456933727,
      "grad_norm": 3.2661757469177246,
      "learning_rate": 0.00012906732371911007,
      "loss": 0.1245,
      "step": 4895
    },
    {
      "epoch": 0.35482117621480597,
      "grad_norm": 1.9866687059402466,
      "learning_rate": 0.00012905282991521126,
      "loss": 0.0972,
      "step": 4896
    },
    {
      "epoch": 0.35489364786027466,
      "grad_norm": 2.5319297313690186,
      "learning_rate": 0.00012903833611131241,
      "loss": 0.0442,
      "step": 4897
    },
    {
      "epoch": 0.35496611950574336,
      "grad_norm": 0.7624121904373169,
      "learning_rate": 0.00012902384230741357,
      "loss": 0.0488,
      "step": 4898
    },
    {
      "epoch": 0.3550385911512121,
      "grad_norm": 1.2781716585159302,
      "learning_rate": 0.00012900934850351475,
      "loss": 0.0294,
      "step": 4899
    },
    {
      "epoch": 0.3551110627966808,
      "grad_norm": 0.8325530886650085,
      "learning_rate": 0.0001289948546996159,
      "loss": 0.0277,
      "step": 4900
    },
    {
      "epoch": 0.3551835344421495,
      "grad_norm": 1.963299036026001,
      "learning_rate": 0.00012898036089571707,
      "loss": 0.0931,
      "step": 4901
    },
    {
      "epoch": 0.3552560060876182,
      "grad_norm": 3.4358386993408203,
      "learning_rate": 0.00012896586709181825,
      "loss": 0.0914,
      "step": 4902
    },
    {
      "epoch": 0.35532847773308696,
      "grad_norm": 1.0419254302978516,
      "learning_rate": 0.0001289513732879194,
      "loss": 0.0416,
      "step": 4903
    },
    {
      "epoch": 0.35540094937855565,
      "grad_norm": 4.952862739562988,
      "learning_rate": 0.0001289368794840206,
      "loss": 0.0643,
      "step": 4904
    },
    {
      "epoch": 0.35547342102402435,
      "grad_norm": 1.6343423128128052,
      "learning_rate": 0.00012892238568012175,
      "loss": 0.0406,
      "step": 4905
    },
    {
      "epoch": 0.35554589266949305,
      "grad_norm": 4.045282363891602,
      "learning_rate": 0.00012890789187622293,
      "loss": 0.0973,
      "step": 4906
    },
    {
      "epoch": 0.35561836431496174,
      "grad_norm": 3.1529343128204346,
      "learning_rate": 0.0001288933980723241,
      "loss": 0.1053,
      "step": 4907
    },
    {
      "epoch": 0.3556908359604305,
      "grad_norm": 4.159043312072754,
      "learning_rate": 0.00012887890426842527,
      "loss": 0.0416,
      "step": 4908
    },
    {
      "epoch": 0.3557633076058992,
      "grad_norm": 3.7352821826934814,
      "learning_rate": 0.00012886441046452643,
      "loss": 0.1047,
      "step": 4909
    },
    {
      "epoch": 0.3558357792513679,
      "grad_norm": 2.63570499420166,
      "learning_rate": 0.00012884991666062758,
      "loss": 0.0632,
      "step": 4910
    },
    {
      "epoch": 0.3559082508968366,
      "grad_norm": 2.748772382736206,
      "learning_rate": 0.00012883542285672877,
      "loss": 0.0705,
      "step": 4911
    },
    {
      "epoch": 0.35598072254230534,
      "grad_norm": 1.7548855543136597,
      "learning_rate": 0.00012882092905282992,
      "loss": 0.0634,
      "step": 4912
    },
    {
      "epoch": 0.35605319418777404,
      "grad_norm": 6.368954181671143,
      "learning_rate": 0.00012880643524893108,
      "loss": 0.1739,
      "step": 4913
    },
    {
      "epoch": 0.35612566583324273,
      "grad_norm": 0.9766214489936829,
      "learning_rate": 0.00012879194144503226,
      "loss": 0.0634,
      "step": 4914
    },
    {
      "epoch": 0.35619813747871143,
      "grad_norm": 1.0231388807296753,
      "learning_rate": 0.00012877744764113342,
      "loss": 0.0686,
      "step": 4915
    },
    {
      "epoch": 0.3562706091241802,
      "grad_norm": 0.4434400498867035,
      "learning_rate": 0.00012876295383723458,
      "loss": 0.0258,
      "step": 4916
    },
    {
      "epoch": 0.3563430807696489,
      "grad_norm": 2.9350507259368896,
      "learning_rate": 0.00012874846003333576,
      "loss": 0.1156,
      "step": 4917
    },
    {
      "epoch": 0.3564155524151176,
      "grad_norm": 0.6120584607124329,
      "learning_rate": 0.00012873396622943692,
      "loss": 0.0133,
      "step": 4918
    },
    {
      "epoch": 0.3564880240605863,
      "grad_norm": 1.035872220993042,
      "learning_rate": 0.00012871947242553807,
      "loss": 0.0463,
      "step": 4919
    },
    {
      "epoch": 0.356560495706055,
      "grad_norm": 4.574954509735107,
      "learning_rate": 0.00012870497862163926,
      "loss": 0.2517,
      "step": 4920
    },
    {
      "epoch": 0.3566329673515237,
      "grad_norm": 4.892768859863281,
      "learning_rate": 0.0001286904848177404,
      "loss": 0.017,
      "step": 4921
    },
    {
      "epoch": 0.3567054389969924,
      "grad_norm": 0.8629169464111328,
      "learning_rate": 0.00012867599101384157,
      "loss": 0.0349,
      "step": 4922
    },
    {
      "epoch": 0.3567779106424611,
      "grad_norm": 2.7506206035614014,
      "learning_rate": 0.00012866149720994275,
      "loss": 0.0652,
      "step": 4923
    },
    {
      "epoch": 0.35685038228792987,
      "grad_norm": 1.2401233911514282,
      "learning_rate": 0.0001286470034060439,
      "loss": 0.0776,
      "step": 4924
    },
    {
      "epoch": 0.35692285393339857,
      "grad_norm": 0.9506118297576904,
      "learning_rate": 0.00012863250960214507,
      "loss": 0.0599,
      "step": 4925
    },
    {
      "epoch": 0.35699532557886726,
      "grad_norm": 0.4324492812156677,
      "learning_rate": 0.00012861801579824625,
      "loss": 0.0133,
      "step": 4926
    },
    {
      "epoch": 0.35706779722433596,
      "grad_norm": 2.3157224655151367,
      "learning_rate": 0.0001286035219943474,
      "loss": 0.0275,
      "step": 4927
    },
    {
      "epoch": 0.3571402688698047,
      "grad_norm": 0.6509444713592529,
      "learning_rate": 0.0001285890281904486,
      "loss": 0.0079,
      "step": 4928
    },
    {
      "epoch": 0.3572127405152734,
      "grad_norm": 3.219007968902588,
      "learning_rate": 0.00012857453438654977,
      "loss": 0.1404,
      "step": 4929
    },
    {
      "epoch": 0.3572852121607421,
      "grad_norm": 3.3184573650360107,
      "learning_rate": 0.00012856004058265093,
      "loss": 0.0365,
      "step": 4930
    },
    {
      "epoch": 0.3573576838062108,
      "grad_norm": 2.730588912963867,
      "learning_rate": 0.0001285455467787521,
      "loss": 0.2093,
      "step": 4931
    },
    {
      "epoch": 0.35743015545167955,
      "grad_norm": 0.45878326892852783,
      "learning_rate": 0.00012853105297485327,
      "loss": 0.0163,
      "step": 4932
    },
    {
      "epoch": 0.35750262709714825,
      "grad_norm": 4.700596809387207,
      "learning_rate": 0.00012851655917095443,
      "loss": 0.1283,
      "step": 4933
    },
    {
      "epoch": 0.35757509874261695,
      "grad_norm": 0.19218505918979645,
      "learning_rate": 0.00012850206536705558,
      "loss": 0.0064,
      "step": 4934
    },
    {
      "epoch": 0.35764757038808564,
      "grad_norm": 1.4789937734603882,
      "learning_rate": 0.00012848757156315677,
      "loss": 0.0496,
      "step": 4935
    },
    {
      "epoch": 0.3577200420335544,
      "grad_norm": 6.134274482727051,
      "learning_rate": 0.00012847307775925792,
      "loss": 0.0503,
      "step": 4936
    },
    {
      "epoch": 0.3577925136790231,
      "grad_norm": 1.0612159967422485,
      "learning_rate": 0.00012845858395535908,
      "loss": 0.0801,
      "step": 4937
    },
    {
      "epoch": 0.3578649853244918,
      "grad_norm": 1.0079143047332764,
      "learning_rate": 0.00012844409015146026,
      "loss": 0.0085,
      "step": 4938
    },
    {
      "epoch": 0.3579374569699605,
      "grad_norm": 3.281547784805298,
      "learning_rate": 0.00012842959634756142,
      "loss": 0.1548,
      "step": 4939
    },
    {
      "epoch": 0.35800992861542924,
      "grad_norm": 1.3945506811141968,
      "learning_rate": 0.00012841510254366258,
      "loss": 0.075,
      "step": 4940
    },
    {
      "epoch": 0.35808240026089794,
      "grad_norm": 3.799562931060791,
      "learning_rate": 0.00012840060873976376,
      "loss": 0.1336,
      "step": 4941
    },
    {
      "epoch": 0.35815487190636663,
      "grad_norm": 1.9852839708328247,
      "learning_rate": 0.00012838611493586492,
      "loss": 0.031,
      "step": 4942
    },
    {
      "epoch": 0.35822734355183533,
      "grad_norm": 5.245846748352051,
      "learning_rate": 0.00012837162113196607,
      "loss": 0.0979,
      "step": 4943
    },
    {
      "epoch": 0.35829981519730403,
      "grad_norm": 1.590753197669983,
      "learning_rate": 0.00012835712732806726,
      "loss": 0.0596,
      "step": 4944
    },
    {
      "epoch": 0.3583722868427728,
      "grad_norm": 0.6761820912361145,
      "learning_rate": 0.0001283426335241684,
      "loss": 0.0509,
      "step": 4945
    },
    {
      "epoch": 0.3584447584882415,
      "grad_norm": 3.4333951473236084,
      "learning_rate": 0.00012832813972026957,
      "loss": 0.1024,
      "step": 4946
    },
    {
      "epoch": 0.3585172301337102,
      "grad_norm": 5.449780464172363,
      "learning_rate": 0.00012831364591637075,
      "loss": 0.075,
      "step": 4947
    },
    {
      "epoch": 0.35858970177917887,
      "grad_norm": 0.9449151158332825,
      "learning_rate": 0.0001282991521124719,
      "loss": 0.0248,
      "step": 4948
    },
    {
      "epoch": 0.3586621734246476,
      "grad_norm": 4.393579483032227,
      "learning_rate": 0.0001282846583085731,
      "loss": 0.0973,
      "step": 4949
    },
    {
      "epoch": 0.3587346450701163,
      "grad_norm": 1.3659781217575073,
      "learning_rate": 0.00012827016450467425,
      "loss": 0.0568,
      "step": 4950
    },
    {
      "epoch": 0.358807116715585,
      "grad_norm": 3.333977460861206,
      "learning_rate": 0.00012825567070077543,
      "loss": 0.2139,
      "step": 4951
    },
    {
      "epoch": 0.3588795883610537,
      "grad_norm": 1.6115093231201172,
      "learning_rate": 0.0001282411768968766,
      "loss": 0.1177,
      "step": 4952
    },
    {
      "epoch": 0.35895206000652247,
      "grad_norm": 1.9552793502807617,
      "learning_rate": 0.00012822668309297777,
      "loss": 0.0983,
      "step": 4953
    },
    {
      "epoch": 0.35902453165199116,
      "grad_norm": 3.813966751098633,
      "learning_rate": 0.00012821218928907893,
      "loss": 0.0833,
      "step": 4954
    },
    {
      "epoch": 0.35909700329745986,
      "grad_norm": 2.848209857940674,
      "learning_rate": 0.0001281976954851801,
      "loss": 0.0686,
      "step": 4955
    },
    {
      "epoch": 0.35916947494292856,
      "grad_norm": 3.113762855529785,
      "learning_rate": 0.00012818320168128127,
      "loss": 0.0356,
      "step": 4956
    },
    {
      "epoch": 0.3592419465883973,
      "grad_norm": 2.633413076400757,
      "learning_rate": 0.00012816870787738243,
      "loss": 0.0827,
      "step": 4957
    },
    {
      "epoch": 0.359314418233866,
      "grad_norm": 3.7306411266326904,
      "learning_rate": 0.0001281542140734836,
      "loss": 0.1375,
      "step": 4958
    },
    {
      "epoch": 0.3593868898793347,
      "grad_norm": 2.001829147338867,
      "learning_rate": 0.00012813972026958477,
      "loss": 0.1217,
      "step": 4959
    },
    {
      "epoch": 0.3594593615248034,
      "grad_norm": 1.096121907234192,
      "learning_rate": 0.00012812522646568592,
      "loss": 0.0281,
      "step": 4960
    },
    {
      "epoch": 0.35953183317027215,
      "grad_norm": 4.440392017364502,
      "learning_rate": 0.0001281107326617871,
      "loss": 0.1089,
      "step": 4961
    },
    {
      "epoch": 0.35960430481574085,
      "grad_norm": 2.0508458614349365,
      "learning_rate": 0.00012809623885788826,
      "loss": 0.0588,
      "step": 4962
    },
    {
      "epoch": 0.35967677646120955,
      "grad_norm": 0.9290618300437927,
      "learning_rate": 0.00012808174505398942,
      "loss": 0.0217,
      "step": 4963
    },
    {
      "epoch": 0.35974924810667824,
      "grad_norm": 2.1268272399902344,
      "learning_rate": 0.0001280672512500906,
      "loss": 0.048,
      "step": 4964
    },
    {
      "epoch": 0.359821719752147,
      "grad_norm": 3.6850414276123047,
      "learning_rate": 0.00012805275744619176,
      "loss": 0.1261,
      "step": 4965
    },
    {
      "epoch": 0.3598941913976157,
      "grad_norm": 1.4745315313339233,
      "learning_rate": 0.00012803826364229292,
      "loss": 0.079,
      "step": 4966
    },
    {
      "epoch": 0.3599666630430844,
      "grad_norm": 0.8698936700820923,
      "learning_rate": 0.0001280237698383941,
      "loss": 0.0288,
      "step": 4967
    },
    {
      "epoch": 0.3600391346885531,
      "grad_norm": 1.3781392574310303,
      "learning_rate": 0.00012800927603449526,
      "loss": 0.1862,
      "step": 4968
    },
    {
      "epoch": 0.36011160633402184,
      "grad_norm": 1.4948303699493408,
      "learning_rate": 0.0001279947822305964,
      "loss": 0.0836,
      "step": 4969
    },
    {
      "epoch": 0.36018407797949054,
      "grad_norm": 1.7947396039962769,
      "learning_rate": 0.0001279802884266976,
      "loss": 0.0748,
      "step": 4970
    },
    {
      "epoch": 0.36025654962495923,
      "grad_norm": 2.323598623275757,
      "learning_rate": 0.00012796579462279875,
      "loss": 0.0776,
      "step": 4971
    },
    {
      "epoch": 0.36032902127042793,
      "grad_norm": 1.2885762453079224,
      "learning_rate": 0.0001279513008188999,
      "loss": 0.084,
      "step": 4972
    },
    {
      "epoch": 0.3604014929158967,
      "grad_norm": 2.351912260055542,
      "learning_rate": 0.0001279368070150011,
      "loss": 0.1555,
      "step": 4973
    },
    {
      "epoch": 0.3604739645613654,
      "grad_norm": 3.129291534423828,
      "learning_rate": 0.00012792231321110225,
      "loss": 0.094,
      "step": 4974
    },
    {
      "epoch": 0.3605464362068341,
      "grad_norm": 1.747029423713684,
      "learning_rate": 0.00012790781940720343,
      "loss": 0.1322,
      "step": 4975
    },
    {
      "epoch": 0.3606189078523028,
      "grad_norm": 0.7713096141815186,
      "learning_rate": 0.00012789332560330462,
      "loss": 0.0354,
      "step": 4976
    },
    {
      "epoch": 0.36069137949777147,
      "grad_norm": 1.9764466285705566,
      "learning_rate": 0.00012787883179940577,
      "loss": 0.0711,
      "step": 4977
    },
    {
      "epoch": 0.3607638511432402,
      "grad_norm": 0.7008746862411499,
      "learning_rate": 0.00012786433799550693,
      "loss": 0.0221,
      "step": 4978
    },
    {
      "epoch": 0.3608363227887089,
      "grad_norm": 1.4216935634613037,
      "learning_rate": 0.0001278498441916081,
      "loss": 0.0746,
      "step": 4979
    },
    {
      "epoch": 0.3609087944341776,
      "grad_norm": 2.557358741760254,
      "learning_rate": 0.00012783535038770927,
      "loss": 0.0599,
      "step": 4980
    },
    {
      "epoch": 0.3609812660796463,
      "grad_norm": 1.2625678777694702,
      "learning_rate": 0.00012782085658381043,
      "loss": 0.0553,
      "step": 4981
    },
    {
      "epoch": 0.36105373772511506,
      "grad_norm": 0.9144482612609863,
      "learning_rate": 0.0001278063627799116,
      "loss": 0.0418,
      "step": 4982
    },
    {
      "epoch": 0.36112620937058376,
      "grad_norm": 1.47297203540802,
      "learning_rate": 0.00012779186897601277,
      "loss": 0.0948,
      "step": 4983
    },
    {
      "epoch": 0.36119868101605246,
      "grad_norm": 0.3525329530239105,
      "learning_rate": 0.00012777737517211392,
      "loss": 0.0112,
      "step": 4984
    },
    {
      "epoch": 0.36127115266152116,
      "grad_norm": 1.4157531261444092,
      "learning_rate": 0.0001277628813682151,
      "loss": 0.0469,
      "step": 4985
    },
    {
      "epoch": 0.3613436243069899,
      "grad_norm": 1.195481538772583,
      "learning_rate": 0.00012774838756431626,
      "loss": 0.0289,
      "step": 4986
    },
    {
      "epoch": 0.3614160959524586,
      "grad_norm": 0.2797427177429199,
      "learning_rate": 0.00012773389376041742,
      "loss": 0.0098,
      "step": 4987
    },
    {
      "epoch": 0.3614885675979273,
      "grad_norm": 1.781825065612793,
      "learning_rate": 0.0001277193999565186,
      "loss": 0.0704,
      "step": 4988
    },
    {
      "epoch": 0.361561039243396,
      "grad_norm": 0.8732214570045471,
      "learning_rate": 0.00012770490615261976,
      "loss": 0.0564,
      "step": 4989
    },
    {
      "epoch": 0.36163351088886475,
      "grad_norm": 6.674959182739258,
      "learning_rate": 0.00012769041234872092,
      "loss": 0.2118,
      "step": 4990
    },
    {
      "epoch": 0.36170598253433345,
      "grad_norm": 2.473174810409546,
      "learning_rate": 0.0001276759185448221,
      "loss": 0.0911,
      "step": 4991
    },
    {
      "epoch": 0.36177845417980214,
      "grad_norm": 1.3959423303604126,
      "learning_rate": 0.00012766142474092326,
      "loss": 0.0494,
      "step": 4992
    },
    {
      "epoch": 0.36185092582527084,
      "grad_norm": 2.1274125576019287,
      "learning_rate": 0.0001276469309370244,
      "loss": 0.1294,
      "step": 4993
    },
    {
      "epoch": 0.3619233974707396,
      "grad_norm": 1.629970669746399,
      "learning_rate": 0.0001276324371331256,
      "loss": 0.0379,
      "step": 4994
    },
    {
      "epoch": 0.3619958691162083,
      "grad_norm": 4.6814045906066895,
      "learning_rate": 0.00012761794332922675,
      "loss": 0.1706,
      "step": 4995
    },
    {
      "epoch": 0.362068340761677,
      "grad_norm": 5.771644115447998,
      "learning_rate": 0.00012760344952532794,
      "loss": 0.2459,
      "step": 4996
    },
    {
      "epoch": 0.3621408124071457,
      "grad_norm": 0.5756041407585144,
      "learning_rate": 0.0001275889557214291,
      "loss": 0.0059,
      "step": 4997
    },
    {
      "epoch": 0.36221328405261444,
      "grad_norm": 5.135010719299316,
      "learning_rate": 0.00012757446191753028,
      "loss": 0.1571,
      "step": 4998
    },
    {
      "epoch": 0.36228575569808313,
      "grad_norm": 1.2155574560165405,
      "learning_rate": 0.00012755996811363143,
      "loss": 0.1315,
      "step": 4999
    },
    {
      "epoch": 0.36235822734355183,
      "grad_norm": 1.8209755420684814,
      "learning_rate": 0.00012754547430973262,
      "loss": 0.0926,
      "step": 5000
    },
    {
      "epoch": 0.3624306989890205,
      "grad_norm": 2.8258869647979736,
      "learning_rate": 0.00012753098050583377,
      "loss": 0.0871,
      "step": 5001
    },
    {
      "epoch": 0.3625031706344893,
      "grad_norm": 1.1721915006637573,
      "learning_rate": 0.00012751648670193493,
      "loss": 0.089,
      "step": 5002
    },
    {
      "epoch": 0.362575642279958,
      "grad_norm": 1.263434886932373,
      "learning_rate": 0.0001275019928980361,
      "loss": 0.0208,
      "step": 5003
    },
    {
      "epoch": 0.3626481139254267,
      "grad_norm": 2.581376314163208,
      "learning_rate": 0.00012748749909413727,
      "loss": 0.1246,
      "step": 5004
    },
    {
      "epoch": 0.36272058557089537,
      "grad_norm": 0.8419910669326782,
      "learning_rate": 0.00012747300529023843,
      "loss": 0.0129,
      "step": 5005
    },
    {
      "epoch": 0.3627930572163641,
      "grad_norm": 1.3635281324386597,
      "learning_rate": 0.0001274585114863396,
      "loss": 0.1035,
      "step": 5006
    },
    {
      "epoch": 0.3628655288618328,
      "grad_norm": 1.4736884832382202,
      "learning_rate": 0.00012744401768244077,
      "loss": 0.1299,
      "step": 5007
    },
    {
      "epoch": 0.3629380005073015,
      "grad_norm": 2.091719150543213,
      "learning_rate": 0.00012742952387854192,
      "loss": 0.023,
      "step": 5008
    },
    {
      "epoch": 0.3630104721527702,
      "grad_norm": 0.6872559785842896,
      "learning_rate": 0.0001274150300746431,
      "loss": 0.0239,
      "step": 5009
    },
    {
      "epoch": 0.36308294379823897,
      "grad_norm": 1.3789782524108887,
      "learning_rate": 0.00012740053627074426,
      "loss": 0.028,
      "step": 5010
    },
    {
      "epoch": 0.36315541544370766,
      "grad_norm": 1.549078106880188,
      "learning_rate": 0.00012738604246684542,
      "loss": 0.0553,
      "step": 5011
    },
    {
      "epoch": 0.36322788708917636,
      "grad_norm": 4.864842891693115,
      "learning_rate": 0.0001273715486629466,
      "loss": 0.2008,
      "step": 5012
    },
    {
      "epoch": 0.36330035873464506,
      "grad_norm": 1.4090182781219482,
      "learning_rate": 0.00012735705485904776,
      "loss": 0.0402,
      "step": 5013
    },
    {
      "epoch": 0.36337283038011375,
      "grad_norm": 1.359580397605896,
      "learning_rate": 0.00012734256105514892,
      "loss": 0.0459,
      "step": 5014
    },
    {
      "epoch": 0.3634453020255825,
      "grad_norm": 1.046280860900879,
      "learning_rate": 0.0001273280672512501,
      "loss": 0.0406,
      "step": 5015
    },
    {
      "epoch": 0.3635177736710512,
      "grad_norm": 0.954304039478302,
      "learning_rate": 0.00012731357344735126,
      "loss": 0.0348,
      "step": 5016
    },
    {
      "epoch": 0.3635902453165199,
      "grad_norm": 1.850658893585205,
      "learning_rate": 0.0001272990796434524,
      "loss": 0.0686,
      "step": 5017
    },
    {
      "epoch": 0.3636627169619886,
      "grad_norm": 4.567958354949951,
      "learning_rate": 0.0001272845858395536,
      "loss": 0.1871,
      "step": 5018
    },
    {
      "epoch": 0.36373518860745735,
      "grad_norm": 3.587395429611206,
      "learning_rate": 0.00012727009203565475,
      "loss": 0.1077,
      "step": 5019
    },
    {
      "epoch": 0.36380766025292605,
      "grad_norm": 1.692602515220642,
      "learning_rate": 0.00012725559823175594,
      "loss": 0.0469,
      "step": 5020
    },
    {
      "epoch": 0.36388013189839474,
      "grad_norm": 2.456533908843994,
      "learning_rate": 0.0001272411044278571,
      "loss": 0.1245,
      "step": 5021
    },
    {
      "epoch": 0.36395260354386344,
      "grad_norm": 1.7855358123779297,
      "learning_rate": 0.00012722661062395828,
      "loss": 0.055,
      "step": 5022
    },
    {
      "epoch": 0.3640250751893322,
      "grad_norm": 1.54068922996521,
      "learning_rate": 0.00012721211682005943,
      "loss": 0.0476,
      "step": 5023
    },
    {
      "epoch": 0.3640975468348009,
      "grad_norm": 3.045487880706787,
      "learning_rate": 0.00012719762301616062,
      "loss": 0.1158,
      "step": 5024
    },
    {
      "epoch": 0.3641700184802696,
      "grad_norm": 1.3461445569992065,
      "learning_rate": 0.00012718312921226177,
      "loss": 0.0282,
      "step": 5025
    },
    {
      "epoch": 0.3642424901257383,
      "grad_norm": 0.9869635105133057,
      "learning_rate": 0.00012716863540836293,
      "loss": 0.0136,
      "step": 5026
    },
    {
      "epoch": 0.36431496177120704,
      "grad_norm": 2.2016007900238037,
      "learning_rate": 0.0001271541416044641,
      "loss": 0.1593,
      "step": 5027
    },
    {
      "epoch": 0.36438743341667573,
      "grad_norm": 1.8796055316925049,
      "learning_rate": 0.00012713964780056527,
      "loss": 0.0819,
      "step": 5028
    },
    {
      "epoch": 0.36445990506214443,
      "grad_norm": 1.5007648468017578,
      "learning_rate": 0.00012712515399666643,
      "loss": 0.0884,
      "step": 5029
    },
    {
      "epoch": 0.3645323767076131,
      "grad_norm": 1.9186047315597534,
      "learning_rate": 0.0001271106601927676,
      "loss": 0.131,
      "step": 5030
    },
    {
      "epoch": 0.3646048483530819,
      "grad_norm": 0.8415567278862,
      "learning_rate": 0.00012709616638886877,
      "loss": 0.0125,
      "step": 5031
    },
    {
      "epoch": 0.3646773199985506,
      "grad_norm": 1.0637787580490112,
      "learning_rate": 0.00012708167258496992,
      "loss": 0.0673,
      "step": 5032
    },
    {
      "epoch": 0.36474979164401927,
      "grad_norm": 2.8939082622528076,
      "learning_rate": 0.0001270671787810711,
      "loss": 0.0375,
      "step": 5033
    },
    {
      "epoch": 0.36482226328948797,
      "grad_norm": 1.124638319015503,
      "learning_rate": 0.00012705268497717226,
      "loss": 0.1106,
      "step": 5034
    },
    {
      "epoch": 0.3648947349349567,
      "grad_norm": 0.8560341596603394,
      "learning_rate": 0.00012703819117327342,
      "loss": 0.0277,
      "step": 5035
    },
    {
      "epoch": 0.3649672065804254,
      "grad_norm": 1.3796659708023071,
      "learning_rate": 0.0001270236973693746,
      "loss": 0.0731,
      "step": 5036
    },
    {
      "epoch": 0.3650396782258941,
      "grad_norm": 2.401204824447632,
      "learning_rate": 0.00012700920356547576,
      "loss": 0.1475,
      "step": 5037
    },
    {
      "epoch": 0.3651121498713628,
      "grad_norm": 1.2880035638809204,
      "learning_rate": 0.00012699470976157691,
      "loss": 0.0654,
      "step": 5038
    },
    {
      "epoch": 0.36518462151683156,
      "grad_norm": 2.434523344039917,
      "learning_rate": 0.0001269802159576781,
      "loss": 0.1172,
      "step": 5039
    },
    {
      "epoch": 0.36525709316230026,
      "grad_norm": 3.959841728210449,
      "learning_rate": 0.00012696572215377925,
      "loss": 0.1264,
      "step": 5040
    },
    {
      "epoch": 0.36532956480776896,
      "grad_norm": 0.974398136138916,
      "learning_rate": 0.0001269512283498804,
      "loss": 0.0663,
      "step": 5041
    },
    {
      "epoch": 0.36540203645323766,
      "grad_norm": 0.4147047996520996,
      "learning_rate": 0.0001269367345459816,
      "loss": 0.0212,
      "step": 5042
    },
    {
      "epoch": 0.3654745080987064,
      "grad_norm": 3.2890968322753906,
      "learning_rate": 0.00012692224074208278,
      "loss": 0.099,
      "step": 5043
    },
    {
      "epoch": 0.3655469797441751,
      "grad_norm": 1.4120293855667114,
      "learning_rate": 0.00012690774693818394,
      "loss": 0.0702,
      "step": 5044
    },
    {
      "epoch": 0.3656194513896438,
      "grad_norm": 3.25689435005188,
      "learning_rate": 0.00012689325313428512,
      "loss": 0.1853,
      "step": 5045
    },
    {
      "epoch": 0.3656919230351125,
      "grad_norm": 1.6337043046951294,
      "learning_rate": 0.00012687875933038628,
      "loss": 0.0717,
      "step": 5046
    },
    {
      "epoch": 0.3657643946805812,
      "grad_norm": 0.6175112724304199,
      "learning_rate": 0.00012686426552648743,
      "loss": 0.0352,
      "step": 5047
    },
    {
      "epoch": 0.36583686632604995,
      "grad_norm": 1.7725168466567993,
      "learning_rate": 0.00012684977172258862,
      "loss": 0.0599,
      "step": 5048
    },
    {
      "epoch": 0.36590933797151864,
      "grad_norm": 1.4689515829086304,
      "learning_rate": 0.00012683527791868977,
      "loss": 0.09,
      "step": 5049
    },
    {
      "epoch": 0.36598180961698734,
      "grad_norm": 5.818883895874023,
      "learning_rate": 0.00012682078411479093,
      "loss": 0.1382,
      "step": 5050
    },
    {
      "epoch": 0.36605428126245604,
      "grad_norm": 0.4549114406108856,
      "learning_rate": 0.0001268062903108921,
      "loss": 0.032,
      "step": 5051
    },
    {
      "epoch": 0.3661267529079248,
      "grad_norm": 0.6948383450508118,
      "learning_rate": 0.00012679179650699327,
      "loss": 0.042,
      "step": 5052
    },
    {
      "epoch": 0.3661992245533935,
      "grad_norm": 2.71262526512146,
      "learning_rate": 0.00012677730270309442,
      "loss": 0.0525,
      "step": 5053
    },
    {
      "epoch": 0.3662716961988622,
      "grad_norm": 2.389906644821167,
      "learning_rate": 0.0001267628088991956,
      "loss": 0.0631,
      "step": 5054
    },
    {
      "epoch": 0.3663441678443309,
      "grad_norm": 3.945549488067627,
      "learning_rate": 0.00012674831509529676,
      "loss": 0.1328,
      "step": 5055
    },
    {
      "epoch": 0.36641663948979963,
      "grad_norm": 1.1849899291992188,
      "learning_rate": 0.00012673382129139792,
      "loss": 0.0443,
      "step": 5056
    },
    {
      "epoch": 0.36648911113526833,
      "grad_norm": 0.48248788714408875,
      "learning_rate": 0.0001267193274874991,
      "loss": 0.0233,
      "step": 5057
    },
    {
      "epoch": 0.366561582780737,
      "grad_norm": 1.8406342267990112,
      "learning_rate": 0.00012670483368360026,
      "loss": 0.063,
      "step": 5058
    },
    {
      "epoch": 0.3666340544262057,
      "grad_norm": 1.8463990688323975,
      "learning_rate": 0.00012669033987970142,
      "loss": 0.0437,
      "step": 5059
    },
    {
      "epoch": 0.3667065260716745,
      "grad_norm": 3.7656195163726807,
      "learning_rate": 0.0001266758460758026,
      "loss": 0.0689,
      "step": 5060
    },
    {
      "epoch": 0.3667789977171432,
      "grad_norm": 2.2716639041900635,
      "learning_rate": 0.00012666135227190376,
      "loss": 0.1289,
      "step": 5061
    },
    {
      "epoch": 0.36685146936261187,
      "grad_norm": 1.0725070238113403,
      "learning_rate": 0.00012664685846800491,
      "loss": 0.078,
      "step": 5062
    },
    {
      "epoch": 0.36692394100808057,
      "grad_norm": 2.489515542984009,
      "learning_rate": 0.0001266323646641061,
      "loss": 0.1276,
      "step": 5063
    },
    {
      "epoch": 0.3669964126535493,
      "grad_norm": 3.1464388370513916,
      "learning_rate": 0.00012661787086020725,
      "loss": 0.0649,
      "step": 5064
    },
    {
      "epoch": 0.367068884299018,
      "grad_norm": 0.1860779970884323,
      "learning_rate": 0.00012660337705630844,
      "loss": 0.0041,
      "step": 5065
    },
    {
      "epoch": 0.3671413559444867,
      "grad_norm": 3.034611701965332,
      "learning_rate": 0.0001265888832524096,
      "loss": 0.0554,
      "step": 5066
    },
    {
      "epoch": 0.3672138275899554,
      "grad_norm": 3.9536216259002686,
      "learning_rate": 0.00012657438944851078,
      "loss": 0.2111,
      "step": 5067
    },
    {
      "epoch": 0.36728629923542416,
      "grad_norm": 1.1005923748016357,
      "learning_rate": 0.00012655989564461193,
      "loss": 0.0314,
      "step": 5068
    },
    {
      "epoch": 0.36735877088089286,
      "grad_norm": 3.5675036907196045,
      "learning_rate": 0.00012654540184071312,
      "loss": 0.1256,
      "step": 5069
    },
    {
      "epoch": 0.36743124252636156,
      "grad_norm": 1.424145221710205,
      "learning_rate": 0.00012653090803681427,
      "loss": 0.0288,
      "step": 5070
    },
    {
      "epoch": 0.36750371417183025,
      "grad_norm": 3.6952452659606934,
      "learning_rate": 0.00012651641423291543,
      "loss": 0.299,
      "step": 5071
    },
    {
      "epoch": 0.367576185817299,
      "grad_norm": 2.452573776245117,
      "learning_rate": 0.00012650192042901661,
      "loss": 0.0257,
      "step": 5072
    },
    {
      "epoch": 0.3676486574627677,
      "grad_norm": 4.298993110656738,
      "learning_rate": 0.00012648742662511777,
      "loss": 0.0723,
      "step": 5073
    },
    {
      "epoch": 0.3677211291082364,
      "grad_norm": 1.0969138145446777,
      "learning_rate": 0.00012647293282121893,
      "loss": 0.0869,
      "step": 5074
    },
    {
      "epoch": 0.3677936007537051,
      "grad_norm": 2.1823372840881348,
      "learning_rate": 0.0001264584390173201,
      "loss": 0.1277,
      "step": 5075
    },
    {
      "epoch": 0.36786607239917385,
      "grad_norm": 0.6693447232246399,
      "learning_rate": 0.00012644394521342127,
      "loss": 0.049,
      "step": 5076
    },
    {
      "epoch": 0.36793854404464255,
      "grad_norm": 6.05558967590332,
      "learning_rate": 0.00012642945140952242,
      "loss": 0.1267,
      "step": 5077
    },
    {
      "epoch": 0.36801101569011124,
      "grad_norm": 5.085331916809082,
      "learning_rate": 0.0001264149576056236,
      "loss": 0.1819,
      "step": 5078
    },
    {
      "epoch": 0.36808348733557994,
      "grad_norm": 3.3325936794281006,
      "learning_rate": 0.00012640046380172476,
      "loss": 0.1056,
      "step": 5079
    },
    {
      "epoch": 0.3681559589810487,
      "grad_norm": 3.332555055618286,
      "learning_rate": 0.00012638596999782592,
      "loss": 0.1229,
      "step": 5080
    },
    {
      "epoch": 0.3682284306265174,
      "grad_norm": 0.7176164388656616,
      "learning_rate": 0.0001263714761939271,
      "loss": 0.0408,
      "step": 5081
    },
    {
      "epoch": 0.3683009022719861,
      "grad_norm": 3.0111193656921387,
      "learning_rate": 0.00012635698239002826,
      "loss": 0.1096,
      "step": 5082
    },
    {
      "epoch": 0.3683733739174548,
      "grad_norm": 1.4900901317596436,
      "learning_rate": 0.00012634248858612942,
      "loss": 0.1076,
      "step": 5083
    },
    {
      "epoch": 0.3684458455629235,
      "grad_norm": 1.4609622955322266,
      "learning_rate": 0.0001263279947822306,
      "loss": 0.0784,
      "step": 5084
    },
    {
      "epoch": 0.36851831720839223,
      "grad_norm": 1.8713672161102295,
      "learning_rate": 0.00012631350097833176,
      "loss": 0.0711,
      "step": 5085
    },
    {
      "epoch": 0.36859078885386093,
      "grad_norm": 0.8441053032875061,
      "learning_rate": 0.00012629900717443291,
      "loss": 0.029,
      "step": 5086
    },
    {
      "epoch": 0.3686632604993296,
      "grad_norm": 4.325974941253662,
      "learning_rate": 0.0001262845133705341,
      "loss": 0.1653,
      "step": 5087
    },
    {
      "epoch": 0.3687357321447983,
      "grad_norm": 6.330726146697998,
      "learning_rate": 0.00012627001956663525,
      "loss": 0.136,
      "step": 5088
    },
    {
      "epoch": 0.3688082037902671,
      "grad_norm": 1.2374755144119263,
      "learning_rate": 0.00012625552576273644,
      "loss": 0.0855,
      "step": 5089
    },
    {
      "epoch": 0.36888067543573577,
      "grad_norm": 0.9969531297683716,
      "learning_rate": 0.0001262410319588376,
      "loss": 0.0434,
      "step": 5090
    },
    {
      "epoch": 0.36895314708120447,
      "grad_norm": 1.9862022399902344,
      "learning_rate": 0.00012622653815493878,
      "loss": 0.0829,
      "step": 5091
    },
    {
      "epoch": 0.36902561872667317,
      "grad_norm": 2.0601119995117188,
      "learning_rate": 0.00012621204435103993,
      "loss": 0.168,
      "step": 5092
    },
    {
      "epoch": 0.3690980903721419,
      "grad_norm": 0.866959810256958,
      "learning_rate": 0.00012619755054714112,
      "loss": 0.0657,
      "step": 5093
    },
    {
      "epoch": 0.3691705620176106,
      "grad_norm": 0.2642398774623871,
      "learning_rate": 0.00012618305674324227,
      "loss": 0.0118,
      "step": 5094
    },
    {
      "epoch": 0.3692430336630793,
      "grad_norm": 0.9676888585090637,
      "learning_rate": 0.00012616856293934343,
      "loss": 0.0413,
      "step": 5095
    },
    {
      "epoch": 0.369315505308548,
      "grad_norm": 1.6330333948135376,
      "learning_rate": 0.00012615406913544461,
      "loss": 0.1015,
      "step": 5096
    },
    {
      "epoch": 0.36938797695401676,
      "grad_norm": 2.6149818897247314,
      "learning_rate": 0.00012613957533154577,
      "loss": 0.1654,
      "step": 5097
    },
    {
      "epoch": 0.36946044859948546,
      "grad_norm": 1.258271336555481,
      "learning_rate": 0.00012612508152764693,
      "loss": 0.0759,
      "step": 5098
    },
    {
      "epoch": 0.36953292024495416,
      "grad_norm": 1.2552508115768433,
      "learning_rate": 0.0001261105877237481,
      "loss": 0.0729,
      "step": 5099
    },
    {
      "epoch": 0.36960539189042285,
      "grad_norm": 1.894939661026001,
      "learning_rate": 0.00012609609391984927,
      "loss": 0.0715,
      "step": 5100
    },
    {
      "epoch": 0.3696778635358916,
      "grad_norm": 1.0656709671020508,
      "learning_rate": 0.00012608160011595042,
      "loss": 0.0306,
      "step": 5101
    },
    {
      "epoch": 0.3697503351813603,
      "grad_norm": 2.6941025257110596,
      "learning_rate": 0.0001260671063120516,
      "loss": 0.0667,
      "step": 5102
    },
    {
      "epoch": 0.369822806826829,
      "grad_norm": 1.7994588613510132,
      "learning_rate": 0.00012605261250815276,
      "loss": 0.0837,
      "step": 5103
    },
    {
      "epoch": 0.3698952784722977,
      "grad_norm": 0.9259496331214905,
      "learning_rate": 0.00012603811870425392,
      "loss": 0.05,
      "step": 5104
    },
    {
      "epoch": 0.36996775011776645,
      "grad_norm": 3.3235785961151123,
      "learning_rate": 0.0001260236249003551,
      "loss": 0.119,
      "step": 5105
    },
    {
      "epoch": 0.37004022176323514,
      "grad_norm": 0.6171079277992249,
      "learning_rate": 0.00012600913109645626,
      "loss": 0.0331,
      "step": 5106
    },
    {
      "epoch": 0.37011269340870384,
      "grad_norm": 2.505075454711914,
      "learning_rate": 0.00012599463729255742,
      "loss": 0.2092,
      "step": 5107
    },
    {
      "epoch": 0.37018516505417254,
      "grad_norm": 0.7279177308082581,
      "learning_rate": 0.0001259801434886586,
      "loss": 0.0276,
      "step": 5108
    },
    {
      "epoch": 0.3702576366996413,
      "grad_norm": 1.9885674715042114,
      "learning_rate": 0.00012596564968475976,
      "loss": 0.1341,
      "step": 5109
    },
    {
      "epoch": 0.37033010834511,
      "grad_norm": 1.993493676185608,
      "learning_rate": 0.00012595115588086091,
      "loss": 0.124,
      "step": 5110
    },
    {
      "epoch": 0.3704025799905787,
      "grad_norm": 3.6026573181152344,
      "learning_rate": 0.0001259366620769621,
      "loss": 0.0329,
      "step": 5111
    },
    {
      "epoch": 0.3704750516360474,
      "grad_norm": 0.6223340630531311,
      "learning_rate": 0.00012592216827306328,
      "loss": 0.0179,
      "step": 5112
    },
    {
      "epoch": 0.37054752328151613,
      "grad_norm": 2.493110418319702,
      "learning_rate": 0.00012590767446916444,
      "loss": 0.1258,
      "step": 5113
    },
    {
      "epoch": 0.37061999492698483,
      "grad_norm": 1.7250995635986328,
      "learning_rate": 0.00012589318066526562,
      "loss": 0.0294,
      "step": 5114
    },
    {
      "epoch": 0.3706924665724535,
      "grad_norm": 1.9270966053009033,
      "learning_rate": 0.00012587868686136678,
      "loss": 0.0896,
      "step": 5115
    },
    {
      "epoch": 0.3707649382179222,
      "grad_norm": 1.1616731882095337,
      "learning_rate": 0.00012586419305746796,
      "loss": 0.0799,
      "step": 5116
    },
    {
      "epoch": 0.3708374098633909,
      "grad_norm": 1.759130597114563,
      "learning_rate": 0.00012584969925356912,
      "loss": 0.0964,
      "step": 5117
    },
    {
      "epoch": 0.3709098815088597,
      "grad_norm": 1.3137086629867554,
      "learning_rate": 0.00012583520544967027,
      "loss": 0.03,
      "step": 5118
    },
    {
      "epoch": 0.37098235315432837,
      "grad_norm": 1.201833724975586,
      "learning_rate": 0.00012582071164577146,
      "loss": 0.0276,
      "step": 5119
    },
    {
      "epoch": 0.37105482479979707,
      "grad_norm": 0.7036411762237549,
      "learning_rate": 0.00012580621784187261,
      "loss": 0.0246,
      "step": 5120
    },
    {
      "epoch": 0.37112729644526576,
      "grad_norm": 0.5602671504020691,
      "learning_rate": 0.00012579172403797377,
      "loss": 0.0235,
      "step": 5121
    },
    {
      "epoch": 0.3711997680907345,
      "grad_norm": 1.306387186050415,
      "learning_rate": 0.00012577723023407495,
      "loss": 0.0599,
      "step": 5122
    },
    {
      "epoch": 0.3712722397362032,
      "grad_norm": 1.170457124710083,
      "learning_rate": 0.0001257627364301761,
      "loss": 0.0624,
      "step": 5123
    },
    {
      "epoch": 0.3713447113816719,
      "grad_norm": 3.4329185485839844,
      "learning_rate": 0.00012574824262627727,
      "loss": 0.0791,
      "step": 5124
    },
    {
      "epoch": 0.3714171830271406,
      "grad_norm": 0.8990930914878845,
      "learning_rate": 0.00012573374882237845,
      "loss": 0.053,
      "step": 5125
    },
    {
      "epoch": 0.37148965467260936,
      "grad_norm": 1.509680151939392,
      "learning_rate": 0.0001257192550184796,
      "loss": 0.0837,
      "step": 5126
    },
    {
      "epoch": 0.37156212631807806,
      "grad_norm": 2.780945301055908,
      "learning_rate": 0.00012570476121458076,
      "loss": 0.2277,
      "step": 5127
    },
    {
      "epoch": 0.37163459796354675,
      "grad_norm": 2.769557476043701,
      "learning_rate": 0.00012569026741068195,
      "loss": 0.0912,
      "step": 5128
    },
    {
      "epoch": 0.37170706960901545,
      "grad_norm": 0.3527764678001404,
      "learning_rate": 0.0001256757736067831,
      "loss": 0.0119,
      "step": 5129
    },
    {
      "epoch": 0.3717795412544842,
      "grad_norm": 1.061711072921753,
      "learning_rate": 0.00012566127980288426,
      "loss": 0.0718,
      "step": 5130
    },
    {
      "epoch": 0.3718520128999529,
      "grad_norm": 0.8534526228904724,
      "learning_rate": 0.00012564678599898544,
      "loss": 0.0278,
      "step": 5131
    },
    {
      "epoch": 0.3719244845454216,
      "grad_norm": 2.0156502723693848,
      "learning_rate": 0.0001256322921950866,
      "loss": 0.1641,
      "step": 5132
    },
    {
      "epoch": 0.3719969561908903,
      "grad_norm": 0.6929048299789429,
      "learning_rate": 0.00012561779839118776,
      "loss": 0.056,
      "step": 5133
    },
    {
      "epoch": 0.37206942783635905,
      "grad_norm": 1.681486964225769,
      "learning_rate": 0.00012560330458728894,
      "loss": 0.1141,
      "step": 5134
    },
    {
      "epoch": 0.37214189948182774,
      "grad_norm": 0.18529443442821503,
      "learning_rate": 0.0001255888107833901,
      "loss": 0.0067,
      "step": 5135
    },
    {
      "epoch": 0.37221437112729644,
      "grad_norm": 1.5375103950500488,
      "learning_rate": 0.00012557431697949128,
      "loss": 0.0806,
      "step": 5136
    },
    {
      "epoch": 0.37228684277276514,
      "grad_norm": 1.9338908195495605,
      "learning_rate": 0.00012555982317559244,
      "loss": 0.1227,
      "step": 5137
    },
    {
      "epoch": 0.3723593144182339,
      "grad_norm": 1.242936372756958,
      "learning_rate": 0.00012554532937169362,
      "loss": 0.0871,
      "step": 5138
    },
    {
      "epoch": 0.3724317860637026,
      "grad_norm": 0.6412917375564575,
      "learning_rate": 0.00012553083556779478,
      "loss": 0.0168,
      "step": 5139
    },
    {
      "epoch": 0.3725042577091713,
      "grad_norm": 2.129889488220215,
      "learning_rate": 0.00012551634176389596,
      "loss": 0.0896,
      "step": 5140
    },
    {
      "epoch": 0.37257672935464,
      "grad_norm": 1.3086789846420288,
      "learning_rate": 0.00012550184795999712,
      "loss": 0.1174,
      "step": 5141
    },
    {
      "epoch": 0.37264920100010873,
      "grad_norm": 0.9256444573402405,
      "learning_rate": 0.00012548735415609827,
      "loss": 0.0959,
      "step": 5142
    },
    {
      "epoch": 0.37272167264557743,
      "grad_norm": 2.599017858505249,
      "learning_rate": 0.00012547286035219946,
      "loss": 0.0483,
      "step": 5143
    },
    {
      "epoch": 0.3727941442910461,
      "grad_norm": 0.6611043810844421,
      "learning_rate": 0.00012545836654830061,
      "loss": 0.0452,
      "step": 5144
    },
    {
      "epoch": 0.3728666159365148,
      "grad_norm": 1.7278404235839844,
      "learning_rate": 0.00012544387274440177,
      "loss": 0.0459,
      "step": 5145
    },
    {
      "epoch": 0.3729390875819836,
      "grad_norm": 3.37874436378479,
      "learning_rate": 0.00012542937894050295,
      "loss": 0.2274,
      "step": 5146
    },
    {
      "epoch": 0.37301155922745227,
      "grad_norm": 0.7515112161636353,
      "learning_rate": 0.0001254148851366041,
      "loss": 0.0259,
      "step": 5147
    },
    {
      "epoch": 0.37308403087292097,
      "grad_norm": 0.9874418377876282,
      "learning_rate": 0.00012540039133270527,
      "loss": 0.0373,
      "step": 5148
    },
    {
      "epoch": 0.37315650251838967,
      "grad_norm": 0.889266312122345,
      "learning_rate": 0.00012538589752880645,
      "loss": 0.041,
      "step": 5149
    },
    {
      "epoch": 0.3732289741638584,
      "grad_norm": 2.2290091514587402,
      "learning_rate": 0.0001253714037249076,
      "loss": 0.1339,
      "step": 5150
    },
    {
      "epoch": 0.3733014458093271,
      "grad_norm": 1.0375429391860962,
      "learning_rate": 0.00012535690992100876,
      "loss": 0.0203,
      "step": 5151
    },
    {
      "epoch": 0.3733739174547958,
      "grad_norm": 1.285352110862732,
      "learning_rate": 0.00012534241611710995,
      "loss": 0.0544,
      "step": 5152
    },
    {
      "epoch": 0.3734463891002645,
      "grad_norm": 3.950897455215454,
      "learning_rate": 0.0001253279223132111,
      "loss": 0.1353,
      "step": 5153
    },
    {
      "epoch": 0.3735188607457332,
      "grad_norm": 0.8259935975074768,
      "learning_rate": 0.00012531342850931226,
      "loss": 0.0517,
      "step": 5154
    },
    {
      "epoch": 0.37359133239120196,
      "grad_norm": 3.488129138946533,
      "learning_rate": 0.00012529893470541344,
      "loss": 0.1442,
      "step": 5155
    },
    {
      "epoch": 0.37366380403667065,
      "grad_norm": 2.0846002101898193,
      "learning_rate": 0.0001252844409015146,
      "loss": 0.0811,
      "step": 5156
    },
    {
      "epoch": 0.37373627568213935,
      "grad_norm": 1.7594575881958008,
      "learning_rate": 0.00012526994709761576,
      "loss": 0.0574,
      "step": 5157
    },
    {
      "epoch": 0.37380874732760805,
      "grad_norm": 0.7840760946273804,
      "learning_rate": 0.00012525545329371694,
      "loss": 0.0353,
      "step": 5158
    },
    {
      "epoch": 0.3738812189730768,
      "grad_norm": 0.9982690215110779,
      "learning_rate": 0.00012524095948981812,
      "loss": 0.0415,
      "step": 5159
    },
    {
      "epoch": 0.3739536906185455,
      "grad_norm": 1.4286199808120728,
      "learning_rate": 0.00012522646568591928,
      "loss": 0.0608,
      "step": 5160
    },
    {
      "epoch": 0.3740261622640142,
      "grad_norm": 4.5522966384887695,
      "learning_rate": 0.00012521197188202046,
      "loss": 0.0764,
      "step": 5161
    },
    {
      "epoch": 0.3740986339094829,
      "grad_norm": 1.1007452011108398,
      "learning_rate": 0.00012519747807812162,
      "loss": 0.0303,
      "step": 5162
    },
    {
      "epoch": 0.37417110555495164,
      "grad_norm": 1.9557489156723022,
      "learning_rate": 0.00012518298427422278,
      "loss": 0.161,
      "step": 5163
    },
    {
      "epoch": 0.37424357720042034,
      "grad_norm": 1.9156237840652466,
      "learning_rate": 0.00012516849047032396,
      "loss": 0.1268,
      "step": 5164
    },
    {
      "epoch": 0.37431604884588904,
      "grad_norm": 1.512317419052124,
      "learning_rate": 0.00012515399666642512,
      "loss": 0.0524,
      "step": 5165
    },
    {
      "epoch": 0.37438852049135773,
      "grad_norm": 1.411159634590149,
      "learning_rate": 0.00012513950286252627,
      "loss": 0.113,
      "step": 5166
    },
    {
      "epoch": 0.3744609921368265,
      "grad_norm": 0.9121069312095642,
      "learning_rate": 0.00012512500905862746,
      "loss": 0.0695,
      "step": 5167
    },
    {
      "epoch": 0.3745334637822952,
      "grad_norm": 0.6811231374740601,
      "learning_rate": 0.0001251105152547286,
      "loss": 0.036,
      "step": 5168
    },
    {
      "epoch": 0.3746059354277639,
      "grad_norm": 3.3225769996643066,
      "learning_rate": 0.00012509602145082977,
      "loss": 0.1238,
      "step": 5169
    },
    {
      "epoch": 0.3746784070732326,
      "grad_norm": 0.9911519289016724,
      "learning_rate": 0.00012508152764693095,
      "loss": 0.0737,
      "step": 5170
    },
    {
      "epoch": 0.37475087871870133,
      "grad_norm": 0.9707359075546265,
      "learning_rate": 0.0001250670338430321,
      "loss": 0.0318,
      "step": 5171
    },
    {
      "epoch": 0.37482335036417,
      "grad_norm": 1.4927668571472168,
      "learning_rate": 0.00012505254003913327,
      "loss": 0.0477,
      "step": 5172
    },
    {
      "epoch": 0.3748958220096387,
      "grad_norm": 2.7481918334960938,
      "learning_rate": 0.00012503804623523445,
      "loss": 0.0536,
      "step": 5173
    },
    {
      "epoch": 0.3749682936551074,
      "grad_norm": 3.1842212677001953,
      "learning_rate": 0.0001250235524313356,
      "loss": 0.1578,
      "step": 5174
    },
    {
      "epoch": 0.3750407653005762,
      "grad_norm": 1.8952102661132812,
      "learning_rate": 0.00012500905862743676,
      "loss": 0.0949,
      "step": 5175
    },
    {
      "epoch": 0.37511323694604487,
      "grad_norm": 0.48649862408638,
      "learning_rate": 0.00012499456482353795,
      "loss": 0.0288,
      "step": 5176
    },
    {
      "epoch": 0.37518570859151357,
      "grad_norm": 2.5778415203094482,
      "learning_rate": 0.0001249800710196391,
      "loss": 0.0795,
      "step": 5177
    },
    {
      "epoch": 0.37525818023698226,
      "grad_norm": 2.266385793685913,
      "learning_rate": 0.00012496557721574026,
      "loss": 0.0826,
      "step": 5178
    },
    {
      "epoch": 0.375330651882451,
      "grad_norm": 0.9614521265029907,
      "learning_rate": 0.00012495108341184144,
      "loss": 0.0863,
      "step": 5179
    },
    {
      "epoch": 0.3754031235279197,
      "grad_norm": 1.0472779273986816,
      "learning_rate": 0.0001249365896079426,
      "loss": 0.0547,
      "step": 5180
    },
    {
      "epoch": 0.3754755951733884,
      "grad_norm": 6.646574020385742,
      "learning_rate": 0.00012492209580404378,
      "loss": 0.1169,
      "step": 5181
    },
    {
      "epoch": 0.3755480668188571,
      "grad_norm": 7.526673793792725,
      "learning_rate": 0.00012490760200014494,
      "loss": 0.1052,
      "step": 5182
    },
    {
      "epoch": 0.37562053846432586,
      "grad_norm": 1.982318639755249,
      "learning_rate": 0.00012489310819624612,
      "loss": 0.0533,
      "step": 5183
    },
    {
      "epoch": 0.37569301010979456,
      "grad_norm": 1.186655879020691,
      "learning_rate": 0.00012487861439234728,
      "loss": 0.0549,
      "step": 5184
    },
    {
      "epoch": 0.37576548175526325,
      "grad_norm": 2.741434335708618,
      "learning_rate": 0.00012486412058844846,
      "loss": 0.094,
      "step": 5185
    },
    {
      "epoch": 0.37583795340073195,
      "grad_norm": 0.9952155351638794,
      "learning_rate": 0.00012484962678454962,
      "loss": 0.0286,
      "step": 5186
    },
    {
      "epoch": 0.37591042504620065,
      "grad_norm": 1.7086522579193115,
      "learning_rate": 0.00012483513298065078,
      "loss": 0.0889,
      "step": 5187
    },
    {
      "epoch": 0.3759828966916694,
      "grad_norm": 1.772903323173523,
      "learning_rate": 0.00012482063917675196,
      "loss": 0.1413,
      "step": 5188
    },
    {
      "epoch": 0.3760553683371381,
      "grad_norm": 2.1544032096862793,
      "learning_rate": 0.00012480614537285312,
      "loss": 0.0761,
      "step": 5189
    },
    {
      "epoch": 0.3761278399826068,
      "grad_norm": 1.6719430685043335,
      "learning_rate": 0.00012479165156895427,
      "loss": 0.1103,
      "step": 5190
    },
    {
      "epoch": 0.3762003116280755,
      "grad_norm": 2.304184675216675,
      "learning_rate": 0.00012477715776505546,
      "loss": 0.0314,
      "step": 5191
    },
    {
      "epoch": 0.37627278327354424,
      "grad_norm": 0.8426096439361572,
      "learning_rate": 0.0001247626639611566,
      "loss": 0.0381,
      "step": 5192
    },
    {
      "epoch": 0.37634525491901294,
      "grad_norm": 1.160495638847351,
      "learning_rate": 0.00012474817015725777,
      "loss": 0.0441,
      "step": 5193
    },
    {
      "epoch": 0.37641772656448164,
      "grad_norm": 0.9312865138053894,
      "learning_rate": 0.00012473367635335895,
      "loss": 0.0594,
      "step": 5194
    },
    {
      "epoch": 0.37649019820995033,
      "grad_norm": 0.9900474548339844,
      "learning_rate": 0.0001247191825494601,
      "loss": 0.0568,
      "step": 5195
    },
    {
      "epoch": 0.3765626698554191,
      "grad_norm": 0.9072611927986145,
      "learning_rate": 0.00012470468874556127,
      "loss": 0.0152,
      "step": 5196
    },
    {
      "epoch": 0.3766351415008878,
      "grad_norm": 2.6136929988861084,
      "learning_rate": 0.00012469019494166245,
      "loss": 0.0927,
      "step": 5197
    },
    {
      "epoch": 0.3767076131463565,
      "grad_norm": 0.7312861084938049,
      "learning_rate": 0.0001246757011377636,
      "loss": 0.0229,
      "step": 5198
    },
    {
      "epoch": 0.3767800847918252,
      "grad_norm": 0.43918120861053467,
      "learning_rate": 0.00012466120733386476,
      "loss": 0.0193,
      "step": 5199
    },
    {
      "epoch": 0.37685255643729393,
      "grad_norm": 3.3411381244659424,
      "learning_rate": 0.00012464671352996595,
      "loss": 0.1888,
      "step": 5200
    },
    {
      "epoch": 0.3769250280827626,
      "grad_norm": 1.0447888374328613,
      "learning_rate": 0.0001246322197260671,
      "loss": 0.0328,
      "step": 5201
    },
    {
      "epoch": 0.3769974997282313,
      "grad_norm": 0.9774119257926941,
      "learning_rate": 0.00012461772592216826,
      "loss": 0.0724,
      "step": 5202
    },
    {
      "epoch": 0.3770699713737,
      "grad_norm": 1.9683729410171509,
      "learning_rate": 0.00012460323211826944,
      "loss": 0.1276,
      "step": 5203
    },
    {
      "epoch": 0.37714244301916877,
      "grad_norm": 1.4617385864257812,
      "learning_rate": 0.0001245887383143706,
      "loss": 0.0427,
      "step": 5204
    },
    {
      "epoch": 0.37721491466463747,
      "grad_norm": 0.68388831615448,
      "learning_rate": 0.00012457424451047178,
      "loss": 0.018,
      "step": 5205
    },
    {
      "epoch": 0.37728738631010617,
      "grad_norm": 4.4730143547058105,
      "learning_rate": 0.00012455975070657297,
      "loss": 0.1489,
      "step": 5206
    },
    {
      "epoch": 0.37735985795557486,
      "grad_norm": 3.878403663635254,
      "learning_rate": 0.00012454525690267412,
      "loss": 0.1193,
      "step": 5207
    },
    {
      "epoch": 0.3774323296010436,
      "grad_norm": 1.3192049264907837,
      "learning_rate": 0.00012453076309877528,
      "loss": 0.0505,
      "step": 5208
    },
    {
      "epoch": 0.3775048012465123,
      "grad_norm": 3.0345897674560547,
      "learning_rate": 0.00012451626929487646,
      "loss": 0.0819,
      "step": 5209
    },
    {
      "epoch": 0.377577272891981,
      "grad_norm": 2.0843307971954346,
      "learning_rate": 0.00012450177549097762,
      "loss": 0.0932,
      "step": 5210
    },
    {
      "epoch": 0.3776497445374497,
      "grad_norm": 5.54966926574707,
      "learning_rate": 0.00012448728168707878,
      "loss": 0.0957,
      "step": 5211
    },
    {
      "epoch": 0.37772221618291846,
      "grad_norm": 2.5905606746673584,
      "learning_rate": 0.00012447278788317996,
      "loss": 0.0295,
      "step": 5212
    },
    {
      "epoch": 0.37779468782838715,
      "grad_norm": 1.349827527999878,
      "learning_rate": 0.00012445829407928112,
      "loss": 0.1153,
      "step": 5213
    },
    {
      "epoch": 0.37786715947385585,
      "grad_norm": 1.6761828660964966,
      "learning_rate": 0.00012444380027538227,
      "loss": 0.0805,
      "step": 5214
    },
    {
      "epoch": 0.37793963111932455,
      "grad_norm": 1.1237120628356934,
      "learning_rate": 0.00012442930647148346,
      "loss": 0.0327,
      "step": 5215
    },
    {
      "epoch": 0.3780121027647933,
      "grad_norm": 1.8092063665390015,
      "learning_rate": 0.0001244148126675846,
      "loss": 0.0808,
      "step": 5216
    },
    {
      "epoch": 0.378084574410262,
      "grad_norm": 2.3661248683929443,
      "learning_rate": 0.00012440031886368577,
      "loss": 0.1243,
      "step": 5217
    },
    {
      "epoch": 0.3781570460557307,
      "grad_norm": 0.3669731318950653,
      "learning_rate": 0.00012438582505978695,
      "loss": 0.0188,
      "step": 5218
    },
    {
      "epoch": 0.3782295177011994,
      "grad_norm": 0.414352685213089,
      "learning_rate": 0.0001243713312558881,
      "loss": 0.0233,
      "step": 5219
    },
    {
      "epoch": 0.37830198934666814,
      "grad_norm": 0.6619167327880859,
      "learning_rate": 0.00012435683745198927,
      "loss": 0.0229,
      "step": 5220
    },
    {
      "epoch": 0.37837446099213684,
      "grad_norm": 0.833607017993927,
      "learning_rate": 0.00012434234364809045,
      "loss": 0.0353,
      "step": 5221
    },
    {
      "epoch": 0.37844693263760554,
      "grad_norm": 2.7716689109802246,
      "learning_rate": 0.0001243278498441916,
      "loss": 0.1428,
      "step": 5222
    },
    {
      "epoch": 0.37851940428307423,
      "grad_norm": 4.212030410766602,
      "learning_rate": 0.00012431335604029276,
      "loss": 0.0604,
      "step": 5223
    },
    {
      "epoch": 0.37859187592854293,
      "grad_norm": 1.0048140287399292,
      "learning_rate": 0.00012429886223639395,
      "loss": 0.0471,
      "step": 5224
    },
    {
      "epoch": 0.3786643475740117,
      "grad_norm": 0.5378667712211609,
      "learning_rate": 0.0001242843684324951,
      "loss": 0.0121,
      "step": 5225
    },
    {
      "epoch": 0.3787368192194804,
      "grad_norm": 1.353519320487976,
      "learning_rate": 0.00012426987462859629,
      "loss": 0.0905,
      "step": 5226
    },
    {
      "epoch": 0.3788092908649491,
      "grad_norm": 2.87100887298584,
      "learning_rate": 0.00012425538082469744,
      "loss": 0.1003,
      "step": 5227
    },
    {
      "epoch": 0.3788817625104178,
      "grad_norm": 1.6298930644989014,
      "learning_rate": 0.00012424088702079863,
      "loss": 0.0434,
      "step": 5228
    },
    {
      "epoch": 0.3789542341558865,
      "grad_norm": 0.3963031470775604,
      "learning_rate": 0.00012422639321689978,
      "loss": 0.0157,
      "step": 5229
    },
    {
      "epoch": 0.3790267058013552,
      "grad_norm": 2.7725250720977783,
      "learning_rate": 0.00012421189941300097,
      "loss": 0.0309,
      "step": 5230
    },
    {
      "epoch": 0.3790991774468239,
      "grad_norm": 0.5991325378417969,
      "learning_rate": 0.00012419740560910212,
      "loss": 0.0255,
      "step": 5231
    },
    {
      "epoch": 0.3791716490922926,
      "grad_norm": 1.8375043869018555,
      "learning_rate": 0.00012418291180520328,
      "loss": 0.0441,
      "step": 5232
    },
    {
      "epoch": 0.37924412073776137,
      "grad_norm": 2.047961711883545,
      "learning_rate": 0.00012416841800130446,
      "loss": 0.0975,
      "step": 5233
    },
    {
      "epoch": 0.37931659238323007,
      "grad_norm": 3.9881057739257812,
      "learning_rate": 0.00012415392419740562,
      "loss": 0.126,
      "step": 5234
    },
    {
      "epoch": 0.37938906402869876,
      "grad_norm": 2.377620220184326,
      "learning_rate": 0.00012413943039350678,
      "loss": 0.0976,
      "step": 5235
    },
    {
      "epoch": 0.37946153567416746,
      "grad_norm": 1.7112525701522827,
      "learning_rate": 0.00012412493658960796,
      "loss": 0.062,
      "step": 5236
    },
    {
      "epoch": 0.3795340073196362,
      "grad_norm": 1.834776759147644,
      "learning_rate": 0.00012411044278570912,
      "loss": 0.139,
      "step": 5237
    },
    {
      "epoch": 0.3796064789651049,
      "grad_norm": 0.7400307655334473,
      "learning_rate": 0.00012409594898181027,
      "loss": 0.0428,
      "step": 5238
    },
    {
      "epoch": 0.3796789506105736,
      "grad_norm": 0.7277054190635681,
      "learning_rate": 0.00012408145517791146,
      "loss": 0.0379,
      "step": 5239
    },
    {
      "epoch": 0.3797514222560423,
      "grad_norm": 0.5848050713539124,
      "learning_rate": 0.0001240669613740126,
      "loss": 0.0391,
      "step": 5240
    },
    {
      "epoch": 0.37982389390151106,
      "grad_norm": 2.874504327774048,
      "learning_rate": 0.00012405246757011377,
      "loss": 0.2116,
      "step": 5241
    },
    {
      "epoch": 0.37989636554697975,
      "grad_norm": 1.4449591636657715,
      "learning_rate": 0.00012403797376621495,
      "loss": 0.1205,
      "step": 5242
    },
    {
      "epoch": 0.37996883719244845,
      "grad_norm": 1.3287581205368042,
      "learning_rate": 0.0001240234799623161,
      "loss": 0.0597,
      "step": 5243
    },
    {
      "epoch": 0.38004130883791715,
      "grad_norm": 2.798839807510376,
      "learning_rate": 0.00012400898615841727,
      "loss": 0.056,
      "step": 5244
    },
    {
      "epoch": 0.3801137804833859,
      "grad_norm": 0.8535158038139343,
      "learning_rate": 0.00012399449235451845,
      "loss": 0.0277,
      "step": 5245
    },
    {
      "epoch": 0.3801862521288546,
      "grad_norm": 3.231295585632324,
      "learning_rate": 0.0001239799985506196,
      "loss": 0.0485,
      "step": 5246
    },
    {
      "epoch": 0.3802587237743233,
      "grad_norm": 2.0941522121429443,
      "learning_rate": 0.00012396550474672076,
      "loss": 0.1524,
      "step": 5247
    },
    {
      "epoch": 0.380331195419792,
      "grad_norm": 1.0042383670806885,
      "learning_rate": 0.00012395101094282195,
      "loss": 0.0634,
      "step": 5248
    },
    {
      "epoch": 0.38040366706526074,
      "grad_norm": 1.41143000125885,
      "learning_rate": 0.0001239365171389231,
      "loss": 0.0248,
      "step": 5249
    },
    {
      "epoch": 0.38047613871072944,
      "grad_norm": 0.8836860656738281,
      "learning_rate": 0.00012392202333502429,
      "loss": 0.0135,
      "step": 5250
    },
    {
      "epoch": 0.38054861035619814,
      "grad_norm": 1.72857666015625,
      "learning_rate": 0.00012390752953112544,
      "loss": 0.1063,
      "step": 5251
    },
    {
      "epoch": 0.38062108200166683,
      "grad_norm": 1.0896018743515015,
      "learning_rate": 0.00012389303572722663,
      "loss": 0.0249,
      "step": 5252
    },
    {
      "epoch": 0.3806935536471356,
      "grad_norm": 1.5343161821365356,
      "learning_rate": 0.00012387854192332778,
      "loss": 0.0836,
      "step": 5253
    },
    {
      "epoch": 0.3807660252926043,
      "grad_norm": 6.192693710327148,
      "learning_rate": 0.00012386404811942897,
      "loss": 0.2835,
      "step": 5254
    },
    {
      "epoch": 0.380838496938073,
      "grad_norm": 3.216331720352173,
      "learning_rate": 0.00012384955431553012,
      "loss": 0.0547,
      "step": 5255
    },
    {
      "epoch": 0.3809109685835417,
      "grad_norm": 0.25065678358078003,
      "learning_rate": 0.00012383506051163128,
      "loss": 0.0054,
      "step": 5256
    },
    {
      "epoch": 0.3809834402290104,
      "grad_norm": 1.5654363632202148,
      "learning_rate": 0.00012382056670773246,
      "loss": 0.1081,
      "step": 5257
    },
    {
      "epoch": 0.3810559118744791,
      "grad_norm": 2.2992146015167236,
      "learning_rate": 0.00012380607290383362,
      "loss": 0.1314,
      "step": 5258
    },
    {
      "epoch": 0.3811283835199478,
      "grad_norm": 1.270118236541748,
      "learning_rate": 0.00012379157909993477,
      "loss": 0.0341,
      "step": 5259
    },
    {
      "epoch": 0.3812008551654165,
      "grad_norm": 2.1353836059570312,
      "learning_rate": 0.00012377708529603596,
      "loss": 0.061,
      "step": 5260
    },
    {
      "epoch": 0.3812733268108852,
      "grad_norm": 0.6819027066230774,
      "learning_rate": 0.00012376259149213712,
      "loss": 0.0563,
      "step": 5261
    },
    {
      "epoch": 0.38134579845635397,
      "grad_norm": 1.0759329795837402,
      "learning_rate": 0.00012374809768823827,
      "loss": 0.0552,
      "step": 5262
    },
    {
      "epoch": 0.38141827010182267,
      "grad_norm": 3.6035709381103516,
      "learning_rate": 0.00012373360388433946,
      "loss": 0.1337,
      "step": 5263
    },
    {
      "epoch": 0.38149074174729136,
      "grad_norm": 1.2303615808486938,
      "learning_rate": 0.0001237191100804406,
      "loss": 0.104,
      "step": 5264
    },
    {
      "epoch": 0.38156321339276006,
      "grad_norm": 1.3488192558288574,
      "learning_rate": 0.00012370461627654177,
      "loss": 0.0276,
      "step": 5265
    },
    {
      "epoch": 0.3816356850382288,
      "grad_norm": 4.859374523162842,
      "learning_rate": 0.00012369012247264295,
      "loss": 0.1209,
      "step": 5266
    },
    {
      "epoch": 0.3817081566836975,
      "grad_norm": 1.9880014657974243,
      "learning_rate": 0.0001236756286687441,
      "loss": 0.0632,
      "step": 5267
    },
    {
      "epoch": 0.3817806283291662,
      "grad_norm": 5.568637371063232,
      "learning_rate": 0.00012366113486484526,
      "loss": 0.1468,
      "step": 5268
    },
    {
      "epoch": 0.3818530999746349,
      "grad_norm": 1.6463782787322998,
      "learning_rate": 0.00012364664106094645,
      "loss": 0.135,
      "step": 5269
    },
    {
      "epoch": 0.38192557162010365,
      "grad_norm": 0.5687738656997681,
      "learning_rate": 0.0001236321472570476,
      "loss": 0.0183,
      "step": 5270
    },
    {
      "epoch": 0.38199804326557235,
      "grad_norm": 1.5815141201019287,
      "learning_rate": 0.00012361765345314876,
      "loss": 0.0802,
      "step": 5271
    },
    {
      "epoch": 0.38207051491104105,
      "grad_norm": 3.2959046363830566,
      "learning_rate": 0.00012360315964924994,
      "loss": 0.1169,
      "step": 5272
    },
    {
      "epoch": 0.38214298655650975,
      "grad_norm": 1.379499912261963,
      "learning_rate": 0.0001235886658453511,
      "loss": 0.0431,
      "step": 5273
    },
    {
      "epoch": 0.3822154582019785,
      "grad_norm": 0.7933112978935242,
      "learning_rate": 0.00012357417204145228,
      "loss": 0.023,
      "step": 5274
    },
    {
      "epoch": 0.3822879298474472,
      "grad_norm": 0.9639958739280701,
      "learning_rate": 0.00012355967823755347,
      "loss": 0.0749,
      "step": 5275
    },
    {
      "epoch": 0.3823604014929159,
      "grad_norm": 2.374758005142212,
      "learning_rate": 0.00012354518443365462,
      "loss": 0.1246,
      "step": 5276
    },
    {
      "epoch": 0.3824328731383846,
      "grad_norm": 0.5087684988975525,
      "learning_rate": 0.00012353069062975578,
      "loss": 0.0362,
      "step": 5277
    },
    {
      "epoch": 0.38250534478385334,
      "grad_norm": 0.8543223738670349,
      "learning_rate": 0.00012351619682585697,
      "loss": 0.0306,
      "step": 5278
    },
    {
      "epoch": 0.38257781642932204,
      "grad_norm": 1.3627628087997437,
      "learning_rate": 0.00012350170302195812,
      "loss": 0.053,
      "step": 5279
    },
    {
      "epoch": 0.38265028807479073,
      "grad_norm": 0.5413772463798523,
      "learning_rate": 0.0001234872092180593,
      "loss": 0.0271,
      "step": 5280
    },
    {
      "epoch": 0.38272275972025943,
      "grad_norm": 2.6161434650421143,
      "learning_rate": 0.00012347271541416046,
      "loss": 0.0804,
      "step": 5281
    },
    {
      "epoch": 0.3827952313657282,
      "grad_norm": 5.90476131439209,
      "learning_rate": 0.00012345822161026162,
      "loss": 0.1037,
      "step": 5282
    },
    {
      "epoch": 0.3828677030111969,
      "grad_norm": 2.752765417098999,
      "learning_rate": 0.0001234437278063628,
      "loss": 0.1599,
      "step": 5283
    },
    {
      "epoch": 0.3829401746566656,
      "grad_norm": 2.557114601135254,
      "learning_rate": 0.00012342923400246396,
      "loss": 0.1326,
      "step": 5284
    },
    {
      "epoch": 0.3830126463021343,
      "grad_norm": 2.042854070663452,
      "learning_rate": 0.00012341474019856511,
      "loss": 0.1331,
      "step": 5285
    },
    {
      "epoch": 0.383085117947603,
      "grad_norm": 2.5742557048797607,
      "learning_rate": 0.0001234002463946663,
      "loss": 0.1735,
      "step": 5286
    },
    {
      "epoch": 0.3831575895930717,
      "grad_norm": 0.6381481885910034,
      "learning_rate": 0.00012338575259076745,
      "loss": 0.0212,
      "step": 5287
    },
    {
      "epoch": 0.3832300612385404,
      "grad_norm": 1.5817197561264038,
      "learning_rate": 0.0001233712587868686,
      "loss": 0.1073,
      "step": 5288
    },
    {
      "epoch": 0.3833025328840091,
      "grad_norm": 1.4154380559921265,
      "learning_rate": 0.0001233567649829698,
      "loss": 0.1114,
      "step": 5289
    },
    {
      "epoch": 0.3833750045294778,
      "grad_norm": 3.564901828765869,
      "learning_rate": 0.00012334227117907095,
      "loss": 0.1943,
      "step": 5290
    },
    {
      "epoch": 0.38344747617494657,
      "grad_norm": 1.4607455730438232,
      "learning_rate": 0.0001233277773751721,
      "loss": 0.0659,
      "step": 5291
    },
    {
      "epoch": 0.38351994782041526,
      "grad_norm": 1.2287976741790771,
      "learning_rate": 0.0001233132835712733,
      "loss": 0.0445,
      "step": 5292
    },
    {
      "epoch": 0.38359241946588396,
      "grad_norm": 2.0283634662628174,
      "learning_rate": 0.00012329878976737445,
      "loss": 0.1863,
      "step": 5293
    },
    {
      "epoch": 0.38366489111135266,
      "grad_norm": 1.6765925884246826,
      "learning_rate": 0.0001232842959634756,
      "loss": 0.0749,
      "step": 5294
    },
    {
      "epoch": 0.3837373627568214,
      "grad_norm": 2.909311532974243,
      "learning_rate": 0.0001232698021595768,
      "loss": 0.1309,
      "step": 5295
    },
    {
      "epoch": 0.3838098344022901,
      "grad_norm": 1.4657825231552124,
      "learning_rate": 0.00012325530835567794,
      "loss": 0.053,
      "step": 5296
    },
    {
      "epoch": 0.3838823060477588,
      "grad_norm": 2.037811040878296,
      "learning_rate": 0.00012324081455177913,
      "loss": 0.0177,
      "step": 5297
    },
    {
      "epoch": 0.3839547776932275,
      "grad_norm": 1.4807814359664917,
      "learning_rate": 0.00012322632074788028,
      "loss": 0.1251,
      "step": 5298
    },
    {
      "epoch": 0.38402724933869625,
      "grad_norm": 2.1302945613861084,
      "learning_rate": 0.00012321182694398147,
      "loss": 0.1198,
      "step": 5299
    },
    {
      "epoch": 0.38409972098416495,
      "grad_norm": 3.4337332248687744,
      "learning_rate": 0.00012319733314008262,
      "loss": 0.0927,
      "step": 5300
    },
    {
      "epoch": 0.38417219262963365,
      "grad_norm": 3.913452386856079,
      "learning_rate": 0.0001231828393361838,
      "loss": 0.1816,
      "step": 5301
    },
    {
      "epoch": 0.38424466427510234,
      "grad_norm": 1.8939839601516724,
      "learning_rate": 0.00012316834553228496,
      "loss": 0.1052,
      "step": 5302
    },
    {
      "epoch": 0.3843171359205711,
      "grad_norm": 2.3497095108032227,
      "learning_rate": 0.00012315385172838612,
      "loss": 0.1095,
      "step": 5303
    },
    {
      "epoch": 0.3843896075660398,
      "grad_norm": 2.0599114894866943,
      "learning_rate": 0.0001231393579244873,
      "loss": 0.0917,
      "step": 5304
    },
    {
      "epoch": 0.3844620792115085,
      "grad_norm": 2.6270225048065186,
      "learning_rate": 0.00012312486412058846,
      "loss": 0.1087,
      "step": 5305
    },
    {
      "epoch": 0.3845345508569772,
      "grad_norm": 1.9469804763793945,
      "learning_rate": 0.00012311037031668962,
      "loss": 0.069,
      "step": 5306
    },
    {
      "epoch": 0.38460702250244594,
      "grad_norm": 1.394627571105957,
      "learning_rate": 0.0001230958765127908,
      "loss": 0.081,
      "step": 5307
    },
    {
      "epoch": 0.38467949414791464,
      "grad_norm": 1.1781065464019775,
      "learning_rate": 0.00012308138270889196,
      "loss": 0.0443,
      "step": 5308
    },
    {
      "epoch": 0.38475196579338333,
      "grad_norm": 2.895846128463745,
      "learning_rate": 0.00012306688890499311,
      "loss": 0.049,
      "step": 5309
    },
    {
      "epoch": 0.38482443743885203,
      "grad_norm": 1.320977807044983,
      "learning_rate": 0.0001230523951010943,
      "loss": 0.1015,
      "step": 5310
    },
    {
      "epoch": 0.3848969090843208,
      "grad_norm": 2.5227088928222656,
      "learning_rate": 0.00012303790129719545,
      "loss": 0.186,
      "step": 5311
    },
    {
      "epoch": 0.3849693807297895,
      "grad_norm": 1.2484571933746338,
      "learning_rate": 0.0001230234074932966,
      "loss": 0.0575,
      "step": 5312
    },
    {
      "epoch": 0.3850418523752582,
      "grad_norm": 0.5608006119728088,
      "learning_rate": 0.0001230089136893978,
      "loss": 0.037,
      "step": 5313
    },
    {
      "epoch": 0.3851143240207269,
      "grad_norm": 0.7535451054573059,
      "learning_rate": 0.00012299441988549895,
      "loss": 0.0289,
      "step": 5314
    },
    {
      "epoch": 0.3851867956661956,
      "grad_norm": 2.697620153427124,
      "learning_rate": 0.0001229799260816001,
      "loss": 0.0364,
      "step": 5315
    },
    {
      "epoch": 0.3852592673116643,
      "grad_norm": 3.203831195831299,
      "learning_rate": 0.0001229654322777013,
      "loss": 0.0378,
      "step": 5316
    },
    {
      "epoch": 0.385331738957133,
      "grad_norm": 4.904008865356445,
      "learning_rate": 0.00012295093847380245,
      "loss": 0.1303,
      "step": 5317
    },
    {
      "epoch": 0.3854042106026017,
      "grad_norm": 1.7917354106903076,
      "learning_rate": 0.0001229364446699036,
      "loss": 0.1085,
      "step": 5318
    },
    {
      "epoch": 0.38547668224807047,
      "grad_norm": 1.1646511554718018,
      "learning_rate": 0.0001229219508660048,
      "loss": 0.0555,
      "step": 5319
    },
    {
      "epoch": 0.38554915389353916,
      "grad_norm": 4.32786750793457,
      "learning_rate": 0.00012290745706210594,
      "loss": 0.1533,
      "step": 5320
    },
    {
      "epoch": 0.38562162553900786,
      "grad_norm": 0.5129909515380859,
      "learning_rate": 0.00012289296325820713,
      "loss": 0.0143,
      "step": 5321
    },
    {
      "epoch": 0.38569409718447656,
      "grad_norm": 2.0798635482788086,
      "learning_rate": 0.0001228784694543083,
      "loss": 0.0946,
      "step": 5322
    },
    {
      "epoch": 0.3857665688299453,
      "grad_norm": 1.5264065265655518,
      "learning_rate": 0.00012286397565040947,
      "loss": 0.027,
      "step": 5323
    },
    {
      "epoch": 0.385839040475414,
      "grad_norm": 1.2706325054168701,
      "learning_rate": 0.00012284948184651062,
      "loss": 0.0679,
      "step": 5324
    },
    {
      "epoch": 0.3859115121208827,
      "grad_norm": 2.3494346141815186,
      "learning_rate": 0.0001228349880426118,
      "loss": 0.1628,
      "step": 5325
    },
    {
      "epoch": 0.3859839837663514,
      "grad_norm": 0.728603184223175,
      "learning_rate": 0.00012282049423871296,
      "loss": 0.0591,
      "step": 5326
    },
    {
      "epoch": 0.3860564554118201,
      "grad_norm": 0.9138764142990112,
      "learning_rate": 0.00012280600043481412,
      "loss": 0.0596,
      "step": 5327
    },
    {
      "epoch": 0.38612892705728885,
      "grad_norm": 0.7609338164329529,
      "learning_rate": 0.0001227915066309153,
      "loss": 0.0665,
      "step": 5328
    },
    {
      "epoch": 0.38620139870275755,
      "grad_norm": 0.6826043725013733,
      "learning_rate": 0.00012277701282701646,
      "loss": 0.0333,
      "step": 5329
    },
    {
      "epoch": 0.38627387034822624,
      "grad_norm": 1.3725221157073975,
      "learning_rate": 0.00012276251902311762,
      "loss": 0.0748,
      "step": 5330
    },
    {
      "epoch": 0.38634634199369494,
      "grad_norm": 2.0793495178222656,
      "learning_rate": 0.0001227480252192188,
      "loss": 0.1377,
      "step": 5331
    },
    {
      "epoch": 0.3864188136391637,
      "grad_norm": 1.6309401988983154,
      "learning_rate": 0.00012273353141531996,
      "loss": 0.0938,
      "step": 5332
    },
    {
      "epoch": 0.3864912852846324,
      "grad_norm": 1.3322561979293823,
      "learning_rate": 0.00012271903761142111,
      "loss": 0.0751,
      "step": 5333
    },
    {
      "epoch": 0.3865637569301011,
      "grad_norm": 1.7853469848632812,
      "learning_rate": 0.0001227045438075223,
      "loss": 0.1373,
      "step": 5334
    },
    {
      "epoch": 0.3866362285755698,
      "grad_norm": 0.4864489734172821,
      "learning_rate": 0.00012269005000362345,
      "loss": 0.031,
      "step": 5335
    },
    {
      "epoch": 0.38670870022103854,
      "grad_norm": 1.1554697751998901,
      "learning_rate": 0.0001226755561997246,
      "loss": 0.061,
      "step": 5336
    },
    {
      "epoch": 0.38678117186650723,
      "grad_norm": 0.7281550765037537,
      "learning_rate": 0.0001226610623958258,
      "loss": 0.0321,
      "step": 5337
    },
    {
      "epoch": 0.38685364351197593,
      "grad_norm": 2.7103047370910645,
      "learning_rate": 0.00012264656859192695,
      "loss": 0.0895,
      "step": 5338
    },
    {
      "epoch": 0.38692611515744463,
      "grad_norm": 3.217900037765503,
      "learning_rate": 0.0001226320747880281,
      "loss": 0.0858,
      "step": 5339
    },
    {
      "epoch": 0.3869985868029134,
      "grad_norm": 0.805898129940033,
      "learning_rate": 0.0001226175809841293,
      "loss": 0.0154,
      "step": 5340
    },
    {
      "epoch": 0.3870710584483821,
      "grad_norm": 0.8165409564971924,
      "learning_rate": 0.00012260308718023045,
      "loss": 0.0588,
      "step": 5341
    },
    {
      "epoch": 0.3871435300938508,
      "grad_norm": 1.6154617071151733,
      "learning_rate": 0.00012258859337633163,
      "loss": 0.1127,
      "step": 5342
    },
    {
      "epoch": 0.38721600173931947,
      "grad_norm": 1.8436187505722046,
      "learning_rate": 0.0001225740995724328,
      "loss": 0.1061,
      "step": 5343
    },
    {
      "epoch": 0.3872884733847882,
      "grad_norm": 3.2857484817504883,
      "learning_rate": 0.00012255960576853397,
      "loss": 0.2177,
      "step": 5344
    },
    {
      "epoch": 0.3873609450302569,
      "grad_norm": 3.3726837635040283,
      "learning_rate": 0.00012254511196463513,
      "loss": 0.053,
      "step": 5345
    },
    {
      "epoch": 0.3874334166757256,
      "grad_norm": 1.308607578277588,
      "learning_rate": 0.0001225306181607363,
      "loss": 0.0721,
      "step": 5346
    },
    {
      "epoch": 0.3875058883211943,
      "grad_norm": 1.6286187171936035,
      "learning_rate": 0.00012251612435683747,
      "loss": 0.1076,
      "step": 5347
    },
    {
      "epoch": 0.38757835996666307,
      "grad_norm": 1.016109824180603,
      "learning_rate": 0.00012250163055293862,
      "loss": 0.0417,
      "step": 5348
    },
    {
      "epoch": 0.38765083161213176,
      "grad_norm": 1.1345794200897217,
      "learning_rate": 0.0001224871367490398,
      "loss": 0.0307,
      "step": 5349
    },
    {
      "epoch": 0.38772330325760046,
      "grad_norm": 1.1570405960083008,
      "learning_rate": 0.00012247264294514096,
      "loss": 0.0578,
      "step": 5350
    },
    {
      "epoch": 0.38779577490306916,
      "grad_norm": 1.1968985795974731,
      "learning_rate": 0.00012245814914124212,
      "loss": 0.0611,
      "step": 5351
    },
    {
      "epoch": 0.3878682465485379,
      "grad_norm": 1.7519980669021606,
      "learning_rate": 0.0001224436553373433,
      "loss": 0.1284,
      "step": 5352
    },
    {
      "epoch": 0.3879407181940066,
      "grad_norm": 1.6798080205917358,
      "learning_rate": 0.00012242916153344446,
      "loss": 0.0677,
      "step": 5353
    },
    {
      "epoch": 0.3880131898394753,
      "grad_norm": 1.5016121864318848,
      "learning_rate": 0.00012241466772954562,
      "loss": 0.0657,
      "step": 5354
    },
    {
      "epoch": 0.388085661484944,
      "grad_norm": 2.933516263961792,
      "learning_rate": 0.0001224001739256468,
      "loss": 0.1418,
      "step": 5355
    },
    {
      "epoch": 0.38815813313041275,
      "grad_norm": 1.3156962394714355,
      "learning_rate": 0.00012238568012174796,
      "loss": 0.0431,
      "step": 5356
    },
    {
      "epoch": 0.38823060477588145,
      "grad_norm": 0.7080417275428772,
      "learning_rate": 0.0001223711863178491,
      "loss": 0.0729,
      "step": 5357
    },
    {
      "epoch": 0.38830307642135015,
      "grad_norm": 0.4516972601413727,
      "learning_rate": 0.0001223566925139503,
      "loss": 0.0245,
      "step": 5358
    },
    {
      "epoch": 0.38837554806681884,
      "grad_norm": 1.053711175918579,
      "learning_rate": 0.00012234219871005145,
      "loss": 0.1019,
      "step": 5359
    },
    {
      "epoch": 0.38844801971228754,
      "grad_norm": 0.6925272941589355,
      "learning_rate": 0.0001223277049061526,
      "loss": 0.0733,
      "step": 5360
    },
    {
      "epoch": 0.3885204913577563,
      "grad_norm": 1.4023659229278564,
      "learning_rate": 0.0001223132111022538,
      "loss": 0.0938,
      "step": 5361
    },
    {
      "epoch": 0.388592963003225,
      "grad_norm": 1.7203731536865234,
      "learning_rate": 0.00012229871729835495,
      "loss": 0.1209,
      "step": 5362
    },
    {
      "epoch": 0.3886654346486937,
      "grad_norm": 1.061463475227356,
      "learning_rate": 0.0001222842234944561,
      "loss": 0.0713,
      "step": 5363
    },
    {
      "epoch": 0.3887379062941624,
      "grad_norm": 0.8627020716667175,
      "learning_rate": 0.0001222697296905573,
      "loss": 0.0552,
      "step": 5364
    },
    {
      "epoch": 0.38881037793963114,
      "grad_norm": 2.6545116901397705,
      "learning_rate": 0.00012225523588665845,
      "loss": 0.0565,
      "step": 5365
    },
    {
      "epoch": 0.38888284958509983,
      "grad_norm": 2.949598789215088,
      "learning_rate": 0.00012224074208275963,
      "loss": 0.1215,
      "step": 5366
    },
    {
      "epoch": 0.38895532123056853,
      "grad_norm": 0.5254750847816467,
      "learning_rate": 0.0001222262482788608,
      "loss": 0.0301,
      "step": 5367
    },
    {
      "epoch": 0.3890277928760372,
      "grad_norm": 0.6382767558097839,
      "learning_rate": 0.00012221175447496197,
      "loss": 0.0226,
      "step": 5368
    },
    {
      "epoch": 0.389100264521506,
      "grad_norm": 1.1459777355194092,
      "learning_rate": 0.00012219726067106313,
      "loss": 0.0441,
      "step": 5369
    },
    {
      "epoch": 0.3891727361669747,
      "grad_norm": 0.6406110525131226,
      "learning_rate": 0.0001221827668671643,
      "loss": 0.0279,
      "step": 5370
    },
    {
      "epoch": 0.3892452078124434,
      "grad_norm": 2.6583096981048584,
      "learning_rate": 0.00012216827306326547,
      "loss": 0.1033,
      "step": 5371
    },
    {
      "epoch": 0.38931767945791207,
      "grad_norm": 0.21090632677078247,
      "learning_rate": 0.00012215377925936662,
      "loss": 0.005,
      "step": 5372
    },
    {
      "epoch": 0.3893901511033808,
      "grad_norm": 1.7328567504882812,
      "learning_rate": 0.0001221392854554678,
      "loss": 0.0746,
      "step": 5373
    },
    {
      "epoch": 0.3894626227488495,
      "grad_norm": 0.45613405108451843,
      "learning_rate": 0.00012212479165156896,
      "loss": 0.0169,
      "step": 5374
    },
    {
      "epoch": 0.3895350943943182,
      "grad_norm": 1.532228946685791,
      "learning_rate": 0.00012211029784767012,
      "loss": 0.0607,
      "step": 5375
    },
    {
      "epoch": 0.3896075660397869,
      "grad_norm": 2.607914686203003,
      "learning_rate": 0.0001220958040437713,
      "loss": 0.0766,
      "step": 5376
    },
    {
      "epoch": 0.38968003768525566,
      "grad_norm": 1.1171025037765503,
      "learning_rate": 0.00012208131023987246,
      "loss": 0.0383,
      "step": 5377
    },
    {
      "epoch": 0.38975250933072436,
      "grad_norm": 2.219050884246826,
      "learning_rate": 0.00012206681643597362,
      "loss": 0.1271,
      "step": 5378
    },
    {
      "epoch": 0.38982498097619306,
      "grad_norm": 1.5764437913894653,
      "learning_rate": 0.0001220523226320748,
      "loss": 0.0857,
      "step": 5379
    },
    {
      "epoch": 0.38989745262166176,
      "grad_norm": 1.300675392150879,
      "learning_rate": 0.00012203782882817596,
      "loss": 0.0708,
      "step": 5380
    },
    {
      "epoch": 0.3899699242671305,
      "grad_norm": 2.392082452774048,
      "learning_rate": 0.00012202333502427711,
      "loss": 0.0545,
      "step": 5381
    },
    {
      "epoch": 0.3900423959125992,
      "grad_norm": 2.2469632625579834,
      "learning_rate": 0.0001220088412203783,
      "loss": 0.1217,
      "step": 5382
    },
    {
      "epoch": 0.3901148675580679,
      "grad_norm": 1.821617603302002,
      "learning_rate": 0.00012199434741647945,
      "loss": 0.1112,
      "step": 5383
    },
    {
      "epoch": 0.3901873392035366,
      "grad_norm": 1.9842755794525146,
      "learning_rate": 0.00012197985361258062,
      "loss": 0.0483,
      "step": 5384
    },
    {
      "epoch": 0.39025981084900535,
      "grad_norm": 1.092300534248352,
      "learning_rate": 0.0001219653598086818,
      "loss": 0.0947,
      "step": 5385
    },
    {
      "epoch": 0.39033228249447405,
      "grad_norm": 2.0550196170806885,
      "learning_rate": 0.00012195086600478296,
      "loss": 0.0816,
      "step": 5386
    },
    {
      "epoch": 0.39040475413994274,
      "grad_norm": 1.0803617238998413,
      "learning_rate": 0.00012193637220088412,
      "loss": 0.0473,
      "step": 5387
    },
    {
      "epoch": 0.39047722578541144,
      "grad_norm": 0.2692590355873108,
      "learning_rate": 0.0001219218783969853,
      "loss": 0.0279,
      "step": 5388
    },
    {
      "epoch": 0.3905496974308802,
      "grad_norm": 1.2439000606536865,
      "learning_rate": 0.00012190738459308646,
      "loss": 0.0459,
      "step": 5389
    },
    {
      "epoch": 0.3906221690763489,
      "grad_norm": 4.709046363830566,
      "learning_rate": 0.00012189289078918762,
      "loss": 0.2129,
      "step": 5390
    },
    {
      "epoch": 0.3906946407218176,
      "grad_norm": 1.2050386667251587,
      "learning_rate": 0.0001218783969852888,
      "loss": 0.0564,
      "step": 5391
    },
    {
      "epoch": 0.3907671123672863,
      "grad_norm": 2.343848943710327,
      "learning_rate": 0.00012186390318138996,
      "loss": 0.0778,
      "step": 5392
    },
    {
      "epoch": 0.39083958401275504,
      "grad_norm": 5.624362468719482,
      "learning_rate": 0.00012184940937749111,
      "loss": 0.0616,
      "step": 5393
    },
    {
      "epoch": 0.39091205565822373,
      "grad_norm": 0.7315155267715454,
      "learning_rate": 0.0001218349155735923,
      "loss": 0.0502,
      "step": 5394
    },
    {
      "epoch": 0.39098452730369243,
      "grad_norm": 1.0166999101638794,
      "learning_rate": 0.00012182042176969347,
      "loss": 0.0582,
      "step": 5395
    },
    {
      "epoch": 0.3910569989491611,
      "grad_norm": 1.5142149925231934,
      "learning_rate": 0.00012180592796579462,
      "loss": 0.0993,
      "step": 5396
    },
    {
      "epoch": 0.3911294705946298,
      "grad_norm": 1.3828341960906982,
      "learning_rate": 0.0001217914341618958,
      "loss": 0.1431,
      "step": 5397
    },
    {
      "epoch": 0.3912019422400986,
      "grad_norm": 1.177597999572754,
      "learning_rate": 0.00012177694035799696,
      "loss": 0.0746,
      "step": 5398
    },
    {
      "epoch": 0.3912744138855673,
      "grad_norm": 0.406030535697937,
      "learning_rate": 0.00012176244655409812,
      "loss": 0.0187,
      "step": 5399
    },
    {
      "epoch": 0.39134688553103597,
      "grad_norm": 2.757439136505127,
      "learning_rate": 0.0001217479527501993,
      "loss": 0.072,
      "step": 5400
    },
    {
      "epoch": 0.39141935717650467,
      "grad_norm": 1.0849498510360718,
      "learning_rate": 0.00012173345894630046,
      "loss": 0.0949,
      "step": 5401
    },
    {
      "epoch": 0.3914918288219734,
      "grad_norm": 0.7401200532913208,
      "learning_rate": 0.00012171896514240162,
      "loss": 0.0472,
      "step": 5402
    },
    {
      "epoch": 0.3915643004674421,
      "grad_norm": 2.5295920372009277,
      "learning_rate": 0.0001217044713385028,
      "loss": 0.1855,
      "step": 5403
    },
    {
      "epoch": 0.3916367721129108,
      "grad_norm": 1.7034302949905396,
      "learning_rate": 0.00012168997753460396,
      "loss": 0.1464,
      "step": 5404
    },
    {
      "epoch": 0.3917092437583795,
      "grad_norm": 0.5023683905601501,
      "learning_rate": 0.00012167548373070513,
      "loss": 0.0257,
      "step": 5405
    },
    {
      "epoch": 0.39178171540384826,
      "grad_norm": 2.1925041675567627,
      "learning_rate": 0.0001216609899268063,
      "loss": 0.1478,
      "step": 5406
    },
    {
      "epoch": 0.39185418704931696,
      "grad_norm": 2.493407726287842,
      "learning_rate": 0.00012164649612290747,
      "loss": 0.1089,
      "step": 5407
    },
    {
      "epoch": 0.39192665869478566,
      "grad_norm": 1.7405081987380981,
      "learning_rate": 0.00012163200231900862,
      "loss": 0.0855,
      "step": 5408
    },
    {
      "epoch": 0.39199913034025435,
      "grad_norm": 2.0777478218078613,
      "learning_rate": 0.0001216175085151098,
      "loss": 0.0987,
      "step": 5409
    },
    {
      "epoch": 0.3920716019857231,
      "grad_norm": 0.42936351895332336,
      "learning_rate": 0.00012160301471121096,
      "loss": 0.009,
      "step": 5410
    },
    {
      "epoch": 0.3921440736311918,
      "grad_norm": 2.71258282661438,
      "learning_rate": 0.00012158852090731212,
      "loss": 0.1045,
      "step": 5411
    },
    {
      "epoch": 0.3922165452766605,
      "grad_norm": 1.0433510541915894,
      "learning_rate": 0.0001215740271034133,
      "loss": 0.1243,
      "step": 5412
    },
    {
      "epoch": 0.3922890169221292,
      "grad_norm": 0.7788964509963989,
      "learning_rate": 0.00012155953329951446,
      "loss": 0.0495,
      "step": 5413
    },
    {
      "epoch": 0.39236148856759795,
      "grad_norm": 0.6026172637939453,
      "learning_rate": 0.00012154503949561562,
      "loss": 0.0619,
      "step": 5414
    },
    {
      "epoch": 0.39243396021306665,
      "grad_norm": 1.340227484703064,
      "learning_rate": 0.0001215305456917168,
      "loss": 0.0415,
      "step": 5415
    },
    {
      "epoch": 0.39250643185853534,
      "grad_norm": 1.2010278701782227,
      "learning_rate": 0.00012151605188781796,
      "loss": 0.0586,
      "step": 5416
    },
    {
      "epoch": 0.39257890350400404,
      "grad_norm": 1.4243961572647095,
      "learning_rate": 0.00012150155808391913,
      "loss": 0.0746,
      "step": 5417
    },
    {
      "epoch": 0.3926513751494728,
      "grad_norm": 1.6272705793380737,
      "learning_rate": 0.0001214870642800203,
      "loss": 0.057,
      "step": 5418
    },
    {
      "epoch": 0.3927238467949415,
      "grad_norm": 5.681696891784668,
      "learning_rate": 0.00012147257047612147,
      "loss": 0.1571,
      "step": 5419
    },
    {
      "epoch": 0.3927963184404102,
      "grad_norm": 0.8654647469520569,
      "learning_rate": 0.00012145807667222262,
      "loss": 0.0329,
      "step": 5420
    },
    {
      "epoch": 0.3928687900858789,
      "grad_norm": 0.9152697920799255,
      "learning_rate": 0.0001214435828683238,
      "loss": 0.0623,
      "step": 5421
    },
    {
      "epoch": 0.39294126173134764,
      "grad_norm": 2.630847215652466,
      "learning_rate": 0.00012142908906442496,
      "loss": 0.1188,
      "step": 5422
    },
    {
      "epoch": 0.39301373337681633,
      "grad_norm": 0.38529103994369507,
      "learning_rate": 0.00012141459526052612,
      "loss": 0.0252,
      "step": 5423
    },
    {
      "epoch": 0.39308620502228503,
      "grad_norm": 0.5839857459068298,
      "learning_rate": 0.0001214001014566273,
      "loss": 0.0437,
      "step": 5424
    },
    {
      "epoch": 0.3931586766677537,
      "grad_norm": 1.4064135551452637,
      "learning_rate": 0.00012138560765272846,
      "loss": 0.1055,
      "step": 5425
    },
    {
      "epoch": 0.3932311483132225,
      "grad_norm": 0.8895629644393921,
      "learning_rate": 0.00012137111384882962,
      "loss": 0.0972,
      "step": 5426
    },
    {
      "epoch": 0.3933036199586912,
      "grad_norm": 1.1432404518127441,
      "learning_rate": 0.0001213566200449308,
      "loss": 0.0396,
      "step": 5427
    },
    {
      "epoch": 0.39337609160415987,
      "grad_norm": 0.8091039061546326,
      "learning_rate": 0.00012134212624103196,
      "loss": 0.0323,
      "step": 5428
    },
    {
      "epoch": 0.39344856324962857,
      "grad_norm": 0.6660820841789246,
      "learning_rate": 0.00012132763243713313,
      "loss": 0.0353,
      "step": 5429
    },
    {
      "epoch": 0.39352103489509727,
      "grad_norm": 1.0560545921325684,
      "learning_rate": 0.0001213131386332343,
      "loss": 0.0566,
      "step": 5430
    },
    {
      "epoch": 0.393593506540566,
      "grad_norm": 0.4018799066543579,
      "learning_rate": 0.00012129864482933547,
      "loss": 0.0205,
      "step": 5431
    },
    {
      "epoch": 0.3936659781860347,
      "grad_norm": 0.622308075428009,
      "learning_rate": 0.00012128415102543662,
      "loss": 0.0467,
      "step": 5432
    },
    {
      "epoch": 0.3937384498315034,
      "grad_norm": 0.5466733574867249,
      "learning_rate": 0.0001212696572215378,
      "loss": 0.0464,
      "step": 5433
    },
    {
      "epoch": 0.3938109214769721,
      "grad_norm": 1.7190483808517456,
      "learning_rate": 0.00012125516341763896,
      "loss": 0.0403,
      "step": 5434
    },
    {
      "epoch": 0.39388339312244086,
      "grad_norm": 2.55298113822937,
      "learning_rate": 0.00012124066961374012,
      "loss": 0.0379,
      "step": 5435
    },
    {
      "epoch": 0.39395586476790956,
      "grad_norm": 3.9043657779693604,
      "learning_rate": 0.0001212261758098413,
      "loss": 0.1021,
      "step": 5436
    },
    {
      "epoch": 0.39402833641337826,
      "grad_norm": 1.468825101852417,
      "learning_rate": 0.00012121168200594246,
      "loss": 0.0667,
      "step": 5437
    },
    {
      "epoch": 0.39410080805884695,
      "grad_norm": 1.1942076683044434,
      "learning_rate": 0.00012119718820204362,
      "loss": 0.0261,
      "step": 5438
    },
    {
      "epoch": 0.3941732797043157,
      "grad_norm": 1.2203937768936157,
      "learning_rate": 0.0001211826943981448,
      "loss": 0.0588,
      "step": 5439
    },
    {
      "epoch": 0.3942457513497844,
      "grad_norm": 1.5607250928878784,
      "learning_rate": 0.00012116820059424596,
      "loss": 0.0244,
      "step": 5440
    },
    {
      "epoch": 0.3943182229952531,
      "grad_norm": 2.501364231109619,
      "learning_rate": 0.00012115370679034714,
      "loss": 0.124,
      "step": 5441
    },
    {
      "epoch": 0.3943906946407218,
      "grad_norm": 2.7348992824554443,
      "learning_rate": 0.00012113921298644831,
      "loss": 0.2047,
      "step": 5442
    },
    {
      "epoch": 0.39446316628619055,
      "grad_norm": 2.2797861099243164,
      "learning_rate": 0.00012112471918254947,
      "loss": 0.2339,
      "step": 5443
    },
    {
      "epoch": 0.39453563793165924,
      "grad_norm": 1.2268317937850952,
      "learning_rate": 0.00012111022537865065,
      "loss": 0.0494,
      "step": 5444
    },
    {
      "epoch": 0.39460810957712794,
      "grad_norm": 3.3018388748168945,
      "learning_rate": 0.0001210957315747518,
      "loss": 0.1268,
      "step": 5445
    },
    {
      "epoch": 0.39468058122259664,
      "grad_norm": 1.4277299642562866,
      "learning_rate": 0.00012108123777085296,
      "loss": 0.0286,
      "step": 5446
    },
    {
      "epoch": 0.3947530528680654,
      "grad_norm": 0.5941639542579651,
      "learning_rate": 0.00012106674396695415,
      "loss": 0.0452,
      "step": 5447
    },
    {
      "epoch": 0.3948255245135341,
      "grad_norm": 0.9210607409477234,
      "learning_rate": 0.0001210522501630553,
      "loss": 0.074,
      "step": 5448
    },
    {
      "epoch": 0.3948979961590028,
      "grad_norm": 7.759204864501953,
      "learning_rate": 0.00012103775635915646,
      "loss": 0.0781,
      "step": 5449
    },
    {
      "epoch": 0.3949704678044715,
      "grad_norm": 0.9796592593193054,
      "learning_rate": 0.00012102326255525764,
      "loss": 0.0622,
      "step": 5450
    },
    {
      "epoch": 0.39504293944994023,
      "grad_norm": 1.6616265773773193,
      "learning_rate": 0.0001210087687513588,
      "loss": 0.0729,
      "step": 5451
    },
    {
      "epoch": 0.39511541109540893,
      "grad_norm": 1.822331190109253,
      "learning_rate": 0.00012099427494745997,
      "loss": 0.082,
      "step": 5452
    },
    {
      "epoch": 0.3951878827408776,
      "grad_norm": 0.6575461626052856,
      "learning_rate": 0.00012097978114356114,
      "loss": 0.0424,
      "step": 5453
    },
    {
      "epoch": 0.3952603543863463,
      "grad_norm": 1.4360071420669556,
      "learning_rate": 0.00012096528733966231,
      "loss": 0.0543,
      "step": 5454
    },
    {
      "epoch": 0.3953328260318151,
      "grad_norm": 1.8835432529449463,
      "learning_rate": 0.00012095079353576347,
      "loss": 0.0551,
      "step": 5455
    },
    {
      "epoch": 0.3954052976772838,
      "grad_norm": 0.6537834405899048,
      "learning_rate": 0.00012093629973186465,
      "loss": 0.0384,
      "step": 5456
    },
    {
      "epoch": 0.39547776932275247,
      "grad_norm": 1.055687427520752,
      "learning_rate": 0.0001209218059279658,
      "loss": 0.0561,
      "step": 5457
    },
    {
      "epoch": 0.39555024096822117,
      "grad_norm": 0.811427891254425,
      "learning_rate": 0.00012090731212406696,
      "loss": 0.0258,
      "step": 5458
    },
    {
      "epoch": 0.3956227126136899,
      "grad_norm": 1.5620816946029663,
      "learning_rate": 0.00012089281832016815,
      "loss": 0.0792,
      "step": 5459
    },
    {
      "epoch": 0.3956951842591586,
      "grad_norm": 2.4680655002593994,
      "learning_rate": 0.0001208783245162693,
      "loss": 0.1134,
      "step": 5460
    },
    {
      "epoch": 0.3957676559046273,
      "grad_norm": 0.4536907970905304,
      "learning_rate": 0.00012086383071237046,
      "loss": 0.0189,
      "step": 5461
    },
    {
      "epoch": 0.395840127550096,
      "grad_norm": 1.464381456375122,
      "learning_rate": 0.00012084933690847164,
      "loss": 0.0398,
      "step": 5462
    },
    {
      "epoch": 0.39591259919556476,
      "grad_norm": 1.5011759996414185,
      "learning_rate": 0.0001208348431045728,
      "loss": 0.0538,
      "step": 5463
    },
    {
      "epoch": 0.39598507084103346,
      "grad_norm": 1.5366342067718506,
      "learning_rate": 0.00012082034930067397,
      "loss": 0.0796,
      "step": 5464
    },
    {
      "epoch": 0.39605754248650216,
      "grad_norm": 2.503854274749756,
      "learning_rate": 0.00012080585549677514,
      "loss": 0.106,
      "step": 5465
    },
    {
      "epoch": 0.39613001413197085,
      "grad_norm": 4.9995341300964355,
      "learning_rate": 0.00012079136169287631,
      "loss": 0.1612,
      "step": 5466
    },
    {
      "epoch": 0.39620248577743955,
      "grad_norm": 3.3703453540802,
      "learning_rate": 0.00012077686788897747,
      "loss": 0.0861,
      "step": 5467
    },
    {
      "epoch": 0.3962749574229083,
      "grad_norm": 2.4779891967773438,
      "learning_rate": 0.00012076237408507865,
      "loss": 0.1281,
      "step": 5468
    },
    {
      "epoch": 0.396347429068377,
      "grad_norm": 2.4485867023468018,
      "learning_rate": 0.0001207478802811798,
      "loss": 0.1108,
      "step": 5469
    },
    {
      "epoch": 0.3964199007138457,
      "grad_norm": 1.3620960712432861,
      "learning_rate": 0.00012073338647728096,
      "loss": 0.0842,
      "step": 5470
    },
    {
      "epoch": 0.3964923723593144,
      "grad_norm": 1.9135711193084717,
      "learning_rate": 0.00012071889267338215,
      "loss": 0.1224,
      "step": 5471
    },
    {
      "epoch": 0.39656484400478315,
      "grad_norm": 0.6640616655349731,
      "learning_rate": 0.0001207043988694833,
      "loss": 0.0289,
      "step": 5472
    },
    {
      "epoch": 0.39663731565025184,
      "grad_norm": 0.6871441006660461,
      "learning_rate": 0.00012068990506558446,
      "loss": 0.0452,
      "step": 5473
    },
    {
      "epoch": 0.39670978729572054,
      "grad_norm": 0.45829740166664124,
      "learning_rate": 0.00012067541126168564,
      "loss": 0.0173,
      "step": 5474
    },
    {
      "epoch": 0.39678225894118924,
      "grad_norm": 2.6640701293945312,
      "learning_rate": 0.0001206609174577868,
      "loss": 0.0972,
      "step": 5475
    },
    {
      "epoch": 0.396854730586658,
      "grad_norm": 0.9771709442138672,
      "learning_rate": 0.00012064642365388797,
      "loss": 0.0578,
      "step": 5476
    },
    {
      "epoch": 0.3969272022321267,
      "grad_norm": 3.08383846282959,
      "learning_rate": 0.00012063192984998914,
      "loss": 0.077,
      "step": 5477
    },
    {
      "epoch": 0.3969996738775954,
      "grad_norm": 2.0453662872314453,
      "learning_rate": 0.00012061743604609031,
      "loss": 0.0437,
      "step": 5478
    },
    {
      "epoch": 0.3970721455230641,
      "grad_norm": 0.9947059154510498,
      "learning_rate": 0.00012060294224219146,
      "loss": 0.0772,
      "step": 5479
    },
    {
      "epoch": 0.39714461716853283,
      "grad_norm": 2.1453864574432373,
      "learning_rate": 0.00012058844843829265,
      "loss": 0.0695,
      "step": 5480
    },
    {
      "epoch": 0.39721708881400153,
      "grad_norm": 0.752974271774292,
      "learning_rate": 0.0001205739546343938,
      "loss": 0.0567,
      "step": 5481
    },
    {
      "epoch": 0.3972895604594702,
      "grad_norm": 0.5305511951446533,
      "learning_rate": 0.00012055946083049496,
      "loss": 0.0151,
      "step": 5482
    },
    {
      "epoch": 0.3973620321049389,
      "grad_norm": 2.1522376537323,
      "learning_rate": 0.00012054496702659615,
      "loss": 0.1036,
      "step": 5483
    },
    {
      "epoch": 0.3974345037504077,
      "grad_norm": 0.6587530970573425,
      "learning_rate": 0.0001205304732226973,
      "loss": 0.0226,
      "step": 5484
    },
    {
      "epoch": 0.39750697539587637,
      "grad_norm": 0.2696113586425781,
      "learning_rate": 0.00012051597941879846,
      "loss": 0.0066,
      "step": 5485
    },
    {
      "epoch": 0.39757944704134507,
      "grad_norm": 3.471079111099243,
      "learning_rate": 0.00012050148561489964,
      "loss": 0.209,
      "step": 5486
    },
    {
      "epoch": 0.39765191868681377,
      "grad_norm": 2.8217785358428955,
      "learning_rate": 0.0001204869918110008,
      "loss": 0.0287,
      "step": 5487
    },
    {
      "epoch": 0.3977243903322825,
      "grad_norm": 0.8079301118850708,
      "learning_rate": 0.00012047249800710197,
      "loss": 0.0722,
      "step": 5488
    },
    {
      "epoch": 0.3977968619777512,
      "grad_norm": 1.946243405342102,
      "learning_rate": 0.00012045800420320315,
      "loss": 0.1133,
      "step": 5489
    },
    {
      "epoch": 0.3978693336232199,
      "grad_norm": 1.877535104751587,
      "learning_rate": 0.00012044351039930431,
      "loss": 0.0601,
      "step": 5490
    },
    {
      "epoch": 0.3979418052686886,
      "grad_norm": 1.538571834564209,
      "learning_rate": 0.00012042901659540546,
      "loss": 0.1113,
      "step": 5491
    },
    {
      "epoch": 0.39801427691415736,
      "grad_norm": 1.8640530109405518,
      "learning_rate": 0.00012041452279150665,
      "loss": 0.0881,
      "step": 5492
    },
    {
      "epoch": 0.39808674855962606,
      "grad_norm": 0.8714824318885803,
      "learning_rate": 0.0001204000289876078,
      "loss": 0.0539,
      "step": 5493
    },
    {
      "epoch": 0.39815922020509475,
      "grad_norm": 0.7747470140457153,
      "learning_rate": 0.00012038553518370896,
      "loss": 0.0221,
      "step": 5494
    },
    {
      "epoch": 0.39823169185056345,
      "grad_norm": 1.8368700742721558,
      "learning_rate": 0.00012037104137981014,
      "loss": 0.1778,
      "step": 5495
    },
    {
      "epoch": 0.3983041634960322,
      "grad_norm": 1.8207273483276367,
      "learning_rate": 0.0001203565475759113,
      "loss": 0.0465,
      "step": 5496
    },
    {
      "epoch": 0.3983766351415009,
      "grad_norm": 0.8608281016349792,
      "learning_rate": 0.00012034205377201246,
      "loss": 0.1,
      "step": 5497
    },
    {
      "epoch": 0.3984491067869696,
      "grad_norm": 1.1435415744781494,
      "learning_rate": 0.00012032755996811364,
      "loss": 0.0522,
      "step": 5498
    },
    {
      "epoch": 0.3985215784324383,
      "grad_norm": 0.8503235578536987,
      "learning_rate": 0.00012031306616421481,
      "loss": 0.0774,
      "step": 5499
    },
    {
      "epoch": 0.398594050077907,
      "grad_norm": 0.45922061800956726,
      "learning_rate": 0.00012029857236031597,
      "loss": 0.0098,
      "step": 5500
    },
    {
      "epoch": 0.39866652172337574,
      "grad_norm": 1.2212793827056885,
      "learning_rate": 0.00012028407855641715,
      "loss": 0.0705,
      "step": 5501
    },
    {
      "epoch": 0.39873899336884444,
      "grad_norm": 0.6787998676300049,
      "learning_rate": 0.00012026958475251831,
      "loss": 0.0387,
      "step": 5502
    },
    {
      "epoch": 0.39881146501431314,
      "grad_norm": 1.2455261945724487,
      "learning_rate": 0.00012025509094861946,
      "loss": 0.0848,
      "step": 5503
    },
    {
      "epoch": 0.39888393665978183,
      "grad_norm": 1.1158006191253662,
      "learning_rate": 0.00012024059714472065,
      "loss": 0.0944,
      "step": 5504
    },
    {
      "epoch": 0.3989564083052506,
      "grad_norm": 3.787717580795288,
      "learning_rate": 0.0001202261033408218,
      "loss": 0.1121,
      "step": 5505
    },
    {
      "epoch": 0.3990288799507193,
      "grad_norm": 0.7230190634727478,
      "learning_rate": 0.00012021160953692296,
      "loss": 0.0193,
      "step": 5506
    },
    {
      "epoch": 0.399101351596188,
      "grad_norm": 0.8865377902984619,
      "learning_rate": 0.00012019711573302414,
      "loss": 0.0315,
      "step": 5507
    },
    {
      "epoch": 0.3991738232416567,
      "grad_norm": 1.59626305103302,
      "learning_rate": 0.0001201826219291253,
      "loss": 0.0526,
      "step": 5508
    },
    {
      "epoch": 0.39924629488712543,
      "grad_norm": 1.1332545280456543,
      "learning_rate": 0.00012016812812522647,
      "loss": 0.0917,
      "step": 5509
    },
    {
      "epoch": 0.3993187665325941,
      "grad_norm": 1.0581938028335571,
      "learning_rate": 0.00012015363432132764,
      "loss": 0.0301,
      "step": 5510
    },
    {
      "epoch": 0.3993912381780628,
      "grad_norm": 1.40708589553833,
      "learning_rate": 0.00012013914051742881,
      "loss": 0.081,
      "step": 5511
    },
    {
      "epoch": 0.3994637098235315,
      "grad_norm": 1.3966126441955566,
      "learning_rate": 0.00012012464671352997,
      "loss": 0.0614,
      "step": 5512
    },
    {
      "epoch": 0.3995361814690003,
      "grad_norm": 3.3991458415985107,
      "learning_rate": 0.00012011015290963115,
      "loss": 0.0335,
      "step": 5513
    },
    {
      "epoch": 0.39960865311446897,
      "grad_norm": 1.0017859935760498,
      "learning_rate": 0.00012009565910573231,
      "loss": 0.0244,
      "step": 5514
    },
    {
      "epoch": 0.39968112475993767,
      "grad_norm": 7.917543411254883,
      "learning_rate": 0.00012008116530183346,
      "loss": 0.0768,
      "step": 5515
    },
    {
      "epoch": 0.39975359640540636,
      "grad_norm": 2.01454496383667,
      "learning_rate": 0.00012006667149793465,
      "loss": 0.1197,
      "step": 5516
    },
    {
      "epoch": 0.3998260680508751,
      "grad_norm": 1.965872883796692,
      "learning_rate": 0.0001200521776940358,
      "loss": 0.1104,
      "step": 5517
    },
    {
      "epoch": 0.3998985396963438,
      "grad_norm": 2.2308833599090576,
      "learning_rate": 0.00012003768389013696,
      "loss": 0.1299,
      "step": 5518
    },
    {
      "epoch": 0.3999710113418125,
      "grad_norm": 2.295980215072632,
      "learning_rate": 0.00012002319008623814,
      "loss": 0.1893,
      "step": 5519
    },
    {
      "epoch": 0.4000434829872812,
      "grad_norm": 3.618919849395752,
      "learning_rate": 0.0001200086962823393,
      "loss": 0.028,
      "step": 5520
    },
    {
      "epoch": 0.40011595463274996,
      "grad_norm": 2.351759433746338,
      "learning_rate": 0.00011999420247844047,
      "loss": 0.0611,
      "step": 5521
    },
    {
      "epoch": 0.40018842627821866,
      "grad_norm": 2.398259401321411,
      "learning_rate": 0.00011997970867454164,
      "loss": 0.0759,
      "step": 5522
    },
    {
      "epoch": 0.40026089792368735,
      "grad_norm": 0.9047154784202576,
      "learning_rate": 0.00011996521487064281,
      "loss": 0.0753,
      "step": 5523
    },
    {
      "epoch": 0.40033336956915605,
      "grad_norm": 1.4326131343841553,
      "learning_rate": 0.00011995072106674397,
      "loss": 0.0903,
      "step": 5524
    },
    {
      "epoch": 0.4004058412146248,
      "grad_norm": 3.0872538089752197,
      "learning_rate": 0.00011993622726284515,
      "loss": 0.1372,
      "step": 5525
    },
    {
      "epoch": 0.4004783128600935,
      "grad_norm": 1.291448950767517,
      "learning_rate": 0.00011992173345894631,
      "loss": 0.05,
      "step": 5526
    },
    {
      "epoch": 0.4005507845055622,
      "grad_norm": 1.4988276958465576,
      "learning_rate": 0.00011990723965504746,
      "loss": 0.0396,
      "step": 5527
    },
    {
      "epoch": 0.4006232561510309,
      "grad_norm": 0.44634395837783813,
      "learning_rate": 0.00011989274585114865,
      "loss": 0.0195,
      "step": 5528
    },
    {
      "epoch": 0.40069572779649965,
      "grad_norm": 0.8484357595443726,
      "learning_rate": 0.0001198782520472498,
      "loss": 0.0445,
      "step": 5529
    },
    {
      "epoch": 0.40076819944196834,
      "grad_norm": 2.671166181564331,
      "learning_rate": 0.00011986375824335096,
      "loss": 0.1123,
      "step": 5530
    },
    {
      "epoch": 0.40084067108743704,
      "grad_norm": 1.049068808555603,
      "learning_rate": 0.00011984926443945214,
      "loss": 0.0978,
      "step": 5531
    },
    {
      "epoch": 0.40091314273290574,
      "grad_norm": 1.597663164138794,
      "learning_rate": 0.0001198347706355533,
      "loss": 0.0479,
      "step": 5532
    },
    {
      "epoch": 0.4009856143783745,
      "grad_norm": 1.5983144044876099,
      "learning_rate": 0.00011982027683165447,
      "loss": 0.0617,
      "step": 5533
    },
    {
      "epoch": 0.4010580860238432,
      "grad_norm": 1.0120669603347778,
      "learning_rate": 0.00011980578302775564,
      "loss": 0.0177,
      "step": 5534
    },
    {
      "epoch": 0.4011305576693119,
      "grad_norm": 0.8444339632987976,
      "learning_rate": 0.00011979128922385681,
      "loss": 0.0778,
      "step": 5535
    },
    {
      "epoch": 0.4012030293147806,
      "grad_norm": 1.6917312145233154,
      "learning_rate": 0.00011977679541995797,
      "loss": 0.087,
      "step": 5536
    },
    {
      "epoch": 0.4012755009602493,
      "grad_norm": 4.116762161254883,
      "learning_rate": 0.00011976230161605915,
      "loss": 0.2173,
      "step": 5537
    },
    {
      "epoch": 0.40134797260571803,
      "grad_norm": 1.055698275566101,
      "learning_rate": 0.00011974780781216031,
      "loss": 0.0525,
      "step": 5538
    },
    {
      "epoch": 0.4014204442511867,
      "grad_norm": 1.1047133207321167,
      "learning_rate": 0.00011973331400826146,
      "loss": 0.0436,
      "step": 5539
    },
    {
      "epoch": 0.4014929158966554,
      "grad_norm": 1.3896937370300293,
      "learning_rate": 0.00011971882020436265,
      "loss": 0.0452,
      "step": 5540
    },
    {
      "epoch": 0.4015653875421241,
      "grad_norm": 0.9215288162231445,
      "learning_rate": 0.0001197043264004638,
      "loss": 0.0596,
      "step": 5541
    },
    {
      "epoch": 0.40163785918759287,
      "grad_norm": 0.9690112471580505,
      "learning_rate": 0.00011968983259656496,
      "loss": 0.0169,
      "step": 5542
    },
    {
      "epoch": 0.40171033083306157,
      "grad_norm": 0.6563411355018616,
      "learning_rate": 0.00011967533879266614,
      "loss": 0.0324,
      "step": 5543
    },
    {
      "epoch": 0.40178280247853027,
      "grad_norm": 1.4543709754943848,
      "learning_rate": 0.0001196608449887673,
      "loss": 0.0772,
      "step": 5544
    },
    {
      "epoch": 0.40185527412399896,
      "grad_norm": 0.5458033680915833,
      "learning_rate": 0.00011964635118486847,
      "loss": 0.03,
      "step": 5545
    },
    {
      "epoch": 0.4019277457694677,
      "grad_norm": 2.2958338260650635,
      "learning_rate": 0.00011963185738096964,
      "loss": 0.2115,
      "step": 5546
    },
    {
      "epoch": 0.4020002174149364,
      "grad_norm": 1.9874266386032104,
      "learning_rate": 0.00011961736357707081,
      "loss": 0.0628,
      "step": 5547
    },
    {
      "epoch": 0.4020726890604051,
      "grad_norm": 0.8050712943077087,
      "learning_rate": 0.00011960286977317197,
      "loss": 0.0223,
      "step": 5548
    },
    {
      "epoch": 0.4021451607058738,
      "grad_norm": 0.781510591506958,
      "learning_rate": 0.00011958837596927315,
      "loss": 0.0534,
      "step": 5549
    },
    {
      "epoch": 0.40221763235134256,
      "grad_norm": 1.6621217727661133,
      "learning_rate": 0.00011957388216537431,
      "loss": 0.1897,
      "step": 5550
    },
    {
      "epoch": 0.40229010399681125,
      "grad_norm": 1.102885127067566,
      "learning_rate": 0.00011955938836147546,
      "loss": 0.0347,
      "step": 5551
    },
    {
      "epoch": 0.40236257564227995,
      "grad_norm": 1.6191062927246094,
      "learning_rate": 0.00011954489455757665,
      "loss": 0.1249,
      "step": 5552
    },
    {
      "epoch": 0.40243504728774865,
      "grad_norm": 1.650119423866272,
      "learning_rate": 0.0001195304007536778,
      "loss": 0.0856,
      "step": 5553
    },
    {
      "epoch": 0.4025075189332174,
      "grad_norm": 0.3767295479774475,
      "learning_rate": 0.00011951590694977896,
      "loss": 0.0161,
      "step": 5554
    },
    {
      "epoch": 0.4025799905786861,
      "grad_norm": 0.9349095225334167,
      "learning_rate": 0.00011950141314588014,
      "loss": 0.0236,
      "step": 5555
    },
    {
      "epoch": 0.4026524622241548,
      "grad_norm": 0.2838386595249176,
      "learning_rate": 0.0001194869193419813,
      "loss": 0.0035,
      "step": 5556
    },
    {
      "epoch": 0.4027249338696235,
      "grad_norm": 2.5276782512664795,
      "learning_rate": 0.00011947242553808247,
      "loss": 0.0399,
      "step": 5557
    },
    {
      "epoch": 0.40279740551509224,
      "grad_norm": 3.0634217262268066,
      "learning_rate": 0.00011945793173418365,
      "loss": 0.089,
      "step": 5558
    },
    {
      "epoch": 0.40286987716056094,
      "grad_norm": 1.1914820671081543,
      "learning_rate": 0.00011944343793028481,
      "loss": 0.0465,
      "step": 5559
    },
    {
      "epoch": 0.40294234880602964,
      "grad_norm": 1.3155970573425293,
      "learning_rate": 0.00011942894412638597,
      "loss": 0.0462,
      "step": 5560
    },
    {
      "epoch": 0.40301482045149833,
      "grad_norm": 0.06858319044113159,
      "learning_rate": 0.00011941445032248715,
      "loss": 0.0014,
      "step": 5561
    },
    {
      "epoch": 0.4030872920969671,
      "grad_norm": 2.00226092338562,
      "learning_rate": 0.00011939995651858831,
      "loss": 0.0524,
      "step": 5562
    },
    {
      "epoch": 0.4031597637424358,
      "grad_norm": 5.003282070159912,
      "learning_rate": 0.00011938546271468946,
      "loss": 0.227,
      "step": 5563
    },
    {
      "epoch": 0.4032322353879045,
      "grad_norm": 4.064285755157471,
      "learning_rate": 0.00011937096891079065,
      "loss": 0.1823,
      "step": 5564
    },
    {
      "epoch": 0.4033047070333732,
      "grad_norm": 2.11661434173584,
      "learning_rate": 0.0001193564751068918,
      "loss": 0.1594,
      "step": 5565
    },
    {
      "epoch": 0.40337717867884193,
      "grad_norm": 0.3415839672088623,
      "learning_rate": 0.00011934198130299296,
      "loss": 0.0201,
      "step": 5566
    },
    {
      "epoch": 0.4034496503243106,
      "grad_norm": 0.587713360786438,
      "learning_rate": 0.00011932748749909414,
      "loss": 0.0589,
      "step": 5567
    },
    {
      "epoch": 0.4035221219697793,
      "grad_norm": 0.8011474609375,
      "learning_rate": 0.00011931299369519531,
      "loss": 0.0496,
      "step": 5568
    },
    {
      "epoch": 0.403594593615248,
      "grad_norm": 0.5969110727310181,
      "learning_rate": 0.00011929849989129647,
      "loss": 0.0274,
      "step": 5569
    },
    {
      "epoch": 0.4036670652607167,
      "grad_norm": 0.4065214991569519,
      "learning_rate": 0.00011928400608739765,
      "loss": 0.009,
      "step": 5570
    },
    {
      "epoch": 0.40373953690618547,
      "grad_norm": 1.7692465782165527,
      "learning_rate": 0.00011926951228349881,
      "loss": 0.1174,
      "step": 5571
    },
    {
      "epoch": 0.40381200855165417,
      "grad_norm": 4.19159460067749,
      "learning_rate": 0.00011925501847959997,
      "loss": 0.0404,
      "step": 5572
    },
    {
      "epoch": 0.40388448019712286,
      "grad_norm": 4.076537132263184,
      "learning_rate": 0.00011924052467570115,
      "loss": 0.2223,
      "step": 5573
    },
    {
      "epoch": 0.40395695184259156,
      "grad_norm": 1.3512535095214844,
      "learning_rate": 0.00011922603087180231,
      "loss": 0.0733,
      "step": 5574
    },
    {
      "epoch": 0.4040294234880603,
      "grad_norm": 3.2066094875335693,
      "learning_rate": 0.00011921153706790346,
      "loss": 0.1379,
      "step": 5575
    },
    {
      "epoch": 0.404101895133529,
      "grad_norm": 0.4924328327178955,
      "learning_rate": 0.00011919704326400465,
      "loss": 0.0035,
      "step": 5576
    },
    {
      "epoch": 0.4041743667789977,
      "grad_norm": 3.235259771347046,
      "learning_rate": 0.0001191825494601058,
      "loss": 0.0694,
      "step": 5577
    },
    {
      "epoch": 0.4042468384244664,
      "grad_norm": 3.7240829467773438,
      "learning_rate": 0.00011916805565620697,
      "loss": 0.1337,
      "step": 5578
    },
    {
      "epoch": 0.40431931006993516,
      "grad_norm": 1.4094486236572266,
      "learning_rate": 0.00011915356185230814,
      "loss": 0.0685,
      "step": 5579
    },
    {
      "epoch": 0.40439178171540385,
      "grad_norm": 1.997542142868042,
      "learning_rate": 0.00011913906804840931,
      "loss": 0.0656,
      "step": 5580
    },
    {
      "epoch": 0.40446425336087255,
      "grad_norm": 1.1419215202331543,
      "learning_rate": 0.00011912457424451047,
      "loss": 0.0496,
      "step": 5581
    },
    {
      "epoch": 0.40453672500634125,
      "grad_norm": 1.1511497497558594,
      "learning_rate": 0.00011911008044061165,
      "loss": 0.0659,
      "step": 5582
    },
    {
      "epoch": 0.40460919665181,
      "grad_norm": 0.7974812388420105,
      "learning_rate": 0.00011909558663671281,
      "loss": 0.0534,
      "step": 5583
    },
    {
      "epoch": 0.4046816682972787,
      "grad_norm": 0.7380195260047913,
      "learning_rate": 0.00011908109283281397,
      "loss": 0.0645,
      "step": 5584
    },
    {
      "epoch": 0.4047541399427474,
      "grad_norm": 2.522681951522827,
      "learning_rate": 0.00011906659902891515,
      "loss": 0.1301,
      "step": 5585
    },
    {
      "epoch": 0.4048266115882161,
      "grad_norm": 1.7260583639144897,
      "learning_rate": 0.0001190521052250163,
      "loss": 0.1202,
      "step": 5586
    },
    {
      "epoch": 0.40489908323368484,
      "grad_norm": 1.6613402366638184,
      "learning_rate": 0.00011903761142111746,
      "loss": 0.0698,
      "step": 5587
    },
    {
      "epoch": 0.40497155487915354,
      "grad_norm": 1.725672721862793,
      "learning_rate": 0.00011902311761721865,
      "loss": 0.0793,
      "step": 5588
    },
    {
      "epoch": 0.40504402652462224,
      "grad_norm": 1.1426711082458496,
      "learning_rate": 0.0001190086238133198,
      "loss": 0.0941,
      "step": 5589
    },
    {
      "epoch": 0.40511649817009093,
      "grad_norm": 1.652613878250122,
      "learning_rate": 0.00011899413000942097,
      "loss": 0.0581,
      "step": 5590
    },
    {
      "epoch": 0.4051889698155597,
      "grad_norm": 0.765739381313324,
      "learning_rate": 0.00011897963620552214,
      "loss": 0.0875,
      "step": 5591
    },
    {
      "epoch": 0.4052614414610284,
      "grad_norm": 3.1533336639404297,
      "learning_rate": 0.00011896514240162331,
      "loss": 0.2072,
      "step": 5592
    },
    {
      "epoch": 0.4053339131064971,
      "grad_norm": 1.6761716604232788,
      "learning_rate": 0.00011895064859772447,
      "loss": 0.0757,
      "step": 5593
    },
    {
      "epoch": 0.4054063847519658,
      "grad_norm": 1.2832013368606567,
      "learning_rate": 0.00011893615479382565,
      "loss": 0.0436,
      "step": 5594
    },
    {
      "epoch": 0.40547885639743453,
      "grad_norm": 0.7497619986534119,
      "learning_rate": 0.00011892166098992681,
      "loss": 0.0502,
      "step": 5595
    },
    {
      "epoch": 0.4055513280429032,
      "grad_norm": 1.9717453718185425,
      "learning_rate": 0.00011890716718602797,
      "loss": 0.0912,
      "step": 5596
    },
    {
      "epoch": 0.4056237996883719,
      "grad_norm": 0.9469842910766602,
      "learning_rate": 0.00011889267338212915,
      "loss": 0.0768,
      "step": 5597
    },
    {
      "epoch": 0.4056962713338406,
      "grad_norm": 1.1222769021987915,
      "learning_rate": 0.0001188781795782303,
      "loss": 0.0451,
      "step": 5598
    },
    {
      "epoch": 0.40576874297930937,
      "grad_norm": 2.535884141921997,
      "learning_rate": 0.00011886368577433146,
      "loss": 0.0913,
      "step": 5599
    },
    {
      "epoch": 0.40584121462477807,
      "grad_norm": 1.3891710042953491,
      "learning_rate": 0.00011884919197043265,
      "loss": 0.0587,
      "step": 5600
    },
    {
      "epoch": 0.40591368627024677,
      "grad_norm": 1.6446183919906616,
      "learning_rate": 0.0001188346981665338,
      "loss": 0.0363,
      "step": 5601
    },
    {
      "epoch": 0.40598615791571546,
      "grad_norm": 1.655214548110962,
      "learning_rate": 0.00011882020436263499,
      "loss": 0.0521,
      "step": 5602
    },
    {
      "epoch": 0.40605862956118416,
      "grad_norm": 0.39667338132858276,
      "learning_rate": 0.00011880571055873614,
      "loss": 0.0361,
      "step": 5603
    },
    {
      "epoch": 0.4061311012066529,
      "grad_norm": 0.9301490783691406,
      "learning_rate": 0.00011879121675483731,
      "loss": 0.0356,
      "step": 5604
    },
    {
      "epoch": 0.4062035728521216,
      "grad_norm": 0.5575115084648132,
      "learning_rate": 0.0001187767229509385,
      "loss": 0.0357,
      "step": 5605
    },
    {
      "epoch": 0.4062760444975903,
      "grad_norm": 1.026970386505127,
      "learning_rate": 0.00011876222914703965,
      "loss": 0.0433,
      "step": 5606
    },
    {
      "epoch": 0.406348516143059,
      "grad_norm": 1.5137454271316528,
      "learning_rate": 0.00011874773534314081,
      "loss": 0.057,
      "step": 5607
    },
    {
      "epoch": 0.40642098778852775,
      "grad_norm": 0.7972562313079834,
      "learning_rate": 0.000118733241539242,
      "loss": 0.0336,
      "step": 5608
    },
    {
      "epoch": 0.40649345943399645,
      "grad_norm": 2.840791940689087,
      "learning_rate": 0.00011871874773534315,
      "loss": 0.1109,
      "step": 5609
    },
    {
      "epoch": 0.40656593107946515,
      "grad_norm": 4.214690685272217,
      "learning_rate": 0.0001187042539314443,
      "loss": 0.1404,
      "step": 5610
    },
    {
      "epoch": 0.40663840272493385,
      "grad_norm": 0.585503101348877,
      "learning_rate": 0.00011868976012754549,
      "loss": 0.0246,
      "step": 5611
    },
    {
      "epoch": 0.4067108743704026,
      "grad_norm": 2.346407413482666,
      "learning_rate": 0.00011867526632364665,
      "loss": 0.0821,
      "step": 5612
    },
    {
      "epoch": 0.4067833460158713,
      "grad_norm": 2.4200358390808105,
      "learning_rate": 0.0001186607725197478,
      "loss": 0.1297,
      "step": 5613
    },
    {
      "epoch": 0.40685581766134,
      "grad_norm": 1.3145716190338135,
      "learning_rate": 0.00011864627871584899,
      "loss": 0.0149,
      "step": 5614
    },
    {
      "epoch": 0.4069282893068087,
      "grad_norm": 0.6894964575767517,
      "learning_rate": 0.00011863178491195016,
      "loss": 0.0264,
      "step": 5615
    },
    {
      "epoch": 0.40700076095227744,
      "grad_norm": 2.468937635421753,
      "learning_rate": 0.00011861729110805131,
      "loss": 0.0263,
      "step": 5616
    },
    {
      "epoch": 0.40707323259774614,
      "grad_norm": 0.5667197704315186,
      "learning_rate": 0.0001186027973041525,
      "loss": 0.0243,
      "step": 5617
    },
    {
      "epoch": 0.40714570424321483,
      "grad_norm": 1.9627526998519897,
      "learning_rate": 0.00011858830350025365,
      "loss": 0.1149,
      "step": 5618
    },
    {
      "epoch": 0.40721817588868353,
      "grad_norm": 1.7296957969665527,
      "learning_rate": 0.00011857380969635481,
      "loss": 0.1264,
      "step": 5619
    },
    {
      "epoch": 0.4072906475341523,
      "grad_norm": 1.320716381072998,
      "learning_rate": 0.00011855931589245599,
      "loss": 0.0687,
      "step": 5620
    },
    {
      "epoch": 0.407363119179621,
      "grad_norm": 1.66935133934021,
      "learning_rate": 0.00011854482208855715,
      "loss": 0.0882,
      "step": 5621
    },
    {
      "epoch": 0.4074355908250897,
      "grad_norm": 1.1210534572601318,
      "learning_rate": 0.0001185303282846583,
      "loss": 0.0211,
      "step": 5622
    },
    {
      "epoch": 0.4075080624705584,
      "grad_norm": 3.883448362350464,
      "learning_rate": 0.00011851583448075949,
      "loss": 0.1926,
      "step": 5623
    },
    {
      "epoch": 0.4075805341160271,
      "grad_norm": 2.2910268306732178,
      "learning_rate": 0.00011850134067686065,
      "loss": 0.1002,
      "step": 5624
    },
    {
      "epoch": 0.4076530057614958,
      "grad_norm": 5.723389625549316,
      "learning_rate": 0.00011848684687296182,
      "loss": 0.1268,
      "step": 5625
    },
    {
      "epoch": 0.4077254774069645,
      "grad_norm": 1.2444565296173096,
      "learning_rate": 0.00011847235306906299,
      "loss": 0.0487,
      "step": 5626
    },
    {
      "epoch": 0.4077979490524332,
      "grad_norm": 0.7480108141899109,
      "learning_rate": 0.00011845785926516416,
      "loss": 0.0433,
      "step": 5627
    },
    {
      "epoch": 0.40787042069790197,
      "grad_norm": 3.268176317214966,
      "learning_rate": 0.00011844336546126531,
      "loss": 0.0877,
      "step": 5628
    },
    {
      "epoch": 0.40794289234337067,
      "grad_norm": 1.9186159372329712,
      "learning_rate": 0.0001184288716573665,
      "loss": 0.0612,
      "step": 5629
    },
    {
      "epoch": 0.40801536398883936,
      "grad_norm": 0.8836759924888611,
      "learning_rate": 0.00011841437785346765,
      "loss": 0.046,
      "step": 5630
    },
    {
      "epoch": 0.40808783563430806,
      "grad_norm": 1.7936958074569702,
      "learning_rate": 0.00011839988404956881,
      "loss": 0.1023,
      "step": 5631
    },
    {
      "epoch": 0.4081603072797768,
      "grad_norm": 0.7049444913864136,
      "learning_rate": 0.00011838539024566999,
      "loss": 0.0251,
      "step": 5632
    },
    {
      "epoch": 0.4082327789252455,
      "grad_norm": 0.7094841003417969,
      "learning_rate": 0.00011837089644177115,
      "loss": 0.048,
      "step": 5633
    },
    {
      "epoch": 0.4083052505707142,
      "grad_norm": 0.7204960584640503,
      "learning_rate": 0.0001183564026378723,
      "loss": 0.0533,
      "step": 5634
    },
    {
      "epoch": 0.4083777222161829,
      "grad_norm": 3.786648988723755,
      "learning_rate": 0.00011834190883397349,
      "loss": 0.0861,
      "step": 5635
    },
    {
      "epoch": 0.40845019386165166,
      "grad_norm": 2.420293092727661,
      "learning_rate": 0.00011832741503007465,
      "loss": 0.0506,
      "step": 5636
    },
    {
      "epoch": 0.40852266550712035,
      "grad_norm": 2.5525949001312256,
      "learning_rate": 0.00011831292122617582,
      "loss": 0.0746,
      "step": 5637
    },
    {
      "epoch": 0.40859513715258905,
      "grad_norm": 1.2585115432739258,
      "learning_rate": 0.00011829842742227699,
      "loss": 0.105,
      "step": 5638
    },
    {
      "epoch": 0.40866760879805775,
      "grad_norm": 0.676185131072998,
      "learning_rate": 0.00011828393361837816,
      "loss": 0.0257,
      "step": 5639
    },
    {
      "epoch": 0.40874008044352644,
      "grad_norm": 2.4127676486968994,
      "learning_rate": 0.00011826943981447931,
      "loss": 0.1207,
      "step": 5640
    },
    {
      "epoch": 0.4088125520889952,
      "grad_norm": 2.3007712364196777,
      "learning_rate": 0.0001182549460105805,
      "loss": 0.1507,
      "step": 5641
    },
    {
      "epoch": 0.4088850237344639,
      "grad_norm": 1.1132670640945435,
      "learning_rate": 0.00011824045220668165,
      "loss": 0.0628,
      "step": 5642
    },
    {
      "epoch": 0.4089574953799326,
      "grad_norm": 2.0136330127716064,
      "learning_rate": 0.00011822595840278281,
      "loss": 0.0409,
      "step": 5643
    },
    {
      "epoch": 0.4090299670254013,
      "grad_norm": 1.26604425907135,
      "learning_rate": 0.00011821146459888399,
      "loss": 0.0662,
      "step": 5644
    },
    {
      "epoch": 0.40910243867087004,
      "grad_norm": 1.066601276397705,
      "learning_rate": 0.00011819697079498515,
      "loss": 0.0605,
      "step": 5645
    },
    {
      "epoch": 0.40917491031633874,
      "grad_norm": 1.5101230144500732,
      "learning_rate": 0.0001181824769910863,
      "loss": 0.0989,
      "step": 5646
    },
    {
      "epoch": 0.40924738196180743,
      "grad_norm": 2.284543037414551,
      "learning_rate": 0.00011816798318718749,
      "loss": 0.1678,
      "step": 5647
    },
    {
      "epoch": 0.40931985360727613,
      "grad_norm": 1.2189370393753052,
      "learning_rate": 0.00011815348938328865,
      "loss": 0.0929,
      "step": 5648
    },
    {
      "epoch": 0.4093923252527449,
      "grad_norm": 0.6104494333267212,
      "learning_rate": 0.00011813899557938982,
      "loss": 0.0314,
      "step": 5649
    },
    {
      "epoch": 0.4094647968982136,
      "grad_norm": 1.9495346546173096,
      "learning_rate": 0.00011812450177549099,
      "loss": 0.0772,
      "step": 5650
    },
    {
      "epoch": 0.4095372685436823,
      "grad_norm": 2.0587925910949707,
      "learning_rate": 0.00011811000797159216,
      "loss": 0.2101,
      "step": 5651
    },
    {
      "epoch": 0.409609740189151,
      "grad_norm": 0.374521404504776,
      "learning_rate": 0.00011809551416769331,
      "loss": 0.03,
      "step": 5652
    },
    {
      "epoch": 0.4096822118346197,
      "grad_norm": 5.517520904541016,
      "learning_rate": 0.0001180810203637945,
      "loss": 0.1134,
      "step": 5653
    },
    {
      "epoch": 0.4097546834800884,
      "grad_norm": 1.473413109779358,
      "learning_rate": 0.00011806652655989565,
      "loss": 0.1112,
      "step": 5654
    },
    {
      "epoch": 0.4098271551255571,
      "grad_norm": 1.3809770345687866,
      "learning_rate": 0.00011805203275599681,
      "loss": 0.1584,
      "step": 5655
    },
    {
      "epoch": 0.4098996267710258,
      "grad_norm": 0.8191571831703186,
      "learning_rate": 0.00011803753895209799,
      "loss": 0.0162,
      "step": 5656
    },
    {
      "epoch": 0.40997209841649457,
      "grad_norm": 0.47594326734542847,
      "learning_rate": 0.00011802304514819915,
      "loss": 0.027,
      "step": 5657
    },
    {
      "epoch": 0.41004457006196326,
      "grad_norm": 2.178546190261841,
      "learning_rate": 0.0001180085513443003,
      "loss": 0.1084,
      "step": 5658
    },
    {
      "epoch": 0.41011704170743196,
      "grad_norm": 1.7601948976516724,
      "learning_rate": 0.00011799405754040149,
      "loss": 0.0623,
      "step": 5659
    },
    {
      "epoch": 0.41018951335290066,
      "grad_norm": 9.183499336242676,
      "learning_rate": 0.00011797956373650265,
      "loss": 0.0668,
      "step": 5660
    },
    {
      "epoch": 0.4102619849983694,
      "grad_norm": 1.1939364671707153,
      "learning_rate": 0.00011796506993260382,
      "loss": 0.0983,
      "step": 5661
    },
    {
      "epoch": 0.4103344566438381,
      "grad_norm": 0.32628658413887024,
      "learning_rate": 0.000117950576128705,
      "loss": 0.0171,
      "step": 5662
    },
    {
      "epoch": 0.4104069282893068,
      "grad_norm": 0.827329695224762,
      "learning_rate": 0.00011793608232480616,
      "loss": 0.0274,
      "step": 5663
    },
    {
      "epoch": 0.4104793999347755,
      "grad_norm": 0.8342359662055969,
      "learning_rate": 0.00011792158852090731,
      "loss": 0.0542,
      "step": 5664
    },
    {
      "epoch": 0.41055187158024425,
      "grad_norm": 1.8447448015213013,
      "learning_rate": 0.0001179070947170085,
      "loss": 0.0617,
      "step": 5665
    },
    {
      "epoch": 0.41062434322571295,
      "grad_norm": 0.9470891952514648,
      "learning_rate": 0.00011789260091310965,
      "loss": 0.022,
      "step": 5666
    },
    {
      "epoch": 0.41069681487118165,
      "grad_norm": 0.9301909804344177,
      "learning_rate": 0.00011787810710921081,
      "loss": 0.0731,
      "step": 5667
    },
    {
      "epoch": 0.41076928651665034,
      "grad_norm": 1.0538127422332764,
      "learning_rate": 0.00011786361330531199,
      "loss": 0.0744,
      "step": 5668
    },
    {
      "epoch": 0.4108417581621191,
      "grad_norm": 1.4653853178024292,
      "learning_rate": 0.00011784911950141315,
      "loss": 0.1137,
      "step": 5669
    },
    {
      "epoch": 0.4109142298075878,
      "grad_norm": 1.457688570022583,
      "learning_rate": 0.0001178346256975143,
      "loss": 0.0946,
      "step": 5670
    },
    {
      "epoch": 0.4109867014530565,
      "grad_norm": 0.48097965121269226,
      "learning_rate": 0.00011782013189361549,
      "loss": 0.0142,
      "step": 5671
    },
    {
      "epoch": 0.4110591730985252,
      "grad_norm": 0.9550682902336121,
      "learning_rate": 0.00011780563808971666,
      "loss": 0.0598,
      "step": 5672
    },
    {
      "epoch": 0.4111316447439939,
      "grad_norm": 1.9482982158660889,
      "learning_rate": 0.00011779114428581782,
      "loss": 0.0843,
      "step": 5673
    },
    {
      "epoch": 0.41120411638946264,
      "grad_norm": 1.6333823204040527,
      "learning_rate": 0.000117776650481919,
      "loss": 0.027,
      "step": 5674
    },
    {
      "epoch": 0.41127658803493133,
      "grad_norm": 1.1683862209320068,
      "learning_rate": 0.00011776215667802016,
      "loss": 0.0587,
      "step": 5675
    },
    {
      "epoch": 0.41134905968040003,
      "grad_norm": 1.2108436822891235,
      "learning_rate": 0.00011774766287412131,
      "loss": 0.0885,
      "step": 5676
    },
    {
      "epoch": 0.41142153132586873,
      "grad_norm": 1.33815598487854,
      "learning_rate": 0.0001177331690702225,
      "loss": 0.0774,
      "step": 5677
    },
    {
      "epoch": 0.4114940029713375,
      "grad_norm": 3.8124639987945557,
      "learning_rate": 0.00011771867526632365,
      "loss": 0.1911,
      "step": 5678
    },
    {
      "epoch": 0.4115664746168062,
      "grad_norm": 4.007326602935791,
      "learning_rate": 0.00011770418146242481,
      "loss": 0.1799,
      "step": 5679
    },
    {
      "epoch": 0.4116389462622749,
      "grad_norm": 2.7983059883117676,
      "learning_rate": 0.00011768968765852599,
      "loss": 0.0966,
      "step": 5680
    },
    {
      "epoch": 0.41171141790774357,
      "grad_norm": 4.276992321014404,
      "learning_rate": 0.00011767519385462715,
      "loss": 0.0607,
      "step": 5681
    },
    {
      "epoch": 0.4117838895532123,
      "grad_norm": 0.9099782109260559,
      "learning_rate": 0.00011766070005072832,
      "loss": 0.0455,
      "step": 5682
    },
    {
      "epoch": 0.411856361198681,
      "grad_norm": 1.2031173706054688,
      "learning_rate": 0.00011764620624682949,
      "loss": 0.073,
      "step": 5683
    },
    {
      "epoch": 0.4119288328441497,
      "grad_norm": 0.6832008361816406,
      "learning_rate": 0.00011763171244293066,
      "loss": 0.022,
      "step": 5684
    },
    {
      "epoch": 0.4120013044896184,
      "grad_norm": 1.7208565473556519,
      "learning_rate": 0.00011761721863903182,
      "loss": 0.0351,
      "step": 5685
    },
    {
      "epoch": 0.41207377613508717,
      "grad_norm": 0.7489060759544373,
      "learning_rate": 0.000117602724835133,
      "loss": 0.034,
      "step": 5686
    },
    {
      "epoch": 0.41214624778055586,
      "grad_norm": 1.5169700384140015,
      "learning_rate": 0.00011758823103123416,
      "loss": 0.1104,
      "step": 5687
    },
    {
      "epoch": 0.41221871942602456,
      "grad_norm": 2.5504939556121826,
      "learning_rate": 0.00011757373722733531,
      "loss": 0.0655,
      "step": 5688
    },
    {
      "epoch": 0.41229119107149326,
      "grad_norm": 1.20138418674469,
      "learning_rate": 0.0001175592434234365,
      "loss": 0.059,
      "step": 5689
    },
    {
      "epoch": 0.412363662716962,
      "grad_norm": 2.1552627086639404,
      "learning_rate": 0.00011754474961953765,
      "loss": 0.0996,
      "step": 5690
    },
    {
      "epoch": 0.4124361343624307,
      "grad_norm": 1.0111219882965088,
      "learning_rate": 0.00011753025581563881,
      "loss": 0.0561,
      "step": 5691
    },
    {
      "epoch": 0.4125086060078994,
      "grad_norm": 0.6970646381378174,
      "learning_rate": 0.00011751576201173999,
      "loss": 0.0327,
      "step": 5692
    },
    {
      "epoch": 0.4125810776533681,
      "grad_norm": 1.6180648803710938,
      "learning_rate": 0.00011750126820784115,
      "loss": 0.0939,
      "step": 5693
    },
    {
      "epoch": 0.41265354929883685,
      "grad_norm": 1.278788447380066,
      "learning_rate": 0.00011748677440394232,
      "loss": 0.0578,
      "step": 5694
    },
    {
      "epoch": 0.41272602094430555,
      "grad_norm": 1.747794508934021,
      "learning_rate": 0.00011747228060004349,
      "loss": 0.1131,
      "step": 5695
    },
    {
      "epoch": 0.41279849258977425,
      "grad_norm": 1.2193782329559326,
      "learning_rate": 0.00011745778679614466,
      "loss": 0.0379,
      "step": 5696
    },
    {
      "epoch": 0.41287096423524294,
      "grad_norm": 0.3032764196395874,
      "learning_rate": 0.00011744329299224581,
      "loss": 0.0174,
      "step": 5697
    },
    {
      "epoch": 0.4129434358807117,
      "grad_norm": 2.202120065689087,
      "learning_rate": 0.000117428799188347,
      "loss": 0.0812,
      "step": 5698
    },
    {
      "epoch": 0.4130159075261804,
      "grad_norm": 1.7421773672103882,
      "learning_rate": 0.00011741430538444816,
      "loss": 0.1431,
      "step": 5699
    },
    {
      "epoch": 0.4130883791716491,
      "grad_norm": 1.8764448165893555,
      "learning_rate": 0.00011739981158054931,
      "loss": 0.0778,
      "step": 5700
    },
    {
      "epoch": 0.4131608508171178,
      "grad_norm": 3.009969711303711,
      "learning_rate": 0.0001173853177766505,
      "loss": 0.0843,
      "step": 5701
    },
    {
      "epoch": 0.41323332246258654,
      "grad_norm": 0.688090443611145,
      "learning_rate": 0.00011737082397275165,
      "loss": 0.0365,
      "step": 5702
    },
    {
      "epoch": 0.41330579410805524,
      "grad_norm": 0.8191509246826172,
      "learning_rate": 0.00011735633016885281,
      "loss": 0.0399,
      "step": 5703
    },
    {
      "epoch": 0.41337826575352393,
      "grad_norm": 3.609975576400757,
      "learning_rate": 0.00011734183636495399,
      "loss": 0.1331,
      "step": 5704
    },
    {
      "epoch": 0.41345073739899263,
      "grad_norm": 1.039655089378357,
      "learning_rate": 0.00011732734256105515,
      "loss": 0.0076,
      "step": 5705
    },
    {
      "epoch": 0.4135232090444614,
      "grad_norm": 1.1188124418258667,
      "learning_rate": 0.00011731284875715632,
      "loss": 0.0713,
      "step": 5706
    },
    {
      "epoch": 0.4135956806899301,
      "grad_norm": 0.939030110836029,
      "learning_rate": 0.00011729835495325749,
      "loss": 0.0335,
      "step": 5707
    },
    {
      "epoch": 0.4136681523353988,
      "grad_norm": 3.0069072246551514,
      "learning_rate": 0.00011728386114935866,
      "loss": 0.1309,
      "step": 5708
    },
    {
      "epoch": 0.4137406239808675,
      "grad_norm": 0.9889737963676453,
      "learning_rate": 0.00011726936734545981,
      "loss": 0.0485,
      "step": 5709
    },
    {
      "epoch": 0.41381309562633617,
      "grad_norm": 1.6110965013504028,
      "learning_rate": 0.000117254873541561,
      "loss": 0.1497,
      "step": 5710
    },
    {
      "epoch": 0.4138855672718049,
      "grad_norm": 0.6478313207626343,
      "learning_rate": 0.00011724037973766215,
      "loss": 0.052,
      "step": 5711
    },
    {
      "epoch": 0.4139580389172736,
      "grad_norm": 0.5715427994728088,
      "learning_rate": 0.00011722588593376331,
      "loss": 0.0546,
      "step": 5712
    },
    {
      "epoch": 0.4140305105627423,
      "grad_norm": 2.19260835647583,
      "learning_rate": 0.0001172113921298645,
      "loss": 0.0529,
      "step": 5713
    },
    {
      "epoch": 0.414102982208211,
      "grad_norm": 2.891042947769165,
      "learning_rate": 0.00011719689832596565,
      "loss": 0.1311,
      "step": 5714
    },
    {
      "epoch": 0.41417545385367976,
      "grad_norm": 1.1853375434875488,
      "learning_rate": 0.00011718240452206681,
      "loss": 0.057,
      "step": 5715
    },
    {
      "epoch": 0.41424792549914846,
      "grad_norm": 1.2534027099609375,
      "learning_rate": 0.00011716791071816799,
      "loss": 0.0454,
      "step": 5716
    },
    {
      "epoch": 0.41432039714461716,
      "grad_norm": 0.40749385952949524,
      "learning_rate": 0.00011715341691426915,
      "loss": 0.0241,
      "step": 5717
    },
    {
      "epoch": 0.41439286879008586,
      "grad_norm": 3.5542359352111816,
      "learning_rate": 0.00011713892311037032,
      "loss": 0.0954,
      "step": 5718
    },
    {
      "epoch": 0.4144653404355546,
      "grad_norm": 0.6326184272766113,
      "learning_rate": 0.0001171244293064715,
      "loss": 0.0232,
      "step": 5719
    },
    {
      "epoch": 0.4145378120810233,
      "grad_norm": 2.3084492683410645,
      "learning_rate": 0.00011710993550257266,
      "loss": 0.0931,
      "step": 5720
    },
    {
      "epoch": 0.414610283726492,
      "grad_norm": 2.277963399887085,
      "learning_rate": 0.00011709544169867381,
      "loss": 0.16,
      "step": 5721
    },
    {
      "epoch": 0.4146827553719607,
      "grad_norm": 1.4584181308746338,
      "learning_rate": 0.000117080947894775,
      "loss": 0.0494,
      "step": 5722
    },
    {
      "epoch": 0.41475522701742945,
      "grad_norm": 3.557506561279297,
      "learning_rate": 0.00011706645409087615,
      "loss": 0.1062,
      "step": 5723
    },
    {
      "epoch": 0.41482769866289815,
      "grad_norm": 1.6666789054870605,
      "learning_rate": 0.00011705196028697731,
      "loss": 0.0735,
      "step": 5724
    },
    {
      "epoch": 0.41490017030836684,
      "grad_norm": 0.4012756645679474,
      "learning_rate": 0.0001170374664830785,
      "loss": 0.0176,
      "step": 5725
    },
    {
      "epoch": 0.41497264195383554,
      "grad_norm": 3.1302802562713623,
      "learning_rate": 0.00011702297267917965,
      "loss": 0.1648,
      "step": 5726
    },
    {
      "epoch": 0.4150451135993043,
      "grad_norm": 1.1051552295684814,
      "learning_rate": 0.00011700847887528081,
      "loss": 0.0749,
      "step": 5727
    },
    {
      "epoch": 0.415117585244773,
      "grad_norm": 4.370365619659424,
      "learning_rate": 0.00011699398507138199,
      "loss": 0.1201,
      "step": 5728
    },
    {
      "epoch": 0.4151900568902417,
      "grad_norm": 2.3303565979003906,
      "learning_rate": 0.00011697949126748315,
      "loss": 0.1356,
      "step": 5729
    },
    {
      "epoch": 0.4152625285357104,
      "grad_norm": 1.5743025541305542,
      "learning_rate": 0.00011696499746358432,
      "loss": 0.0973,
      "step": 5730
    },
    {
      "epoch": 0.41533500018117914,
      "grad_norm": 1.829846978187561,
      "learning_rate": 0.0001169505036596855,
      "loss": 0.0731,
      "step": 5731
    },
    {
      "epoch": 0.41540747182664783,
      "grad_norm": 3.7487776279449463,
      "learning_rate": 0.00011693600985578666,
      "loss": 0.0739,
      "step": 5732
    },
    {
      "epoch": 0.41547994347211653,
      "grad_norm": 0.5804978013038635,
      "learning_rate": 0.00011692151605188781,
      "loss": 0.0208,
      "step": 5733
    },
    {
      "epoch": 0.4155524151175852,
      "grad_norm": 0.9049407839775085,
      "learning_rate": 0.000116907022247989,
      "loss": 0.053,
      "step": 5734
    },
    {
      "epoch": 0.415624886763054,
      "grad_norm": 3.8541131019592285,
      "learning_rate": 0.00011689252844409015,
      "loss": 0.0972,
      "step": 5735
    },
    {
      "epoch": 0.4156973584085227,
      "grad_norm": 1.9344333410263062,
      "learning_rate": 0.00011687803464019131,
      "loss": 0.1954,
      "step": 5736
    },
    {
      "epoch": 0.4157698300539914,
      "grad_norm": 8.223379135131836,
      "learning_rate": 0.0001168635408362925,
      "loss": 0.0858,
      "step": 5737
    },
    {
      "epoch": 0.41584230169946007,
      "grad_norm": 1.3650527000427246,
      "learning_rate": 0.00011684904703239365,
      "loss": 0.0417,
      "step": 5738
    },
    {
      "epoch": 0.4159147733449288,
      "grad_norm": 3.8243846893310547,
      "learning_rate": 0.00011683455322849481,
      "loss": 0.0749,
      "step": 5739
    },
    {
      "epoch": 0.4159872449903975,
      "grad_norm": 1.4658679962158203,
      "learning_rate": 0.00011682005942459599,
      "loss": 0.0865,
      "step": 5740
    },
    {
      "epoch": 0.4160597166358662,
      "grad_norm": 1.9587645530700684,
      "learning_rate": 0.00011680556562069716,
      "loss": 0.0795,
      "step": 5741
    },
    {
      "epoch": 0.4161321882813349,
      "grad_norm": 1.2102067470550537,
      "learning_rate": 0.00011679107181679832,
      "loss": 0.0534,
      "step": 5742
    },
    {
      "epoch": 0.4162046599268036,
      "grad_norm": 1.5617669820785522,
      "learning_rate": 0.0001167765780128995,
      "loss": 0.0957,
      "step": 5743
    },
    {
      "epoch": 0.41627713157227236,
      "grad_norm": 1.1202183961868286,
      "learning_rate": 0.00011676208420900066,
      "loss": 0.0454,
      "step": 5744
    },
    {
      "epoch": 0.41634960321774106,
      "grad_norm": 1.917116403579712,
      "learning_rate": 0.00011674759040510181,
      "loss": 0.0436,
      "step": 5745
    },
    {
      "epoch": 0.41642207486320976,
      "grad_norm": 0.6743407845497131,
      "learning_rate": 0.000116733096601203,
      "loss": 0.0569,
      "step": 5746
    },
    {
      "epoch": 0.41649454650867845,
      "grad_norm": 0.9294843673706055,
      "learning_rate": 0.00011671860279730415,
      "loss": 0.0286,
      "step": 5747
    },
    {
      "epoch": 0.4165670181541472,
      "grad_norm": 1.3488318920135498,
      "learning_rate": 0.00011670410899340531,
      "loss": 0.0742,
      "step": 5748
    },
    {
      "epoch": 0.4166394897996159,
      "grad_norm": 0.6002969741821289,
      "learning_rate": 0.0001166896151895065,
      "loss": 0.0093,
      "step": 5749
    },
    {
      "epoch": 0.4167119614450846,
      "grad_norm": 1.2439533472061157,
      "learning_rate": 0.00011667512138560765,
      "loss": 0.1057,
      "step": 5750
    },
    {
      "epoch": 0.4167844330905533,
      "grad_norm": 2.2056431770324707,
      "learning_rate": 0.00011666062758170882,
      "loss": 0.0426,
      "step": 5751
    },
    {
      "epoch": 0.41685690473602205,
      "grad_norm": 0.6324701309204102,
      "learning_rate": 0.00011664613377780999,
      "loss": 0.0396,
      "step": 5752
    },
    {
      "epoch": 0.41692937638149075,
      "grad_norm": 1.3249115943908691,
      "learning_rate": 0.00011663163997391116,
      "loss": 0.0859,
      "step": 5753
    },
    {
      "epoch": 0.41700184802695944,
      "grad_norm": 0.5941235423088074,
      "learning_rate": 0.00011661714617001232,
      "loss": 0.0219,
      "step": 5754
    },
    {
      "epoch": 0.41707431967242814,
      "grad_norm": 1.0259219408035278,
      "learning_rate": 0.0001166026523661135,
      "loss": 0.0431,
      "step": 5755
    },
    {
      "epoch": 0.4171467913178969,
      "grad_norm": 0.5689396262168884,
      "learning_rate": 0.00011658815856221466,
      "loss": 0.0554,
      "step": 5756
    },
    {
      "epoch": 0.4172192629633656,
      "grad_norm": 1.9460841417312622,
      "learning_rate": 0.00011657366475831581,
      "loss": 0.0647,
      "step": 5757
    },
    {
      "epoch": 0.4172917346088343,
      "grad_norm": 2.77970814704895,
      "learning_rate": 0.000116559170954417,
      "loss": 0.2061,
      "step": 5758
    },
    {
      "epoch": 0.417364206254303,
      "grad_norm": 1.6782690286636353,
      "learning_rate": 0.00011654467715051815,
      "loss": 0.0899,
      "step": 5759
    },
    {
      "epoch": 0.41743667789977174,
      "grad_norm": 2.0931410789489746,
      "learning_rate": 0.00011653018334661931,
      "loss": 0.0471,
      "step": 5760
    },
    {
      "epoch": 0.41750914954524043,
      "grad_norm": 0.8729591965675354,
      "learning_rate": 0.0001165156895427205,
      "loss": 0.0446,
      "step": 5761
    },
    {
      "epoch": 0.41758162119070913,
      "grad_norm": 3.4824955463409424,
      "learning_rate": 0.00011650119573882165,
      "loss": 0.0428,
      "step": 5762
    },
    {
      "epoch": 0.4176540928361778,
      "grad_norm": 4.175022602081299,
      "learning_rate": 0.00011648670193492282,
      "loss": 0.1397,
      "step": 5763
    },
    {
      "epoch": 0.4177265644816466,
      "grad_norm": 2.3572919368743896,
      "learning_rate": 0.00011647220813102399,
      "loss": 0.1162,
      "step": 5764
    },
    {
      "epoch": 0.4177990361271153,
      "grad_norm": 4.5222063064575195,
      "learning_rate": 0.00011645771432712516,
      "loss": 0.1108,
      "step": 5765
    },
    {
      "epoch": 0.41787150777258397,
      "grad_norm": 0.5866248607635498,
      "learning_rate": 0.00011644322052322633,
      "loss": 0.0277,
      "step": 5766
    },
    {
      "epoch": 0.41794397941805267,
      "grad_norm": 2.928821086883545,
      "learning_rate": 0.0001164287267193275,
      "loss": 0.1038,
      "step": 5767
    },
    {
      "epoch": 0.4180164510635214,
      "grad_norm": 5.2398681640625,
      "learning_rate": 0.00011641423291542866,
      "loss": 0.1212,
      "step": 5768
    },
    {
      "epoch": 0.4180889227089901,
      "grad_norm": 1.6508758068084717,
      "learning_rate": 0.00011639973911152984,
      "loss": 0.0678,
      "step": 5769
    },
    {
      "epoch": 0.4181613943544588,
      "grad_norm": 1.4032701253890991,
      "learning_rate": 0.000116385245307631,
      "loss": 0.0752,
      "step": 5770
    },
    {
      "epoch": 0.4182338659999275,
      "grad_norm": 2.862945079803467,
      "learning_rate": 0.00011637075150373215,
      "loss": 0.313,
      "step": 5771
    },
    {
      "epoch": 0.41830633764539626,
      "grad_norm": 0.8113645911216736,
      "learning_rate": 0.00011635625769983334,
      "loss": 0.0565,
      "step": 5772
    },
    {
      "epoch": 0.41837880929086496,
      "grad_norm": 6.393208980560303,
      "learning_rate": 0.0001163417638959345,
      "loss": 0.0796,
      "step": 5773
    },
    {
      "epoch": 0.41845128093633366,
      "grad_norm": 3.4085536003112793,
      "learning_rate": 0.00011632727009203565,
      "loss": 0.0651,
      "step": 5774
    },
    {
      "epoch": 0.41852375258180236,
      "grad_norm": 1.3225499391555786,
      "learning_rate": 0.00011631277628813683,
      "loss": 0.0171,
      "step": 5775
    },
    {
      "epoch": 0.4185962242272711,
      "grad_norm": 1.5561245679855347,
      "learning_rate": 0.00011629828248423799,
      "loss": 0.0619,
      "step": 5776
    },
    {
      "epoch": 0.4186686958727398,
      "grad_norm": 2.449779510498047,
      "learning_rate": 0.00011628378868033916,
      "loss": 0.1268,
      "step": 5777
    },
    {
      "epoch": 0.4187411675182085,
      "grad_norm": 1.6053763628005981,
      "learning_rate": 0.00011626929487644034,
      "loss": 0.0512,
      "step": 5778
    },
    {
      "epoch": 0.4188136391636772,
      "grad_norm": 0.5131190419197083,
      "learning_rate": 0.0001162548010725415,
      "loss": 0.0684,
      "step": 5779
    },
    {
      "epoch": 0.4188861108091459,
      "grad_norm": 1.1834560632705688,
      "learning_rate": 0.00011624030726864266,
      "loss": 0.0452,
      "step": 5780
    },
    {
      "epoch": 0.41895858245461465,
      "grad_norm": 0.7522176504135132,
      "learning_rate": 0.00011622581346474384,
      "loss": 0.0237,
      "step": 5781
    },
    {
      "epoch": 0.41903105410008334,
      "grad_norm": 1.011896014213562,
      "learning_rate": 0.000116211319660845,
      "loss": 0.0409,
      "step": 5782
    },
    {
      "epoch": 0.41910352574555204,
      "grad_norm": 0.8873791098594666,
      "learning_rate": 0.00011619682585694615,
      "loss": 0.0106,
      "step": 5783
    },
    {
      "epoch": 0.41917599739102074,
      "grad_norm": 5.688323974609375,
      "learning_rate": 0.00011618233205304734,
      "loss": 0.1266,
      "step": 5784
    },
    {
      "epoch": 0.4192484690364895,
      "grad_norm": 1.654178261756897,
      "learning_rate": 0.0001161678382491485,
      "loss": 0.0911,
      "step": 5785
    },
    {
      "epoch": 0.4193209406819582,
      "grad_norm": 2.7647454738616943,
      "learning_rate": 0.00011615334444524965,
      "loss": 0.2061,
      "step": 5786
    },
    {
      "epoch": 0.4193934123274269,
      "grad_norm": 0.5749514102935791,
      "learning_rate": 0.00011613885064135083,
      "loss": 0.0301,
      "step": 5787
    },
    {
      "epoch": 0.4194658839728956,
      "grad_norm": 1.3968745470046997,
      "learning_rate": 0.000116124356837452,
      "loss": 0.0545,
      "step": 5788
    },
    {
      "epoch": 0.41953835561836433,
      "grad_norm": 0.7982815504074097,
      "learning_rate": 0.00011610986303355316,
      "loss": 0.0368,
      "step": 5789
    },
    {
      "epoch": 0.41961082726383303,
      "grad_norm": 1.7906922101974487,
      "learning_rate": 0.00011609536922965434,
      "loss": 0.0885,
      "step": 5790
    },
    {
      "epoch": 0.4196832989093017,
      "grad_norm": 1.8360627889633179,
      "learning_rate": 0.0001160808754257555,
      "loss": 0.0382,
      "step": 5791
    },
    {
      "epoch": 0.4197557705547704,
      "grad_norm": 1.1405614614486694,
      "learning_rate": 0.00011606638162185666,
      "loss": 0.0135,
      "step": 5792
    },
    {
      "epoch": 0.4198282422002392,
      "grad_norm": 1.1185814142227173,
      "learning_rate": 0.00011605188781795784,
      "loss": 0.0585,
      "step": 5793
    },
    {
      "epoch": 0.4199007138457079,
      "grad_norm": 1.7089861631393433,
      "learning_rate": 0.000116037394014059,
      "loss": 0.0968,
      "step": 5794
    },
    {
      "epoch": 0.41997318549117657,
      "grad_norm": 1.315411925315857,
      "learning_rate": 0.00011602290021016015,
      "loss": 0.0754,
      "step": 5795
    },
    {
      "epoch": 0.42004565713664527,
      "grad_norm": 1.5281912088394165,
      "learning_rate": 0.00011600840640626134,
      "loss": 0.151,
      "step": 5796
    },
    {
      "epoch": 0.420118128782114,
      "grad_norm": 1.2324594259262085,
      "learning_rate": 0.0001159939126023625,
      "loss": 0.0685,
      "step": 5797
    },
    {
      "epoch": 0.4201906004275827,
      "grad_norm": 0.9538143277168274,
      "learning_rate": 0.00011597941879846366,
      "loss": 0.0687,
      "step": 5798
    },
    {
      "epoch": 0.4202630720730514,
      "grad_norm": 3.7510228157043457,
      "learning_rate": 0.00011596492499456483,
      "loss": 0.1207,
      "step": 5799
    },
    {
      "epoch": 0.4203355437185201,
      "grad_norm": 0.5789720416069031,
      "learning_rate": 0.000115950431190666,
      "loss": 0.0299,
      "step": 5800
    },
    {
      "epoch": 0.42040801536398886,
      "grad_norm": 1.0952666997909546,
      "learning_rate": 0.00011593593738676716,
      "loss": 0.0754,
      "step": 5801
    },
    {
      "epoch": 0.42048048700945756,
      "grad_norm": 2.9912755489349365,
      "learning_rate": 0.00011592144358286834,
      "loss": 0.0482,
      "step": 5802
    },
    {
      "epoch": 0.42055295865492626,
      "grad_norm": 1.316398024559021,
      "learning_rate": 0.0001159069497789695,
      "loss": 0.1477,
      "step": 5803
    },
    {
      "epoch": 0.42062543030039495,
      "grad_norm": 2.2864267826080322,
      "learning_rate": 0.00011589245597507066,
      "loss": 0.1338,
      "step": 5804
    },
    {
      "epoch": 0.4206979019458637,
      "grad_norm": 1.022584319114685,
      "learning_rate": 0.00011587796217117184,
      "loss": 0.1143,
      "step": 5805
    },
    {
      "epoch": 0.4207703735913324,
      "grad_norm": 1.7790392637252808,
      "learning_rate": 0.000115863468367273,
      "loss": 0.1499,
      "step": 5806
    },
    {
      "epoch": 0.4208428452368011,
      "grad_norm": 1.2356412410736084,
      "learning_rate": 0.00011584897456337415,
      "loss": 0.0947,
      "step": 5807
    },
    {
      "epoch": 0.4209153168822698,
      "grad_norm": 2.2612295150756836,
      "learning_rate": 0.00011583448075947534,
      "loss": 0.0671,
      "step": 5808
    },
    {
      "epoch": 0.42098778852773855,
      "grad_norm": 0.42562997341156006,
      "learning_rate": 0.0001158199869555765,
      "loss": 0.0235,
      "step": 5809
    },
    {
      "epoch": 0.42106026017320725,
      "grad_norm": 1.3319214582443237,
      "learning_rate": 0.00011580549315167766,
      "loss": 0.0331,
      "step": 5810
    },
    {
      "epoch": 0.42113273181867594,
      "grad_norm": 1.129529356956482,
      "learning_rate": 0.00011579099934777883,
      "loss": 0.1033,
      "step": 5811
    },
    {
      "epoch": 0.42120520346414464,
      "grad_norm": 7.272531032562256,
      "learning_rate": 0.00011577650554388,
      "loss": 0.0665,
      "step": 5812
    },
    {
      "epoch": 0.42127767510961334,
      "grad_norm": 1.2761039733886719,
      "learning_rate": 0.00011576201173998116,
      "loss": 0.0463,
      "step": 5813
    },
    {
      "epoch": 0.4213501467550821,
      "grad_norm": 1.7738007307052612,
      "learning_rate": 0.00011574751793608234,
      "loss": 0.0763,
      "step": 5814
    },
    {
      "epoch": 0.4214226184005508,
      "grad_norm": 1.0664416551589966,
      "learning_rate": 0.0001157330241321835,
      "loss": 0.032,
      "step": 5815
    },
    {
      "epoch": 0.4214950900460195,
      "grad_norm": 1.333323359489441,
      "learning_rate": 0.00011571853032828466,
      "loss": 0.0639,
      "step": 5816
    },
    {
      "epoch": 0.4215675616914882,
      "grad_norm": 2.9218926429748535,
      "learning_rate": 0.00011570403652438584,
      "loss": 0.1736,
      "step": 5817
    },
    {
      "epoch": 0.42164003333695693,
      "grad_norm": 1.8281147480010986,
      "learning_rate": 0.000115689542720487,
      "loss": 0.0563,
      "step": 5818
    },
    {
      "epoch": 0.42171250498242563,
      "grad_norm": 0.23967911303043365,
      "learning_rate": 0.00011567504891658815,
      "loss": 0.0048,
      "step": 5819
    },
    {
      "epoch": 0.4217849766278943,
      "grad_norm": 1.346453070640564,
      "learning_rate": 0.00011566055511268934,
      "loss": 0.0399,
      "step": 5820
    },
    {
      "epoch": 0.421857448273363,
      "grad_norm": 1.0748742818832397,
      "learning_rate": 0.00011564606130879049,
      "loss": 0.0242,
      "step": 5821
    },
    {
      "epoch": 0.4219299199188318,
      "grad_norm": 3.793038845062256,
      "learning_rate": 0.00011563156750489166,
      "loss": 0.0766,
      "step": 5822
    },
    {
      "epoch": 0.42200239156430047,
      "grad_norm": 0.934412956237793,
      "learning_rate": 0.00011561707370099283,
      "loss": 0.0593,
      "step": 5823
    },
    {
      "epoch": 0.42207486320976917,
      "grad_norm": 1.8981742858886719,
      "learning_rate": 0.000115602579897094,
      "loss": 0.1205,
      "step": 5824
    },
    {
      "epoch": 0.42214733485523787,
      "grad_norm": 2.2452850341796875,
      "learning_rate": 0.00011558808609319516,
      "loss": 0.0749,
      "step": 5825
    },
    {
      "epoch": 0.4222198065007066,
      "grad_norm": 2.2648980617523193,
      "learning_rate": 0.00011557359228929634,
      "loss": 0.1155,
      "step": 5826
    },
    {
      "epoch": 0.4222922781461753,
      "grad_norm": 1.7804286479949951,
      "learning_rate": 0.0001155590984853975,
      "loss": 0.0455,
      "step": 5827
    },
    {
      "epoch": 0.422364749791644,
      "grad_norm": 1.3623167276382446,
      "learning_rate": 0.00011554460468149866,
      "loss": 0.0558,
      "step": 5828
    },
    {
      "epoch": 0.4224372214371127,
      "grad_norm": 7.586324691772461,
      "learning_rate": 0.00011553011087759984,
      "loss": 0.0994,
      "step": 5829
    },
    {
      "epoch": 0.42250969308258146,
      "grad_norm": 1.0149203538894653,
      "learning_rate": 0.000115515617073701,
      "loss": 0.0491,
      "step": 5830
    },
    {
      "epoch": 0.42258216472805016,
      "grad_norm": 1.5927191972732544,
      "learning_rate": 0.00011550112326980215,
      "loss": 0.0308,
      "step": 5831
    },
    {
      "epoch": 0.42265463637351885,
      "grad_norm": 1.4647133350372314,
      "learning_rate": 0.00011548662946590334,
      "loss": 0.0998,
      "step": 5832
    },
    {
      "epoch": 0.42272710801898755,
      "grad_norm": 3.001725435256958,
      "learning_rate": 0.00011547213566200449,
      "loss": 0.1432,
      "step": 5833
    },
    {
      "epoch": 0.4227995796644563,
      "grad_norm": 3.0907602310180664,
      "learning_rate": 0.00011545764185810566,
      "loss": 0.1408,
      "step": 5834
    },
    {
      "epoch": 0.422872051309925,
      "grad_norm": 1.336364984512329,
      "learning_rate": 0.00011544314805420685,
      "loss": 0.0493,
      "step": 5835
    },
    {
      "epoch": 0.4229445229553937,
      "grad_norm": 3.4627768993377686,
      "learning_rate": 0.000115428654250308,
      "loss": 0.1357,
      "step": 5836
    },
    {
      "epoch": 0.4230169946008624,
      "grad_norm": 1.3016043901443481,
      "learning_rate": 0.00011541416044640916,
      "loss": 0.0634,
      "step": 5837
    },
    {
      "epoch": 0.42308946624633115,
      "grad_norm": 0.9758614897727966,
      "learning_rate": 0.00011539966664251034,
      "loss": 0.0279,
      "step": 5838
    },
    {
      "epoch": 0.42316193789179984,
      "grad_norm": 0.2812643349170685,
      "learning_rate": 0.0001153851728386115,
      "loss": 0.0113,
      "step": 5839
    },
    {
      "epoch": 0.42323440953726854,
      "grad_norm": 4.629220485687256,
      "learning_rate": 0.00011537067903471266,
      "loss": 0.1409,
      "step": 5840
    },
    {
      "epoch": 0.42330688118273724,
      "grad_norm": 0.6668776869773865,
      "learning_rate": 0.00011535618523081384,
      "loss": 0.0716,
      "step": 5841
    },
    {
      "epoch": 0.423379352828206,
      "grad_norm": 1.707305908203125,
      "learning_rate": 0.000115341691426915,
      "loss": 0.0836,
      "step": 5842
    },
    {
      "epoch": 0.4234518244736747,
      "grad_norm": 1.626115322113037,
      "learning_rate": 0.00011532719762301615,
      "loss": 0.1712,
      "step": 5843
    },
    {
      "epoch": 0.4235242961191434,
      "grad_norm": 1.7103365659713745,
      "learning_rate": 0.00011531270381911734,
      "loss": 0.0663,
      "step": 5844
    },
    {
      "epoch": 0.4235967677646121,
      "grad_norm": 5.132594585418701,
      "learning_rate": 0.0001152982100152185,
      "loss": 0.1487,
      "step": 5845
    },
    {
      "epoch": 0.42366923941008083,
      "grad_norm": 1.204323649406433,
      "learning_rate": 0.00011528371621131966,
      "loss": 0.128,
      "step": 5846
    },
    {
      "epoch": 0.42374171105554953,
      "grad_norm": 1.1525115966796875,
      "learning_rate": 0.00011526922240742085,
      "loss": 0.0998,
      "step": 5847
    },
    {
      "epoch": 0.4238141827010182,
      "grad_norm": 0.49221813678741455,
      "learning_rate": 0.000115254728603522,
      "loss": 0.0244,
      "step": 5848
    },
    {
      "epoch": 0.4238866543464869,
      "grad_norm": 0.36909595131874084,
      "learning_rate": 0.00011524023479962316,
      "loss": 0.0214,
      "step": 5849
    },
    {
      "epoch": 0.4239591259919556,
      "grad_norm": 0.3882453143596649,
      "learning_rate": 0.00011522574099572434,
      "loss": 0.0222,
      "step": 5850
    },
    {
      "epoch": 0.4240315976374244,
      "grad_norm": 2.6443557739257812,
      "learning_rate": 0.0001152112471918255,
      "loss": 0.1394,
      "step": 5851
    },
    {
      "epoch": 0.42410406928289307,
      "grad_norm": 1.1505484580993652,
      "learning_rate": 0.00011519675338792666,
      "loss": 0.0748,
      "step": 5852
    },
    {
      "epoch": 0.42417654092836177,
      "grad_norm": 2.265571355819702,
      "learning_rate": 0.00011518225958402784,
      "loss": 0.1816,
      "step": 5853
    },
    {
      "epoch": 0.42424901257383046,
      "grad_norm": 1.0389435291290283,
      "learning_rate": 0.000115167765780129,
      "loss": 0.0504,
      "step": 5854
    },
    {
      "epoch": 0.4243214842192992,
      "grad_norm": 0.43440595269203186,
      "learning_rate": 0.00011515327197623017,
      "loss": 0.0343,
      "step": 5855
    },
    {
      "epoch": 0.4243939558647679,
      "grad_norm": 1.0087318420410156,
      "learning_rate": 0.00011513877817233134,
      "loss": 0.0397,
      "step": 5856
    },
    {
      "epoch": 0.4244664275102366,
      "grad_norm": 0.7217127084732056,
      "learning_rate": 0.0001151242843684325,
      "loss": 0.0583,
      "step": 5857
    },
    {
      "epoch": 0.4245388991557053,
      "grad_norm": 1.0768208503723145,
      "learning_rate": 0.00011510979056453366,
      "loss": 0.0762,
      "step": 5858
    },
    {
      "epoch": 0.42461137080117406,
      "grad_norm": 1.9719891548156738,
      "learning_rate": 0.00011509529676063485,
      "loss": 0.1723,
      "step": 5859
    },
    {
      "epoch": 0.42468384244664276,
      "grad_norm": 1.5453150272369385,
      "learning_rate": 0.000115080802956736,
      "loss": 0.111,
      "step": 5860
    },
    {
      "epoch": 0.42475631409211145,
      "grad_norm": 1.6983510255813599,
      "learning_rate": 0.00011506630915283716,
      "loss": 0.0834,
      "step": 5861
    },
    {
      "epoch": 0.42482878573758015,
      "grad_norm": 0.651106595993042,
      "learning_rate": 0.00011505181534893834,
      "loss": 0.0268,
      "step": 5862
    },
    {
      "epoch": 0.4249012573830489,
      "grad_norm": 0.7783423066139221,
      "learning_rate": 0.0001150373215450395,
      "loss": 0.0674,
      "step": 5863
    },
    {
      "epoch": 0.4249737290285176,
      "grad_norm": 1.0828394889831543,
      "learning_rate": 0.00011502282774114066,
      "loss": 0.0235,
      "step": 5864
    },
    {
      "epoch": 0.4250462006739863,
      "grad_norm": 0.7790302634239197,
      "learning_rate": 0.00011500833393724184,
      "loss": 0.0307,
      "step": 5865
    },
    {
      "epoch": 0.425118672319455,
      "grad_norm": 0.4529806673526764,
      "learning_rate": 0.000114993840133343,
      "loss": 0.0177,
      "step": 5866
    },
    {
      "epoch": 0.42519114396492375,
      "grad_norm": 0.9601588845252991,
      "learning_rate": 0.00011497934632944417,
      "loss": 0.0345,
      "step": 5867
    },
    {
      "epoch": 0.42526361561039244,
      "grad_norm": 0.5362185835838318,
      "learning_rate": 0.00011496485252554534,
      "loss": 0.012,
      "step": 5868
    },
    {
      "epoch": 0.42533608725586114,
      "grad_norm": 1.3624663352966309,
      "learning_rate": 0.0001149503587216465,
      "loss": 0.053,
      "step": 5869
    },
    {
      "epoch": 0.42540855890132984,
      "grad_norm": 2.561082363128662,
      "learning_rate": 0.00011493586491774766,
      "loss": 0.1596,
      "step": 5870
    },
    {
      "epoch": 0.4254810305467986,
      "grad_norm": 1.7626670598983765,
      "learning_rate": 0.00011492137111384885,
      "loss": 0.1127,
      "step": 5871
    },
    {
      "epoch": 0.4255535021922673,
      "grad_norm": 1.9534789323806763,
      "learning_rate": 0.00011490687730995,
      "loss": 0.154,
      "step": 5872
    },
    {
      "epoch": 0.425625973837736,
      "grad_norm": 0.6524829268455505,
      "learning_rate": 0.00011489238350605116,
      "loss": 0.0191,
      "step": 5873
    },
    {
      "epoch": 0.4256984454832047,
      "grad_norm": 1.897573471069336,
      "learning_rate": 0.00011487788970215234,
      "loss": 0.0884,
      "step": 5874
    },
    {
      "epoch": 0.42577091712867343,
      "grad_norm": 0.6156785488128662,
      "learning_rate": 0.0001148633958982535,
      "loss": 0.0272,
      "step": 5875
    },
    {
      "epoch": 0.42584338877414213,
      "grad_norm": 0.6514720916748047,
      "learning_rate": 0.00011484890209435466,
      "loss": 0.0435,
      "step": 5876
    },
    {
      "epoch": 0.4259158604196108,
      "grad_norm": 1.730743408203125,
      "learning_rate": 0.00011483440829045584,
      "loss": 0.1102,
      "step": 5877
    },
    {
      "epoch": 0.4259883320650795,
      "grad_norm": 0.3450808823108673,
      "learning_rate": 0.000114819914486557,
      "loss": 0.0153,
      "step": 5878
    },
    {
      "epoch": 0.4260608037105483,
      "grad_norm": 0.30471140146255493,
      "learning_rate": 0.00011480542068265817,
      "loss": 0.0051,
      "step": 5879
    },
    {
      "epoch": 0.42613327535601697,
      "grad_norm": 0.5359026789665222,
      "learning_rate": 0.00011479092687875934,
      "loss": 0.0186,
      "step": 5880
    },
    {
      "epoch": 0.42620574700148567,
      "grad_norm": 2.521982431411743,
      "learning_rate": 0.0001147764330748605,
      "loss": 0.1316,
      "step": 5881
    },
    {
      "epoch": 0.42627821864695437,
      "grad_norm": 4.157721042633057,
      "learning_rate": 0.00011476193927096166,
      "loss": 0.1101,
      "step": 5882
    },
    {
      "epoch": 0.42635069029242306,
      "grad_norm": 0.6530039310455322,
      "learning_rate": 0.00011474744546706285,
      "loss": 0.0397,
      "step": 5883
    },
    {
      "epoch": 0.4264231619378918,
      "grad_norm": 1.7597235441207886,
      "learning_rate": 0.000114732951663164,
      "loss": 0.0494,
      "step": 5884
    },
    {
      "epoch": 0.4264956335833605,
      "grad_norm": 1.386120319366455,
      "learning_rate": 0.00011471845785926516,
      "loss": 0.1879,
      "step": 5885
    },
    {
      "epoch": 0.4265681052288292,
      "grad_norm": 3.260603189468384,
      "learning_rate": 0.00011470396405536634,
      "loss": 0.1219,
      "step": 5886
    },
    {
      "epoch": 0.4266405768742979,
      "grad_norm": 0.6939361691474915,
      "learning_rate": 0.0001146894702514675,
      "loss": 0.024,
      "step": 5887
    },
    {
      "epoch": 0.42671304851976666,
      "grad_norm": 1.158979892730713,
      "learning_rate": 0.00011467497644756866,
      "loss": 0.0349,
      "step": 5888
    },
    {
      "epoch": 0.42678552016523535,
      "grad_norm": 0.5232912302017212,
      "learning_rate": 0.00011466048264366984,
      "loss": 0.0187,
      "step": 5889
    },
    {
      "epoch": 0.42685799181070405,
      "grad_norm": 1.662213683128357,
      "learning_rate": 0.000114645988839771,
      "loss": 0.125,
      "step": 5890
    },
    {
      "epoch": 0.42693046345617275,
      "grad_norm": 0.4549556076526642,
      "learning_rate": 0.00011463149503587217,
      "loss": 0.0159,
      "step": 5891
    },
    {
      "epoch": 0.4270029351016415,
      "grad_norm": 0.7286481857299805,
      "learning_rate": 0.00011461700123197335,
      "loss": 0.0179,
      "step": 5892
    },
    {
      "epoch": 0.4270754067471102,
      "grad_norm": 1.24086594581604,
      "learning_rate": 0.0001146025074280745,
      "loss": 0.0322,
      "step": 5893
    },
    {
      "epoch": 0.4271478783925789,
      "grad_norm": 1.4316908121109009,
      "learning_rate": 0.00011458801362417566,
      "loss": 0.0291,
      "step": 5894
    },
    {
      "epoch": 0.4272203500380476,
      "grad_norm": 1.3419750928878784,
      "learning_rate": 0.00011457351982027685,
      "loss": 0.1511,
      "step": 5895
    },
    {
      "epoch": 0.42729282168351634,
      "grad_norm": 0.7912040948867798,
      "learning_rate": 0.000114559026016378,
      "loss": 0.0922,
      "step": 5896
    },
    {
      "epoch": 0.42736529332898504,
      "grad_norm": 1.5516499280929565,
      "learning_rate": 0.00011454453221247916,
      "loss": 0.0939,
      "step": 5897
    },
    {
      "epoch": 0.42743776497445374,
      "grad_norm": 2.2662503719329834,
      "learning_rate": 0.00011453003840858034,
      "loss": 0.1012,
      "step": 5898
    },
    {
      "epoch": 0.42751023661992243,
      "grad_norm": 0.5676171183586121,
      "learning_rate": 0.0001145155446046815,
      "loss": 0.0447,
      "step": 5899
    },
    {
      "epoch": 0.4275827082653912,
      "grad_norm": 1.910720944404602,
      "learning_rate": 0.00011450105080078265,
      "loss": 0.1556,
      "step": 5900
    },
    {
      "epoch": 0.4276551799108599,
      "grad_norm": 1.5395921468734741,
      "learning_rate": 0.00011448655699688384,
      "loss": 0.1089,
      "step": 5901
    },
    {
      "epoch": 0.4277276515563286,
      "grad_norm": 3.6024277210235596,
      "learning_rate": 0.000114472063192985,
      "loss": 0.1641,
      "step": 5902
    },
    {
      "epoch": 0.4278001232017973,
      "grad_norm": 0.8996506333351135,
      "learning_rate": 0.00011445756938908617,
      "loss": 0.0327,
      "step": 5903
    },
    {
      "epoch": 0.42787259484726603,
      "grad_norm": 0.9362156987190247,
      "learning_rate": 0.00011444307558518735,
      "loss": 0.0934,
      "step": 5904
    },
    {
      "epoch": 0.4279450664927347,
      "grad_norm": 1.1494277715682983,
      "learning_rate": 0.0001144285817812885,
      "loss": 0.0255,
      "step": 5905
    },
    {
      "epoch": 0.4280175381382034,
      "grad_norm": 0.4422774016857147,
      "learning_rate": 0.00011441408797738966,
      "loss": 0.0154,
      "step": 5906
    },
    {
      "epoch": 0.4280900097836721,
      "grad_norm": 0.5246090888977051,
      "learning_rate": 0.00011439959417349085,
      "loss": 0.0186,
      "step": 5907
    },
    {
      "epoch": 0.4281624814291409,
      "grad_norm": 0.28855428099632263,
      "learning_rate": 0.000114385100369592,
      "loss": 0.0051,
      "step": 5908
    },
    {
      "epoch": 0.42823495307460957,
      "grad_norm": 1.9717342853546143,
      "learning_rate": 0.00011437060656569316,
      "loss": 0.0907,
      "step": 5909
    },
    {
      "epoch": 0.42830742472007827,
      "grad_norm": 0.46827375888824463,
      "learning_rate": 0.00011435611276179434,
      "loss": 0.036,
      "step": 5910
    },
    {
      "epoch": 0.42837989636554696,
      "grad_norm": 1.1547460556030273,
      "learning_rate": 0.0001143416189578955,
      "loss": 0.0363,
      "step": 5911
    },
    {
      "epoch": 0.4284523680110157,
      "grad_norm": 1.4201020002365112,
      "learning_rate": 0.00011432712515399665,
      "loss": 0.0519,
      "step": 5912
    },
    {
      "epoch": 0.4285248396564844,
      "grad_norm": 1.0080424547195435,
      "learning_rate": 0.00011431263135009784,
      "loss": 0.0578,
      "step": 5913
    },
    {
      "epoch": 0.4285973113019531,
      "grad_norm": 1.7447384595870972,
      "learning_rate": 0.00011429813754619901,
      "loss": 0.0953,
      "step": 5914
    },
    {
      "epoch": 0.4286697829474218,
      "grad_norm": 0.20656831562519073,
      "learning_rate": 0.00011428364374230016,
      "loss": 0.0062,
      "step": 5915
    },
    {
      "epoch": 0.42874225459289056,
      "grad_norm": 1.7445963621139526,
      "learning_rate": 0.00011426914993840135,
      "loss": 0.1005,
      "step": 5916
    },
    {
      "epoch": 0.42881472623835926,
      "grad_norm": 1.1008810997009277,
      "learning_rate": 0.0001142546561345025,
      "loss": 0.0363,
      "step": 5917
    },
    {
      "epoch": 0.42888719788382795,
      "grad_norm": 2.238054037094116,
      "learning_rate": 0.00011424016233060366,
      "loss": 0.0638,
      "step": 5918
    },
    {
      "epoch": 0.42895966952929665,
      "grad_norm": 2.215698719024658,
      "learning_rate": 0.00011422566852670485,
      "loss": 0.0678,
      "step": 5919
    },
    {
      "epoch": 0.42903214117476535,
      "grad_norm": 0.6475645899772644,
      "learning_rate": 0.000114211174722806,
      "loss": 0.0105,
      "step": 5920
    },
    {
      "epoch": 0.4291046128202341,
      "grad_norm": 1.2644857168197632,
      "learning_rate": 0.00011419668091890716,
      "loss": 0.039,
      "step": 5921
    },
    {
      "epoch": 0.4291770844657028,
      "grad_norm": 1.4156270027160645,
      "learning_rate": 0.00011418218711500834,
      "loss": 0.0525,
      "step": 5922
    },
    {
      "epoch": 0.4292495561111715,
      "grad_norm": 0.3638961613178253,
      "learning_rate": 0.0001141676933111095,
      "loss": 0.0151,
      "step": 5923
    },
    {
      "epoch": 0.4293220277566402,
      "grad_norm": 1.1965343952178955,
      "learning_rate": 0.00011415319950721067,
      "loss": 0.0573,
      "step": 5924
    },
    {
      "epoch": 0.42939449940210894,
      "grad_norm": 1.9969722032546997,
      "learning_rate": 0.00011413870570331184,
      "loss": 0.1403,
      "step": 5925
    },
    {
      "epoch": 0.42946697104757764,
      "grad_norm": 0.43273240327835083,
      "learning_rate": 0.00011412421189941301,
      "loss": 0.0049,
      "step": 5926
    },
    {
      "epoch": 0.42953944269304634,
      "grad_norm": 3.205996513366699,
      "learning_rate": 0.00011410971809551418,
      "loss": 0.1312,
      "step": 5927
    },
    {
      "epoch": 0.42961191433851503,
      "grad_norm": 2.7783048152923584,
      "learning_rate": 0.00011409522429161535,
      "loss": 0.0404,
      "step": 5928
    },
    {
      "epoch": 0.4296843859839838,
      "grad_norm": 2.7501659393310547,
      "learning_rate": 0.0001140807304877165,
      "loss": 0.0685,
      "step": 5929
    },
    {
      "epoch": 0.4297568576294525,
      "grad_norm": 6.266803741455078,
      "learning_rate": 0.00011406623668381769,
      "loss": 0.0586,
      "step": 5930
    },
    {
      "epoch": 0.4298293292749212,
      "grad_norm": 1.9645434617996216,
      "learning_rate": 0.00011405174287991884,
      "loss": 0.0394,
      "step": 5931
    },
    {
      "epoch": 0.4299018009203899,
      "grad_norm": 2.587395668029785,
      "learning_rate": 0.00011403724907602,
      "loss": 0.0936,
      "step": 5932
    },
    {
      "epoch": 0.42997427256585863,
      "grad_norm": 2.3184378147125244,
      "learning_rate": 0.00011402275527212118,
      "loss": 0.1473,
      "step": 5933
    },
    {
      "epoch": 0.4300467442113273,
      "grad_norm": 1.673433542251587,
      "learning_rate": 0.00011400826146822234,
      "loss": 0.1153,
      "step": 5934
    },
    {
      "epoch": 0.430119215856796,
      "grad_norm": 0.8078849911689758,
      "learning_rate": 0.0001139937676643235,
      "loss": 0.0348,
      "step": 5935
    },
    {
      "epoch": 0.4301916875022647,
      "grad_norm": 1.548683524131775,
      "learning_rate": 0.00011397927386042468,
      "loss": 0.044,
      "step": 5936
    },
    {
      "epoch": 0.43026415914773347,
      "grad_norm": 1.6662418842315674,
      "learning_rate": 0.00011396478005652584,
      "loss": 0.0475,
      "step": 5937
    },
    {
      "epoch": 0.43033663079320217,
      "grad_norm": 0.7845708131790161,
      "learning_rate": 0.00011395028625262701,
      "loss": 0.0269,
      "step": 5938
    },
    {
      "epoch": 0.43040910243867087,
      "grad_norm": 0.43316835165023804,
      "learning_rate": 0.00011393579244872818,
      "loss": 0.0352,
      "step": 5939
    },
    {
      "epoch": 0.43048157408413956,
      "grad_norm": 0.8816404342651367,
      "learning_rate": 0.00011392129864482935,
      "loss": 0.0728,
      "step": 5940
    },
    {
      "epoch": 0.4305540457296083,
      "grad_norm": 0.7819458246231079,
      "learning_rate": 0.0001139068048409305,
      "loss": 0.0175,
      "step": 5941
    },
    {
      "epoch": 0.430626517375077,
      "grad_norm": 1.724908709526062,
      "learning_rate": 0.00011389231103703169,
      "loss": 0.0958,
      "step": 5942
    },
    {
      "epoch": 0.4306989890205457,
      "grad_norm": 2.2196197509765625,
      "learning_rate": 0.00011387781723313284,
      "loss": 0.1492,
      "step": 5943
    },
    {
      "epoch": 0.4307714606660144,
      "grad_norm": 0.6738176345825195,
      "learning_rate": 0.000113863323429234,
      "loss": 0.0277,
      "step": 5944
    },
    {
      "epoch": 0.43084393231148316,
      "grad_norm": 0.45804643630981445,
      "learning_rate": 0.00011384882962533518,
      "loss": 0.0389,
      "step": 5945
    },
    {
      "epoch": 0.43091640395695185,
      "grad_norm": 0.8268958926200867,
      "learning_rate": 0.00011383433582143634,
      "loss": 0.0243,
      "step": 5946
    },
    {
      "epoch": 0.43098887560242055,
      "grad_norm": 0.9971920847892761,
      "learning_rate": 0.0001138198420175375,
      "loss": 0.0434,
      "step": 5947
    },
    {
      "epoch": 0.43106134724788925,
      "grad_norm": 1.4365015029907227,
      "learning_rate": 0.00011380534821363868,
      "loss": 0.0416,
      "step": 5948
    },
    {
      "epoch": 0.431133818893358,
      "grad_norm": 1.8933459520339966,
      "learning_rate": 0.00011379085440973984,
      "loss": 0.0541,
      "step": 5949
    },
    {
      "epoch": 0.4312062905388267,
      "grad_norm": 0.12924878299236298,
      "learning_rate": 0.00011377636060584101,
      "loss": 0.0042,
      "step": 5950
    },
    {
      "epoch": 0.4312787621842954,
      "grad_norm": 0.5907954573631287,
      "learning_rate": 0.00011376186680194219,
      "loss": 0.0283,
      "step": 5951
    },
    {
      "epoch": 0.4313512338297641,
      "grad_norm": 4.220656394958496,
      "learning_rate": 0.00011374737299804335,
      "loss": 0.039,
      "step": 5952
    },
    {
      "epoch": 0.4314237054752328,
      "grad_norm": 7.613380432128906,
      "learning_rate": 0.0001137328791941445,
      "loss": 0.1413,
      "step": 5953
    },
    {
      "epoch": 0.43149617712070154,
      "grad_norm": 3.265789747238159,
      "learning_rate": 0.00011371838539024569,
      "loss": 0.0806,
      "step": 5954
    },
    {
      "epoch": 0.43156864876617024,
      "grad_norm": 0.9324926733970642,
      "learning_rate": 0.00011370389158634684,
      "loss": 0.0655,
      "step": 5955
    },
    {
      "epoch": 0.43164112041163893,
      "grad_norm": 1.1494678258895874,
      "learning_rate": 0.000113689397782448,
      "loss": 0.0393,
      "step": 5956
    },
    {
      "epoch": 0.43171359205710763,
      "grad_norm": 1.5848060846328735,
      "learning_rate": 0.00011367490397854918,
      "loss": 0.1877,
      "step": 5957
    },
    {
      "epoch": 0.4317860637025764,
      "grad_norm": 3.372793436050415,
      "learning_rate": 0.00011366041017465034,
      "loss": 0.0613,
      "step": 5958
    },
    {
      "epoch": 0.4318585353480451,
      "grad_norm": 1.4361170530319214,
      "learning_rate": 0.0001136459163707515,
      "loss": 0.0825,
      "step": 5959
    },
    {
      "epoch": 0.4319310069935138,
      "grad_norm": 0.8329209089279175,
      "learning_rate": 0.00011363142256685268,
      "loss": 0.0246,
      "step": 5960
    },
    {
      "epoch": 0.4320034786389825,
      "grad_norm": 0.8476417660713196,
      "learning_rate": 0.00011361692876295385,
      "loss": 0.05,
      "step": 5961
    },
    {
      "epoch": 0.4320759502844512,
      "grad_norm": 3.360490083694458,
      "learning_rate": 0.00011360243495905501,
      "loss": 0.2121,
      "step": 5962
    },
    {
      "epoch": 0.4321484219299199,
      "grad_norm": 7.413188934326172,
      "learning_rate": 0.00011358794115515619,
      "loss": 0.0817,
      "step": 5963
    },
    {
      "epoch": 0.4322208935753886,
      "grad_norm": 1.329537272453308,
      "learning_rate": 0.00011357344735125735,
      "loss": 0.0583,
      "step": 5964
    },
    {
      "epoch": 0.4322933652208573,
      "grad_norm": 6.225454807281494,
      "learning_rate": 0.0001135589535473585,
      "loss": 0.072,
      "step": 5965
    },
    {
      "epoch": 0.43236583686632607,
      "grad_norm": 2.2568609714508057,
      "learning_rate": 0.00011354445974345969,
      "loss": 0.0402,
      "step": 5966
    },
    {
      "epoch": 0.43243830851179477,
      "grad_norm": 2.5327539443969727,
      "learning_rate": 0.00011352996593956084,
      "loss": 0.1014,
      "step": 5967
    },
    {
      "epoch": 0.43251078015726346,
      "grad_norm": 4.259815692901611,
      "learning_rate": 0.000113515472135662,
      "loss": 0.0623,
      "step": 5968
    },
    {
      "epoch": 0.43258325180273216,
      "grad_norm": 0.5883274674415588,
      "learning_rate": 0.00011350097833176318,
      "loss": 0.0533,
      "step": 5969
    },
    {
      "epoch": 0.4326557234482009,
      "grad_norm": 0.8882694840431213,
      "learning_rate": 0.00011348648452786434,
      "loss": 0.042,
      "step": 5970
    },
    {
      "epoch": 0.4327281950936696,
      "grad_norm": 1.1530046463012695,
      "learning_rate": 0.00011347199072396551,
      "loss": 0.0443,
      "step": 5971
    },
    {
      "epoch": 0.4328006667391383,
      "grad_norm": 1.4411559104919434,
      "learning_rate": 0.00011345749692006668,
      "loss": 0.0686,
      "step": 5972
    },
    {
      "epoch": 0.432873138384607,
      "grad_norm": 0.8332395553588867,
      "learning_rate": 0.00011344300311616785,
      "loss": 0.0227,
      "step": 5973
    },
    {
      "epoch": 0.43294561003007576,
      "grad_norm": 0.8218008875846863,
      "learning_rate": 0.00011342850931226901,
      "loss": 0.0197,
      "step": 5974
    },
    {
      "epoch": 0.43301808167554445,
      "grad_norm": 1.4435780048370361,
      "learning_rate": 0.00011341401550837019,
      "loss": 0.0956,
      "step": 5975
    },
    {
      "epoch": 0.43309055332101315,
      "grad_norm": 1.2294936180114746,
      "learning_rate": 0.00011339952170447135,
      "loss": 0.0191,
      "step": 5976
    },
    {
      "epoch": 0.43316302496648185,
      "grad_norm": 2.6968369483947754,
      "learning_rate": 0.0001133850279005725,
      "loss": 0.0812,
      "step": 5977
    },
    {
      "epoch": 0.4332354966119506,
      "grad_norm": 5.224407196044922,
      "learning_rate": 0.00011337053409667369,
      "loss": 0.1799,
      "step": 5978
    },
    {
      "epoch": 0.4333079682574193,
      "grad_norm": 2.5523252487182617,
      "learning_rate": 0.00011335604029277484,
      "loss": 0.1298,
      "step": 5979
    },
    {
      "epoch": 0.433380439902888,
      "grad_norm": 0.6297754049301147,
      "learning_rate": 0.000113341546488876,
      "loss": 0.0264,
      "step": 5980
    },
    {
      "epoch": 0.4334529115483567,
      "grad_norm": 2.188762664794922,
      "learning_rate": 0.00011332705268497718,
      "loss": 0.0492,
      "step": 5981
    },
    {
      "epoch": 0.43352538319382544,
      "grad_norm": 4.243755340576172,
      "learning_rate": 0.00011331255888107834,
      "loss": 0.0771,
      "step": 5982
    },
    {
      "epoch": 0.43359785483929414,
      "grad_norm": 2.771515130996704,
      "learning_rate": 0.00011329806507717951,
      "loss": 0.1125,
      "step": 5983
    },
    {
      "epoch": 0.43367032648476284,
      "grad_norm": 2.268674612045288,
      "learning_rate": 0.00011328357127328068,
      "loss": 0.1954,
      "step": 5984
    },
    {
      "epoch": 0.43374279813023153,
      "grad_norm": 1.7904431819915771,
      "learning_rate": 0.00011326907746938185,
      "loss": 0.0866,
      "step": 5985
    },
    {
      "epoch": 0.43381526977570023,
      "grad_norm": 0.8922761082649231,
      "learning_rate": 0.00011325458366548301,
      "loss": 0.0441,
      "step": 5986
    },
    {
      "epoch": 0.433887741421169,
      "grad_norm": 0.9984239339828491,
      "learning_rate": 0.00011324008986158419,
      "loss": 0.0467,
      "step": 5987
    },
    {
      "epoch": 0.4339602130666377,
      "grad_norm": 1.366890549659729,
      "learning_rate": 0.00011322559605768535,
      "loss": 0.1253,
      "step": 5988
    },
    {
      "epoch": 0.4340326847121064,
      "grad_norm": 1.5314065217971802,
      "learning_rate": 0.0001132111022537865,
      "loss": 0.0769,
      "step": 5989
    },
    {
      "epoch": 0.4341051563575751,
      "grad_norm": 2.11803936958313,
      "learning_rate": 0.00011319660844988769,
      "loss": 0.1534,
      "step": 5990
    },
    {
      "epoch": 0.4341776280030438,
      "grad_norm": 0.9520419836044312,
      "learning_rate": 0.00011318211464598884,
      "loss": 0.057,
      "step": 5991
    },
    {
      "epoch": 0.4342500996485125,
      "grad_norm": 3.385078191757202,
      "learning_rate": 0.00011316762084209,
      "loss": 0.0219,
      "step": 5992
    },
    {
      "epoch": 0.4343225712939812,
      "grad_norm": 0.8372945785522461,
      "learning_rate": 0.00011315312703819118,
      "loss": 0.0333,
      "step": 5993
    },
    {
      "epoch": 0.4343950429394499,
      "grad_norm": 1.9134619235992432,
      "learning_rate": 0.00011313863323429234,
      "loss": 0.0517,
      "step": 5994
    },
    {
      "epoch": 0.43446751458491867,
      "grad_norm": 1.9960781335830688,
      "learning_rate": 0.00011312413943039351,
      "loss": 0.1294,
      "step": 5995
    },
    {
      "epoch": 0.43453998623038737,
      "grad_norm": 2.212285041809082,
      "learning_rate": 0.00011310964562649468,
      "loss": 0.0514,
      "step": 5996
    },
    {
      "epoch": 0.43461245787585606,
      "grad_norm": 1.3629721403121948,
      "learning_rate": 0.00011309515182259585,
      "loss": 0.0523,
      "step": 5997
    },
    {
      "epoch": 0.43468492952132476,
      "grad_norm": 2.815312385559082,
      "learning_rate": 0.00011308065801869701,
      "loss": 0.1475,
      "step": 5998
    },
    {
      "epoch": 0.4347574011667935,
      "grad_norm": 0.43874743580818176,
      "learning_rate": 0.00011306616421479819,
      "loss": 0.0245,
      "step": 5999
    },
    {
      "epoch": 0.4348298728122622,
      "grad_norm": 2.32293963432312,
      "learning_rate": 0.00011305167041089935,
      "loss": 0.0443,
      "step": 6000
    },
    {
      "epoch": 0.4349023444577309,
      "grad_norm": 1.9729100465774536,
      "learning_rate": 0.0001130371766070005,
      "loss": 0.0661,
      "step": 6001
    },
    {
      "epoch": 0.4349748161031996,
      "grad_norm": 2.3724799156188965,
      "learning_rate": 0.00011302268280310169,
      "loss": 0.0957,
      "step": 6002
    },
    {
      "epoch": 0.43504728774866835,
      "grad_norm": 2.188711166381836,
      "learning_rate": 0.00011300818899920284,
      "loss": 0.0754,
      "step": 6003
    },
    {
      "epoch": 0.43511975939413705,
      "grad_norm": 2.0552563667297363,
      "learning_rate": 0.000112993695195304,
      "loss": 0.135,
      "step": 6004
    },
    {
      "epoch": 0.43519223103960575,
      "grad_norm": 1.7723802328109741,
      "learning_rate": 0.00011297920139140518,
      "loss": 0.0747,
      "step": 6005
    },
    {
      "epoch": 0.43526470268507444,
      "grad_norm": 0.506450355052948,
      "learning_rate": 0.00011296470758750634,
      "loss": 0.0188,
      "step": 6006
    },
    {
      "epoch": 0.4353371743305432,
      "grad_norm": 5.651040554046631,
      "learning_rate": 0.00011295021378360751,
      "loss": 0.0857,
      "step": 6007
    },
    {
      "epoch": 0.4354096459760119,
      "grad_norm": 1.8454294204711914,
      "learning_rate": 0.0001129357199797087,
      "loss": 0.0894,
      "step": 6008
    },
    {
      "epoch": 0.4354821176214806,
      "grad_norm": 1.0238350629806519,
      "learning_rate": 0.00011292122617580985,
      "loss": 0.1062,
      "step": 6009
    },
    {
      "epoch": 0.4355545892669493,
      "grad_norm": 6.670548915863037,
      "learning_rate": 0.000112906732371911,
      "loss": 0.1295,
      "step": 6010
    },
    {
      "epoch": 0.43562706091241804,
      "grad_norm": 0.6907719969749451,
      "learning_rate": 0.00011289223856801219,
      "loss": 0.057,
      "step": 6011
    },
    {
      "epoch": 0.43569953255788674,
      "grad_norm": 0.7458196878433228,
      "learning_rate": 0.00011287774476411335,
      "loss": 0.0374,
      "step": 6012
    },
    {
      "epoch": 0.43577200420335543,
      "grad_norm": 0.5075157880783081,
      "learning_rate": 0.0001128632509602145,
      "loss": 0.0123,
      "step": 6013
    },
    {
      "epoch": 0.43584447584882413,
      "grad_norm": 2.5103225708007812,
      "learning_rate": 0.00011284875715631569,
      "loss": 0.0223,
      "step": 6014
    },
    {
      "epoch": 0.4359169474942929,
      "grad_norm": 1.6617861986160278,
      "learning_rate": 0.00011283426335241684,
      "loss": 0.1278,
      "step": 6015
    },
    {
      "epoch": 0.4359894191397616,
      "grad_norm": 1.642581582069397,
      "learning_rate": 0.000112819769548518,
      "loss": 0.075,
      "step": 6016
    },
    {
      "epoch": 0.4360618907852303,
      "grad_norm": 1.1639045476913452,
      "learning_rate": 0.00011280527574461918,
      "loss": 0.0439,
      "step": 6017
    },
    {
      "epoch": 0.436134362430699,
      "grad_norm": 0.6674382090568542,
      "learning_rate": 0.00011279078194072035,
      "loss": 0.0379,
      "step": 6018
    },
    {
      "epoch": 0.4362068340761677,
      "grad_norm": 2.114379405975342,
      "learning_rate": 0.00011277628813682151,
      "loss": 0.0993,
      "step": 6019
    },
    {
      "epoch": 0.4362793057216364,
      "grad_norm": 2.339468240737915,
      "learning_rate": 0.0001127617943329227,
      "loss": 0.1043,
      "step": 6020
    },
    {
      "epoch": 0.4363517773671051,
      "grad_norm": 1.4247231483459473,
      "learning_rate": 0.00011274730052902385,
      "loss": 0.0858,
      "step": 6021
    },
    {
      "epoch": 0.4364242490125738,
      "grad_norm": 2.341440200805664,
      "learning_rate": 0.000112732806725125,
      "loss": 0.1192,
      "step": 6022
    },
    {
      "epoch": 0.4364967206580425,
      "grad_norm": 1.3157014846801758,
      "learning_rate": 0.00011271831292122619,
      "loss": 0.024,
      "step": 6023
    },
    {
      "epoch": 0.43656919230351127,
      "grad_norm": 2.123345136642456,
      "learning_rate": 0.00011270381911732735,
      "loss": 0.0356,
      "step": 6024
    },
    {
      "epoch": 0.43664166394897996,
      "grad_norm": 1.1491754055023193,
      "learning_rate": 0.0001126893253134285,
      "loss": 0.0451,
      "step": 6025
    },
    {
      "epoch": 0.43671413559444866,
      "grad_norm": 1.1638838052749634,
      "learning_rate": 0.00011267483150952969,
      "loss": 0.0721,
      "step": 6026
    },
    {
      "epoch": 0.43678660723991736,
      "grad_norm": 1.6447327136993408,
      "learning_rate": 0.00011266033770563084,
      "loss": 0.1521,
      "step": 6027
    },
    {
      "epoch": 0.4368590788853861,
      "grad_norm": 0.7592236995697021,
      "learning_rate": 0.00011264584390173201,
      "loss": 0.0719,
      "step": 6028
    },
    {
      "epoch": 0.4369315505308548,
      "grad_norm": 1.268632173538208,
      "learning_rate": 0.00011263135009783318,
      "loss": 0.1151,
      "step": 6029
    },
    {
      "epoch": 0.4370040221763235,
      "grad_norm": 1.5751014947891235,
      "learning_rate": 0.00011261685629393435,
      "loss": 0.0504,
      "step": 6030
    },
    {
      "epoch": 0.4370764938217922,
      "grad_norm": 2.26936936378479,
      "learning_rate": 0.00011260236249003551,
      "loss": 0.0522,
      "step": 6031
    },
    {
      "epoch": 0.43714896546726095,
      "grad_norm": 2.1374614238739014,
      "learning_rate": 0.0001125878686861367,
      "loss": 0.0597,
      "step": 6032
    },
    {
      "epoch": 0.43722143711272965,
      "grad_norm": 1.111100673675537,
      "learning_rate": 0.00011257337488223785,
      "loss": 0.0502,
      "step": 6033
    },
    {
      "epoch": 0.43729390875819835,
      "grad_norm": 0.6408158540725708,
      "learning_rate": 0.000112558881078339,
      "loss": 0.0359,
      "step": 6034
    },
    {
      "epoch": 0.43736638040366704,
      "grad_norm": 1.1972426176071167,
      "learning_rate": 0.00011254438727444019,
      "loss": 0.0662,
      "step": 6035
    },
    {
      "epoch": 0.4374388520491358,
      "grad_norm": 1.0362898111343384,
      "learning_rate": 0.00011252989347054135,
      "loss": 0.047,
      "step": 6036
    },
    {
      "epoch": 0.4375113236946045,
      "grad_norm": 4.017563343048096,
      "learning_rate": 0.0001125153996666425,
      "loss": 0.0736,
      "step": 6037
    },
    {
      "epoch": 0.4375837953400732,
      "grad_norm": 0.9311161041259766,
      "learning_rate": 0.00011250090586274369,
      "loss": 0.0588,
      "step": 6038
    },
    {
      "epoch": 0.4376562669855419,
      "grad_norm": 2.4006786346435547,
      "learning_rate": 0.00011248641205884484,
      "loss": 0.0401,
      "step": 6039
    },
    {
      "epoch": 0.43772873863101064,
      "grad_norm": 0.8860116600990295,
      "learning_rate": 0.00011247191825494601,
      "loss": 0.0188,
      "step": 6040
    },
    {
      "epoch": 0.43780121027647934,
      "grad_norm": 3.0578463077545166,
      "learning_rate": 0.00011245742445104718,
      "loss": 0.0534,
      "step": 6041
    },
    {
      "epoch": 0.43787368192194803,
      "grad_norm": 1.4646109342575073,
      "learning_rate": 0.00011244293064714835,
      "loss": 0.0628,
      "step": 6042
    },
    {
      "epoch": 0.43794615356741673,
      "grad_norm": 0.2696448564529419,
      "learning_rate": 0.00011242843684324951,
      "loss": 0.0252,
      "step": 6043
    },
    {
      "epoch": 0.4380186252128855,
      "grad_norm": 1.0187146663665771,
      "learning_rate": 0.00011241394303935069,
      "loss": 0.0714,
      "step": 6044
    },
    {
      "epoch": 0.4380910968583542,
      "grad_norm": 0.7163909673690796,
      "learning_rate": 0.00011239944923545185,
      "loss": 0.0252,
      "step": 6045
    },
    {
      "epoch": 0.4381635685038229,
      "grad_norm": 0.9560196399688721,
      "learning_rate": 0.000112384955431553,
      "loss": 0.0638,
      "step": 6046
    },
    {
      "epoch": 0.4382360401492916,
      "grad_norm": 1.3990269899368286,
      "learning_rate": 0.00011237046162765419,
      "loss": 0.0794,
      "step": 6047
    },
    {
      "epoch": 0.4383085117947603,
      "grad_norm": 0.527239978313446,
      "learning_rate": 0.00011235596782375535,
      "loss": 0.0411,
      "step": 6048
    },
    {
      "epoch": 0.438380983440229,
      "grad_norm": 1.0319385528564453,
      "learning_rate": 0.0001123414740198565,
      "loss": 0.0334,
      "step": 6049
    },
    {
      "epoch": 0.4384534550856977,
      "grad_norm": 3.1484241485595703,
      "learning_rate": 0.00011232698021595769,
      "loss": 0.0871,
      "step": 6050
    },
    {
      "epoch": 0.4385259267311664,
      "grad_norm": 0.7865747809410095,
      "learning_rate": 0.00011231248641205884,
      "loss": 0.041,
      "step": 6051
    },
    {
      "epoch": 0.43859839837663517,
      "grad_norm": 0.32223406434059143,
      "learning_rate": 0.00011229799260816001,
      "loss": 0.0093,
      "step": 6052
    },
    {
      "epoch": 0.43867087002210386,
      "grad_norm": 1.4024571180343628,
      "learning_rate": 0.00011228349880426118,
      "loss": 0.105,
      "step": 6053
    },
    {
      "epoch": 0.43874334166757256,
      "grad_norm": 0.9448915123939514,
      "learning_rate": 0.00011226900500036235,
      "loss": 0.0407,
      "step": 6054
    },
    {
      "epoch": 0.43881581331304126,
      "grad_norm": 2.072657585144043,
      "learning_rate": 0.00011225451119646351,
      "loss": 0.0631,
      "step": 6055
    },
    {
      "epoch": 0.43888828495850996,
      "grad_norm": 0.24079419672489166,
      "learning_rate": 0.00011224001739256469,
      "loss": 0.0104,
      "step": 6056
    },
    {
      "epoch": 0.4389607566039787,
      "grad_norm": 0.8910695314407349,
      "learning_rate": 0.00011222552358866585,
      "loss": 0.0423,
      "step": 6057
    },
    {
      "epoch": 0.4390332282494474,
      "grad_norm": 1.0578360557556152,
      "learning_rate": 0.000112211029784767,
      "loss": 0.0511,
      "step": 6058
    },
    {
      "epoch": 0.4391056998949161,
      "grad_norm": 0.8796014189720154,
      "learning_rate": 0.00011219653598086819,
      "loss": 0.0605,
      "step": 6059
    },
    {
      "epoch": 0.4391781715403848,
      "grad_norm": 2.9101269245147705,
      "learning_rate": 0.00011218204217696935,
      "loss": 0.0412,
      "step": 6060
    },
    {
      "epoch": 0.43925064318585355,
      "grad_norm": 1.0352567434310913,
      "learning_rate": 0.0001121675483730705,
      "loss": 0.0579,
      "step": 6061
    },
    {
      "epoch": 0.43932311483132225,
      "grad_norm": 7.256298542022705,
      "learning_rate": 0.00011215305456917169,
      "loss": 0.1663,
      "step": 6062
    },
    {
      "epoch": 0.43939558647679094,
      "grad_norm": 0.7823992371559143,
      "learning_rate": 0.00011213856076527284,
      "loss": 0.0117,
      "step": 6063
    },
    {
      "epoch": 0.43946805812225964,
      "grad_norm": 0.8542677760124207,
      "learning_rate": 0.00011212406696137401,
      "loss": 0.0334,
      "step": 6064
    },
    {
      "epoch": 0.4395405297677284,
      "grad_norm": 2.0272278785705566,
      "learning_rate": 0.0001121095731574752,
      "loss": 0.0332,
      "step": 6065
    },
    {
      "epoch": 0.4396130014131971,
      "grad_norm": 2.508734703063965,
      "learning_rate": 0.00011209507935357635,
      "loss": 0.16,
      "step": 6066
    },
    {
      "epoch": 0.4396854730586658,
      "grad_norm": 1.4983558654785156,
      "learning_rate": 0.00011208058554967751,
      "loss": 0.1046,
      "step": 6067
    },
    {
      "epoch": 0.4397579447041345,
      "grad_norm": 1.1165049076080322,
      "learning_rate": 0.00011206609174577869,
      "loss": 0.0466,
      "step": 6068
    },
    {
      "epoch": 0.43983041634960324,
      "grad_norm": 2.1178019046783447,
      "learning_rate": 0.00011205159794187985,
      "loss": 0.1455,
      "step": 6069
    },
    {
      "epoch": 0.43990288799507193,
      "grad_norm": 0.6781020760536194,
      "learning_rate": 0.000112037104137981,
      "loss": 0.0225,
      "step": 6070
    },
    {
      "epoch": 0.43997535964054063,
      "grad_norm": 1.7919591665267944,
      "learning_rate": 0.00011202261033408219,
      "loss": 0.0395,
      "step": 6071
    },
    {
      "epoch": 0.4400478312860093,
      "grad_norm": 1.0374555587768555,
      "learning_rate": 0.00011200811653018335,
      "loss": 0.0763,
      "step": 6072
    },
    {
      "epoch": 0.4401203029314781,
      "grad_norm": 1.2556766271591187,
      "learning_rate": 0.0001119936227262845,
      "loss": 0.0903,
      "step": 6073
    },
    {
      "epoch": 0.4401927745769468,
      "grad_norm": 1.7841198444366455,
      "learning_rate": 0.00011197912892238569,
      "loss": 0.0583,
      "step": 6074
    },
    {
      "epoch": 0.4402652462224155,
      "grad_norm": 2.6808207035064697,
      "learning_rate": 0.00011196463511848686,
      "loss": 0.1137,
      "step": 6075
    },
    {
      "epoch": 0.44033771786788417,
      "grad_norm": 5.899682998657227,
      "learning_rate": 0.00011195014131458801,
      "loss": 0.0596,
      "step": 6076
    },
    {
      "epoch": 0.4404101895133529,
      "grad_norm": 2.0498743057250977,
      "learning_rate": 0.0001119356475106892,
      "loss": 0.0515,
      "step": 6077
    },
    {
      "epoch": 0.4404826611588216,
      "grad_norm": 0.4673413336277008,
      "learning_rate": 0.00011192115370679035,
      "loss": 0.035,
      "step": 6078
    },
    {
      "epoch": 0.4405551328042903,
      "grad_norm": 2.741499900817871,
      "learning_rate": 0.00011190665990289151,
      "loss": 0.085,
      "step": 6079
    },
    {
      "epoch": 0.440627604449759,
      "grad_norm": 0.3648587465286255,
      "learning_rate": 0.00011189216609899269,
      "loss": 0.0175,
      "step": 6080
    },
    {
      "epoch": 0.44070007609522777,
      "grad_norm": 0.7983720898628235,
      "learning_rate": 0.00011187767229509385,
      "loss": 0.0507,
      "step": 6081
    },
    {
      "epoch": 0.44077254774069646,
      "grad_norm": 3.6652626991271973,
      "learning_rate": 0.000111863178491195,
      "loss": 0.1077,
      "step": 6082
    },
    {
      "epoch": 0.44084501938616516,
      "grad_norm": 1.2056671380996704,
      "learning_rate": 0.00011184868468729619,
      "loss": 0.0818,
      "step": 6083
    },
    {
      "epoch": 0.44091749103163386,
      "grad_norm": 2.4507458209991455,
      "learning_rate": 0.00011183419088339735,
      "loss": 0.1558,
      "step": 6084
    },
    {
      "epoch": 0.4409899626771026,
      "grad_norm": 4.858744144439697,
      "learning_rate": 0.0001118196970794985,
      "loss": 0.1828,
      "step": 6085
    },
    {
      "epoch": 0.4410624343225713,
      "grad_norm": 1.1763888597488403,
      "learning_rate": 0.00011180520327559969,
      "loss": 0.0214,
      "step": 6086
    },
    {
      "epoch": 0.44113490596804,
      "grad_norm": 1.2000471353530884,
      "learning_rate": 0.00011179070947170086,
      "loss": 0.0749,
      "step": 6087
    },
    {
      "epoch": 0.4412073776135087,
      "grad_norm": 1.0887584686279297,
      "learning_rate": 0.00011177621566780201,
      "loss": 0.0283,
      "step": 6088
    },
    {
      "epoch": 0.44127984925897745,
      "grad_norm": 0.6109632253646851,
      "learning_rate": 0.0001117617218639032,
      "loss": 0.0191,
      "step": 6089
    },
    {
      "epoch": 0.44135232090444615,
      "grad_norm": 0.7244284749031067,
      "learning_rate": 0.00011174722806000435,
      "loss": 0.0422,
      "step": 6090
    },
    {
      "epoch": 0.44142479254991485,
      "grad_norm": 0.7514237761497498,
      "learning_rate": 0.00011173273425610554,
      "loss": 0.0095,
      "step": 6091
    },
    {
      "epoch": 0.44149726419538354,
      "grad_norm": 1.7117005586624146,
      "learning_rate": 0.00011171824045220669,
      "loss": 0.0816,
      "step": 6092
    },
    {
      "epoch": 0.44156973584085224,
      "grad_norm": 0.6931955218315125,
      "learning_rate": 0.00011170374664830785,
      "loss": 0.0409,
      "step": 6093
    },
    {
      "epoch": 0.441642207486321,
      "grad_norm": 0.3413493037223816,
      "learning_rate": 0.00011168925284440903,
      "loss": 0.0082,
      "step": 6094
    },
    {
      "epoch": 0.4417146791317897,
      "grad_norm": 1.5393294095993042,
      "learning_rate": 0.00011167475904051019,
      "loss": 0.093,
      "step": 6095
    },
    {
      "epoch": 0.4417871507772584,
      "grad_norm": 2.4275665283203125,
      "learning_rate": 0.00011166026523661135,
      "loss": 0.0825,
      "step": 6096
    },
    {
      "epoch": 0.4418596224227271,
      "grad_norm": 2.996654987335205,
      "learning_rate": 0.00011164577143271253,
      "loss": 0.0303,
      "step": 6097
    },
    {
      "epoch": 0.44193209406819584,
      "grad_norm": 2.3317623138427734,
      "learning_rate": 0.00011163127762881369,
      "loss": 0.0947,
      "step": 6098
    },
    {
      "epoch": 0.44200456571366453,
      "grad_norm": 0.8488363027572632,
      "learning_rate": 0.00011161678382491486,
      "loss": 0.0314,
      "step": 6099
    },
    {
      "epoch": 0.44207703735913323,
      "grad_norm": 1.8434466123580933,
      "learning_rate": 0.00011160229002101603,
      "loss": 0.0385,
      "step": 6100
    },
    {
      "epoch": 0.4421495090046019,
      "grad_norm": 4.9399518966674805,
      "learning_rate": 0.0001115877962171172,
      "loss": 0.1458,
      "step": 6101
    },
    {
      "epoch": 0.4422219806500707,
      "grad_norm": 0.41390278935432434,
      "learning_rate": 0.00011157330241321835,
      "loss": 0.0053,
      "step": 6102
    },
    {
      "epoch": 0.4422944522955394,
      "grad_norm": 0.8804426789283752,
      "learning_rate": 0.00011155880860931954,
      "loss": 0.0325,
      "step": 6103
    },
    {
      "epoch": 0.44236692394100807,
      "grad_norm": 1.4635200500488281,
      "learning_rate": 0.00011154431480542069,
      "loss": 0.1109,
      "step": 6104
    },
    {
      "epoch": 0.44243939558647677,
      "grad_norm": 1.0195918083190918,
      "learning_rate": 0.00011152982100152185,
      "loss": 0.0352,
      "step": 6105
    },
    {
      "epoch": 0.4425118672319455,
      "grad_norm": 1.604166030883789,
      "learning_rate": 0.00011151532719762303,
      "loss": 0.0696,
      "step": 6106
    },
    {
      "epoch": 0.4425843388774142,
      "grad_norm": 1.6160157918930054,
      "learning_rate": 0.00011150083339372419,
      "loss": 0.1119,
      "step": 6107
    },
    {
      "epoch": 0.4426568105228829,
      "grad_norm": 0.9223116040229797,
      "learning_rate": 0.00011148633958982535,
      "loss": 0.0924,
      "step": 6108
    },
    {
      "epoch": 0.4427292821683516,
      "grad_norm": 0.6940441727638245,
      "learning_rate": 0.00011147184578592653,
      "loss": 0.0799,
      "step": 6109
    },
    {
      "epoch": 0.44280175381382036,
      "grad_norm": 2.765165090560913,
      "learning_rate": 0.00011145735198202769,
      "loss": 0.1498,
      "step": 6110
    },
    {
      "epoch": 0.44287422545928906,
      "grad_norm": 2.127075672149658,
      "learning_rate": 0.00011144285817812886,
      "loss": 0.092,
      "step": 6111
    },
    {
      "epoch": 0.44294669710475776,
      "grad_norm": 0.48970556259155273,
      "learning_rate": 0.00011142836437423003,
      "loss": 0.0201,
      "step": 6112
    },
    {
      "epoch": 0.44301916875022646,
      "grad_norm": 1.2120954990386963,
      "learning_rate": 0.0001114138705703312,
      "loss": 0.098,
      "step": 6113
    },
    {
      "epoch": 0.4430916403956952,
      "grad_norm": 1.3956687450408936,
      "learning_rate": 0.00011139937676643235,
      "loss": 0.0779,
      "step": 6114
    },
    {
      "epoch": 0.4431641120411639,
      "grad_norm": 1.5336331129074097,
      "learning_rate": 0.00011138488296253354,
      "loss": 0.0842,
      "step": 6115
    },
    {
      "epoch": 0.4432365836866326,
      "grad_norm": 0.9728654623031616,
      "learning_rate": 0.00011137038915863469,
      "loss": 0.0509,
      "step": 6116
    },
    {
      "epoch": 0.4433090553321013,
      "grad_norm": 3.92907977104187,
      "learning_rate": 0.00011135589535473585,
      "loss": 0.1439,
      "step": 6117
    },
    {
      "epoch": 0.44338152697757005,
      "grad_norm": 1.2060316801071167,
      "learning_rate": 0.00011134140155083703,
      "loss": 0.0708,
      "step": 6118
    },
    {
      "epoch": 0.44345399862303875,
      "grad_norm": 0.8094190955162048,
      "learning_rate": 0.00011132690774693819,
      "loss": 0.0338,
      "step": 6119
    },
    {
      "epoch": 0.44352647026850744,
      "grad_norm": 0.49224337935447693,
      "learning_rate": 0.00011131241394303934,
      "loss": 0.0498,
      "step": 6120
    },
    {
      "epoch": 0.44359894191397614,
      "grad_norm": 2.2268266677856445,
      "learning_rate": 0.00011129792013914053,
      "loss": 0.0722,
      "step": 6121
    },
    {
      "epoch": 0.4436714135594449,
      "grad_norm": 3.9812569618225098,
      "learning_rate": 0.00011128342633524169,
      "loss": 0.0532,
      "step": 6122
    },
    {
      "epoch": 0.4437438852049136,
      "grad_norm": 1.902547001838684,
      "learning_rate": 0.00011126893253134286,
      "loss": 0.0554,
      "step": 6123
    },
    {
      "epoch": 0.4438163568503823,
      "grad_norm": 1.0630136728286743,
      "learning_rate": 0.00011125443872744404,
      "loss": 0.066,
      "step": 6124
    },
    {
      "epoch": 0.443888828495851,
      "grad_norm": 0.8441827297210693,
      "learning_rate": 0.0001112399449235452,
      "loss": 0.0601,
      "step": 6125
    },
    {
      "epoch": 0.4439613001413197,
      "grad_norm": 0.4371321201324463,
      "learning_rate": 0.00011122545111964635,
      "loss": 0.028,
      "step": 6126
    },
    {
      "epoch": 0.44403377178678843,
      "grad_norm": 0.7717539072036743,
      "learning_rate": 0.00011121095731574754,
      "loss": 0.0999,
      "step": 6127
    },
    {
      "epoch": 0.44410624343225713,
      "grad_norm": 2.749406099319458,
      "learning_rate": 0.00011119646351184869,
      "loss": 0.0338,
      "step": 6128
    },
    {
      "epoch": 0.4441787150777258,
      "grad_norm": 2.842539072036743,
      "learning_rate": 0.00011118196970794985,
      "loss": 0.0906,
      "step": 6129
    },
    {
      "epoch": 0.4442511867231945,
      "grad_norm": 1.4648743867874146,
      "learning_rate": 0.00011116747590405103,
      "loss": 0.0961,
      "step": 6130
    },
    {
      "epoch": 0.4443236583686633,
      "grad_norm": 1.6611460447311401,
      "learning_rate": 0.00011115298210015219,
      "loss": 0.0557,
      "step": 6131
    },
    {
      "epoch": 0.444396130014132,
      "grad_norm": 1.9862133264541626,
      "learning_rate": 0.00011113848829625334,
      "loss": 0.1291,
      "step": 6132
    },
    {
      "epoch": 0.44446860165960067,
      "grad_norm": 2.2470204830169678,
      "learning_rate": 0.00011112399449235453,
      "loss": 0.0755,
      "step": 6133
    },
    {
      "epoch": 0.44454107330506937,
      "grad_norm": 0.9478038549423218,
      "learning_rate": 0.0001111095006884557,
      "loss": 0.0434,
      "step": 6134
    },
    {
      "epoch": 0.4446135449505381,
      "grad_norm": 2.0756216049194336,
      "learning_rate": 0.00011109500688455685,
      "loss": 0.0993,
      "step": 6135
    },
    {
      "epoch": 0.4446860165960068,
      "grad_norm": 1.666141152381897,
      "learning_rate": 0.00011108051308065804,
      "loss": 0.0613,
      "step": 6136
    },
    {
      "epoch": 0.4447584882414755,
      "grad_norm": 0.3306935429573059,
      "learning_rate": 0.0001110660192767592,
      "loss": 0.0224,
      "step": 6137
    },
    {
      "epoch": 0.4448309598869442,
      "grad_norm": 3.3169705867767334,
      "learning_rate": 0.00011105152547286035,
      "loss": 0.0745,
      "step": 6138
    },
    {
      "epoch": 0.44490343153241296,
      "grad_norm": 0.6335697174072266,
      "learning_rate": 0.00011103703166896154,
      "loss": 0.037,
      "step": 6139
    },
    {
      "epoch": 0.44497590317788166,
      "grad_norm": 1.1150370836257935,
      "learning_rate": 0.00011102253786506269,
      "loss": 0.0704,
      "step": 6140
    },
    {
      "epoch": 0.44504837482335036,
      "grad_norm": 2.5422563552856445,
      "learning_rate": 0.00011100804406116385,
      "loss": 0.0646,
      "step": 6141
    },
    {
      "epoch": 0.44512084646881905,
      "grad_norm": 0.4488673508167267,
      "learning_rate": 0.00011099355025726503,
      "loss": 0.0237,
      "step": 6142
    },
    {
      "epoch": 0.4451933181142878,
      "grad_norm": 2.4642627239227295,
      "learning_rate": 0.00011097905645336619,
      "loss": 0.0756,
      "step": 6143
    },
    {
      "epoch": 0.4452657897597565,
      "grad_norm": 1.4885039329528809,
      "learning_rate": 0.00011096456264946736,
      "loss": 0.0397,
      "step": 6144
    },
    {
      "epoch": 0.4453382614052252,
      "grad_norm": 1.5465166568756104,
      "learning_rate": 0.00011095006884556853,
      "loss": 0.1142,
      "step": 6145
    },
    {
      "epoch": 0.4454107330506939,
      "grad_norm": 1.0168052911758423,
      "learning_rate": 0.0001109355750416697,
      "loss": 0.0229,
      "step": 6146
    },
    {
      "epoch": 0.44548320469616265,
      "grad_norm": 2.9775850772857666,
      "learning_rate": 0.00011092108123777085,
      "loss": 0.0574,
      "step": 6147
    },
    {
      "epoch": 0.44555567634163135,
      "grad_norm": 0.6297950744628906,
      "learning_rate": 0.00011090658743387204,
      "loss": 0.0437,
      "step": 6148
    },
    {
      "epoch": 0.44562814798710004,
      "grad_norm": 2.5763180255889893,
      "learning_rate": 0.0001108920936299732,
      "loss": 0.1927,
      "step": 6149
    },
    {
      "epoch": 0.44570061963256874,
      "grad_norm": 0.7246236205101013,
      "learning_rate": 0.00011087759982607435,
      "loss": 0.0786,
      "step": 6150
    },
    {
      "epoch": 0.4457730912780375,
      "grad_norm": 1.7322373390197754,
      "learning_rate": 0.00011086310602217553,
      "loss": 0.0759,
      "step": 6151
    },
    {
      "epoch": 0.4458455629235062,
      "grad_norm": 1.7049018144607544,
      "learning_rate": 0.00011084861221827669,
      "loss": 0.0814,
      "step": 6152
    },
    {
      "epoch": 0.4459180345689749,
      "grad_norm": 2.7500879764556885,
      "learning_rate": 0.00011083411841437785,
      "loss": 0.1894,
      "step": 6153
    },
    {
      "epoch": 0.4459905062144436,
      "grad_norm": 0.705754816532135,
      "learning_rate": 0.00011081962461047903,
      "loss": 0.0371,
      "step": 6154
    },
    {
      "epoch": 0.44606297785991234,
      "grad_norm": 2.0330536365509033,
      "learning_rate": 0.00011080513080658019,
      "loss": 0.0876,
      "step": 6155
    },
    {
      "epoch": 0.44613544950538103,
      "grad_norm": 1.5859005451202393,
      "learning_rate": 0.00011079063700268136,
      "loss": 0.0732,
      "step": 6156
    },
    {
      "epoch": 0.44620792115084973,
      "grad_norm": 1.181354284286499,
      "learning_rate": 0.00011077614319878253,
      "loss": 0.0657,
      "step": 6157
    },
    {
      "epoch": 0.4462803927963184,
      "grad_norm": 1.4306097030639648,
      "learning_rate": 0.0001107616493948837,
      "loss": 0.0673,
      "step": 6158
    },
    {
      "epoch": 0.4463528644417872,
      "grad_norm": 1.2264906167984009,
      "learning_rate": 0.00011074715559098485,
      "loss": 0.0703,
      "step": 6159
    },
    {
      "epoch": 0.4464253360872559,
      "grad_norm": 4.510406970977783,
      "learning_rate": 0.00011073266178708604,
      "loss": 0.1899,
      "step": 6160
    },
    {
      "epoch": 0.44649780773272457,
      "grad_norm": 3.9181933403015137,
      "learning_rate": 0.0001107181679831872,
      "loss": 0.0948,
      "step": 6161
    },
    {
      "epoch": 0.44657027937819327,
      "grad_norm": 1.7818857431411743,
      "learning_rate": 0.00011070367417928835,
      "loss": 0.0565,
      "step": 6162
    },
    {
      "epoch": 0.44664275102366197,
      "grad_norm": 1.067694067955017,
      "learning_rate": 0.00011068918037538953,
      "loss": 0.0189,
      "step": 6163
    },
    {
      "epoch": 0.4467152226691307,
      "grad_norm": 0.6308477520942688,
      "learning_rate": 0.00011067468657149069,
      "loss": 0.049,
      "step": 6164
    },
    {
      "epoch": 0.4467876943145994,
      "grad_norm": 2.0105764865875244,
      "learning_rate": 0.00011066019276759185,
      "loss": 0.1755,
      "step": 6165
    },
    {
      "epoch": 0.4468601659600681,
      "grad_norm": 2.3900647163391113,
      "learning_rate": 0.00011064569896369303,
      "loss": 0.091,
      "step": 6166
    },
    {
      "epoch": 0.4469326376055368,
      "grad_norm": 0.1688995659351349,
      "learning_rate": 0.00011063120515979419,
      "loss": 0.0134,
      "step": 6167
    },
    {
      "epoch": 0.44700510925100556,
      "grad_norm": 0.8527319431304932,
      "learning_rate": 0.00011061671135589536,
      "loss": 0.0657,
      "step": 6168
    },
    {
      "epoch": 0.44707758089647426,
      "grad_norm": 3.6125364303588867,
      "learning_rate": 0.00011060221755199653,
      "loss": 0.1582,
      "step": 6169
    },
    {
      "epoch": 0.44715005254194296,
      "grad_norm": 1.6815555095672607,
      "learning_rate": 0.0001105877237480977,
      "loss": 0.0466,
      "step": 6170
    },
    {
      "epoch": 0.44722252418741165,
      "grad_norm": 3.1566309928894043,
      "learning_rate": 0.00011057322994419885,
      "loss": 0.04,
      "step": 6171
    },
    {
      "epoch": 0.4472949958328804,
      "grad_norm": 1.7665122747421265,
      "learning_rate": 0.00011055873614030004,
      "loss": 0.0437,
      "step": 6172
    },
    {
      "epoch": 0.4473674674783491,
      "grad_norm": 0.6323127746582031,
      "learning_rate": 0.0001105442423364012,
      "loss": 0.055,
      "step": 6173
    },
    {
      "epoch": 0.4474399391238178,
      "grad_norm": 1.4160151481628418,
      "learning_rate": 0.00011052974853250235,
      "loss": 0.1136,
      "step": 6174
    },
    {
      "epoch": 0.4475124107692865,
      "grad_norm": 2.052222728729248,
      "learning_rate": 0.00011051525472860353,
      "loss": 0.1252,
      "step": 6175
    },
    {
      "epoch": 0.44758488241475525,
      "grad_norm": 3.703197956085205,
      "learning_rate": 0.00011050076092470469,
      "loss": 0.0662,
      "step": 6176
    },
    {
      "epoch": 0.44765735406022394,
      "grad_norm": 2.649376153945923,
      "learning_rate": 0.00011048626712080585,
      "loss": 0.1705,
      "step": 6177
    },
    {
      "epoch": 0.44772982570569264,
      "grad_norm": 0.8940668106079102,
      "learning_rate": 0.00011047177331690703,
      "loss": 0.0287,
      "step": 6178
    },
    {
      "epoch": 0.44780229735116134,
      "grad_norm": 0.9411755800247192,
      "learning_rate": 0.00011045727951300819,
      "loss": 0.0476,
      "step": 6179
    },
    {
      "epoch": 0.4478747689966301,
      "grad_norm": 0.9076911807060242,
      "learning_rate": 0.00011044278570910936,
      "loss": 0.0339,
      "step": 6180
    },
    {
      "epoch": 0.4479472406420988,
      "grad_norm": 0.9482071399688721,
      "learning_rate": 0.00011042829190521054,
      "loss": 0.0498,
      "step": 6181
    },
    {
      "epoch": 0.4480197122875675,
      "grad_norm": 1.6649099588394165,
      "learning_rate": 0.0001104137981013117,
      "loss": 0.1016,
      "step": 6182
    },
    {
      "epoch": 0.4480921839330362,
      "grad_norm": 1.4257665872573853,
      "learning_rate": 0.00011039930429741285,
      "loss": 0.0997,
      "step": 6183
    },
    {
      "epoch": 0.44816465557850493,
      "grad_norm": 0.8302456736564636,
      "learning_rate": 0.00011038481049351404,
      "loss": 0.0528,
      "step": 6184
    },
    {
      "epoch": 0.44823712722397363,
      "grad_norm": 2.8398306369781494,
      "learning_rate": 0.0001103703166896152,
      "loss": 0.0651,
      "step": 6185
    },
    {
      "epoch": 0.4483095988694423,
      "grad_norm": 3.3080990314483643,
      "learning_rate": 0.00011035582288571635,
      "loss": 0.0725,
      "step": 6186
    },
    {
      "epoch": 0.448382070514911,
      "grad_norm": 0.6040692329406738,
      "learning_rate": 0.00011034132908181753,
      "loss": 0.0546,
      "step": 6187
    },
    {
      "epoch": 0.4484545421603798,
      "grad_norm": 1.856973648071289,
      "learning_rate": 0.00011032683527791869,
      "loss": 0.1301,
      "step": 6188
    },
    {
      "epoch": 0.4485270138058485,
      "grad_norm": 2.4363536834716797,
      "learning_rate": 0.00011031234147401985,
      "loss": 0.1686,
      "step": 6189
    },
    {
      "epoch": 0.44859948545131717,
      "grad_norm": 1.0449857711791992,
      "learning_rate": 0.00011029784767012103,
      "loss": 0.0453,
      "step": 6190
    },
    {
      "epoch": 0.44867195709678587,
      "grad_norm": 1.528624176979065,
      "learning_rate": 0.0001102833538662222,
      "loss": 0.0313,
      "step": 6191
    },
    {
      "epoch": 0.4487444287422546,
      "grad_norm": 0.9541491270065308,
      "learning_rate": 0.00011026886006232336,
      "loss": 0.0678,
      "step": 6192
    },
    {
      "epoch": 0.4488169003877233,
      "grad_norm": 1.3870618343353271,
      "learning_rate": 0.00011025436625842454,
      "loss": 0.0677,
      "step": 6193
    },
    {
      "epoch": 0.448889372033192,
      "grad_norm": 0.8328701853752136,
      "learning_rate": 0.0001102398724545257,
      "loss": 0.0598,
      "step": 6194
    },
    {
      "epoch": 0.4489618436786607,
      "grad_norm": 2.855424404144287,
      "learning_rate": 0.00011022537865062685,
      "loss": 0.1447,
      "step": 6195
    },
    {
      "epoch": 0.4490343153241294,
      "grad_norm": 1.227756142616272,
      "learning_rate": 0.00011021088484672804,
      "loss": 0.0807,
      "step": 6196
    },
    {
      "epoch": 0.44910678696959816,
      "grad_norm": 2.441897392272949,
      "learning_rate": 0.0001101963910428292,
      "loss": 0.1199,
      "step": 6197
    },
    {
      "epoch": 0.44917925861506686,
      "grad_norm": 5.644467830657959,
      "learning_rate": 0.00011018189723893035,
      "loss": 0.0917,
      "step": 6198
    },
    {
      "epoch": 0.44925173026053555,
      "grad_norm": 4.258619785308838,
      "learning_rate": 0.00011016740343503153,
      "loss": 0.0186,
      "step": 6199
    },
    {
      "epoch": 0.44932420190600425,
      "grad_norm": 1.7558497190475464,
      "learning_rate": 0.00011015290963113269,
      "loss": 0.0736,
      "step": 6200
    },
    {
      "epoch": 0.449396673551473,
      "grad_norm": 0.0529104582965374,
      "learning_rate": 0.00011013841582723386,
      "loss": 0.0011,
      "step": 6201
    },
    {
      "epoch": 0.4494691451969417,
      "grad_norm": 1.9974457025527954,
      "learning_rate": 0.00011012392202333503,
      "loss": 0.0399,
      "step": 6202
    },
    {
      "epoch": 0.4495416168424104,
      "grad_norm": 0.8728572130203247,
      "learning_rate": 0.0001101094282194362,
      "loss": 0.0435,
      "step": 6203
    },
    {
      "epoch": 0.4496140884878791,
      "grad_norm": 1.831181526184082,
      "learning_rate": 0.00011009493441553736,
      "loss": 0.0877,
      "step": 6204
    },
    {
      "epoch": 0.44968656013334785,
      "grad_norm": 0.4373757243156433,
      "learning_rate": 0.00011008044061163854,
      "loss": 0.0383,
      "step": 6205
    },
    {
      "epoch": 0.44975903177881654,
      "grad_norm": 1.114703893661499,
      "learning_rate": 0.0001100659468077397,
      "loss": 0.0469,
      "step": 6206
    },
    {
      "epoch": 0.44983150342428524,
      "grad_norm": 1.6197201013565063,
      "learning_rate": 0.00011005145300384085,
      "loss": 0.0822,
      "step": 6207
    },
    {
      "epoch": 0.44990397506975394,
      "grad_norm": 0.7477127313613892,
      "learning_rate": 0.00011003695919994204,
      "loss": 0.0208,
      "step": 6208
    },
    {
      "epoch": 0.4499764467152227,
      "grad_norm": 6.675085067749023,
      "learning_rate": 0.0001100224653960432,
      "loss": 0.0693,
      "step": 6209
    },
    {
      "epoch": 0.4500489183606914,
      "grad_norm": 1.2552765607833862,
      "learning_rate": 0.00011000797159214435,
      "loss": 0.0625,
      "step": 6210
    },
    {
      "epoch": 0.4501213900061601,
      "grad_norm": 1.3415874242782593,
      "learning_rate": 0.00010999347778824553,
      "loss": 0.0864,
      "step": 6211
    },
    {
      "epoch": 0.4501938616516288,
      "grad_norm": 0.7394647002220154,
      "learning_rate": 0.00010997898398434669,
      "loss": 0.0625,
      "step": 6212
    },
    {
      "epoch": 0.45026633329709753,
      "grad_norm": 1.9506510496139526,
      "learning_rate": 0.00010996449018044786,
      "loss": 0.1272,
      "step": 6213
    },
    {
      "epoch": 0.45033880494256623,
      "grad_norm": 1.1347880363464355,
      "learning_rate": 0.00010994999637654903,
      "loss": 0.064,
      "step": 6214
    },
    {
      "epoch": 0.4504112765880349,
      "grad_norm": 1.7098325490951538,
      "learning_rate": 0.0001099355025726502,
      "loss": 0.1392,
      "step": 6215
    },
    {
      "epoch": 0.4504837482335036,
      "grad_norm": 1.3690967559814453,
      "learning_rate": 0.00010992100876875136,
      "loss": 0.0898,
      "step": 6216
    },
    {
      "epoch": 0.4505562198789724,
      "grad_norm": 1.06611967086792,
      "learning_rate": 0.00010990651496485254,
      "loss": 0.0782,
      "step": 6217
    },
    {
      "epoch": 0.45062869152444107,
      "grad_norm": 4.911893367767334,
      "learning_rate": 0.0001098920211609537,
      "loss": 0.166,
      "step": 6218
    },
    {
      "epoch": 0.45070116316990977,
      "grad_norm": 0.8044574856758118,
      "learning_rate": 0.00010987752735705485,
      "loss": 0.0238,
      "step": 6219
    },
    {
      "epoch": 0.45077363481537847,
      "grad_norm": 1.592659592628479,
      "learning_rate": 0.00010986303355315604,
      "loss": 0.0822,
      "step": 6220
    },
    {
      "epoch": 0.4508461064608472,
      "grad_norm": 1.3072844743728638,
      "learning_rate": 0.0001098485397492572,
      "loss": 0.0099,
      "step": 6221
    },
    {
      "epoch": 0.4509185781063159,
      "grad_norm": 1.5114891529083252,
      "learning_rate": 0.00010983404594535835,
      "loss": 0.0775,
      "step": 6222
    },
    {
      "epoch": 0.4509910497517846,
      "grad_norm": 2.7224791049957275,
      "learning_rate": 0.00010981955214145953,
      "loss": 0.175,
      "step": 6223
    },
    {
      "epoch": 0.4510635213972533,
      "grad_norm": 1.2994033098220825,
      "learning_rate": 0.00010980505833756069,
      "loss": 0.076,
      "step": 6224
    },
    {
      "epoch": 0.45113599304272206,
      "grad_norm": 0.6802178621292114,
      "learning_rate": 0.00010979056453366186,
      "loss": 0.0166,
      "step": 6225
    },
    {
      "epoch": 0.45120846468819076,
      "grad_norm": 2.0454695224761963,
      "learning_rate": 0.00010977607072976303,
      "loss": 0.0728,
      "step": 6226
    },
    {
      "epoch": 0.45128093633365945,
      "grad_norm": 1.30354905128479,
      "learning_rate": 0.0001097615769258642,
      "loss": 0.0339,
      "step": 6227
    },
    {
      "epoch": 0.45135340797912815,
      "grad_norm": 0.6493934392929077,
      "learning_rate": 0.00010974708312196536,
      "loss": 0.0138,
      "step": 6228
    },
    {
      "epoch": 0.4514258796245969,
      "grad_norm": 0.9335606694221497,
      "learning_rate": 0.00010973258931806654,
      "loss": 0.0499,
      "step": 6229
    },
    {
      "epoch": 0.4514983512700656,
      "grad_norm": 1.2667073011398315,
      "learning_rate": 0.0001097180955141677,
      "loss": 0.0471,
      "step": 6230
    },
    {
      "epoch": 0.4515708229155343,
      "grad_norm": 2.6525325775146484,
      "learning_rate": 0.00010970360171026885,
      "loss": 0.1279,
      "step": 6231
    },
    {
      "epoch": 0.451643294561003,
      "grad_norm": 7.2201247215271,
      "learning_rate": 0.00010968910790637004,
      "loss": 0.1289,
      "step": 6232
    },
    {
      "epoch": 0.4517157662064717,
      "grad_norm": 4.257639408111572,
      "learning_rate": 0.0001096746141024712,
      "loss": 0.0734,
      "step": 6233
    },
    {
      "epoch": 0.45178823785194044,
      "grad_norm": 1.7611573934555054,
      "learning_rate": 0.00010966012029857235,
      "loss": 0.0551,
      "step": 6234
    },
    {
      "epoch": 0.45186070949740914,
      "grad_norm": 2.277014970779419,
      "learning_rate": 0.00010964562649467353,
      "loss": 0.0592,
      "step": 6235
    },
    {
      "epoch": 0.45193318114287784,
      "grad_norm": 0.38555607199668884,
      "learning_rate": 0.00010963113269077469,
      "loss": 0.0206,
      "step": 6236
    },
    {
      "epoch": 0.45200565278834653,
      "grad_norm": 0.33790966868400574,
      "learning_rate": 0.00010961663888687586,
      "loss": 0.0093,
      "step": 6237
    },
    {
      "epoch": 0.4520781244338153,
      "grad_norm": 2.451979637145996,
      "learning_rate": 0.00010960214508297704,
      "loss": 0.1606,
      "step": 6238
    },
    {
      "epoch": 0.452150596079284,
      "grad_norm": 0.39884188771247864,
      "learning_rate": 0.0001095876512790782,
      "loss": 0.0316,
      "step": 6239
    },
    {
      "epoch": 0.4522230677247527,
      "grad_norm": 1.6894888877868652,
      "learning_rate": 0.00010957315747517936,
      "loss": 0.0306,
      "step": 6240
    },
    {
      "epoch": 0.4522955393702214,
      "grad_norm": 0.52411949634552,
      "learning_rate": 0.00010955866367128054,
      "loss": 0.0227,
      "step": 6241
    },
    {
      "epoch": 0.45236801101569013,
      "grad_norm": 2.7944459915161133,
      "learning_rate": 0.0001095441698673817,
      "loss": 0.1256,
      "step": 6242
    },
    {
      "epoch": 0.4524404826611588,
      "grad_norm": 1.3283506631851196,
      "learning_rate": 0.00010952967606348285,
      "loss": 0.0458,
      "step": 6243
    },
    {
      "epoch": 0.4525129543066275,
      "grad_norm": 0.9859650731086731,
      "learning_rate": 0.00010951518225958404,
      "loss": 0.0834,
      "step": 6244
    },
    {
      "epoch": 0.4525854259520962,
      "grad_norm": 1.3604615926742554,
      "learning_rate": 0.00010950068845568519,
      "loss": 0.0796,
      "step": 6245
    },
    {
      "epoch": 0.452657897597565,
      "grad_norm": 1.2129392623901367,
      "learning_rate": 0.00010948619465178635,
      "loss": 0.0674,
      "step": 6246
    },
    {
      "epoch": 0.45273036924303367,
      "grad_norm": 2.1757283210754395,
      "learning_rate": 0.00010947170084788753,
      "loss": 0.106,
      "step": 6247
    },
    {
      "epoch": 0.45280284088850237,
      "grad_norm": 1.481481671333313,
      "learning_rate": 0.0001094572070439887,
      "loss": 0.0755,
      "step": 6248
    },
    {
      "epoch": 0.45287531253397106,
      "grad_norm": 0.9126524329185486,
      "learning_rate": 0.00010944271324008986,
      "loss": 0.0713,
      "step": 6249
    },
    {
      "epoch": 0.4529477841794398,
      "grad_norm": 6.343966484069824,
      "learning_rate": 0.00010942821943619104,
      "loss": 0.0569,
      "step": 6250
    },
    {
      "epoch": 0.4530202558249085,
      "grad_norm": 0.5931630730628967,
      "learning_rate": 0.0001094137256322922,
      "loss": 0.0248,
      "step": 6251
    },
    {
      "epoch": 0.4530927274703772,
      "grad_norm": 0.8457430601119995,
      "learning_rate": 0.00010939923182839338,
      "loss": 0.0332,
      "step": 6252
    },
    {
      "epoch": 0.4531651991158459,
      "grad_norm": 3.3317575454711914,
      "learning_rate": 0.00010938473802449454,
      "loss": 0.0615,
      "step": 6253
    },
    {
      "epoch": 0.45323767076131466,
      "grad_norm": 1.0326389074325562,
      "learning_rate": 0.0001093702442205957,
      "loss": 0.0578,
      "step": 6254
    },
    {
      "epoch": 0.45331014240678336,
      "grad_norm": 0.6418525576591492,
      "learning_rate": 0.00010935575041669688,
      "loss": 0.0293,
      "step": 6255
    },
    {
      "epoch": 0.45338261405225205,
      "grad_norm": 0.809855043888092,
      "learning_rate": 0.00010934125661279804,
      "loss": 0.0536,
      "step": 6256
    },
    {
      "epoch": 0.45345508569772075,
      "grad_norm": 0.7355828881263733,
      "learning_rate": 0.00010932676280889919,
      "loss": 0.0283,
      "step": 6257
    },
    {
      "epoch": 0.4535275573431895,
      "grad_norm": 0.3628491759300232,
      "learning_rate": 0.00010931226900500038,
      "loss": 0.0159,
      "step": 6258
    },
    {
      "epoch": 0.4536000289886582,
      "grad_norm": 2.0991556644439697,
      "learning_rate": 0.00010929777520110153,
      "loss": 0.0645,
      "step": 6259
    },
    {
      "epoch": 0.4536725006341269,
      "grad_norm": 0.5733867883682251,
      "learning_rate": 0.0001092832813972027,
      "loss": 0.0457,
      "step": 6260
    },
    {
      "epoch": 0.4537449722795956,
      "grad_norm": 0.8121073246002197,
      "learning_rate": 0.00010926878759330387,
      "loss": 0.0352,
      "step": 6261
    },
    {
      "epoch": 0.45381744392506435,
      "grad_norm": 1.6697441339492798,
      "learning_rate": 0.00010925429378940504,
      "loss": 0.0623,
      "step": 6262
    },
    {
      "epoch": 0.45388991557053304,
      "grad_norm": 3.6113383769989014,
      "learning_rate": 0.0001092397999855062,
      "loss": 0.1566,
      "step": 6263
    },
    {
      "epoch": 0.45396238721600174,
      "grad_norm": 0.9269571900367737,
      "learning_rate": 0.00010922530618160738,
      "loss": 0.0829,
      "step": 6264
    },
    {
      "epoch": 0.45403485886147044,
      "grad_norm": 2.7204790115356445,
      "learning_rate": 0.00010921081237770854,
      "loss": 0.1057,
      "step": 6265
    },
    {
      "epoch": 0.45410733050693913,
      "grad_norm": 3.6978566646575928,
      "learning_rate": 0.0001091963185738097,
      "loss": 0.0897,
      "step": 6266
    },
    {
      "epoch": 0.4541798021524079,
      "grad_norm": 1.8579320907592773,
      "learning_rate": 0.00010918182476991088,
      "loss": 0.0481,
      "step": 6267
    },
    {
      "epoch": 0.4542522737978766,
      "grad_norm": 2.7796127796173096,
      "learning_rate": 0.00010916733096601204,
      "loss": 0.1154,
      "step": 6268
    },
    {
      "epoch": 0.4543247454433453,
      "grad_norm": 3.028334379196167,
      "learning_rate": 0.00010915283716211319,
      "loss": 0.0655,
      "step": 6269
    },
    {
      "epoch": 0.454397217088814,
      "grad_norm": 2.2286293506622314,
      "learning_rate": 0.00010913834335821438,
      "loss": 0.1565,
      "step": 6270
    },
    {
      "epoch": 0.45446968873428273,
      "grad_norm": 2.858825206756592,
      "learning_rate": 0.00010912384955431553,
      "loss": 0.1386,
      "step": 6271
    },
    {
      "epoch": 0.4545421603797514,
      "grad_norm": 1.573574185371399,
      "learning_rate": 0.0001091093557504167,
      "loss": 0.0468,
      "step": 6272
    },
    {
      "epoch": 0.4546146320252201,
      "grad_norm": 2.8466737270355225,
      "learning_rate": 0.00010909486194651787,
      "loss": 0.0485,
      "step": 6273
    },
    {
      "epoch": 0.4546871036706888,
      "grad_norm": 2.851409435272217,
      "learning_rate": 0.00010908036814261904,
      "loss": 0.0691,
      "step": 6274
    },
    {
      "epoch": 0.45475957531615757,
      "grad_norm": 0.5617342591285706,
      "learning_rate": 0.0001090658743387202,
      "loss": 0.0163,
      "step": 6275
    },
    {
      "epoch": 0.45483204696162627,
      "grad_norm": 1.5832206010818481,
      "learning_rate": 0.00010905138053482138,
      "loss": 0.1071,
      "step": 6276
    },
    {
      "epoch": 0.45490451860709497,
      "grad_norm": 0.5709360241889954,
      "learning_rate": 0.00010903688673092254,
      "loss": 0.0416,
      "step": 6277
    },
    {
      "epoch": 0.45497699025256366,
      "grad_norm": 2.932093620300293,
      "learning_rate": 0.0001090223929270237,
      "loss": 0.0531,
      "step": 6278
    },
    {
      "epoch": 0.4550494618980324,
      "grad_norm": 1.7761256694793701,
      "learning_rate": 0.00010900789912312488,
      "loss": 0.0563,
      "step": 6279
    },
    {
      "epoch": 0.4551219335435011,
      "grad_norm": 1.6450990438461304,
      "learning_rate": 0.00010899340531922604,
      "loss": 0.085,
      "step": 6280
    },
    {
      "epoch": 0.4551944051889698,
      "grad_norm": 4.291261196136475,
      "learning_rate": 0.00010897891151532719,
      "loss": 0.0797,
      "step": 6281
    },
    {
      "epoch": 0.4552668768344385,
      "grad_norm": 1.5464798212051392,
      "learning_rate": 0.00010896441771142838,
      "loss": 0.069,
      "step": 6282
    },
    {
      "epoch": 0.45533934847990726,
      "grad_norm": 1.538256049156189,
      "learning_rate": 0.00010894992390752953,
      "loss": 0.0148,
      "step": 6283
    },
    {
      "epoch": 0.45541182012537595,
      "grad_norm": 1.964462161064148,
      "learning_rate": 0.0001089354301036307,
      "loss": 0.0917,
      "step": 6284
    },
    {
      "epoch": 0.45548429177084465,
      "grad_norm": 0.5341212749481201,
      "learning_rate": 0.00010892093629973187,
      "loss": 0.0162,
      "step": 6285
    },
    {
      "epoch": 0.45555676341631335,
      "grad_norm": 0.9602997303009033,
      "learning_rate": 0.00010890644249583304,
      "loss": 0.0456,
      "step": 6286
    },
    {
      "epoch": 0.4556292350617821,
      "grad_norm": 1.362840175628662,
      "learning_rate": 0.0001088919486919342,
      "loss": 0.0394,
      "step": 6287
    },
    {
      "epoch": 0.4557017067072508,
      "grad_norm": 1.7597341537475586,
      "learning_rate": 0.00010887745488803538,
      "loss": 0.0846,
      "step": 6288
    },
    {
      "epoch": 0.4557741783527195,
      "grad_norm": 0.7022000551223755,
      "learning_rate": 0.00010886296108413654,
      "loss": 0.0294,
      "step": 6289
    },
    {
      "epoch": 0.4558466499981882,
      "grad_norm": 0.6689898371696472,
      "learning_rate": 0.0001088484672802377,
      "loss": 0.0442,
      "step": 6290
    },
    {
      "epoch": 0.45591912164365694,
      "grad_norm": 0.9888092279434204,
      "learning_rate": 0.00010883397347633888,
      "loss": 0.0457,
      "step": 6291
    },
    {
      "epoch": 0.45599159328912564,
      "grad_norm": 0.6335251331329346,
      "learning_rate": 0.00010881947967244004,
      "loss": 0.0438,
      "step": 6292
    },
    {
      "epoch": 0.45606406493459434,
      "grad_norm": 1.2968844175338745,
      "learning_rate": 0.00010880498586854119,
      "loss": 0.0491,
      "step": 6293
    },
    {
      "epoch": 0.45613653658006303,
      "grad_norm": 2.3813235759735107,
      "learning_rate": 0.00010879049206464238,
      "loss": 0.1435,
      "step": 6294
    },
    {
      "epoch": 0.4562090082255318,
      "grad_norm": 4.451196193695068,
      "learning_rate": 0.00010877599826074353,
      "loss": 0.1082,
      "step": 6295
    },
    {
      "epoch": 0.4562814798710005,
      "grad_norm": 2.5672531127929688,
      "learning_rate": 0.0001087615044568447,
      "loss": 0.1456,
      "step": 6296
    },
    {
      "epoch": 0.4563539515164692,
      "grad_norm": 4.738173007965088,
      "learning_rate": 0.00010874701065294589,
      "loss": 0.1047,
      "step": 6297
    },
    {
      "epoch": 0.4564264231619379,
      "grad_norm": 2.901880979537964,
      "learning_rate": 0.00010873251684904704,
      "loss": 0.2332,
      "step": 6298
    },
    {
      "epoch": 0.4564988948074066,
      "grad_norm": 1.9173181056976318,
      "learning_rate": 0.0001087180230451482,
      "loss": 0.067,
      "step": 6299
    },
    {
      "epoch": 0.4565713664528753,
      "grad_norm": 0.4489203989505768,
      "learning_rate": 0.00010870352924124938,
      "loss": 0.0061,
      "step": 6300
    },
    {
      "epoch": 0.456643838098344,
      "grad_norm": 2.433354616165161,
      "learning_rate": 0.00010868903543735054,
      "loss": 0.0515,
      "step": 6301
    },
    {
      "epoch": 0.4567163097438127,
      "grad_norm": 0.8152216076850891,
      "learning_rate": 0.0001086745416334517,
      "loss": 0.0576,
      "step": 6302
    },
    {
      "epoch": 0.4567887813892814,
      "grad_norm": 1.066074013710022,
      "learning_rate": 0.00010866004782955288,
      "loss": 0.0409,
      "step": 6303
    },
    {
      "epoch": 0.45686125303475017,
      "grad_norm": 1.4365746974945068,
      "learning_rate": 0.00010864555402565404,
      "loss": 0.1325,
      "step": 6304
    },
    {
      "epoch": 0.45693372468021887,
      "grad_norm": 1.7918366193771362,
      "learning_rate": 0.00010863106022175519,
      "loss": 0.1693,
      "step": 6305
    },
    {
      "epoch": 0.45700619632568756,
      "grad_norm": 0.7994197607040405,
      "learning_rate": 0.00010861656641785638,
      "loss": 0.0194,
      "step": 6306
    },
    {
      "epoch": 0.45707866797115626,
      "grad_norm": 1.8773783445358276,
      "learning_rate": 0.00010860207261395755,
      "loss": 0.0926,
      "step": 6307
    },
    {
      "epoch": 0.457151139616625,
      "grad_norm": 1.4838383197784424,
      "learning_rate": 0.0001085875788100587,
      "loss": 0.039,
      "step": 6308
    },
    {
      "epoch": 0.4572236112620937,
      "grad_norm": 1.1926790475845337,
      "learning_rate": 0.00010857308500615989,
      "loss": 0.0681,
      "step": 6309
    },
    {
      "epoch": 0.4572960829075624,
      "grad_norm": 1.0301756858825684,
      "learning_rate": 0.00010855859120226104,
      "loss": 0.0309,
      "step": 6310
    },
    {
      "epoch": 0.4573685545530311,
      "grad_norm": 0.8135219216346741,
      "learning_rate": 0.0001085440973983622,
      "loss": 0.0371,
      "step": 6311
    },
    {
      "epoch": 0.45744102619849986,
      "grad_norm": 0.7129963636398315,
      "learning_rate": 0.00010852960359446338,
      "loss": 0.0486,
      "step": 6312
    },
    {
      "epoch": 0.45751349784396855,
      "grad_norm": 0.9250205755233765,
      "learning_rate": 0.00010851510979056454,
      "loss": 0.0466,
      "step": 6313
    },
    {
      "epoch": 0.45758596948943725,
      "grad_norm": 3.2233338356018066,
      "learning_rate": 0.0001085006159866657,
      "loss": 0.2211,
      "step": 6314
    },
    {
      "epoch": 0.45765844113490595,
      "grad_norm": 0.432579904794693,
      "learning_rate": 0.00010848612218276688,
      "loss": 0.0286,
      "step": 6315
    },
    {
      "epoch": 0.4577309127803747,
      "grad_norm": 2.3158349990844727,
      "learning_rate": 0.00010847162837886804,
      "loss": 0.0785,
      "step": 6316
    },
    {
      "epoch": 0.4578033844258434,
      "grad_norm": 1.3843257427215576,
      "learning_rate": 0.0001084571345749692,
      "loss": 0.0654,
      "step": 6317
    },
    {
      "epoch": 0.4578758560713121,
      "grad_norm": 6.660421848297119,
      "learning_rate": 0.00010844264077107038,
      "loss": 0.2591,
      "step": 6318
    },
    {
      "epoch": 0.4579483277167808,
      "grad_norm": 2.180492639541626,
      "learning_rate": 0.00010842814696717155,
      "loss": 0.139,
      "step": 6319
    },
    {
      "epoch": 0.45802079936224954,
      "grad_norm": 1.4037412405014038,
      "learning_rate": 0.0001084136531632727,
      "loss": 0.0586,
      "step": 6320
    },
    {
      "epoch": 0.45809327100771824,
      "grad_norm": 1.3090089559555054,
      "learning_rate": 0.00010839915935937389,
      "loss": 0.073,
      "step": 6321
    },
    {
      "epoch": 0.45816574265318694,
      "grad_norm": 7.138683795928955,
      "learning_rate": 0.00010838466555547504,
      "loss": 0.1011,
      "step": 6322
    },
    {
      "epoch": 0.45823821429865563,
      "grad_norm": 1.885666847229004,
      "learning_rate": 0.0001083701717515762,
      "loss": 0.052,
      "step": 6323
    },
    {
      "epoch": 0.4583106859441244,
      "grad_norm": 0.7405003309249878,
      "learning_rate": 0.00010835567794767738,
      "loss": 0.034,
      "step": 6324
    },
    {
      "epoch": 0.4583831575895931,
      "grad_norm": 2.120231866836548,
      "learning_rate": 0.00010834118414377854,
      "loss": 0.1373,
      "step": 6325
    },
    {
      "epoch": 0.4584556292350618,
      "grad_norm": 0.9823142290115356,
      "learning_rate": 0.0001083266903398797,
      "loss": 0.0505,
      "step": 6326
    },
    {
      "epoch": 0.4585281008805305,
      "grad_norm": 2.764277696609497,
      "learning_rate": 0.00010831219653598088,
      "loss": 0.0944,
      "step": 6327
    },
    {
      "epoch": 0.45860057252599923,
      "grad_norm": 0.7925410866737366,
      "learning_rate": 0.00010829770273208204,
      "loss": 0.0575,
      "step": 6328
    },
    {
      "epoch": 0.4586730441714679,
      "grad_norm": 0.8886945843696594,
      "learning_rate": 0.0001082832089281832,
      "loss": 0.0101,
      "step": 6329
    },
    {
      "epoch": 0.4587455158169366,
      "grad_norm": 2.9903783798217773,
      "learning_rate": 0.00010826871512428438,
      "loss": 0.0755,
      "step": 6330
    },
    {
      "epoch": 0.4588179874624053,
      "grad_norm": 1.1820144653320312,
      "learning_rate": 0.00010825422132038555,
      "loss": 0.059,
      "step": 6331
    },
    {
      "epoch": 0.45889045910787407,
      "grad_norm": 0.44480419158935547,
      "learning_rate": 0.0001082397275164867,
      "loss": 0.028,
      "step": 6332
    },
    {
      "epoch": 0.45896293075334277,
      "grad_norm": 5.941815376281738,
      "learning_rate": 0.00010822523371258789,
      "loss": 0.0873,
      "step": 6333
    },
    {
      "epoch": 0.45903540239881147,
      "grad_norm": 0.6180952191352844,
      "learning_rate": 0.00010821073990868904,
      "loss": 0.0184,
      "step": 6334
    },
    {
      "epoch": 0.45910787404428016,
      "grad_norm": 1.1461918354034424,
      "learning_rate": 0.0001081962461047902,
      "loss": 0.0745,
      "step": 6335
    },
    {
      "epoch": 0.45918034568974886,
      "grad_norm": 0.6241663098335266,
      "learning_rate": 0.00010818175230089138,
      "loss": 0.0084,
      "step": 6336
    },
    {
      "epoch": 0.4592528173352176,
      "grad_norm": 1.0002992153167725,
      "learning_rate": 0.00010816725849699254,
      "loss": 0.0773,
      "step": 6337
    },
    {
      "epoch": 0.4593252889806863,
      "grad_norm": 1.3711010217666626,
      "learning_rate": 0.0001081527646930937,
      "loss": 0.0598,
      "step": 6338
    },
    {
      "epoch": 0.459397760626155,
      "grad_norm": 0.39583250880241394,
      "learning_rate": 0.00010813827088919488,
      "loss": 0.021,
      "step": 6339
    },
    {
      "epoch": 0.4594702322716237,
      "grad_norm": 1.6061874628067017,
      "learning_rate": 0.00010812377708529604,
      "loss": 0.0658,
      "step": 6340
    },
    {
      "epoch": 0.45954270391709245,
      "grad_norm": 0.653635561466217,
      "learning_rate": 0.0001081092832813972,
      "loss": 0.0554,
      "step": 6341
    },
    {
      "epoch": 0.45961517556256115,
      "grad_norm": 0.4299251139163971,
      "learning_rate": 0.00010809478947749838,
      "loss": 0.0263,
      "step": 6342
    },
    {
      "epoch": 0.45968764720802985,
      "grad_norm": 0.549758791923523,
      "learning_rate": 0.00010808029567359955,
      "loss": 0.018,
      "step": 6343
    },
    {
      "epoch": 0.45976011885349855,
      "grad_norm": 1.4768861532211304,
      "learning_rate": 0.0001080658018697007,
      "loss": 0.0673,
      "step": 6344
    },
    {
      "epoch": 0.4598325904989673,
      "grad_norm": 1.1988747119903564,
      "learning_rate": 0.00010805130806580189,
      "loss": 0.0847,
      "step": 6345
    },
    {
      "epoch": 0.459905062144436,
      "grad_norm": 1.338870644569397,
      "learning_rate": 0.00010803681426190304,
      "loss": 0.0593,
      "step": 6346
    },
    {
      "epoch": 0.4599775337899047,
      "grad_norm": 1.7541338205337524,
      "learning_rate": 0.0001080223204580042,
      "loss": 0.0515,
      "step": 6347
    },
    {
      "epoch": 0.4600500054353734,
      "grad_norm": 0.608128547668457,
      "learning_rate": 0.00010800782665410538,
      "loss": 0.0293,
      "step": 6348
    },
    {
      "epoch": 0.46012247708084214,
      "grad_norm": 0.8129456043243408,
      "learning_rate": 0.00010799333285020654,
      "loss": 0.0344,
      "step": 6349
    },
    {
      "epoch": 0.46019494872631084,
      "grad_norm": 0.9795897006988525,
      "learning_rate": 0.0001079788390463077,
      "loss": 0.0667,
      "step": 6350
    },
    {
      "epoch": 0.46026742037177953,
      "grad_norm": 1.1510028839111328,
      "learning_rate": 0.00010796434524240888,
      "loss": 0.0439,
      "step": 6351
    },
    {
      "epoch": 0.46033989201724823,
      "grad_norm": 2.1257359981536865,
      "learning_rate": 0.00010794985143851003,
      "loss": 0.0305,
      "step": 6352
    },
    {
      "epoch": 0.460412363662717,
      "grad_norm": 1.3417450189590454,
      "learning_rate": 0.0001079353576346112,
      "loss": 0.0096,
      "step": 6353
    },
    {
      "epoch": 0.4604848353081857,
      "grad_norm": 0.5400143265724182,
      "learning_rate": 0.00010792086383071239,
      "loss": 0.0159,
      "step": 6354
    },
    {
      "epoch": 0.4605573069536544,
      "grad_norm": 5.118285655975342,
      "learning_rate": 0.00010790637002681354,
      "loss": 0.2322,
      "step": 6355
    },
    {
      "epoch": 0.4606297785991231,
      "grad_norm": 1.6745004653930664,
      "learning_rate": 0.0001078918762229147,
      "loss": 0.0419,
      "step": 6356
    },
    {
      "epoch": 0.4607022502445918,
      "grad_norm": 0.8910148739814758,
      "learning_rate": 0.00010787738241901588,
      "loss": 0.0034,
      "step": 6357
    },
    {
      "epoch": 0.4607747218900605,
      "grad_norm": 0.864240825176239,
      "learning_rate": 0.00010786288861511704,
      "loss": 0.0169,
      "step": 6358
    },
    {
      "epoch": 0.4608471935355292,
      "grad_norm": 1.6986104249954224,
      "learning_rate": 0.0001078483948112182,
      "loss": 0.0606,
      "step": 6359
    },
    {
      "epoch": 0.4609196651809979,
      "grad_norm": 1.2768049240112305,
      "learning_rate": 0.00010783390100731938,
      "loss": 0.0448,
      "step": 6360
    },
    {
      "epoch": 0.46099213682646667,
      "grad_norm": 1.4427425861358643,
      "learning_rate": 0.00010781940720342054,
      "loss": 0.0795,
      "step": 6361
    },
    {
      "epoch": 0.46106460847193537,
      "grad_norm": 3.8168234825134277,
      "learning_rate": 0.0001078049133995217,
      "loss": 0.1809,
      "step": 6362
    },
    {
      "epoch": 0.46113708011740406,
      "grad_norm": 5.16063928604126,
      "learning_rate": 0.00010779041959562288,
      "loss": 0.0775,
      "step": 6363
    },
    {
      "epoch": 0.46120955176287276,
      "grad_norm": 2.784569025039673,
      "learning_rate": 0.00010777592579172405,
      "loss": 0.0993,
      "step": 6364
    },
    {
      "epoch": 0.4612820234083415,
      "grad_norm": 1.121608018875122,
      "learning_rate": 0.0001077614319878252,
      "loss": 0.0121,
      "step": 6365
    },
    {
      "epoch": 0.4613544950538102,
      "grad_norm": 1.6480770111083984,
      "learning_rate": 0.00010774693818392639,
      "loss": 0.0744,
      "step": 6366
    },
    {
      "epoch": 0.4614269666992789,
      "grad_norm": 2.276860475540161,
      "learning_rate": 0.00010773244438002754,
      "loss": 0.0448,
      "step": 6367
    },
    {
      "epoch": 0.4614994383447476,
      "grad_norm": 1.1659127473831177,
      "learning_rate": 0.0001077179505761287,
      "loss": 0.0463,
      "step": 6368
    },
    {
      "epoch": 0.4615719099902163,
      "grad_norm": 2.294675350189209,
      "learning_rate": 0.00010770345677222988,
      "loss": 0.1018,
      "step": 6369
    },
    {
      "epoch": 0.46164438163568505,
      "grad_norm": 0.42160454392433167,
      "learning_rate": 0.00010768896296833104,
      "loss": 0.0062,
      "step": 6370
    },
    {
      "epoch": 0.46171685328115375,
      "grad_norm": 0.8919793367385864,
      "learning_rate": 0.0001076744691644322,
      "loss": 0.0437,
      "step": 6371
    },
    {
      "epoch": 0.46178932492662245,
      "grad_norm": 0.903872013092041,
      "learning_rate": 0.00010765997536053338,
      "loss": 0.0196,
      "step": 6372
    },
    {
      "epoch": 0.46186179657209114,
      "grad_norm": 6.299968242645264,
      "learning_rate": 0.00010764548155663454,
      "loss": 0.0734,
      "step": 6373
    },
    {
      "epoch": 0.4619342682175599,
      "grad_norm": 0.8393833637237549,
      "learning_rate": 0.00010763098775273571,
      "loss": 0.0391,
      "step": 6374
    },
    {
      "epoch": 0.4620067398630286,
      "grad_norm": 0.4539869725704193,
      "learning_rate": 0.00010761649394883688,
      "loss": 0.0209,
      "step": 6375
    },
    {
      "epoch": 0.4620792115084973,
      "grad_norm": 0.9019170999526978,
      "learning_rate": 0.00010760200014493805,
      "loss": 0.0458,
      "step": 6376
    },
    {
      "epoch": 0.462151683153966,
      "grad_norm": 1.393354892730713,
      "learning_rate": 0.0001075875063410392,
      "loss": 0.072,
      "step": 6377
    },
    {
      "epoch": 0.46222415479943474,
      "grad_norm": 1.9660723209381104,
      "learning_rate": 0.00010757301253714039,
      "loss": 0.0951,
      "step": 6378
    },
    {
      "epoch": 0.46229662644490344,
      "grad_norm": 1.531969428062439,
      "learning_rate": 0.00010755851873324154,
      "loss": 0.0469,
      "step": 6379
    },
    {
      "epoch": 0.46236909809037213,
      "grad_norm": 1.4138922691345215,
      "learning_rate": 0.0001075440249293427,
      "loss": 0.0362,
      "step": 6380
    },
    {
      "epoch": 0.46244156973584083,
      "grad_norm": 0.7024297714233398,
      "learning_rate": 0.00010752953112544388,
      "loss": 0.0168,
      "step": 6381
    },
    {
      "epoch": 0.4625140413813096,
      "grad_norm": 2.6340744495391846,
      "learning_rate": 0.00010751503732154504,
      "loss": 0.0937,
      "step": 6382
    },
    {
      "epoch": 0.4625865130267783,
      "grad_norm": 0.6567676663398743,
      "learning_rate": 0.0001075005435176462,
      "loss": 0.0286,
      "step": 6383
    },
    {
      "epoch": 0.462658984672247,
      "grad_norm": 0.5809335112571716,
      "learning_rate": 0.00010748604971374738,
      "loss": 0.0156,
      "step": 6384
    },
    {
      "epoch": 0.4627314563177157,
      "grad_norm": 1.4054416418075562,
      "learning_rate": 0.00010747155590984854,
      "loss": 0.0773,
      "step": 6385
    },
    {
      "epoch": 0.4628039279631844,
      "grad_norm": 0.36652153730392456,
      "learning_rate": 0.00010745706210594971,
      "loss": 0.0122,
      "step": 6386
    },
    {
      "epoch": 0.4628763996086531,
      "grad_norm": 0.554741621017456,
      "learning_rate": 0.00010744256830205088,
      "loss": 0.0402,
      "step": 6387
    },
    {
      "epoch": 0.4629488712541218,
      "grad_norm": 1.921383023262024,
      "learning_rate": 0.00010742807449815205,
      "loss": 0.0477,
      "step": 6388
    },
    {
      "epoch": 0.4630213428995905,
      "grad_norm": 0.849815309047699,
      "learning_rate": 0.0001074135806942532,
      "loss": 0.059,
      "step": 6389
    },
    {
      "epoch": 0.46309381454505927,
      "grad_norm": 1.6810399293899536,
      "learning_rate": 0.00010739908689035439,
      "loss": 0.1026,
      "step": 6390
    },
    {
      "epoch": 0.46316628619052796,
      "grad_norm": 1.3883440494537354,
      "learning_rate": 0.00010738459308645554,
      "loss": 0.0311,
      "step": 6391
    },
    {
      "epoch": 0.46323875783599666,
      "grad_norm": 0.07248233258724213,
      "learning_rate": 0.0001073700992825567,
      "loss": 0.0021,
      "step": 6392
    },
    {
      "epoch": 0.46331122948146536,
      "grad_norm": 3.25984787940979,
      "learning_rate": 0.00010735560547865788,
      "loss": 0.1751,
      "step": 6393
    },
    {
      "epoch": 0.4633837011269341,
      "grad_norm": 9.912010192871094,
      "learning_rate": 0.00010734111167475904,
      "loss": 0.138,
      "step": 6394
    },
    {
      "epoch": 0.4634561727724028,
      "grad_norm": 4.005911350250244,
      "learning_rate": 0.0001073266178708602,
      "loss": 0.0908,
      "step": 6395
    },
    {
      "epoch": 0.4635286444178715,
      "grad_norm": 2.3367278575897217,
      "learning_rate": 0.00010731212406696138,
      "loss": 0.0531,
      "step": 6396
    },
    {
      "epoch": 0.4636011160633402,
      "grad_norm": 0.46552574634552,
      "learning_rate": 0.00010729763026306254,
      "loss": 0.0121,
      "step": 6397
    },
    {
      "epoch": 0.46367358770880895,
      "grad_norm": 0.9983808994293213,
      "learning_rate": 0.00010728313645916371,
      "loss": 0.0593,
      "step": 6398
    },
    {
      "epoch": 0.46374605935427765,
      "grad_norm": 0.5487664937973022,
      "learning_rate": 0.00010726864265526488,
      "loss": 0.0214,
      "step": 6399
    },
    {
      "epoch": 0.46381853099974635,
      "grad_norm": 0.3905733525753021,
      "learning_rate": 0.00010725414885136605,
      "loss": 0.0159,
      "step": 6400
    },
    {
      "epoch": 0.46389100264521504,
      "grad_norm": 3.678621292114258,
      "learning_rate": 0.0001072396550474672,
      "loss": 0.0721,
      "step": 6401
    },
    {
      "epoch": 0.4639634742906838,
      "grad_norm": 3.6253774166107178,
      "learning_rate": 0.00010722516124356839,
      "loss": 0.0806,
      "step": 6402
    },
    {
      "epoch": 0.4640359459361525,
      "grad_norm": 1.58528733253479,
      "learning_rate": 0.00010721066743966954,
      "loss": 0.1288,
      "step": 6403
    },
    {
      "epoch": 0.4641084175816212,
      "grad_norm": 2.4022538661956787,
      "learning_rate": 0.0001071961736357707,
      "loss": 0.0229,
      "step": 6404
    },
    {
      "epoch": 0.4641808892270899,
      "grad_norm": 2.9747190475463867,
      "learning_rate": 0.00010718167983187188,
      "loss": 0.0598,
      "step": 6405
    },
    {
      "epoch": 0.4642533608725586,
      "grad_norm": 0.5801672339439392,
      "learning_rate": 0.00010716718602797304,
      "loss": 0.016,
      "step": 6406
    },
    {
      "epoch": 0.46432583251802734,
      "grad_norm": 1.0918883085250854,
      "learning_rate": 0.0001071526922240742,
      "loss": 0.0227,
      "step": 6407
    },
    {
      "epoch": 0.46439830416349603,
      "grad_norm": 0.4108973741531372,
      "learning_rate": 0.00010713819842017538,
      "loss": 0.0146,
      "step": 6408
    },
    {
      "epoch": 0.46447077580896473,
      "grad_norm": 2.1177945137023926,
      "learning_rate": 0.00010712370461627654,
      "loss": 0.0561,
      "step": 6409
    },
    {
      "epoch": 0.46454324745443343,
      "grad_norm": 7.533576488494873,
      "learning_rate": 0.00010710921081237771,
      "loss": 0.1552,
      "step": 6410
    },
    {
      "epoch": 0.4646157190999022,
      "grad_norm": 0.16250444948673248,
      "learning_rate": 0.00010709471700847889,
      "loss": 0.0024,
      "step": 6411
    },
    {
      "epoch": 0.4646881907453709,
      "grad_norm": 6.569858074188232,
      "learning_rate": 0.00010708022320458005,
      "loss": 0.0559,
      "step": 6412
    },
    {
      "epoch": 0.4647606623908396,
      "grad_norm": 0.6004757881164551,
      "learning_rate": 0.0001070657294006812,
      "loss": 0.03,
      "step": 6413
    },
    {
      "epoch": 0.46483313403630827,
      "grad_norm": 2.3452372550964355,
      "learning_rate": 0.00010705123559678239,
      "loss": 0.0386,
      "step": 6414
    },
    {
      "epoch": 0.464905605681777,
      "grad_norm": 1.0962797403335571,
      "learning_rate": 0.00010703674179288354,
      "loss": 0.0738,
      "step": 6415
    },
    {
      "epoch": 0.4649780773272457,
      "grad_norm": 3.74821400642395,
      "learning_rate": 0.00010702224798898473,
      "loss": 0.0988,
      "step": 6416
    },
    {
      "epoch": 0.4650505489727144,
      "grad_norm": 1.3983690738677979,
      "learning_rate": 0.00010700775418508588,
      "loss": 0.0566,
      "step": 6417
    },
    {
      "epoch": 0.4651230206181831,
      "grad_norm": 0.826043963432312,
      "learning_rate": 0.00010699326038118704,
      "loss": 0.022,
      "step": 6418
    },
    {
      "epoch": 0.46519549226365187,
      "grad_norm": 2.022850751876831,
      "learning_rate": 0.00010697876657728822,
      "loss": 0.068,
      "step": 6419
    },
    {
      "epoch": 0.46526796390912056,
      "grad_norm": 1.3012241125106812,
      "learning_rate": 0.00010696427277338938,
      "loss": 0.0982,
      "step": 6420
    },
    {
      "epoch": 0.46534043555458926,
      "grad_norm": 2.8526034355163574,
      "learning_rate": 0.00010694977896949055,
      "loss": 0.1894,
      "step": 6421
    },
    {
      "epoch": 0.46541290720005796,
      "grad_norm": 0.8079940676689148,
      "learning_rate": 0.00010693528516559172,
      "loss": 0.036,
      "step": 6422
    },
    {
      "epoch": 0.4654853788455267,
      "grad_norm": 1.7499417066574097,
      "learning_rate": 0.00010692079136169289,
      "loss": 0.0494,
      "step": 6423
    },
    {
      "epoch": 0.4655578504909954,
      "grad_norm": 2.2646536827087402,
      "learning_rate": 0.00010690629755779405,
      "loss": 0.0365,
      "step": 6424
    },
    {
      "epoch": 0.4656303221364641,
      "grad_norm": 2.0808582305908203,
      "learning_rate": 0.00010689180375389523,
      "loss": 0.0343,
      "step": 6425
    },
    {
      "epoch": 0.4657027937819328,
      "grad_norm": 2.866860866546631,
      "learning_rate": 0.00010687730994999639,
      "loss": 0.1156,
      "step": 6426
    },
    {
      "epoch": 0.46577526542740155,
      "grad_norm": 1.3071973323822021,
      "learning_rate": 0.00010686281614609754,
      "loss": 0.0486,
      "step": 6427
    },
    {
      "epoch": 0.46584773707287025,
      "grad_norm": 2.514420747756958,
      "learning_rate": 0.00010684832234219873,
      "loss": 0.0905,
      "step": 6428
    },
    {
      "epoch": 0.46592020871833895,
      "grad_norm": 4.065054416656494,
      "learning_rate": 0.00010683382853829988,
      "loss": 0.0585,
      "step": 6429
    },
    {
      "epoch": 0.46599268036380764,
      "grad_norm": 0.9940820932388306,
      "learning_rate": 0.00010681933473440104,
      "loss": 0.0406,
      "step": 6430
    },
    {
      "epoch": 0.4660651520092764,
      "grad_norm": 0.8197024464607239,
      "learning_rate": 0.00010680484093050222,
      "loss": 0.0286,
      "step": 6431
    },
    {
      "epoch": 0.4661376236547451,
      "grad_norm": 1.6812275648117065,
      "learning_rate": 0.00010679034712660338,
      "loss": 0.0555,
      "step": 6432
    },
    {
      "epoch": 0.4662100953002138,
      "grad_norm": 1.7645857334136963,
      "learning_rate": 0.00010677585332270455,
      "loss": 0.0898,
      "step": 6433
    },
    {
      "epoch": 0.4662825669456825,
      "grad_norm": 1.2469074726104736,
      "learning_rate": 0.00010676135951880572,
      "loss": 0.0247,
      "step": 6434
    },
    {
      "epoch": 0.46635503859115124,
      "grad_norm": 0.831444501876831,
      "learning_rate": 0.00010674686571490689,
      "loss": 0.0638,
      "step": 6435
    },
    {
      "epoch": 0.46642751023661994,
      "grad_norm": 12.677016258239746,
      "learning_rate": 0.00010673237191100805,
      "loss": 0.0863,
      "step": 6436
    },
    {
      "epoch": 0.46649998188208863,
      "grad_norm": 2.990628480911255,
      "learning_rate": 0.00010671787810710923,
      "loss": 0.1747,
      "step": 6437
    },
    {
      "epoch": 0.46657245352755733,
      "grad_norm": 2.0987730026245117,
      "learning_rate": 0.00010670338430321039,
      "loss": 0.1388,
      "step": 6438
    },
    {
      "epoch": 0.466644925173026,
      "grad_norm": 2.0154457092285156,
      "learning_rate": 0.00010668889049931154,
      "loss": 0.0503,
      "step": 6439
    },
    {
      "epoch": 0.4667173968184948,
      "grad_norm": 2.0202648639678955,
      "learning_rate": 0.00010667439669541273,
      "loss": 0.0803,
      "step": 6440
    },
    {
      "epoch": 0.4667898684639635,
      "grad_norm": 2.858076572418213,
      "learning_rate": 0.00010665990289151388,
      "loss": 0.1378,
      "step": 6441
    },
    {
      "epoch": 0.4668623401094322,
      "grad_norm": 0.23212072253227234,
      "learning_rate": 0.00010664540908761504,
      "loss": 0.006,
      "step": 6442
    },
    {
      "epoch": 0.46693481175490087,
      "grad_norm": 1.5218534469604492,
      "learning_rate": 0.00010663091528371622,
      "loss": 0.0902,
      "step": 6443
    },
    {
      "epoch": 0.4670072834003696,
      "grad_norm": 3.8635497093200684,
      "learning_rate": 0.00010661642147981738,
      "loss": 0.2486,
      "step": 6444
    },
    {
      "epoch": 0.4670797550458383,
      "grad_norm": 0.4778651297092438,
      "learning_rate": 0.00010660192767591855,
      "loss": 0.0248,
      "step": 6445
    },
    {
      "epoch": 0.467152226691307,
      "grad_norm": 1.0623747110366821,
      "learning_rate": 0.00010658743387201972,
      "loss": 0.1155,
      "step": 6446
    },
    {
      "epoch": 0.4672246983367757,
      "grad_norm": 2.6917850971221924,
      "learning_rate": 0.00010657294006812089,
      "loss": 0.0542,
      "step": 6447
    },
    {
      "epoch": 0.46729716998224446,
      "grad_norm": 0.8759124875068665,
      "learning_rate": 0.00010655844626422205,
      "loss": 0.0835,
      "step": 6448
    },
    {
      "epoch": 0.46736964162771316,
      "grad_norm": 1.825073003768921,
      "learning_rate": 0.00010654395246032323,
      "loss": 0.0568,
      "step": 6449
    },
    {
      "epoch": 0.46744211327318186,
      "grad_norm": 1.2756094932556152,
      "learning_rate": 0.00010652945865642439,
      "loss": 0.0487,
      "step": 6450
    },
    {
      "epoch": 0.46751458491865056,
      "grad_norm": 3.281602144241333,
      "learning_rate": 0.00010651496485252554,
      "loss": 0.0514,
      "step": 6451
    },
    {
      "epoch": 0.4675870565641193,
      "grad_norm": 2.5505290031433105,
      "learning_rate": 0.00010650047104862673,
      "loss": 0.1241,
      "step": 6452
    },
    {
      "epoch": 0.467659528209588,
      "grad_norm": 1.4433224201202393,
      "learning_rate": 0.00010648597724472788,
      "loss": 0.0834,
      "step": 6453
    },
    {
      "epoch": 0.4677319998550567,
      "grad_norm": 0.8193639516830444,
      "learning_rate": 0.00010647148344082904,
      "loss": 0.0543,
      "step": 6454
    },
    {
      "epoch": 0.4678044715005254,
      "grad_norm": 1.4441477060317993,
      "learning_rate": 0.00010645698963693022,
      "loss": 0.064,
      "step": 6455
    },
    {
      "epoch": 0.46787694314599415,
      "grad_norm": 5.480988025665283,
      "learning_rate": 0.00010644249583303138,
      "loss": 0.2596,
      "step": 6456
    },
    {
      "epoch": 0.46794941479146285,
      "grad_norm": 1.9485499858856201,
      "learning_rate": 0.00010642800202913255,
      "loss": 0.1386,
      "step": 6457
    },
    {
      "epoch": 0.46802188643693154,
      "grad_norm": 1.7863707542419434,
      "learning_rate": 0.00010641350822523372,
      "loss": 0.0588,
      "step": 6458
    },
    {
      "epoch": 0.46809435808240024,
      "grad_norm": 1.2479971647262573,
      "learning_rate": 0.00010639901442133489,
      "loss": 0.0261,
      "step": 6459
    },
    {
      "epoch": 0.468166829727869,
      "grad_norm": 3.9693946838378906,
      "learning_rate": 0.00010638452061743605,
      "loss": 0.1477,
      "step": 6460
    },
    {
      "epoch": 0.4682393013733377,
      "grad_norm": 1.3104523420333862,
      "learning_rate": 0.00010637002681353723,
      "loss": 0.0433,
      "step": 6461
    },
    {
      "epoch": 0.4683117730188064,
      "grad_norm": 0.5010510683059692,
      "learning_rate": 0.00010635553300963839,
      "loss": 0.0125,
      "step": 6462
    },
    {
      "epoch": 0.4683842446642751,
      "grad_norm": 0.3233582079410553,
      "learning_rate": 0.00010634103920573954,
      "loss": 0.0206,
      "step": 6463
    },
    {
      "epoch": 0.46845671630974384,
      "grad_norm": 0.890570878982544,
      "learning_rate": 0.00010632654540184073,
      "loss": 0.056,
      "step": 6464
    },
    {
      "epoch": 0.46852918795521253,
      "grad_norm": 0.6283726692199707,
      "learning_rate": 0.00010631205159794188,
      "loss": 0.0125,
      "step": 6465
    },
    {
      "epoch": 0.46860165960068123,
      "grad_norm": 2.6717565059661865,
      "learning_rate": 0.00010629755779404304,
      "loss": 0.0677,
      "step": 6466
    },
    {
      "epoch": 0.4686741312461499,
      "grad_norm": 2.0434648990631104,
      "learning_rate": 0.00010628306399014422,
      "loss": 0.12,
      "step": 6467
    },
    {
      "epoch": 0.4687466028916187,
      "grad_norm": 0.4924014210700989,
      "learning_rate": 0.00010626857018624538,
      "loss": 0.0083,
      "step": 6468
    },
    {
      "epoch": 0.4688190745370874,
      "grad_norm": 0.7469127178192139,
      "learning_rate": 0.00010625407638234655,
      "loss": 0.0821,
      "step": 6469
    },
    {
      "epoch": 0.4688915461825561,
      "grad_norm": 0.09383758157491684,
      "learning_rate": 0.00010623958257844773,
      "loss": 0.0026,
      "step": 6470
    },
    {
      "epoch": 0.46896401782802477,
      "grad_norm": 2.874572277069092,
      "learning_rate": 0.00010622508877454889,
      "loss": 0.0812,
      "step": 6471
    },
    {
      "epoch": 0.4690364894734935,
      "grad_norm": 2.8162896633148193,
      "learning_rate": 0.00010621059497065005,
      "loss": 0.1112,
      "step": 6472
    },
    {
      "epoch": 0.4691089611189622,
      "grad_norm": 0.6273853778839111,
      "learning_rate": 0.00010619610116675123,
      "loss": 0.026,
      "step": 6473
    },
    {
      "epoch": 0.4691814327644309,
      "grad_norm": 1.7127211093902588,
      "learning_rate": 0.00010618160736285239,
      "loss": 0.0456,
      "step": 6474
    },
    {
      "epoch": 0.4692539044098996,
      "grad_norm": 2.4201788902282715,
      "learning_rate": 0.00010616711355895354,
      "loss": 0.0365,
      "step": 6475
    },
    {
      "epoch": 0.4693263760553683,
      "grad_norm": 2.302483558654785,
      "learning_rate": 0.00010615261975505473,
      "loss": 0.0885,
      "step": 6476
    },
    {
      "epoch": 0.46939884770083706,
      "grad_norm": 0.6940475702285767,
      "learning_rate": 0.00010613812595115588,
      "loss": 0.0082,
      "step": 6477
    },
    {
      "epoch": 0.46947131934630576,
      "grad_norm": 1.5213303565979004,
      "learning_rate": 0.00010612363214725704,
      "loss": 0.0468,
      "step": 6478
    },
    {
      "epoch": 0.46954379099177446,
      "grad_norm": 0.782164454460144,
      "learning_rate": 0.00010610913834335822,
      "loss": 0.0458,
      "step": 6479
    },
    {
      "epoch": 0.46961626263724315,
      "grad_norm": 1.1351988315582275,
      "learning_rate": 0.00010609464453945939,
      "loss": 0.0519,
      "step": 6480
    },
    {
      "epoch": 0.4696887342827119,
      "grad_norm": 1.5485397577285767,
      "learning_rate": 0.00010608015073556055,
      "loss": 0.0417,
      "step": 6481
    },
    {
      "epoch": 0.4697612059281806,
      "grad_norm": 2.034698724746704,
      "learning_rate": 0.00010606565693166173,
      "loss": 0.0828,
      "step": 6482
    },
    {
      "epoch": 0.4698336775736493,
      "grad_norm": 1.0345005989074707,
      "learning_rate": 0.00010605116312776289,
      "loss": 0.0593,
      "step": 6483
    },
    {
      "epoch": 0.469906149219118,
      "grad_norm": 2.2965927124023438,
      "learning_rate": 0.00010603666932386405,
      "loss": 0.0833,
      "step": 6484
    },
    {
      "epoch": 0.46997862086458675,
      "grad_norm": 2.518139123916626,
      "learning_rate": 0.00010602217551996523,
      "loss": 0.0413,
      "step": 6485
    },
    {
      "epoch": 0.47005109251005545,
      "grad_norm": 0.44732776284217834,
      "learning_rate": 0.00010600768171606639,
      "loss": 0.0113,
      "step": 6486
    },
    {
      "epoch": 0.47012356415552414,
      "grad_norm": 3.9445619583129883,
      "learning_rate": 0.00010599318791216754,
      "loss": 0.0477,
      "step": 6487
    },
    {
      "epoch": 0.47019603580099284,
      "grad_norm": 1.5328716039657593,
      "learning_rate": 0.00010597869410826873,
      "loss": 0.0668,
      "step": 6488
    },
    {
      "epoch": 0.4702685074464616,
      "grad_norm": 4.182941913604736,
      "learning_rate": 0.00010596420030436988,
      "loss": 0.088,
      "step": 6489
    },
    {
      "epoch": 0.4703409790919303,
      "grad_norm": 1.874819040298462,
      "learning_rate": 0.00010594970650047105,
      "loss": 0.0832,
      "step": 6490
    },
    {
      "epoch": 0.470413450737399,
      "grad_norm": 2.0738840103149414,
      "learning_rate": 0.00010593521269657222,
      "loss": 0.0331,
      "step": 6491
    },
    {
      "epoch": 0.4704859223828677,
      "grad_norm": 5.579883575439453,
      "learning_rate": 0.00010592071889267339,
      "loss": 0.0555,
      "step": 6492
    },
    {
      "epoch": 0.47055839402833644,
      "grad_norm": 4.0277910232543945,
      "learning_rate": 0.00010590622508877455,
      "loss": 0.1792,
      "step": 6493
    },
    {
      "epoch": 0.47063086567380513,
      "grad_norm": 1.7676671743392944,
      "learning_rate": 0.00010589173128487573,
      "loss": 0.0397,
      "step": 6494
    },
    {
      "epoch": 0.47070333731927383,
      "grad_norm": 2.6818649768829346,
      "learning_rate": 0.00010587723748097689,
      "loss": 0.105,
      "step": 6495
    },
    {
      "epoch": 0.4707758089647425,
      "grad_norm": 1.8583835363388062,
      "learning_rate": 0.00010586274367707805,
      "loss": 0.0894,
      "step": 6496
    },
    {
      "epoch": 0.4708482806102113,
      "grad_norm": 1.1985728740692139,
      "learning_rate": 0.00010584824987317923,
      "loss": 0.0252,
      "step": 6497
    },
    {
      "epoch": 0.47092075225568,
      "grad_norm": 1.163327932357788,
      "learning_rate": 0.00010583375606928039,
      "loss": 0.0261,
      "step": 6498
    },
    {
      "epoch": 0.47099322390114867,
      "grad_norm": 2.2990505695343018,
      "learning_rate": 0.00010581926226538154,
      "loss": 0.1116,
      "step": 6499
    },
    {
      "epoch": 0.47106569554661737,
      "grad_norm": 2.6636545658111572,
      "learning_rate": 0.00010580476846148273,
      "loss": 0.0767,
      "step": 6500
    },
    {
      "epoch": 0.4711381671920861,
      "grad_norm": 1.6245980262756348,
      "learning_rate": 0.00010579027465758388,
      "loss": 0.1628,
      "step": 6501
    },
    {
      "epoch": 0.4712106388375548,
      "grad_norm": 0.7159820795059204,
      "learning_rate": 0.00010577578085368505,
      "loss": 0.0323,
      "step": 6502
    },
    {
      "epoch": 0.4712831104830235,
      "grad_norm": 1.4219162464141846,
      "learning_rate": 0.00010576128704978622,
      "loss": 0.0501,
      "step": 6503
    },
    {
      "epoch": 0.4713555821284922,
      "grad_norm": 5.36342191696167,
      "learning_rate": 0.00010574679324588739,
      "loss": 0.0239,
      "step": 6504
    },
    {
      "epoch": 0.47142805377396096,
      "grad_norm": 4.473581790924072,
      "learning_rate": 0.00010573229944198855,
      "loss": 0.0756,
      "step": 6505
    },
    {
      "epoch": 0.47150052541942966,
      "grad_norm": 1.1244248151779175,
      "learning_rate": 0.00010571780563808973,
      "loss": 0.0442,
      "step": 6506
    },
    {
      "epoch": 0.47157299706489836,
      "grad_norm": 2.1664206981658936,
      "learning_rate": 0.00010570331183419089,
      "loss": 0.0123,
      "step": 6507
    },
    {
      "epoch": 0.47164546871036706,
      "grad_norm": 3.4048707485198975,
      "learning_rate": 0.00010568881803029205,
      "loss": 0.0193,
      "step": 6508
    },
    {
      "epoch": 0.47171794035583575,
      "grad_norm": 1.722672700881958,
      "learning_rate": 0.00010567432422639323,
      "loss": 0.1208,
      "step": 6509
    },
    {
      "epoch": 0.4717904120013045,
      "grad_norm": 2.1965808868408203,
      "learning_rate": 0.00010565983042249439,
      "loss": 0.0872,
      "step": 6510
    },
    {
      "epoch": 0.4718628836467732,
      "grad_norm": 1.6398197412490845,
      "learning_rate": 0.00010564533661859554,
      "loss": 0.1747,
      "step": 6511
    },
    {
      "epoch": 0.4719353552922419,
      "grad_norm": 1.124975323677063,
      "learning_rate": 0.00010563084281469673,
      "loss": 0.0785,
      "step": 6512
    },
    {
      "epoch": 0.4720078269377106,
      "grad_norm": 1.1212877035140991,
      "learning_rate": 0.00010561634901079788,
      "loss": 0.0855,
      "step": 6513
    },
    {
      "epoch": 0.47208029858317935,
      "grad_norm": 2.4898569583892822,
      "learning_rate": 0.00010560185520689905,
      "loss": 0.0509,
      "step": 6514
    },
    {
      "epoch": 0.47215277022864804,
      "grad_norm": 0.6899726390838623,
      "learning_rate": 0.00010558736140300022,
      "loss": 0.0448,
      "step": 6515
    },
    {
      "epoch": 0.47222524187411674,
      "grad_norm": 1.384524941444397,
      "learning_rate": 0.00010557286759910139,
      "loss": 0.0438,
      "step": 6516
    },
    {
      "epoch": 0.47229771351958544,
      "grad_norm": 0.8100939989089966,
      "learning_rate": 0.00010555837379520255,
      "loss": 0.0548,
      "step": 6517
    },
    {
      "epoch": 0.4723701851650542,
      "grad_norm": 0.6986439824104309,
      "learning_rate": 0.00010554387999130373,
      "loss": 0.0257,
      "step": 6518
    },
    {
      "epoch": 0.4724426568105229,
      "grad_norm": 1.2830841541290283,
      "learning_rate": 0.00010552938618740489,
      "loss": 0.061,
      "step": 6519
    },
    {
      "epoch": 0.4725151284559916,
      "grad_norm": 0.3898923099040985,
      "learning_rate": 0.00010551489238350605,
      "loss": 0.0267,
      "step": 6520
    },
    {
      "epoch": 0.4725876001014603,
      "grad_norm": 0.8514382243156433,
      "learning_rate": 0.00010550039857960723,
      "loss": 0.0332,
      "step": 6521
    },
    {
      "epoch": 0.47266007174692903,
      "grad_norm": 0.4562125504016876,
      "learning_rate": 0.00010548590477570839,
      "loss": 0.0259,
      "step": 6522
    },
    {
      "epoch": 0.47273254339239773,
      "grad_norm": 0.48075637221336365,
      "learning_rate": 0.00010547141097180954,
      "loss": 0.0286,
      "step": 6523
    },
    {
      "epoch": 0.4728050150378664,
      "grad_norm": 1.5799062252044678,
      "learning_rate": 0.00010545691716791073,
      "loss": 0.0696,
      "step": 6524
    },
    {
      "epoch": 0.4728774866833351,
      "grad_norm": 0.991072416305542,
      "learning_rate": 0.00010544242336401188,
      "loss": 0.1153,
      "step": 6525
    },
    {
      "epoch": 0.4729499583288039,
      "grad_norm": 1.0441710948944092,
      "learning_rate": 0.00010542792956011305,
      "loss": 0.019,
      "step": 6526
    },
    {
      "epoch": 0.4730224299742726,
      "grad_norm": 1.808249592781067,
      "learning_rate": 0.00010541343575621424,
      "loss": 0.1303,
      "step": 6527
    },
    {
      "epoch": 0.47309490161974127,
      "grad_norm": 0.5805422067642212,
      "learning_rate": 0.00010539894195231539,
      "loss": 0.0308,
      "step": 6528
    },
    {
      "epoch": 0.47316737326520997,
      "grad_norm": 1.1931809186935425,
      "learning_rate": 0.00010538444814841655,
      "loss": 0.0321,
      "step": 6529
    },
    {
      "epoch": 0.4732398449106787,
      "grad_norm": 0.1944083869457245,
      "learning_rate": 0.00010536995434451773,
      "loss": 0.0103,
      "step": 6530
    },
    {
      "epoch": 0.4733123165561474,
      "grad_norm": 4.133833408355713,
      "learning_rate": 0.00010535546054061889,
      "loss": 0.0292,
      "step": 6531
    },
    {
      "epoch": 0.4733847882016161,
      "grad_norm": 0.19245103001594543,
      "learning_rate": 0.00010534096673672005,
      "loss": 0.0085,
      "step": 6532
    },
    {
      "epoch": 0.4734572598470848,
      "grad_norm": 3.522624969482422,
      "learning_rate": 0.00010532647293282123,
      "loss": 0.0787,
      "step": 6533
    },
    {
      "epoch": 0.47352973149255356,
      "grad_norm": 2.0078909397125244,
      "learning_rate": 0.00010531197912892239,
      "loss": 0.0622,
      "step": 6534
    },
    {
      "epoch": 0.47360220313802226,
      "grad_norm": 1.0015259981155396,
      "learning_rate": 0.00010529748532502354,
      "loss": 0.0462,
      "step": 6535
    },
    {
      "epoch": 0.47367467478349096,
      "grad_norm": 1.7538760900497437,
      "learning_rate": 0.00010528299152112473,
      "loss": 0.1006,
      "step": 6536
    },
    {
      "epoch": 0.47374714642895965,
      "grad_norm": 1.1270335912704468,
      "learning_rate": 0.0001052684977172259,
      "loss": 0.0145,
      "step": 6537
    },
    {
      "epoch": 0.4738196180744284,
      "grad_norm": 1.5813730955123901,
      "learning_rate": 0.00010525400391332705,
      "loss": 0.0467,
      "step": 6538
    },
    {
      "epoch": 0.4738920897198971,
      "grad_norm": 0.7905194759368896,
      "learning_rate": 0.00010523951010942824,
      "loss": 0.0738,
      "step": 6539
    },
    {
      "epoch": 0.4739645613653658,
      "grad_norm": 1.1899548768997192,
      "learning_rate": 0.00010522501630552939,
      "loss": 0.1335,
      "step": 6540
    },
    {
      "epoch": 0.4740370330108345,
      "grad_norm": 1.003129482269287,
      "learning_rate": 0.00010521052250163055,
      "loss": 0.0226,
      "step": 6541
    },
    {
      "epoch": 0.47410950465630325,
      "grad_norm": 1.6312097311019897,
      "learning_rate": 0.00010519602869773173,
      "loss": 0.0347,
      "step": 6542
    },
    {
      "epoch": 0.47418197630177195,
      "grad_norm": 1.2646892070770264,
      "learning_rate": 0.00010518153489383289,
      "loss": 0.0786,
      "step": 6543
    },
    {
      "epoch": 0.47425444794724064,
      "grad_norm": 1.7974884510040283,
      "learning_rate": 0.00010516704108993405,
      "loss": 0.0632,
      "step": 6544
    },
    {
      "epoch": 0.47432691959270934,
      "grad_norm": 1.1845805644989014,
      "learning_rate": 0.00010515254728603523,
      "loss": 0.0407,
      "step": 6545
    },
    {
      "epoch": 0.47439939123817804,
      "grad_norm": 2.053971529006958,
      "learning_rate": 0.00010513805348213639,
      "loss": 0.1098,
      "step": 6546
    },
    {
      "epoch": 0.4744718628836468,
      "grad_norm": 1.3803341388702393,
      "learning_rate": 0.00010512355967823756,
      "loss": 0.057,
      "step": 6547
    },
    {
      "epoch": 0.4745443345291155,
      "grad_norm": 2.9635493755340576,
      "learning_rate": 0.00010510906587433873,
      "loss": 0.1704,
      "step": 6548
    },
    {
      "epoch": 0.4746168061745842,
      "grad_norm": 2.0218286514282227,
      "learning_rate": 0.0001050945720704399,
      "loss": 0.0906,
      "step": 6549
    },
    {
      "epoch": 0.4746892778200529,
      "grad_norm": 2.047435760498047,
      "learning_rate": 0.00010508007826654105,
      "loss": 0.1454,
      "step": 6550
    },
    {
      "epoch": 0.47476174946552163,
      "grad_norm": 3.8881661891937256,
      "learning_rate": 0.00010506558446264224,
      "loss": 0.2146,
      "step": 6551
    },
    {
      "epoch": 0.47483422111099033,
      "grad_norm": 1.7360918521881104,
      "learning_rate": 0.00010505109065874339,
      "loss": 0.0373,
      "step": 6552
    },
    {
      "epoch": 0.474906692756459,
      "grad_norm": 0.6315820813179016,
      "learning_rate": 0.00010503659685484455,
      "loss": 0.0282,
      "step": 6553
    },
    {
      "epoch": 0.4749791644019277,
      "grad_norm": 1.1606000661849976,
      "learning_rate": 0.00010502210305094573,
      "loss": 0.0406,
      "step": 6554
    },
    {
      "epoch": 0.4750516360473965,
      "grad_norm": 1.7248589992523193,
      "learning_rate": 0.00010500760924704689,
      "loss": 0.1566,
      "step": 6555
    },
    {
      "epoch": 0.47512410769286517,
      "grad_norm": 0.419772207736969,
      "learning_rate": 0.00010499311544314804,
      "loss": 0.0162,
      "step": 6556
    },
    {
      "epoch": 0.47519657933833387,
      "grad_norm": 0.9594671130180359,
      "learning_rate": 0.00010497862163924923,
      "loss": 0.0445,
      "step": 6557
    },
    {
      "epoch": 0.47526905098380257,
      "grad_norm": 1.6547698974609375,
      "learning_rate": 0.00010496412783535038,
      "loss": 0.1432,
      "step": 6558
    },
    {
      "epoch": 0.4753415226292713,
      "grad_norm": 1.218164086341858,
      "learning_rate": 0.00010494963403145155,
      "loss": 0.081,
      "step": 6559
    },
    {
      "epoch": 0.47541399427474,
      "grad_norm": 0.6542162895202637,
      "learning_rate": 0.00010493514022755273,
      "loss": 0.022,
      "step": 6560
    },
    {
      "epoch": 0.4754864659202087,
      "grad_norm": 1.614828109741211,
      "learning_rate": 0.0001049206464236539,
      "loss": 0.1117,
      "step": 6561
    },
    {
      "epoch": 0.4755589375656774,
      "grad_norm": 1.3844547271728516,
      "learning_rate": 0.00010490615261975505,
      "loss": 0.0591,
      "step": 6562
    },
    {
      "epoch": 0.47563140921114616,
      "grad_norm": 5.727989673614502,
      "learning_rate": 0.00010489165881585624,
      "loss": 0.1941,
      "step": 6563
    },
    {
      "epoch": 0.47570388085661486,
      "grad_norm": 1.44368577003479,
      "learning_rate": 0.00010487716501195739,
      "loss": 0.0519,
      "step": 6564
    },
    {
      "epoch": 0.47577635250208355,
      "grad_norm": 1.123749017715454,
      "learning_rate": 0.00010486267120805855,
      "loss": 0.0316,
      "step": 6565
    },
    {
      "epoch": 0.47584882414755225,
      "grad_norm": 2.876474142074585,
      "learning_rate": 0.00010484817740415973,
      "loss": 0.1658,
      "step": 6566
    },
    {
      "epoch": 0.475921295793021,
      "grad_norm": 3.4324758052825928,
      "learning_rate": 0.00010483368360026089,
      "loss": 0.0932,
      "step": 6567
    },
    {
      "epoch": 0.4759937674384897,
      "grad_norm": 0.7525606751441956,
      "learning_rate": 0.00010481918979636204,
      "loss": 0.039,
      "step": 6568
    },
    {
      "epoch": 0.4760662390839584,
      "grad_norm": 0.5738095045089722,
      "learning_rate": 0.00010480469599246323,
      "loss": 0.016,
      "step": 6569
    },
    {
      "epoch": 0.4761387107294271,
      "grad_norm": 2.6590018272399902,
      "learning_rate": 0.00010479020218856438,
      "loss": 0.078,
      "step": 6570
    },
    {
      "epoch": 0.47621118237489585,
      "grad_norm": 2.4019834995269775,
      "learning_rate": 0.00010477570838466555,
      "loss": 0.1918,
      "step": 6571
    },
    {
      "epoch": 0.47628365402036454,
      "grad_norm": 1.047857403755188,
      "learning_rate": 0.00010476121458076672,
      "loss": 0.0834,
      "step": 6572
    },
    {
      "epoch": 0.47635612566583324,
      "grad_norm": 0.6133144497871399,
      "learning_rate": 0.0001047467207768679,
      "loss": 0.0509,
      "step": 6573
    },
    {
      "epoch": 0.47642859731130194,
      "grad_norm": 0.49487581849098206,
      "learning_rate": 0.00010473222697296905,
      "loss": 0.0167,
      "step": 6574
    },
    {
      "epoch": 0.4765010689567707,
      "grad_norm": 1.4131231307983398,
      "learning_rate": 0.00010471773316907023,
      "loss": 0.1127,
      "step": 6575
    },
    {
      "epoch": 0.4765735406022394,
      "grad_norm": 0.7809414863586426,
      "learning_rate": 0.00010470323936517139,
      "loss": 0.0676,
      "step": 6576
    },
    {
      "epoch": 0.4766460122477081,
      "grad_norm": 0.32646486163139343,
      "learning_rate": 0.00010468874556127258,
      "loss": 0.0261,
      "step": 6577
    },
    {
      "epoch": 0.4767184838931768,
      "grad_norm": 3.615602731704712,
      "learning_rate": 0.00010467425175737373,
      "loss": 0.1623,
      "step": 6578
    },
    {
      "epoch": 0.4767909555386455,
      "grad_norm": 1.9102239608764648,
      "learning_rate": 0.00010465975795347489,
      "loss": 0.0924,
      "step": 6579
    },
    {
      "epoch": 0.47686342718411423,
      "grad_norm": 0.4423506557941437,
      "learning_rate": 0.00010464526414957607,
      "loss": 0.0346,
      "step": 6580
    },
    {
      "epoch": 0.4769358988295829,
      "grad_norm": 4.1344757080078125,
      "learning_rate": 0.00010463077034567723,
      "loss": 0.1879,
      "step": 6581
    },
    {
      "epoch": 0.4770083704750516,
      "grad_norm": 0.6511875987052917,
      "learning_rate": 0.00010461627654177838,
      "loss": 0.0257,
      "step": 6582
    },
    {
      "epoch": 0.4770808421205203,
      "grad_norm": 1.7984884977340698,
      "learning_rate": 0.00010460178273787957,
      "loss": 0.0155,
      "step": 6583
    },
    {
      "epoch": 0.4771533137659891,
      "grad_norm": 0.9720094799995422,
      "learning_rate": 0.00010458728893398074,
      "loss": 0.0708,
      "step": 6584
    },
    {
      "epoch": 0.47722578541145777,
      "grad_norm": 2.041652202606201,
      "learning_rate": 0.0001045727951300819,
      "loss": 0.0777,
      "step": 6585
    },
    {
      "epoch": 0.47729825705692647,
      "grad_norm": 0.6298955678939819,
      "learning_rate": 0.00010455830132618308,
      "loss": 0.0825,
      "step": 6586
    },
    {
      "epoch": 0.47737072870239516,
      "grad_norm": 2.24035906791687,
      "learning_rate": 0.00010454380752228423,
      "loss": 0.1059,
      "step": 6587
    },
    {
      "epoch": 0.4774432003478639,
      "grad_norm": 0.8909078240394592,
      "learning_rate": 0.00010452931371838539,
      "loss": 0.0617,
      "step": 6588
    },
    {
      "epoch": 0.4775156719933326,
      "grad_norm": 1.0764650106430054,
      "learning_rate": 0.00010451481991448657,
      "loss": 0.0837,
      "step": 6589
    },
    {
      "epoch": 0.4775881436388013,
      "grad_norm": 2.516439914703369,
      "learning_rate": 0.00010450032611058773,
      "loss": 0.1438,
      "step": 6590
    },
    {
      "epoch": 0.47766061528427,
      "grad_norm": 1.9433485269546509,
      "learning_rate": 0.00010448583230668889,
      "loss": 0.136,
      "step": 6591
    },
    {
      "epoch": 0.47773308692973876,
      "grad_norm": 2.212216377258301,
      "learning_rate": 0.00010447133850279007,
      "loss": 0.1183,
      "step": 6592
    },
    {
      "epoch": 0.47780555857520746,
      "grad_norm": 2.124614715576172,
      "learning_rate": 0.00010445684469889123,
      "loss": 0.1207,
      "step": 6593
    },
    {
      "epoch": 0.47787803022067615,
      "grad_norm": 1.1158573627471924,
      "learning_rate": 0.0001044423508949924,
      "loss": 0.1164,
      "step": 6594
    },
    {
      "epoch": 0.47795050186614485,
      "grad_norm": 1.4725617170333862,
      "learning_rate": 0.00010442785709109357,
      "loss": 0.0623,
      "step": 6595
    },
    {
      "epoch": 0.4780229735116136,
      "grad_norm": 1.0813802480697632,
      "learning_rate": 0.00010441336328719474,
      "loss": 0.0352,
      "step": 6596
    },
    {
      "epoch": 0.4780954451570823,
      "grad_norm": 0.5451867580413818,
      "learning_rate": 0.0001043988694832959,
      "loss": 0.0304,
      "step": 6597
    },
    {
      "epoch": 0.478167916802551,
      "grad_norm": 1.6782420873641968,
      "learning_rate": 0.00010438437567939708,
      "loss": 0.099,
      "step": 6598
    },
    {
      "epoch": 0.4782403884480197,
      "grad_norm": 1.009708285331726,
      "learning_rate": 0.00010436988187549823,
      "loss": 0.0404,
      "step": 6599
    },
    {
      "epoch": 0.47831286009348845,
      "grad_norm": 0.8631862998008728,
      "learning_rate": 0.00010435538807159939,
      "loss": 0.0698,
      "step": 6600
    },
    {
      "epoch": 0.47838533173895714,
      "grad_norm": 2.5021557807922363,
      "learning_rate": 0.00010434089426770057,
      "loss": 0.1599,
      "step": 6601
    },
    {
      "epoch": 0.47845780338442584,
      "grad_norm": 1.2229708433151245,
      "learning_rate": 0.00010432640046380173,
      "loss": 0.0894,
      "step": 6602
    },
    {
      "epoch": 0.47853027502989454,
      "grad_norm": 2.1349830627441406,
      "learning_rate": 0.00010431190665990289,
      "loss": 0.0933,
      "step": 6603
    },
    {
      "epoch": 0.4786027466753633,
      "grad_norm": 1.3364256620407104,
      "learning_rate": 0.00010429741285600407,
      "loss": 0.0744,
      "step": 6604
    },
    {
      "epoch": 0.478675218320832,
      "grad_norm": 0.871978759765625,
      "learning_rate": 0.00010428291905210523,
      "loss": 0.1039,
      "step": 6605
    },
    {
      "epoch": 0.4787476899663007,
      "grad_norm": 0.6173749566078186,
      "learning_rate": 0.0001042684252482064,
      "loss": 0.017,
      "step": 6606
    },
    {
      "epoch": 0.4788201616117694,
      "grad_norm": 0.4420130252838135,
      "learning_rate": 0.00010425393144430757,
      "loss": 0.0199,
      "step": 6607
    },
    {
      "epoch": 0.47889263325723813,
      "grad_norm": 1.0211824178695679,
      "learning_rate": 0.00010423943764040874,
      "loss": 0.041,
      "step": 6608
    },
    {
      "epoch": 0.47896510490270683,
      "grad_norm": 2.1678707599639893,
      "learning_rate": 0.0001042249438365099,
      "loss": 0.1549,
      "step": 6609
    },
    {
      "epoch": 0.4790375765481755,
      "grad_norm": 1.1418720483779907,
      "learning_rate": 0.00010421045003261108,
      "loss": 0.0699,
      "step": 6610
    },
    {
      "epoch": 0.4791100481936442,
      "grad_norm": 4.751776218414307,
      "learning_rate": 0.00010419595622871223,
      "loss": 0.1129,
      "step": 6611
    },
    {
      "epoch": 0.479182519839113,
      "grad_norm": 1.4508309364318848,
      "learning_rate": 0.00010418146242481339,
      "loss": 0.1015,
      "step": 6612
    },
    {
      "epoch": 0.47925499148458167,
      "grad_norm": 1.5365915298461914,
      "learning_rate": 0.00010416696862091457,
      "loss": 0.0551,
      "step": 6613
    },
    {
      "epoch": 0.47932746313005037,
      "grad_norm": 0.6381880044937134,
      "learning_rate": 0.00010415247481701573,
      "loss": 0.0575,
      "step": 6614
    },
    {
      "epoch": 0.47939993477551907,
      "grad_norm": 0.7756525278091431,
      "learning_rate": 0.00010413798101311689,
      "loss": 0.0441,
      "step": 6615
    },
    {
      "epoch": 0.47947240642098776,
      "grad_norm": 1.5940958261489868,
      "learning_rate": 0.00010412348720921807,
      "loss": 0.0312,
      "step": 6616
    },
    {
      "epoch": 0.4795448780664565,
      "grad_norm": 0.4171437621116638,
      "learning_rate": 0.00010410899340531923,
      "loss": 0.0184,
      "step": 6617
    },
    {
      "epoch": 0.4796173497119252,
      "grad_norm": 1.4022825956344604,
      "learning_rate": 0.0001040944996014204,
      "loss": 0.0857,
      "step": 6618
    },
    {
      "epoch": 0.4796898213573939,
      "grad_norm": 1.9288462400436401,
      "learning_rate": 0.00010408000579752157,
      "loss": 0.0758,
      "step": 6619
    },
    {
      "epoch": 0.4797622930028626,
      "grad_norm": 1.7145832777023315,
      "learning_rate": 0.00010406551199362274,
      "loss": 0.1555,
      "step": 6620
    },
    {
      "epoch": 0.47983476464833136,
      "grad_norm": 3.020664930343628,
      "learning_rate": 0.0001040510181897239,
      "loss": 0.0514,
      "step": 6621
    },
    {
      "epoch": 0.47990723629380005,
      "grad_norm": 0.30502912402153015,
      "learning_rate": 0.00010403652438582508,
      "loss": 0.0075,
      "step": 6622
    },
    {
      "epoch": 0.47997970793926875,
      "grad_norm": 0.6506296992301941,
      "learning_rate": 0.00010402203058192623,
      "loss": 0.0305,
      "step": 6623
    },
    {
      "epoch": 0.48005217958473745,
      "grad_norm": 1.2223951816558838,
      "learning_rate": 0.00010400753677802739,
      "loss": 0.0389,
      "step": 6624
    },
    {
      "epoch": 0.4801246512302062,
      "grad_norm": 0.7740856409072876,
      "learning_rate": 0.00010399304297412857,
      "loss": 0.0736,
      "step": 6625
    },
    {
      "epoch": 0.4801971228756749,
      "grad_norm": 0.9271517992019653,
      "learning_rate": 0.00010397854917022973,
      "loss": 0.0443,
      "step": 6626
    },
    {
      "epoch": 0.4802695945211436,
      "grad_norm": 2.881971836090088,
      "learning_rate": 0.00010396405536633089,
      "loss": 0.0445,
      "step": 6627
    },
    {
      "epoch": 0.4803420661666123,
      "grad_norm": 0.6651924848556519,
      "learning_rate": 0.00010394956156243207,
      "loss": 0.0224,
      "step": 6628
    },
    {
      "epoch": 0.48041453781208104,
      "grad_norm": 0.6425862908363342,
      "learning_rate": 0.00010393506775853323,
      "loss": 0.0484,
      "step": 6629
    },
    {
      "epoch": 0.48048700945754974,
      "grad_norm": 1.8696873188018799,
      "learning_rate": 0.0001039205739546344,
      "loss": 0.0605,
      "step": 6630
    },
    {
      "epoch": 0.48055948110301844,
      "grad_norm": 0.5078787803649902,
      "learning_rate": 0.00010390608015073558,
      "loss": 0.0242,
      "step": 6631
    },
    {
      "epoch": 0.48063195274848713,
      "grad_norm": 2.211477041244507,
      "learning_rate": 0.00010389158634683674,
      "loss": 0.0223,
      "step": 6632
    },
    {
      "epoch": 0.4807044243939559,
      "grad_norm": 2.9560718536376953,
      "learning_rate": 0.0001038770925429379,
      "loss": 0.0903,
      "step": 6633
    },
    {
      "epoch": 0.4807768960394246,
      "grad_norm": 0.6188578605651855,
      "learning_rate": 0.00010386259873903908,
      "loss": 0.0209,
      "step": 6634
    },
    {
      "epoch": 0.4808493676848933,
      "grad_norm": 2.9720699787139893,
      "learning_rate": 0.00010384810493514023,
      "loss": 0.2044,
      "step": 6635
    },
    {
      "epoch": 0.480921839330362,
      "grad_norm": 0.6176705360412598,
      "learning_rate": 0.00010383361113124139,
      "loss": 0.025,
      "step": 6636
    },
    {
      "epoch": 0.48099431097583073,
      "grad_norm": 2.6166532039642334,
      "learning_rate": 0.00010381911732734257,
      "loss": 0.0473,
      "step": 6637
    },
    {
      "epoch": 0.4810667826212994,
      "grad_norm": 1.4783849716186523,
      "learning_rate": 0.00010380462352344373,
      "loss": 0.0758,
      "step": 6638
    },
    {
      "epoch": 0.4811392542667681,
      "grad_norm": 0.8819493055343628,
      "learning_rate": 0.00010379012971954489,
      "loss": 0.0237,
      "step": 6639
    },
    {
      "epoch": 0.4812117259122368,
      "grad_norm": 2.1625185012817383,
      "learning_rate": 0.00010377563591564607,
      "loss": 0.1014,
      "step": 6640
    },
    {
      "epoch": 0.4812841975577056,
      "grad_norm": 2.276259422302246,
      "learning_rate": 0.00010376114211174723,
      "loss": 0.1878,
      "step": 6641
    },
    {
      "epoch": 0.48135666920317427,
      "grad_norm": 0.8012977242469788,
      "learning_rate": 0.0001037466483078484,
      "loss": 0.0104,
      "step": 6642
    },
    {
      "epoch": 0.48142914084864297,
      "grad_norm": 1.051316261291504,
      "learning_rate": 0.00010373215450394958,
      "loss": 0.0591,
      "step": 6643
    },
    {
      "epoch": 0.48150161249411166,
      "grad_norm": 0.6152463555335999,
      "learning_rate": 0.00010371766070005074,
      "loss": 0.0295,
      "step": 6644
    },
    {
      "epoch": 0.4815740841395804,
      "grad_norm": 2.3185205459594727,
      "learning_rate": 0.0001037031668961519,
      "loss": 0.019,
      "step": 6645
    },
    {
      "epoch": 0.4816465557850491,
      "grad_norm": 2.242734909057617,
      "learning_rate": 0.00010368867309225308,
      "loss": 0.0968,
      "step": 6646
    },
    {
      "epoch": 0.4817190274305178,
      "grad_norm": 3.262535333633423,
      "learning_rate": 0.00010367417928835423,
      "loss": 0.0832,
      "step": 6647
    },
    {
      "epoch": 0.4817914990759865,
      "grad_norm": 2.816767454147339,
      "learning_rate": 0.00010365968548445539,
      "loss": 0.1404,
      "step": 6648
    },
    {
      "epoch": 0.4818639707214552,
      "grad_norm": 1.5372155904769897,
      "learning_rate": 0.00010364519168055657,
      "loss": 0.1057,
      "step": 6649
    },
    {
      "epoch": 0.48193644236692396,
      "grad_norm": 0.85127192735672,
      "learning_rate": 0.00010363069787665773,
      "loss": 0.0496,
      "step": 6650
    },
    {
      "epoch": 0.48200891401239265,
      "grad_norm": 3.80840802192688,
      "learning_rate": 0.00010361620407275889,
      "loss": 0.0566,
      "step": 6651
    },
    {
      "epoch": 0.48208138565786135,
      "grad_norm": 0.5664020776748657,
      "learning_rate": 0.00010360171026886007,
      "loss": 0.033,
      "step": 6652
    },
    {
      "epoch": 0.48215385730333005,
      "grad_norm": 0.8522039651870728,
      "learning_rate": 0.00010358721646496124,
      "loss": 0.0378,
      "step": 6653
    },
    {
      "epoch": 0.4822263289487988,
      "grad_norm": 1.0081942081451416,
      "learning_rate": 0.0001035727226610624,
      "loss": 0.055,
      "step": 6654
    },
    {
      "epoch": 0.4822988005942675,
      "grad_norm": 0.7036905288696289,
      "learning_rate": 0.00010355822885716358,
      "loss": 0.0503,
      "step": 6655
    },
    {
      "epoch": 0.4823712722397362,
      "grad_norm": 0.6424356698989868,
      "learning_rate": 0.00010354373505326474,
      "loss": 0.0199,
      "step": 6656
    },
    {
      "epoch": 0.4824437438852049,
      "grad_norm": 3.466998815536499,
      "learning_rate": 0.0001035292412493659,
      "loss": 0.1578,
      "step": 6657
    },
    {
      "epoch": 0.48251621553067364,
      "grad_norm": 0.7984814643859863,
      "learning_rate": 0.00010351474744546708,
      "loss": 0.0426,
      "step": 6658
    },
    {
      "epoch": 0.48258868717614234,
      "grad_norm": 0.428897887468338,
      "learning_rate": 0.00010350025364156823,
      "loss": 0.0695,
      "step": 6659
    },
    {
      "epoch": 0.48266115882161104,
      "grad_norm": 3.7227072715759277,
      "learning_rate": 0.00010348575983766939,
      "loss": 0.0618,
      "step": 6660
    },
    {
      "epoch": 0.48273363046707973,
      "grad_norm": 2.2779691219329834,
      "learning_rate": 0.00010347126603377057,
      "loss": 0.0495,
      "step": 6661
    },
    {
      "epoch": 0.4828061021125485,
      "grad_norm": 1.2436697483062744,
      "learning_rate": 0.00010345677222987173,
      "loss": 0.0602,
      "step": 6662
    },
    {
      "epoch": 0.4828785737580172,
      "grad_norm": 2.141540050506592,
      "learning_rate": 0.0001034422784259729,
      "loss": 0.1079,
      "step": 6663
    },
    {
      "epoch": 0.4829510454034859,
      "grad_norm": 1.4595561027526855,
      "learning_rate": 0.00010342778462207407,
      "loss": 0.0392,
      "step": 6664
    },
    {
      "epoch": 0.4830235170489546,
      "grad_norm": 2.6664388179779053,
      "learning_rate": 0.00010341329081817524,
      "loss": 0.0797,
      "step": 6665
    },
    {
      "epoch": 0.48309598869442333,
      "grad_norm": 0.5573366284370422,
      "learning_rate": 0.0001033987970142764,
      "loss": 0.0249,
      "step": 6666
    },
    {
      "epoch": 0.483168460339892,
      "grad_norm": 1.7657370567321777,
      "learning_rate": 0.00010338430321037758,
      "loss": 0.0977,
      "step": 6667
    },
    {
      "epoch": 0.4832409319853607,
      "grad_norm": 1.0499789714813232,
      "learning_rate": 0.00010336980940647874,
      "loss": 0.0732,
      "step": 6668
    },
    {
      "epoch": 0.4833134036308294,
      "grad_norm": 2.1931426525115967,
      "learning_rate": 0.00010335531560257989,
      "loss": 0.0995,
      "step": 6669
    },
    {
      "epoch": 0.48338587527629817,
      "grad_norm": 1.356662392616272,
      "learning_rate": 0.00010334082179868108,
      "loss": 0.027,
      "step": 6670
    },
    {
      "epoch": 0.48345834692176687,
      "grad_norm": 1.7006064653396606,
      "learning_rate": 0.00010332632799478223,
      "loss": 0.0312,
      "step": 6671
    },
    {
      "epoch": 0.48353081856723557,
      "grad_norm": 9.205215454101562,
      "learning_rate": 0.00010331183419088339,
      "loss": 0.1843,
      "step": 6672
    },
    {
      "epoch": 0.48360329021270426,
      "grad_norm": 3.8677096366882324,
      "learning_rate": 0.00010329734038698457,
      "loss": 0.0934,
      "step": 6673
    },
    {
      "epoch": 0.483675761858173,
      "grad_norm": 0.7175815105438232,
      "learning_rate": 0.00010328284658308573,
      "loss": 0.0445,
      "step": 6674
    },
    {
      "epoch": 0.4837482335036417,
      "grad_norm": 4.269176006317139,
      "learning_rate": 0.0001032683527791869,
      "loss": 0.1575,
      "step": 6675
    },
    {
      "epoch": 0.4838207051491104,
      "grad_norm": 3.126986265182495,
      "learning_rate": 0.00010325385897528807,
      "loss": 0.1915,
      "step": 6676
    },
    {
      "epoch": 0.4838931767945791,
      "grad_norm": 1.2726508378982544,
      "learning_rate": 0.00010323936517138924,
      "loss": 0.1056,
      "step": 6677
    },
    {
      "epoch": 0.48396564844004786,
      "grad_norm": 0.9992685317993164,
      "learning_rate": 0.0001032248713674904,
      "loss": 0.0463,
      "step": 6678
    },
    {
      "epoch": 0.48403812008551655,
      "grad_norm": 1.5704658031463623,
      "learning_rate": 0.00010321037756359158,
      "loss": 0.032,
      "step": 6679
    },
    {
      "epoch": 0.48411059173098525,
      "grad_norm": 1.710427165031433,
      "learning_rate": 0.00010319588375969274,
      "loss": 0.086,
      "step": 6680
    },
    {
      "epoch": 0.48418306337645395,
      "grad_norm": 0.7946102619171143,
      "learning_rate": 0.00010318138995579389,
      "loss": 0.0689,
      "step": 6681
    },
    {
      "epoch": 0.48425553502192265,
      "grad_norm": 0.9739460349082947,
      "learning_rate": 0.00010316689615189508,
      "loss": 0.0319,
      "step": 6682
    },
    {
      "epoch": 0.4843280066673914,
      "grad_norm": 1.2370269298553467,
      "learning_rate": 0.00010315240234799623,
      "loss": 0.0755,
      "step": 6683
    },
    {
      "epoch": 0.4844004783128601,
      "grad_norm": 1.282208800315857,
      "learning_rate": 0.00010313790854409739,
      "loss": 0.0521,
      "step": 6684
    },
    {
      "epoch": 0.4844729499583288,
      "grad_norm": 5.492347717285156,
      "learning_rate": 0.00010312341474019857,
      "loss": 0.0949,
      "step": 6685
    },
    {
      "epoch": 0.4845454216037975,
      "grad_norm": 0.5598483085632324,
      "learning_rate": 0.00010310892093629973,
      "loss": 0.024,
      "step": 6686
    },
    {
      "epoch": 0.48461789324926624,
      "grad_norm": 3.5491139888763428,
      "learning_rate": 0.0001030944271324009,
      "loss": 0.0313,
      "step": 6687
    },
    {
      "epoch": 0.48469036489473494,
      "grad_norm": 0.48832565546035767,
      "learning_rate": 0.00010307993332850207,
      "loss": 0.0072,
      "step": 6688
    },
    {
      "epoch": 0.48476283654020363,
      "grad_norm": 0.8886464238166809,
      "learning_rate": 0.00010306543952460324,
      "loss": 0.0704,
      "step": 6689
    },
    {
      "epoch": 0.48483530818567233,
      "grad_norm": 0.4573095440864563,
      "learning_rate": 0.0001030509457207044,
      "loss": 0.0078,
      "step": 6690
    },
    {
      "epoch": 0.4849077798311411,
      "grad_norm": 3.114452838897705,
      "learning_rate": 0.00010303645191680558,
      "loss": 0.0547,
      "step": 6691
    },
    {
      "epoch": 0.4849802514766098,
      "grad_norm": 4.2242655754089355,
      "learning_rate": 0.00010302195811290674,
      "loss": 0.2207,
      "step": 6692
    },
    {
      "epoch": 0.4850527231220785,
      "grad_norm": 1.4107046127319336,
      "learning_rate": 0.00010300746430900789,
      "loss": 0.0373,
      "step": 6693
    },
    {
      "epoch": 0.4851251947675472,
      "grad_norm": 4.759146213531494,
      "learning_rate": 0.00010299297050510908,
      "loss": 0.0943,
      "step": 6694
    },
    {
      "epoch": 0.4851976664130159,
      "grad_norm": 2.0664496421813965,
      "learning_rate": 0.00010297847670121023,
      "loss": 0.0914,
      "step": 6695
    },
    {
      "epoch": 0.4852701380584846,
      "grad_norm": 2.2645468711853027,
      "learning_rate": 0.00010296398289731139,
      "loss": 0.1335,
      "step": 6696
    },
    {
      "epoch": 0.4853426097039533,
      "grad_norm": 1.0223993062973022,
      "learning_rate": 0.00010294948909341257,
      "loss": 0.0414,
      "step": 6697
    },
    {
      "epoch": 0.485415081349422,
      "grad_norm": 8.024949073791504,
      "learning_rate": 0.00010293499528951373,
      "loss": 0.2188,
      "step": 6698
    },
    {
      "epoch": 0.48548755299489077,
      "grad_norm": 3.010737657546997,
      "learning_rate": 0.0001029205014856149,
      "loss": 0.0693,
      "step": 6699
    },
    {
      "epoch": 0.48556002464035947,
      "grad_norm": 1.7254712581634521,
      "learning_rate": 0.00010290600768171608,
      "loss": 0.0546,
      "step": 6700
    },
    {
      "epoch": 0.48563249628582816,
      "grad_norm": 1.3775008916854858,
      "learning_rate": 0.00010289151387781724,
      "loss": 0.0535,
      "step": 6701
    },
    {
      "epoch": 0.48570496793129686,
      "grad_norm": 0.5557657480239868,
      "learning_rate": 0.0001028770200739184,
      "loss": 0.0334,
      "step": 6702
    },
    {
      "epoch": 0.4857774395767656,
      "grad_norm": 1.718724012374878,
      "learning_rate": 0.00010286252627001958,
      "loss": 0.1321,
      "step": 6703
    },
    {
      "epoch": 0.4858499112222343,
      "grad_norm": 1.5748125314712524,
      "learning_rate": 0.00010284803246612074,
      "loss": 0.1376,
      "step": 6704
    },
    {
      "epoch": 0.485922382867703,
      "grad_norm": 0.25687873363494873,
      "learning_rate": 0.00010283353866222189,
      "loss": 0.009,
      "step": 6705
    },
    {
      "epoch": 0.4859948545131717,
      "grad_norm": 2.224337339401245,
      "learning_rate": 0.00010281904485832308,
      "loss": 0.0708,
      "step": 6706
    },
    {
      "epoch": 0.48606732615864046,
      "grad_norm": 0.9722204208374023,
      "learning_rate": 0.00010280455105442423,
      "loss": 0.0445,
      "step": 6707
    },
    {
      "epoch": 0.48613979780410915,
      "grad_norm": 0.5307363867759705,
      "learning_rate": 0.00010279005725052539,
      "loss": 0.0135,
      "step": 6708
    },
    {
      "epoch": 0.48621226944957785,
      "grad_norm": 0.9448790550231934,
      "learning_rate": 0.00010277556344662657,
      "loss": 0.058,
      "step": 6709
    },
    {
      "epoch": 0.48628474109504655,
      "grad_norm": 1.7536706924438477,
      "learning_rate": 0.00010276106964272774,
      "loss": 0.0934,
      "step": 6710
    },
    {
      "epoch": 0.4863572127405153,
      "grad_norm": 1.030403733253479,
      "learning_rate": 0.0001027465758388289,
      "loss": 0.0874,
      "step": 6711
    },
    {
      "epoch": 0.486429684385984,
      "grad_norm": 1.806799054145813,
      "learning_rate": 0.00010273208203493008,
      "loss": 0.1146,
      "step": 6712
    },
    {
      "epoch": 0.4865021560314527,
      "grad_norm": 0.5994672775268555,
      "learning_rate": 0.00010271758823103124,
      "loss": 0.0351,
      "step": 6713
    },
    {
      "epoch": 0.4865746276769214,
      "grad_norm": 0.9097591042518616,
      "learning_rate": 0.0001027030944271324,
      "loss": 0.0303,
      "step": 6714
    },
    {
      "epoch": 0.48664709932239014,
      "grad_norm": 0.6673910021781921,
      "learning_rate": 0.00010268860062323358,
      "loss": 0.0175,
      "step": 6715
    },
    {
      "epoch": 0.48671957096785884,
      "grad_norm": 0.5036755204200745,
      "learning_rate": 0.00010267410681933474,
      "loss": 0.0213,
      "step": 6716
    },
    {
      "epoch": 0.48679204261332754,
      "grad_norm": 1.7773414850234985,
      "learning_rate": 0.00010265961301543589,
      "loss": 0.0587,
      "step": 6717
    },
    {
      "epoch": 0.48686451425879623,
      "grad_norm": 0.5154566168785095,
      "learning_rate": 0.00010264511921153708,
      "loss": 0.041,
      "step": 6718
    },
    {
      "epoch": 0.48693698590426493,
      "grad_norm": 0.710469663143158,
      "learning_rate": 0.00010263062540763823,
      "loss": 0.0287,
      "step": 6719
    },
    {
      "epoch": 0.4870094575497337,
      "grad_norm": 0.8377621173858643,
      "learning_rate": 0.0001026161316037394,
      "loss": 0.0398,
      "step": 6720
    },
    {
      "epoch": 0.4870819291952024,
      "grad_norm": 2.1775877475738525,
      "learning_rate": 0.00010260163779984057,
      "loss": 0.0485,
      "step": 6721
    },
    {
      "epoch": 0.4871544008406711,
      "grad_norm": 0.9161426424980164,
      "learning_rate": 0.00010258714399594174,
      "loss": 0.0348,
      "step": 6722
    },
    {
      "epoch": 0.4872268724861398,
      "grad_norm": 0.3317350745201111,
      "learning_rate": 0.0001025726501920429,
      "loss": 0.012,
      "step": 6723
    },
    {
      "epoch": 0.4872993441316085,
      "grad_norm": 0.05835123360157013,
      "learning_rate": 0.00010255815638814408,
      "loss": 0.0013,
      "step": 6724
    },
    {
      "epoch": 0.4873718157770772,
      "grad_norm": 1.0094645023345947,
      "learning_rate": 0.00010254366258424524,
      "loss": 0.0239,
      "step": 6725
    },
    {
      "epoch": 0.4874442874225459,
      "grad_norm": 2.2073493003845215,
      "learning_rate": 0.0001025291687803464,
      "loss": 0.1226,
      "step": 6726
    },
    {
      "epoch": 0.4875167590680146,
      "grad_norm": 1.0295523405075073,
      "learning_rate": 0.00010251467497644758,
      "loss": 0.0584,
      "step": 6727
    },
    {
      "epoch": 0.48758923071348337,
      "grad_norm": 2.1084275245666504,
      "learning_rate": 0.00010250018117254874,
      "loss": 0.0732,
      "step": 6728
    },
    {
      "epoch": 0.48766170235895206,
      "grad_norm": 2.9355216026306152,
      "learning_rate": 0.00010248568736864989,
      "loss": 0.1161,
      "step": 6729
    },
    {
      "epoch": 0.48773417400442076,
      "grad_norm": 0.6169402003288269,
      "learning_rate": 0.00010247119356475108,
      "loss": 0.0109,
      "step": 6730
    },
    {
      "epoch": 0.48780664564988946,
      "grad_norm": 2.0006113052368164,
      "learning_rate": 0.00010245669976085223,
      "loss": 0.0683,
      "step": 6731
    },
    {
      "epoch": 0.4878791172953582,
      "grad_norm": 0.9450214505195618,
      "learning_rate": 0.0001024422059569534,
      "loss": 0.0341,
      "step": 6732
    },
    {
      "epoch": 0.4879515889408269,
      "grad_norm": 1.1140503883361816,
      "learning_rate": 0.00010242771215305457,
      "loss": 0.068,
      "step": 6733
    },
    {
      "epoch": 0.4880240605862956,
      "grad_norm": 1.0628374814987183,
      "learning_rate": 0.00010241321834915574,
      "loss": 0.0306,
      "step": 6734
    },
    {
      "epoch": 0.4880965322317643,
      "grad_norm": 0.6783627271652222,
      "learning_rate": 0.0001023987245452569,
      "loss": 0.0066,
      "step": 6735
    },
    {
      "epoch": 0.48816900387723305,
      "grad_norm": 1.088708519935608,
      "learning_rate": 0.00010238423074135808,
      "loss": 0.0411,
      "step": 6736
    },
    {
      "epoch": 0.48824147552270175,
      "grad_norm": 3.7635750770568848,
      "learning_rate": 0.00010236973693745924,
      "loss": 0.0402,
      "step": 6737
    },
    {
      "epoch": 0.48831394716817045,
      "grad_norm": 2.057401418685913,
      "learning_rate": 0.0001023552431335604,
      "loss": 0.0635,
      "step": 6738
    },
    {
      "epoch": 0.48838641881363914,
      "grad_norm": 0.6671409010887146,
      "learning_rate": 0.00010234074932966158,
      "loss": 0.0375,
      "step": 6739
    },
    {
      "epoch": 0.4884588904591079,
      "grad_norm": 0.9495929479598999,
      "learning_rate": 0.00010232625552576274,
      "loss": 0.0565,
      "step": 6740
    },
    {
      "epoch": 0.4885313621045766,
      "grad_norm": 3.3946566581726074,
      "learning_rate": 0.00010231176172186392,
      "loss": 0.2205,
      "step": 6741
    },
    {
      "epoch": 0.4886038337500453,
      "grad_norm": 2.182270050048828,
      "learning_rate": 0.00010229726791796508,
      "loss": 0.082,
      "step": 6742
    },
    {
      "epoch": 0.488676305395514,
      "grad_norm": 1.7910500764846802,
      "learning_rate": 0.00010228277411406623,
      "loss": 0.0969,
      "step": 6743
    },
    {
      "epoch": 0.48874877704098274,
      "grad_norm": 1.0641252994537354,
      "learning_rate": 0.00010226828031016742,
      "loss": 0.0332,
      "step": 6744
    },
    {
      "epoch": 0.48882124868645144,
      "grad_norm": 0.8004282712936401,
      "learning_rate": 0.00010225378650626857,
      "loss": 0.0202,
      "step": 6745
    },
    {
      "epoch": 0.48889372033192013,
      "grad_norm": 0.7887818217277527,
      "learning_rate": 0.00010223929270236974,
      "loss": 0.015,
      "step": 6746
    },
    {
      "epoch": 0.48896619197738883,
      "grad_norm": 0.9193359017372131,
      "learning_rate": 0.00010222479889847093,
      "loss": 0.0296,
      "step": 6747
    },
    {
      "epoch": 0.4890386636228576,
      "grad_norm": 0.9743654727935791,
      "learning_rate": 0.00010221030509457208,
      "loss": 0.0433,
      "step": 6748
    },
    {
      "epoch": 0.4891111352683263,
      "grad_norm": 1.7186884880065918,
      "learning_rate": 0.00010219581129067324,
      "loss": 0.0743,
      "step": 6749
    },
    {
      "epoch": 0.489183606913795,
      "grad_norm": 2.8362441062927246,
      "learning_rate": 0.00010218131748677442,
      "loss": 0.0983,
      "step": 6750
    },
    {
      "epoch": 0.4892560785592637,
      "grad_norm": 0.5932912826538086,
      "learning_rate": 0.00010216682368287558,
      "loss": 0.0379,
      "step": 6751
    },
    {
      "epoch": 0.48932855020473237,
      "grad_norm": 2.512152671813965,
      "learning_rate": 0.00010215232987897674,
      "loss": 0.1106,
      "step": 6752
    },
    {
      "epoch": 0.4894010218502011,
      "grad_norm": 1.3675895929336548,
      "learning_rate": 0.00010213783607507792,
      "loss": 0.0989,
      "step": 6753
    },
    {
      "epoch": 0.4894734934956698,
      "grad_norm": 2.8221678733825684,
      "learning_rate": 0.00010212334227117908,
      "loss": 0.1264,
      "step": 6754
    },
    {
      "epoch": 0.4895459651411385,
      "grad_norm": 1.488832712173462,
      "learning_rate": 0.00010210884846728023,
      "loss": 0.0795,
      "step": 6755
    },
    {
      "epoch": 0.4896184367866072,
      "grad_norm": 1.8749982118606567,
      "learning_rate": 0.00010209435466338142,
      "loss": 0.0823,
      "step": 6756
    },
    {
      "epoch": 0.48969090843207597,
      "grad_norm": 1.8536604642868042,
      "learning_rate": 0.00010207986085948259,
      "loss": 0.1211,
      "step": 6757
    },
    {
      "epoch": 0.48976338007754466,
      "grad_norm": 1.5245976448059082,
      "learning_rate": 0.00010206536705558374,
      "loss": 0.0498,
      "step": 6758
    },
    {
      "epoch": 0.48983585172301336,
      "grad_norm": 0.6613232493400574,
      "learning_rate": 0.00010205087325168493,
      "loss": 0.03,
      "step": 6759
    },
    {
      "epoch": 0.48990832336848206,
      "grad_norm": 1.2691218852996826,
      "learning_rate": 0.00010203637944778608,
      "loss": 0.0473,
      "step": 6760
    },
    {
      "epoch": 0.4899807950139508,
      "grad_norm": 2.8621253967285156,
      "learning_rate": 0.00010202188564388724,
      "loss": 0.1275,
      "step": 6761
    },
    {
      "epoch": 0.4900532666594195,
      "grad_norm": 1.0830549001693726,
      "learning_rate": 0.00010200739183998842,
      "loss": 0.0724,
      "step": 6762
    },
    {
      "epoch": 0.4901257383048882,
      "grad_norm": 1.3331146240234375,
      "learning_rate": 0.00010199289803608958,
      "loss": 0.0287,
      "step": 6763
    },
    {
      "epoch": 0.4901982099503569,
      "grad_norm": 1.1890733242034912,
      "learning_rate": 0.00010197840423219074,
      "loss": 0.0646,
      "step": 6764
    },
    {
      "epoch": 0.49027068159582565,
      "grad_norm": 2.9617812633514404,
      "learning_rate": 0.00010196391042829192,
      "loss": 0.094,
      "step": 6765
    },
    {
      "epoch": 0.49034315324129435,
      "grad_norm": 0.9351149797439575,
      "learning_rate": 0.00010194941662439308,
      "loss": 0.0383,
      "step": 6766
    },
    {
      "epoch": 0.49041562488676305,
      "grad_norm": 1.3038129806518555,
      "learning_rate": 0.00010193492282049425,
      "loss": 0.0682,
      "step": 6767
    },
    {
      "epoch": 0.49048809653223174,
      "grad_norm": 0.9389483332633972,
      "learning_rate": 0.00010192042901659542,
      "loss": 0.0518,
      "step": 6768
    },
    {
      "epoch": 0.4905605681777005,
      "grad_norm": 0.9090145230293274,
      "learning_rate": 0.00010190593521269659,
      "loss": 0.0361,
      "step": 6769
    },
    {
      "epoch": 0.4906330398231692,
      "grad_norm": 1.72086763381958,
      "learning_rate": 0.00010189144140879774,
      "loss": 0.1423,
      "step": 6770
    },
    {
      "epoch": 0.4907055114686379,
      "grad_norm": 1.5795692205429077,
      "learning_rate": 0.00010187694760489893,
      "loss": 0.0684,
      "step": 6771
    },
    {
      "epoch": 0.4907779831141066,
      "grad_norm": 0.4739444851875305,
      "learning_rate": 0.00010186245380100008,
      "loss": 0.0377,
      "step": 6772
    },
    {
      "epoch": 0.49085045475957534,
      "grad_norm": 1.3003222942352295,
      "learning_rate": 0.00010184795999710124,
      "loss": 0.0332,
      "step": 6773
    },
    {
      "epoch": 0.49092292640504404,
      "grad_norm": 1.2496079206466675,
      "learning_rate": 0.00010183346619320242,
      "loss": 0.0482,
      "step": 6774
    },
    {
      "epoch": 0.49099539805051273,
      "grad_norm": 0.7683574557304382,
      "learning_rate": 0.00010181897238930358,
      "loss": 0.0461,
      "step": 6775
    },
    {
      "epoch": 0.49106786969598143,
      "grad_norm": 0.4783645570278168,
      "learning_rate": 0.00010180447858540473,
      "loss": 0.0131,
      "step": 6776
    },
    {
      "epoch": 0.4911403413414502,
      "grad_norm": 1.4034526348114014,
      "learning_rate": 0.00010178998478150592,
      "loss": 0.0944,
      "step": 6777
    },
    {
      "epoch": 0.4912128129869189,
      "grad_norm": 3.1655447483062744,
      "learning_rate": 0.00010177549097760707,
      "loss": 0.1587,
      "step": 6778
    },
    {
      "epoch": 0.4912852846323876,
      "grad_norm": 1.1394070386886597,
      "learning_rate": 0.00010176099717370825,
      "loss": 0.0578,
      "step": 6779
    },
    {
      "epoch": 0.4913577562778563,
      "grad_norm": 1.323278546333313,
      "learning_rate": 0.00010174650336980942,
      "loss": 0.0569,
      "step": 6780
    },
    {
      "epoch": 0.491430227923325,
      "grad_norm": 2.3402929306030273,
      "learning_rate": 0.00010173200956591059,
      "loss": 0.1196,
      "step": 6781
    },
    {
      "epoch": 0.4915026995687937,
      "grad_norm": 0.40943068265914917,
      "learning_rate": 0.00010171751576201174,
      "loss": 0.0254,
      "step": 6782
    },
    {
      "epoch": 0.4915751712142624,
      "grad_norm": 1.3323770761489868,
      "learning_rate": 0.00010170302195811293,
      "loss": 0.0511,
      "step": 6783
    },
    {
      "epoch": 0.4916476428597311,
      "grad_norm": 2.402996301651001,
      "learning_rate": 0.00010168852815421408,
      "loss": 0.0259,
      "step": 6784
    },
    {
      "epoch": 0.49172011450519987,
      "grad_norm": 1.5884207487106323,
      "learning_rate": 0.00010167403435031524,
      "loss": 0.0913,
      "step": 6785
    },
    {
      "epoch": 0.49179258615066856,
      "grad_norm": 1.1215026378631592,
      "learning_rate": 0.00010165954054641642,
      "loss": 0.0266,
      "step": 6786
    },
    {
      "epoch": 0.49186505779613726,
      "grad_norm": 1.2150851488113403,
      "learning_rate": 0.00010164504674251758,
      "loss": 0.0254,
      "step": 6787
    },
    {
      "epoch": 0.49193752944160596,
      "grad_norm": 3.165933609008789,
      "learning_rate": 0.00010163055293861873,
      "loss": 0.1079,
      "step": 6788
    },
    {
      "epoch": 0.49201000108707466,
      "grad_norm": 1.0853159427642822,
      "learning_rate": 0.00010161605913471992,
      "loss": 0.0307,
      "step": 6789
    },
    {
      "epoch": 0.4920824727325434,
      "grad_norm": 0.7167274951934814,
      "learning_rate": 0.00010160156533082107,
      "loss": 0.0722,
      "step": 6790
    },
    {
      "epoch": 0.4921549443780121,
      "grad_norm": 3.162299633026123,
      "learning_rate": 0.00010158707152692224,
      "loss": 0.0589,
      "step": 6791
    },
    {
      "epoch": 0.4922274160234808,
      "grad_norm": 1.5861694812774658,
      "learning_rate": 0.00010157257772302341,
      "loss": 0.0786,
      "step": 6792
    },
    {
      "epoch": 0.4922998876689495,
      "grad_norm": 0.9840179681777954,
      "learning_rate": 0.00010155808391912458,
      "loss": 0.0276,
      "step": 6793
    },
    {
      "epoch": 0.49237235931441825,
      "grad_norm": 2.384878396987915,
      "learning_rate": 0.00010154359011522574,
      "loss": 0.092,
      "step": 6794
    },
    {
      "epoch": 0.49244483095988695,
      "grad_norm": 0.7291162014007568,
      "learning_rate": 0.00010152909631132692,
      "loss": 0.0549,
      "step": 6795
    },
    {
      "epoch": 0.49251730260535564,
      "grad_norm": 0.30955782532691956,
      "learning_rate": 0.00010151460250742808,
      "loss": 0.0082,
      "step": 6796
    },
    {
      "epoch": 0.49258977425082434,
      "grad_norm": 1.5796072483062744,
      "learning_rate": 0.00010150010870352924,
      "loss": 0.0525,
      "step": 6797
    },
    {
      "epoch": 0.4926622458962931,
      "grad_norm": 1.4185879230499268,
      "learning_rate": 0.00010148561489963042,
      "loss": 0.1201,
      "step": 6798
    },
    {
      "epoch": 0.4927347175417618,
      "grad_norm": 2.3704895973205566,
      "learning_rate": 0.00010147112109573158,
      "loss": 0.1017,
      "step": 6799
    },
    {
      "epoch": 0.4928071891872305,
      "grad_norm": 0.7167389392852783,
      "learning_rate": 0.00010145662729183273,
      "loss": 0.0757,
      "step": 6800
    },
    {
      "epoch": 0.4928796608326992,
      "grad_norm": 0.5779552459716797,
      "learning_rate": 0.00010144213348793392,
      "loss": 0.0098,
      "step": 6801
    },
    {
      "epoch": 0.49295213247816794,
      "grad_norm": 2.23083758354187,
      "learning_rate": 0.00010142763968403507,
      "loss": 0.151,
      "step": 6802
    },
    {
      "epoch": 0.49302460412363663,
      "grad_norm": 5.129293918609619,
      "learning_rate": 0.00010141314588013624,
      "loss": 0.1894,
      "step": 6803
    },
    {
      "epoch": 0.49309707576910533,
      "grad_norm": 0.651496946811676,
      "learning_rate": 0.00010139865207623743,
      "loss": 0.0178,
      "step": 6804
    },
    {
      "epoch": 0.493169547414574,
      "grad_norm": 1.0126855373382568,
      "learning_rate": 0.00010138415827233858,
      "loss": 0.0902,
      "step": 6805
    },
    {
      "epoch": 0.4932420190600428,
      "grad_norm": 2.419661283493042,
      "learning_rate": 0.00010136966446843974,
      "loss": 0.0403,
      "step": 6806
    },
    {
      "epoch": 0.4933144907055115,
      "grad_norm": 3.3207733631134033,
      "learning_rate": 0.00010135517066454092,
      "loss": 0.0641,
      "step": 6807
    },
    {
      "epoch": 0.4933869623509802,
      "grad_norm": 0.7455012798309326,
      "learning_rate": 0.00010134067686064208,
      "loss": 0.0248,
      "step": 6808
    },
    {
      "epoch": 0.49345943399644887,
      "grad_norm": 1.1087039709091187,
      "learning_rate": 0.00010132618305674324,
      "loss": 0.0539,
      "step": 6809
    },
    {
      "epoch": 0.4935319056419176,
      "grad_norm": 4.386135101318359,
      "learning_rate": 0.00010131168925284442,
      "loss": 0.1161,
      "step": 6810
    },
    {
      "epoch": 0.4936043772873863,
      "grad_norm": 2.5941050052642822,
      "learning_rate": 0.00010129719544894558,
      "loss": 0.1393,
      "step": 6811
    },
    {
      "epoch": 0.493676848932855,
      "grad_norm": 1.6451741456985474,
      "learning_rate": 0.00010128270164504673,
      "loss": 0.0817,
      "step": 6812
    },
    {
      "epoch": 0.4937493205783237,
      "grad_norm": 1.335519790649414,
      "learning_rate": 0.00010126820784114792,
      "loss": 0.0608,
      "step": 6813
    },
    {
      "epoch": 0.49382179222379247,
      "grad_norm": 1.188437819480896,
      "learning_rate": 0.00010125371403724907,
      "loss": 0.0256,
      "step": 6814
    },
    {
      "epoch": 0.49389426386926116,
      "grad_norm": 1.095361590385437,
      "learning_rate": 0.00010123922023335024,
      "loss": 0.025,
      "step": 6815
    },
    {
      "epoch": 0.49396673551472986,
      "grad_norm": 1.8686422109603882,
      "learning_rate": 0.00010122472642945143,
      "loss": 0.0489,
      "step": 6816
    },
    {
      "epoch": 0.49403920716019856,
      "grad_norm": 1.0050277709960938,
      "learning_rate": 0.00010121023262555258,
      "loss": 0.051,
      "step": 6817
    },
    {
      "epoch": 0.4941116788056673,
      "grad_norm": 1.431282639503479,
      "learning_rate": 0.00010119573882165374,
      "loss": 0.0786,
      "step": 6818
    },
    {
      "epoch": 0.494184150451136,
      "grad_norm": 0.48353561758995056,
      "learning_rate": 0.00010118124501775492,
      "loss": 0.0094,
      "step": 6819
    },
    {
      "epoch": 0.4942566220966047,
      "grad_norm": 1.4907866716384888,
      "learning_rate": 0.00010116675121385608,
      "loss": 0.1169,
      "step": 6820
    },
    {
      "epoch": 0.4943290937420734,
      "grad_norm": 0.9211298823356628,
      "learning_rate": 0.00010115225740995724,
      "loss": 0.0342,
      "step": 6821
    },
    {
      "epoch": 0.4944015653875421,
      "grad_norm": 0.9516976475715637,
      "learning_rate": 0.00010113776360605842,
      "loss": 0.0304,
      "step": 6822
    },
    {
      "epoch": 0.49447403703301085,
      "grad_norm": 1.403887391090393,
      "learning_rate": 0.00010112326980215958,
      "loss": 0.0357,
      "step": 6823
    },
    {
      "epoch": 0.49454650867847955,
      "grad_norm": 2.2058820724487305,
      "learning_rate": 0.00010110877599826073,
      "loss": 0.0491,
      "step": 6824
    },
    {
      "epoch": 0.49461898032394824,
      "grad_norm": 0.308439701795578,
      "learning_rate": 0.00010109428219436192,
      "loss": 0.0157,
      "step": 6825
    },
    {
      "epoch": 0.49469145196941694,
      "grad_norm": 1.035375714302063,
      "learning_rate": 0.00010107978839046309,
      "loss": 0.0421,
      "step": 6826
    },
    {
      "epoch": 0.4947639236148857,
      "grad_norm": 0.8079494833946228,
      "learning_rate": 0.00010106529458656424,
      "loss": 0.044,
      "step": 6827
    },
    {
      "epoch": 0.4948363952603544,
      "grad_norm": 1.5111855268478394,
      "learning_rate": 0.00010105080078266543,
      "loss": 0.0316,
      "step": 6828
    },
    {
      "epoch": 0.4949088669058231,
      "grad_norm": 1.5934865474700928,
      "learning_rate": 0.00010103630697876658,
      "loss": 0.0217,
      "step": 6829
    },
    {
      "epoch": 0.4949813385512918,
      "grad_norm": 1.9785311222076416,
      "learning_rate": 0.00010102181317486774,
      "loss": 0.0584,
      "step": 6830
    },
    {
      "epoch": 0.49505381019676054,
      "grad_norm": 1.3473488092422485,
      "learning_rate": 0.00010100731937096892,
      "loss": 0.0511,
      "step": 6831
    },
    {
      "epoch": 0.49512628184222923,
      "grad_norm": 0.6735839247703552,
      "learning_rate": 0.00010099282556707008,
      "loss": 0.0327,
      "step": 6832
    },
    {
      "epoch": 0.49519875348769793,
      "grad_norm": 2.6367244720458984,
      "learning_rate": 0.00010097833176317124,
      "loss": 0.1501,
      "step": 6833
    },
    {
      "epoch": 0.4952712251331666,
      "grad_norm": 2.223059892654419,
      "learning_rate": 0.00010096383795927242,
      "loss": 0.0734,
      "step": 6834
    },
    {
      "epoch": 0.4953436967786354,
      "grad_norm": 1.7558214664459229,
      "learning_rate": 0.00010094934415537358,
      "loss": 0.0737,
      "step": 6835
    },
    {
      "epoch": 0.4954161684241041,
      "grad_norm": 3.1829330921173096,
      "learning_rate": 0.00010093485035147475,
      "loss": 0.0929,
      "step": 6836
    },
    {
      "epoch": 0.49548864006957277,
      "grad_norm": 2.3006646633148193,
      "learning_rate": 0.00010092035654757592,
      "loss": 0.03,
      "step": 6837
    },
    {
      "epoch": 0.49556111171504147,
      "grad_norm": 3.89412522315979,
      "learning_rate": 0.00010090586274367709,
      "loss": 0.1546,
      "step": 6838
    },
    {
      "epoch": 0.4956335833605102,
      "grad_norm": 0.5556145310401917,
      "learning_rate": 0.00010089136893977824,
      "loss": 0.0365,
      "step": 6839
    },
    {
      "epoch": 0.4957060550059789,
      "grad_norm": 1.7255724668502808,
      "learning_rate": 0.00010087687513587943,
      "loss": 0.0845,
      "step": 6840
    },
    {
      "epoch": 0.4957785266514476,
      "grad_norm": 1.7111762762069702,
      "learning_rate": 0.00010086238133198058,
      "loss": 0.1009,
      "step": 6841
    },
    {
      "epoch": 0.4958509982969163,
      "grad_norm": 2.294738292694092,
      "learning_rate": 0.00010084788752808174,
      "loss": 0.1027,
      "step": 6842
    },
    {
      "epoch": 0.49592346994238506,
      "grad_norm": 3.4712045192718506,
      "learning_rate": 0.00010083339372418292,
      "loss": 0.1756,
      "step": 6843
    },
    {
      "epoch": 0.49599594158785376,
      "grad_norm": 2.5232813358306885,
      "learning_rate": 0.00010081889992028408,
      "loss": 0.0525,
      "step": 6844
    },
    {
      "epoch": 0.49606841323332246,
      "grad_norm": 0.9360592365264893,
      "learning_rate": 0.00010080440611638524,
      "loss": 0.0309,
      "step": 6845
    },
    {
      "epoch": 0.49614088487879116,
      "grad_norm": 1.1861350536346436,
      "learning_rate": 0.00010078991231248642,
      "loss": 0.0459,
      "step": 6846
    },
    {
      "epoch": 0.4962133565242599,
      "grad_norm": 2.420830726623535,
      "learning_rate": 0.00010077541850858758,
      "loss": 0.0674,
      "step": 6847
    },
    {
      "epoch": 0.4962858281697286,
      "grad_norm": 1.0266324281692505,
      "learning_rate": 0.00010076092470468875,
      "loss": 0.1019,
      "step": 6848
    },
    {
      "epoch": 0.4963582998151973,
      "grad_norm": 1.0147005319595337,
      "learning_rate": 0.00010074643090078992,
      "loss": 0.0314,
      "step": 6849
    },
    {
      "epoch": 0.496430771460666,
      "grad_norm": 1.3857539892196655,
      "learning_rate": 0.00010073193709689109,
      "loss": 0.1072,
      "step": 6850
    },
    {
      "epoch": 0.49650324310613475,
      "grad_norm": 0.36085546016693115,
      "learning_rate": 0.00010071744329299224,
      "loss": 0.0121,
      "step": 6851
    },
    {
      "epoch": 0.49657571475160345,
      "grad_norm": 1.726372241973877,
      "learning_rate": 0.00010070294948909343,
      "loss": 0.0743,
      "step": 6852
    },
    {
      "epoch": 0.49664818639707214,
      "grad_norm": 0.79457026720047,
      "learning_rate": 0.00010068845568519458,
      "loss": 0.0613,
      "step": 6853
    },
    {
      "epoch": 0.49672065804254084,
      "grad_norm": 0.9090813398361206,
      "learning_rate": 0.00010067396188129574,
      "loss": 0.0382,
      "step": 6854
    },
    {
      "epoch": 0.4967931296880096,
      "grad_norm": 3.3275413513183594,
      "learning_rate": 0.00010065946807739692,
      "loss": 0.0519,
      "step": 6855
    },
    {
      "epoch": 0.4968656013334783,
      "grad_norm": 1.770938754081726,
      "learning_rate": 0.00010064497427349808,
      "loss": 0.1308,
      "step": 6856
    },
    {
      "epoch": 0.496938072978947,
      "grad_norm": 0.9013294577598572,
      "learning_rate": 0.00010063048046959924,
      "loss": 0.0277,
      "step": 6857
    },
    {
      "epoch": 0.4970105446244157,
      "grad_norm": 0.7084078788757324,
      "learning_rate": 0.00010061598666570042,
      "loss": 0.0076,
      "step": 6858
    },
    {
      "epoch": 0.4970830162698844,
      "grad_norm": 0.6917394995689392,
      "learning_rate": 0.00010060149286180158,
      "loss": 0.0517,
      "step": 6859
    },
    {
      "epoch": 0.49715548791535313,
      "grad_norm": 0.4122640788555145,
      "learning_rate": 0.00010058699905790275,
      "loss": 0.0087,
      "step": 6860
    },
    {
      "epoch": 0.49722795956082183,
      "grad_norm": 2.5605356693267822,
      "learning_rate": 0.00010057250525400392,
      "loss": 0.1015,
      "step": 6861
    },
    {
      "epoch": 0.4973004312062905,
      "grad_norm": 0.7688886523246765,
      "learning_rate": 0.00010055801145010509,
      "loss": 0.0526,
      "step": 6862
    },
    {
      "epoch": 0.4973729028517592,
      "grad_norm": 2.114957809448242,
      "learning_rate": 0.00010054351764620624,
      "loss": 0.0954,
      "step": 6863
    },
    {
      "epoch": 0.497445374497228,
      "grad_norm": 0.7976166009902954,
      "learning_rate": 0.00010052902384230743,
      "loss": 0.0372,
      "step": 6864
    },
    {
      "epoch": 0.4975178461426967,
      "grad_norm": 3.183980703353882,
      "learning_rate": 0.00010051453003840858,
      "loss": 0.0735,
      "step": 6865
    },
    {
      "epoch": 0.49759031778816537,
      "grad_norm": 1.4423811435699463,
      "learning_rate": 0.00010050003623450974,
      "loss": 0.0621,
      "step": 6866
    },
    {
      "epoch": 0.49766278943363407,
      "grad_norm": 1.06593656539917,
      "learning_rate": 0.00010048554243061092,
      "loss": 0.0242,
      "step": 6867
    },
    {
      "epoch": 0.4977352610791028,
      "grad_norm": 2.2113139629364014,
      "learning_rate": 0.00010047104862671208,
      "loss": 0.051,
      "step": 6868
    },
    {
      "epoch": 0.4978077327245715,
      "grad_norm": 0.3144921064376831,
      "learning_rate": 0.00010045655482281324,
      "loss": 0.0109,
      "step": 6869
    },
    {
      "epoch": 0.4978802043700402,
      "grad_norm": 2.202989339828491,
      "learning_rate": 0.00010044206101891442,
      "loss": 0.0757,
      "step": 6870
    },
    {
      "epoch": 0.4979526760155089,
      "grad_norm": 1.5659005641937256,
      "learning_rate": 0.00010042756721501558,
      "loss": 0.1252,
      "step": 6871
    },
    {
      "epoch": 0.49802514766097766,
      "grad_norm": 1.2755175828933716,
      "learning_rate": 0.00010041307341111675,
      "loss": 0.0127,
      "step": 6872
    },
    {
      "epoch": 0.49809761930644636,
      "grad_norm": 0.9210647344589233,
      "learning_rate": 0.00010039857960721793,
      "loss": 0.0174,
      "step": 6873
    },
    {
      "epoch": 0.49817009095191506,
      "grad_norm": 1.4347306489944458,
      "learning_rate": 0.00010038408580331909,
      "loss": 0.1078,
      "step": 6874
    },
    {
      "epoch": 0.49824256259738375,
      "grad_norm": 0.20381289720535278,
      "learning_rate": 0.00010036959199942024,
      "loss": 0.0047,
      "step": 6875
    },
    {
      "epoch": 0.4983150342428525,
      "grad_norm": 1.217113971710205,
      "learning_rate": 0.00010035509819552143,
      "loss": 0.0503,
      "step": 6876
    },
    {
      "epoch": 0.4983875058883212,
      "grad_norm": 0.5948686599731445,
      "learning_rate": 0.00010034060439162258,
      "loss": 0.0173,
      "step": 6877
    },
    {
      "epoch": 0.4984599775337899,
      "grad_norm": 1.7837423086166382,
      "learning_rate": 0.00010032611058772374,
      "loss": 0.0239,
      "step": 6878
    },
    {
      "epoch": 0.4985324491792586,
      "grad_norm": 0.5142990350723267,
      "learning_rate": 0.00010031161678382492,
      "loss": 0.0195,
      "step": 6879
    },
    {
      "epoch": 0.49860492082472735,
      "grad_norm": 0.2759707272052765,
      "learning_rate": 0.00010029712297992608,
      "loss": 0.0046,
      "step": 6880
    },
    {
      "epoch": 0.49867739247019605,
      "grad_norm": 1.469085693359375,
      "learning_rate": 0.00010028262917602724,
      "loss": 0.0527,
      "step": 6881
    },
    {
      "epoch": 0.49874986411566474,
      "grad_norm": 1.5813733339309692,
      "learning_rate": 0.00010026813537212842,
      "loss": 0.0352,
      "step": 6882
    },
    {
      "epoch": 0.49882233576113344,
      "grad_norm": 2.3304951190948486,
      "learning_rate": 0.00010025364156822959,
      "loss": 0.0278,
      "step": 6883
    },
    {
      "epoch": 0.4988948074066022,
      "grad_norm": 1.2552508115768433,
      "learning_rate": 0.00010023914776433075,
      "loss": 0.0512,
      "step": 6884
    },
    {
      "epoch": 0.4989672790520709,
      "grad_norm": 3.954975128173828,
      "learning_rate": 0.00010022465396043193,
      "loss": 0.1443,
      "step": 6885
    },
    {
      "epoch": 0.4990397506975396,
      "grad_norm": 2.087015151977539,
      "learning_rate": 0.00010021016015653309,
      "loss": 0.0572,
      "step": 6886
    },
    {
      "epoch": 0.4991122223430083,
      "grad_norm": 1.4434049129486084,
      "learning_rate": 0.00010019566635263424,
      "loss": 0.0566,
      "step": 6887
    },
    {
      "epoch": 0.49918469398847704,
      "grad_norm": 5.574732780456543,
      "learning_rate": 0.00010018117254873543,
      "loss": 0.116,
      "step": 6888
    },
    {
      "epoch": 0.49925716563394573,
      "grad_norm": 5.069983005523682,
      "learning_rate": 0.00010016667874483658,
      "loss": 0.1907,
      "step": 6889
    },
    {
      "epoch": 0.49932963727941443,
      "grad_norm": 3.2969226837158203,
      "learning_rate": 0.00010015218494093774,
      "loss": 0.136,
      "step": 6890
    },
    {
      "epoch": 0.4994021089248831,
      "grad_norm": 1.957751989364624,
      "learning_rate": 0.00010013769113703892,
      "loss": 0.0568,
      "step": 6891
    },
    {
      "epoch": 0.4994745805703518,
      "grad_norm": 1.6244057416915894,
      "learning_rate": 0.00010012319733314008,
      "loss": 0.0782,
      "step": 6892
    },
    {
      "epoch": 0.4995470522158206,
      "grad_norm": 1.4710527658462524,
      "learning_rate": 0.00010010870352924125,
      "loss": 0.0672,
      "step": 6893
    },
    {
      "epoch": 0.49961952386128927,
      "grad_norm": 0.36757519841194153,
      "learning_rate": 0.00010009420972534242,
      "loss": 0.0207,
      "step": 6894
    },
    {
      "epoch": 0.49969199550675797,
      "grad_norm": 0.5952305793762207,
      "learning_rate": 0.00010007971592144359,
      "loss": 0.0064,
      "step": 6895
    },
    {
      "epoch": 0.49976446715222667,
      "grad_norm": 4.21475887298584,
      "learning_rate": 0.00010006522211754475,
      "loss": 0.2711,
      "step": 6896
    },
    {
      "epoch": 0.4998369387976954,
      "grad_norm": 2.233473539352417,
      "learning_rate": 0.00010005072831364593,
      "loss": 0.0268,
      "step": 6897
    },
    {
      "epoch": 0.4999094104431641,
      "grad_norm": 0.7356153130531311,
      "learning_rate": 0.00010003623450974709,
      "loss": 0.0114,
      "step": 6898
    },
    {
      "epoch": 0.4999818820886328,
      "grad_norm": 2.4776086807250977,
      "learning_rate": 0.00010002174070584824,
      "loss": 0.1982,
      "step": 6899
    },
    {
      "epoch": 0.5000543537341016,
      "grad_norm": 1.8200342655181885,
      "learning_rate": 0.00010000724690194943,
      "loss": 0.0944,
      "step": 6900
    },
    {
      "epoch": 0.5001268253795702,
      "grad_norm": 1.0572209358215332,
      "learning_rate": 9.999275309805058e-05,
      "loss": 0.0444,
      "step": 6901
    },
    {
      "epoch": 0.500199297025039,
      "grad_norm": 0.21372090280056,
      "learning_rate": 9.997825929415175e-05,
      "loss": 0.0126,
      "step": 6902
    },
    {
      "epoch": 0.5002717686705077,
      "grad_norm": 0.13465963304042816,
      "learning_rate": 9.996376549025292e-05,
      "loss": 0.0029,
      "step": 6903
    },
    {
      "epoch": 0.5003442403159764,
      "grad_norm": 0.2783597707748413,
      "learning_rate": 9.994927168635408e-05,
      "loss": 0.011,
      "step": 6904
    },
    {
      "epoch": 0.5004167119614451,
      "grad_norm": 1.423424243927002,
      "learning_rate": 9.993477788245525e-05,
      "loss": 0.0928,
      "step": 6905
    },
    {
      "epoch": 0.5004891836069137,
      "grad_norm": 1.5104656219482422,
      "learning_rate": 9.992028407855642e-05,
      "loss": 0.0225,
      "step": 6906
    },
    {
      "epoch": 0.5005616552523825,
      "grad_norm": 3.5406641960144043,
      "learning_rate": 9.990579027465759e-05,
      "loss": 0.1081,
      "step": 6907
    },
    {
      "epoch": 0.5006341268978513,
      "grad_norm": 1.3205162286758423,
      "learning_rate": 9.989129647075876e-05,
      "loss": 0.079,
      "step": 6908
    },
    {
      "epoch": 0.5007065985433199,
      "grad_norm": 0.7271172404289246,
      "learning_rate": 9.987680266685993e-05,
      "loss": 0.0509,
      "step": 6909
    },
    {
      "epoch": 0.5007790701887886,
      "grad_norm": 1.374311923980713,
      "learning_rate": 9.986230886296109e-05,
      "loss": 0.0861,
      "step": 6910
    },
    {
      "epoch": 0.5008515418342574,
      "grad_norm": 0.5661256909370422,
      "learning_rate": 9.984781505906226e-05,
      "loss": 0.0447,
      "step": 6911
    },
    {
      "epoch": 0.500924013479726,
      "grad_norm": 0.6825513243675232,
      "learning_rate": 9.983332125516343e-05,
      "loss": 0.0407,
      "step": 6912
    },
    {
      "epoch": 0.5009964851251948,
      "grad_norm": 2.1615781784057617,
      "learning_rate": 9.981882745126458e-05,
      "loss": 0.078,
      "step": 6913
    },
    {
      "epoch": 0.5010689567706634,
      "grad_norm": 0.643909215927124,
      "learning_rate": 9.980433364736575e-05,
      "loss": 0.0314,
      "step": 6914
    },
    {
      "epoch": 0.5011414284161322,
      "grad_norm": 0.7411299347877502,
      "learning_rate": 9.978983984346692e-05,
      "loss": 0.0328,
      "step": 6915
    },
    {
      "epoch": 0.5012139000616009,
      "grad_norm": 0.6956508755683899,
      "learning_rate": 9.977534603956808e-05,
      "loss": 0.056,
      "step": 6916
    },
    {
      "epoch": 0.5012863717070696,
      "grad_norm": 2.2467691898345947,
      "learning_rate": 9.976085223566925e-05,
      "loss": 0.2239,
      "step": 6917
    },
    {
      "epoch": 0.5013588433525383,
      "grad_norm": 1.4494280815124512,
      "learning_rate": 9.974635843177042e-05,
      "loss": 0.0628,
      "step": 6918
    },
    {
      "epoch": 0.5014313149980071,
      "grad_norm": 0.44617483019828796,
      "learning_rate": 9.973186462787159e-05,
      "loss": 0.0155,
      "step": 6919
    },
    {
      "epoch": 0.5015037866434757,
      "grad_norm": 1.3098483085632324,
      "learning_rate": 9.971737082397276e-05,
      "loss": 0.057,
      "step": 6920
    },
    {
      "epoch": 0.5015762582889445,
      "grad_norm": 1.6796460151672363,
      "learning_rate": 9.970287702007393e-05,
      "loss": 0.0685,
      "step": 6921
    },
    {
      "epoch": 0.5016487299344131,
      "grad_norm": 0.7309629321098328,
      "learning_rate": 9.968838321617509e-05,
      "loss": 0.0715,
      "step": 6922
    },
    {
      "epoch": 0.5017212015798819,
      "grad_norm": 1.3071808815002441,
      "learning_rate": 9.967388941227626e-05,
      "loss": 0.0496,
      "step": 6923
    },
    {
      "epoch": 0.5017936732253506,
      "grad_norm": 0.5042733550071716,
      "learning_rate": 9.965939560837743e-05,
      "loss": 0.0195,
      "step": 6924
    },
    {
      "epoch": 0.5018661448708193,
      "grad_norm": 1.2769004106521606,
      "learning_rate": 9.964490180447858e-05,
      "loss": 0.0394,
      "step": 6925
    },
    {
      "epoch": 0.501938616516288,
      "grad_norm": 1.1191680431365967,
      "learning_rate": 9.963040800057975e-05,
      "loss": 0.0361,
      "step": 6926
    },
    {
      "epoch": 0.5020110881617567,
      "grad_norm": 0.26309508085250854,
      "learning_rate": 9.961591419668092e-05,
      "loss": 0.0233,
      "step": 6927
    },
    {
      "epoch": 0.5020835598072254,
      "grad_norm": 2.4510467052459717,
      "learning_rate": 9.960142039278208e-05,
      "loss": 0.0814,
      "step": 6928
    },
    {
      "epoch": 0.5021560314526942,
      "grad_norm": 0.2986082136631012,
      "learning_rate": 9.958692658888325e-05,
      "loss": 0.0191,
      "step": 6929
    },
    {
      "epoch": 0.5022285030981628,
      "grad_norm": 2.3344526290893555,
      "learning_rate": 9.957243278498443e-05,
      "loss": 0.087,
      "step": 6930
    },
    {
      "epoch": 0.5023009747436316,
      "grad_norm": 1.923101544380188,
      "learning_rate": 9.955793898108559e-05,
      "loss": 0.0819,
      "step": 6931
    },
    {
      "epoch": 0.5023734463891003,
      "grad_norm": 1.0915669202804565,
      "learning_rate": 9.954344517718676e-05,
      "loss": 0.0631,
      "step": 6932
    },
    {
      "epoch": 0.502445918034569,
      "grad_norm": 1.0094280242919922,
      "learning_rate": 9.952895137328793e-05,
      "loss": 0.0474,
      "step": 6933
    },
    {
      "epoch": 0.5025183896800377,
      "grad_norm": 0.5538408756256104,
      "learning_rate": 9.951445756938909e-05,
      "loss": 0.0368,
      "step": 6934
    },
    {
      "epoch": 0.5025908613255063,
      "grad_norm": 5.2638139724731445,
      "learning_rate": 9.949996376549026e-05,
      "loss": 0.1015,
      "step": 6935
    },
    {
      "epoch": 0.5026633329709751,
      "grad_norm": 1.8588204383850098,
      "learning_rate": 9.948546996159143e-05,
      "loss": 0.0506,
      "step": 6936
    },
    {
      "epoch": 0.5027358046164438,
      "grad_norm": 1.0184816122055054,
      "learning_rate": 9.947097615769258e-05,
      "loss": 0.0351,
      "step": 6937
    },
    {
      "epoch": 0.5028082762619125,
      "grad_norm": 1.7062748670578003,
      "learning_rate": 9.945648235379375e-05,
      "loss": 0.0502,
      "step": 6938
    },
    {
      "epoch": 0.5028807479073812,
      "grad_norm": 1.3404147624969482,
      "learning_rate": 9.944198854989492e-05,
      "loss": 0.0532,
      "step": 6939
    },
    {
      "epoch": 0.50295321955285,
      "grad_norm": 0.5343487858772278,
      "learning_rate": 9.942749474599609e-05,
      "loss": 0.0129,
      "step": 6940
    },
    {
      "epoch": 0.5030256911983186,
      "grad_norm": 1.4643783569335938,
      "learning_rate": 9.941300094209726e-05,
      "loss": 0.0772,
      "step": 6941
    },
    {
      "epoch": 0.5030981628437874,
      "grad_norm": 1.5737133026123047,
      "learning_rate": 9.939850713819843e-05,
      "loss": 0.0128,
      "step": 6942
    },
    {
      "epoch": 0.503170634489256,
      "grad_norm": 0.30167561769485474,
      "learning_rate": 9.93840133342996e-05,
      "loss": 0.0168,
      "step": 6943
    },
    {
      "epoch": 0.5032431061347248,
      "grad_norm": 1.0417516231536865,
      "learning_rate": 9.936951953040076e-05,
      "loss": 0.0525,
      "step": 6944
    },
    {
      "epoch": 0.5033155777801935,
      "grad_norm": 0.3581402003765106,
      "learning_rate": 9.935502572650193e-05,
      "loss": 0.015,
      "step": 6945
    },
    {
      "epoch": 0.5033880494256622,
      "grad_norm": 1.6702845096588135,
      "learning_rate": 9.93405319226031e-05,
      "loss": 0.0763,
      "step": 6946
    },
    {
      "epoch": 0.5034605210711309,
      "grad_norm": 1.2453575134277344,
      "learning_rate": 9.932603811870426e-05,
      "loss": 0.0354,
      "step": 6947
    },
    {
      "epoch": 0.5035329927165997,
      "grad_norm": 1.0962477922439575,
      "learning_rate": 9.931154431480543e-05,
      "loss": 0.0942,
      "step": 6948
    },
    {
      "epoch": 0.5036054643620683,
      "grad_norm": 0.5984545350074768,
      "learning_rate": 9.92970505109066e-05,
      "loss": 0.0677,
      "step": 6949
    },
    {
      "epoch": 0.5036779360075371,
      "grad_norm": 1.3472124338150024,
      "learning_rate": 9.928255670700775e-05,
      "loss": 0.0829,
      "step": 6950
    },
    {
      "epoch": 0.5037504076530057,
      "grad_norm": 0.09560737013816833,
      "learning_rate": 9.926806290310892e-05,
      "loss": 0.003,
      "step": 6951
    },
    {
      "epoch": 0.5038228792984745,
      "grad_norm": 1.4535179138183594,
      "learning_rate": 9.925356909921009e-05,
      "loss": 0.0826,
      "step": 6952
    },
    {
      "epoch": 0.5038953509439432,
      "grad_norm": 2.117356300354004,
      "learning_rate": 9.923907529531126e-05,
      "loss": 0.0558,
      "step": 6953
    },
    {
      "epoch": 0.5039678225894119,
      "grad_norm": 0.5466699600219727,
      "learning_rate": 9.922458149141243e-05,
      "loss": 0.0104,
      "step": 6954
    },
    {
      "epoch": 0.5040402942348806,
      "grad_norm": 1.2580788135528564,
      "learning_rate": 9.92100876875136e-05,
      "loss": 0.1051,
      "step": 6955
    },
    {
      "epoch": 0.5041127658803494,
      "grad_norm": 3.1491966247558594,
      "learning_rate": 9.919559388361476e-05,
      "loss": 0.1414,
      "step": 6956
    },
    {
      "epoch": 0.504185237525818,
      "grad_norm": 1.2362112998962402,
      "learning_rate": 9.918110007971593e-05,
      "loss": 0.0346,
      "step": 6957
    },
    {
      "epoch": 0.5042577091712868,
      "grad_norm": 0.6935940980911255,
      "learning_rate": 9.91666062758171e-05,
      "loss": 0.092,
      "step": 6958
    },
    {
      "epoch": 0.5043301808167554,
      "grad_norm": 2.8315258026123047,
      "learning_rate": 9.915211247191826e-05,
      "loss": 0.143,
      "step": 6959
    },
    {
      "epoch": 0.5044026524622242,
      "grad_norm": 1.6868852376937866,
      "learning_rate": 9.913761866801943e-05,
      "loss": 0.0633,
      "step": 6960
    },
    {
      "epoch": 0.5044751241076929,
      "grad_norm": 4.381934642791748,
      "learning_rate": 9.91231248641206e-05,
      "loss": 0.0883,
      "step": 6961
    },
    {
      "epoch": 0.5045475957531615,
      "grad_norm": 0.6825749278068542,
      "learning_rate": 9.910863106022175e-05,
      "loss": 0.0251,
      "step": 6962
    },
    {
      "epoch": 0.5046200673986303,
      "grad_norm": 1.5720467567443848,
      "learning_rate": 9.909413725632292e-05,
      "loss": 0.1114,
      "step": 6963
    },
    {
      "epoch": 0.5046925390440989,
      "grad_norm": 0.8301889300346375,
      "learning_rate": 9.907964345242409e-05,
      "loss": 0.0367,
      "step": 6964
    },
    {
      "epoch": 0.5047650106895677,
      "grad_norm": 1.4977307319641113,
      "learning_rate": 9.906514964852526e-05,
      "loss": 0.049,
      "step": 6965
    },
    {
      "epoch": 0.5048374823350364,
      "grad_norm": 2.002692937850952,
      "learning_rate": 9.905065584462643e-05,
      "loss": 0.1392,
      "step": 6966
    },
    {
      "epoch": 0.5049099539805051,
      "grad_norm": 2.010974645614624,
      "learning_rate": 9.90361620407276e-05,
      "loss": 0.0517,
      "step": 6967
    },
    {
      "epoch": 0.5049824256259738,
      "grad_norm": 1.7978931665420532,
      "learning_rate": 9.902166823682876e-05,
      "loss": 0.0991,
      "step": 6968
    },
    {
      "epoch": 0.5050548972714426,
      "grad_norm": 0.95913165807724,
      "learning_rate": 9.900717443292993e-05,
      "loss": 0.0904,
      "step": 6969
    },
    {
      "epoch": 0.5051273689169112,
      "grad_norm": 0.7133687734603882,
      "learning_rate": 9.89926806290311e-05,
      "loss": 0.029,
      "step": 6970
    },
    {
      "epoch": 0.50519984056238,
      "grad_norm": 0.7405511140823364,
      "learning_rate": 9.897818682513226e-05,
      "loss": 0.028,
      "step": 6971
    },
    {
      "epoch": 0.5052723122078486,
      "grad_norm": 0.8970418572425842,
      "learning_rate": 9.896369302123343e-05,
      "loss": 0.0249,
      "step": 6972
    },
    {
      "epoch": 0.5053447838533174,
      "grad_norm": 0.7211898565292358,
      "learning_rate": 9.89491992173346e-05,
      "loss": 0.0147,
      "step": 6973
    },
    {
      "epoch": 0.5054172554987861,
      "grad_norm": 3.0563461780548096,
      "learning_rate": 9.893470541343575e-05,
      "loss": 0.1002,
      "step": 6974
    },
    {
      "epoch": 0.5054897271442548,
      "grad_norm": 4.150193691253662,
      "learning_rate": 9.892021160953692e-05,
      "loss": 0.2644,
      "step": 6975
    },
    {
      "epoch": 0.5055621987897235,
      "grad_norm": 0.37098392844200134,
      "learning_rate": 9.890571780563809e-05,
      "loss": 0.012,
      "step": 6976
    },
    {
      "epoch": 0.5056346704351923,
      "grad_norm": 0.8521645069122314,
      "learning_rate": 9.889122400173926e-05,
      "loss": 0.0239,
      "step": 6977
    },
    {
      "epoch": 0.5057071420806609,
      "grad_norm": 0.7899095416069031,
      "learning_rate": 9.887673019784043e-05,
      "loss": 0.0338,
      "step": 6978
    },
    {
      "epoch": 0.5057796137261297,
      "grad_norm": 2.093024969100952,
      "learning_rate": 9.88622363939416e-05,
      "loss": 0.0267,
      "step": 6979
    },
    {
      "epoch": 0.5058520853715983,
      "grad_norm": 2.334549903869629,
      "learning_rate": 9.884774259004276e-05,
      "loss": 0.1094,
      "step": 6980
    },
    {
      "epoch": 0.5059245570170671,
      "grad_norm": 1.1390131711959839,
      "learning_rate": 9.883324878614393e-05,
      "loss": 0.0588,
      "step": 6981
    },
    {
      "epoch": 0.5059970286625358,
      "grad_norm": 2.792733669281006,
      "learning_rate": 9.88187549822451e-05,
      "loss": 0.1033,
      "step": 6982
    },
    {
      "epoch": 0.5060695003080045,
      "grad_norm": 0.6305861473083496,
      "learning_rate": 9.880426117834626e-05,
      "loss": 0.0122,
      "step": 6983
    },
    {
      "epoch": 0.5061419719534732,
      "grad_norm": 1.093688726425171,
      "learning_rate": 9.878976737444743e-05,
      "loss": 0.0626,
      "step": 6984
    },
    {
      "epoch": 0.506214443598942,
      "grad_norm": 2.097522020339966,
      "learning_rate": 9.87752735705486e-05,
      "loss": 0.0495,
      "step": 6985
    },
    {
      "epoch": 0.5062869152444106,
      "grad_norm": 0.22878867387771606,
      "learning_rate": 9.876077976664975e-05,
      "loss": 0.0098,
      "step": 6986
    },
    {
      "epoch": 0.5063593868898794,
      "grad_norm": 0.7677196264266968,
      "learning_rate": 9.874628596275094e-05,
      "loss": 0.0458,
      "step": 6987
    },
    {
      "epoch": 0.506431858535348,
      "grad_norm": 1.5868258476257324,
      "learning_rate": 9.87317921588521e-05,
      "loss": 0.0593,
      "step": 6988
    },
    {
      "epoch": 0.5065043301808168,
      "grad_norm": 1.5814372301101685,
      "learning_rate": 9.871729835495326e-05,
      "loss": 0.0839,
      "step": 6989
    },
    {
      "epoch": 0.5065768018262855,
      "grad_norm": 2.145163059234619,
      "learning_rate": 9.870280455105443e-05,
      "loss": 0.0632,
      "step": 6990
    },
    {
      "epoch": 0.5066492734717541,
      "grad_norm": 0.41164928674697876,
      "learning_rate": 9.86883107471556e-05,
      "loss": 0.0046,
      "step": 6991
    },
    {
      "epoch": 0.5067217451172229,
      "grad_norm": 0.9270519614219666,
      "learning_rate": 9.867381694325676e-05,
      "loss": 0.0288,
      "step": 6992
    },
    {
      "epoch": 0.5067942167626917,
      "grad_norm": 0.46191534399986267,
      "learning_rate": 9.865932313935793e-05,
      "loss": 0.0338,
      "step": 6993
    },
    {
      "epoch": 0.5068666884081603,
      "grad_norm": 4.184652805328369,
      "learning_rate": 9.86448293354591e-05,
      "loss": 0.0634,
      "step": 6994
    },
    {
      "epoch": 0.506939160053629,
      "grad_norm": 0.1544436514377594,
      "learning_rate": 9.863033553156025e-05,
      "loss": 0.0052,
      "step": 6995
    },
    {
      "epoch": 0.5070116316990977,
      "grad_norm": 0.6547266244888306,
      "learning_rate": 9.861584172766142e-05,
      "loss": 0.0235,
      "step": 6996
    },
    {
      "epoch": 0.5070841033445664,
      "grad_norm": 1.1881999969482422,
      "learning_rate": 9.86013479237626e-05,
      "loss": 0.0384,
      "step": 6997
    },
    {
      "epoch": 0.5071565749900352,
      "grad_norm": 1.609128713607788,
      "learning_rate": 9.858685411986376e-05,
      "loss": 0.1504,
      "step": 6998
    },
    {
      "epoch": 0.5072290466355038,
      "grad_norm": 1.6957412958145142,
      "learning_rate": 9.857236031596494e-05,
      "loss": 0.0411,
      "step": 6999
    },
    {
      "epoch": 0.5073015182809726,
      "grad_norm": 0.6428996920585632,
      "learning_rate": 9.85578665120661e-05,
      "loss": 0.0477,
      "step": 7000
    },
    {
      "epoch": 0.5073739899264412,
      "grad_norm": 3.0750160217285156,
      "learning_rate": 9.854337270816726e-05,
      "loss": 0.039,
      "step": 7001
    },
    {
      "epoch": 0.50744646157191,
      "grad_norm": 0.6081297993659973,
      "learning_rate": 9.852887890426843e-05,
      "loss": 0.0429,
      "step": 7002
    },
    {
      "epoch": 0.5075189332173787,
      "grad_norm": 0.7351927757263184,
      "learning_rate": 9.85143851003696e-05,
      "loss": 0.0203,
      "step": 7003
    },
    {
      "epoch": 0.5075914048628474,
      "grad_norm": 0.7471440434455872,
      "learning_rate": 9.849989129647076e-05,
      "loss": 0.0328,
      "step": 7004
    },
    {
      "epoch": 0.5076638765083161,
      "grad_norm": 0.8686582446098328,
      "learning_rate": 9.848539749257193e-05,
      "loss": 0.0236,
      "step": 7005
    },
    {
      "epoch": 0.5077363481537849,
      "grad_norm": 1.5747517347335815,
      "learning_rate": 9.84709036886731e-05,
      "loss": 0.0699,
      "step": 7006
    },
    {
      "epoch": 0.5078088197992535,
      "grad_norm": 1.6896305084228516,
      "learning_rate": 9.845640988477425e-05,
      "loss": 0.0524,
      "step": 7007
    },
    {
      "epoch": 0.5078812914447223,
      "grad_norm": 2.057279348373413,
      "learning_rate": 9.844191608087542e-05,
      "loss": 0.0838,
      "step": 7008
    },
    {
      "epoch": 0.5079537630901909,
      "grad_norm": 2.794325113296509,
      "learning_rate": 9.84274222769766e-05,
      "loss": 0.0827,
      "step": 7009
    },
    {
      "epoch": 0.5080262347356597,
      "grad_norm": 0.8729718327522278,
      "learning_rate": 9.841292847307776e-05,
      "loss": 0.0222,
      "step": 7010
    },
    {
      "epoch": 0.5080987063811284,
      "grad_norm": 1.3960312604904175,
      "learning_rate": 9.839843466917893e-05,
      "loss": 0.0323,
      "step": 7011
    },
    {
      "epoch": 0.5081711780265971,
      "grad_norm": 0.9286412000656128,
      "learning_rate": 9.83839408652801e-05,
      "loss": 0.049,
      "step": 7012
    },
    {
      "epoch": 0.5082436496720658,
      "grad_norm": 1.2817455530166626,
      "learning_rate": 9.836944706138126e-05,
      "loss": 0.0397,
      "step": 7013
    },
    {
      "epoch": 0.5083161213175346,
      "grad_norm": 2.674535036087036,
      "learning_rate": 9.835495325748243e-05,
      "loss": 0.1457,
      "step": 7014
    },
    {
      "epoch": 0.5083885929630032,
      "grad_norm": 1.7188955545425415,
      "learning_rate": 9.83404594535836e-05,
      "loss": 0.0704,
      "step": 7015
    },
    {
      "epoch": 0.508461064608472,
      "grad_norm": 1.0998554229736328,
      "learning_rate": 9.832596564968476e-05,
      "loss": 0.0283,
      "step": 7016
    },
    {
      "epoch": 0.5085335362539406,
      "grad_norm": 0.3383125960826874,
      "learning_rate": 9.831147184578593e-05,
      "loss": 0.0073,
      "step": 7017
    },
    {
      "epoch": 0.5086060078994094,
      "grad_norm": 2.753746271133423,
      "learning_rate": 9.82969780418871e-05,
      "loss": 0.1045,
      "step": 7018
    },
    {
      "epoch": 0.5086784795448781,
      "grad_norm": 0.11780636012554169,
      "learning_rate": 9.828248423798825e-05,
      "loss": 0.0028,
      "step": 7019
    },
    {
      "epoch": 0.5087509511903467,
      "grad_norm": 0.5700356364250183,
      "learning_rate": 9.826799043408942e-05,
      "loss": 0.0697,
      "step": 7020
    },
    {
      "epoch": 0.5088234228358155,
      "grad_norm": 1.7136787176132202,
      "learning_rate": 9.82534966301906e-05,
      "loss": 0.0907,
      "step": 7021
    },
    {
      "epoch": 0.5088958944812842,
      "grad_norm": 1.4373273849487305,
      "learning_rate": 9.823900282629176e-05,
      "loss": 0.0706,
      "step": 7022
    },
    {
      "epoch": 0.5089683661267529,
      "grad_norm": 0.3163186311721802,
      "learning_rate": 9.822450902239293e-05,
      "loss": 0.014,
      "step": 7023
    },
    {
      "epoch": 0.5090408377722216,
      "grad_norm": 1.6399930715560913,
      "learning_rate": 9.82100152184941e-05,
      "loss": 0.046,
      "step": 7024
    },
    {
      "epoch": 0.5091133094176903,
      "grad_norm": 3.2013003826141357,
      "learning_rate": 9.819552141459527e-05,
      "loss": 0.0286,
      "step": 7025
    },
    {
      "epoch": 0.509185781063159,
      "grad_norm": 1.022444725036621,
      "learning_rate": 9.818102761069643e-05,
      "loss": 0.0306,
      "step": 7026
    },
    {
      "epoch": 0.5092582527086278,
      "grad_norm": 1.5546849966049194,
      "learning_rate": 9.81665338067976e-05,
      "loss": 0.0679,
      "step": 7027
    },
    {
      "epoch": 0.5093307243540964,
      "grad_norm": 1.656854510307312,
      "learning_rate": 9.815204000289877e-05,
      "loss": 0.1258,
      "step": 7028
    },
    {
      "epoch": 0.5094031959995652,
      "grad_norm": 1.7750335931777954,
      "learning_rate": 9.813754619899993e-05,
      "loss": 0.0738,
      "step": 7029
    },
    {
      "epoch": 0.5094756676450338,
      "grad_norm": 1.6666172742843628,
      "learning_rate": 9.81230523951011e-05,
      "loss": 0.0617,
      "step": 7030
    },
    {
      "epoch": 0.5095481392905026,
      "grad_norm": 0.8666368722915649,
      "learning_rate": 9.810855859120227e-05,
      "loss": 0.015,
      "step": 7031
    },
    {
      "epoch": 0.5096206109359713,
      "grad_norm": 1.4030200242996216,
      "learning_rate": 9.809406478730342e-05,
      "loss": 0.0853,
      "step": 7032
    },
    {
      "epoch": 0.50969308258144,
      "grad_norm": 2.2782466411590576,
      "learning_rate": 9.80795709834046e-05,
      "loss": 0.0907,
      "step": 7033
    },
    {
      "epoch": 0.5097655542269087,
      "grad_norm": 0.9602320790290833,
      "learning_rate": 9.806507717950576e-05,
      "loss": 0.0635,
      "step": 7034
    },
    {
      "epoch": 0.5098380258723775,
      "grad_norm": 3.3047003746032715,
      "learning_rate": 9.805058337560693e-05,
      "loss": 0.1677,
      "step": 7035
    },
    {
      "epoch": 0.5099104975178461,
      "grad_norm": 2.378054141998291,
      "learning_rate": 9.80360895717081e-05,
      "loss": 0.0672,
      "step": 7036
    },
    {
      "epoch": 0.5099829691633149,
      "grad_norm": 1.0311410427093506,
      "learning_rate": 9.802159576780927e-05,
      "loss": 0.0475,
      "step": 7037
    },
    {
      "epoch": 0.5100554408087835,
      "grad_norm": 1.021368145942688,
      "learning_rate": 9.800710196391043e-05,
      "loss": 0.0451,
      "step": 7038
    },
    {
      "epoch": 0.5101279124542523,
      "grad_norm": 2.869065761566162,
      "learning_rate": 9.79926081600116e-05,
      "loss": 0.1391,
      "step": 7039
    },
    {
      "epoch": 0.510200384099721,
      "grad_norm": 1.0635675191879272,
      "learning_rate": 9.797811435611277e-05,
      "loss": 0.0629,
      "step": 7040
    },
    {
      "epoch": 0.5102728557451897,
      "grad_norm": 1.4193828105926514,
      "learning_rate": 9.796362055221393e-05,
      "loss": 0.0418,
      "step": 7041
    },
    {
      "epoch": 0.5103453273906584,
      "grad_norm": 1.5863488912582397,
      "learning_rate": 9.79491267483151e-05,
      "loss": 0.023,
      "step": 7042
    },
    {
      "epoch": 0.5104177990361272,
      "grad_norm": 1.1494182348251343,
      "learning_rate": 9.793463294441627e-05,
      "loss": 0.0723,
      "step": 7043
    },
    {
      "epoch": 0.5104902706815958,
      "grad_norm": 1.0356179475784302,
      "learning_rate": 9.792013914051742e-05,
      "loss": 0.0395,
      "step": 7044
    },
    {
      "epoch": 0.5105627423270646,
      "grad_norm": 4.312613010406494,
      "learning_rate": 9.790564533661861e-05,
      "loss": 0.06,
      "step": 7045
    },
    {
      "epoch": 0.5106352139725332,
      "grad_norm": 1.5741326808929443,
      "learning_rate": 9.789115153271978e-05,
      "loss": 0.102,
      "step": 7046
    },
    {
      "epoch": 0.510707685618002,
      "grad_norm": 1.3203449249267578,
      "learning_rate": 9.787665772882093e-05,
      "loss": 0.0292,
      "step": 7047
    },
    {
      "epoch": 0.5107801572634707,
      "grad_norm": 0.9101927280426025,
      "learning_rate": 9.78621639249221e-05,
      "loss": 0.0874,
      "step": 7048
    },
    {
      "epoch": 0.5108526289089393,
      "grad_norm": 2.429417371749878,
      "learning_rate": 9.784767012102327e-05,
      "loss": 0.0909,
      "step": 7049
    },
    {
      "epoch": 0.5109251005544081,
      "grad_norm": 0.5690865516662598,
      "learning_rate": 9.783317631712443e-05,
      "loss": 0.0251,
      "step": 7050
    },
    {
      "epoch": 0.5109975721998768,
      "grad_norm": 0.14036056399345398,
      "learning_rate": 9.78186825132256e-05,
      "loss": 0.0039,
      "step": 7051
    },
    {
      "epoch": 0.5110700438453455,
      "grad_norm": 1.1333163976669312,
      "learning_rate": 9.780418870932677e-05,
      "loss": 0.0139,
      "step": 7052
    },
    {
      "epoch": 0.5111425154908142,
      "grad_norm": 2.3834102153778076,
      "learning_rate": 9.778969490542793e-05,
      "loss": 0.1211,
      "step": 7053
    },
    {
      "epoch": 0.5112149871362829,
      "grad_norm": 2.1121559143066406,
      "learning_rate": 9.77752011015291e-05,
      "loss": 0.0722,
      "step": 7054
    },
    {
      "epoch": 0.5112874587817516,
      "grad_norm": 1.3148400783538818,
      "learning_rate": 9.776070729763027e-05,
      "loss": 0.091,
      "step": 7055
    },
    {
      "epoch": 0.5113599304272204,
      "grad_norm": 1.4255229234695435,
      "learning_rate": 9.774621349373144e-05,
      "loss": 0.0392,
      "step": 7056
    },
    {
      "epoch": 0.511432402072689,
      "grad_norm": 0.9334323406219482,
      "learning_rate": 9.773171968983261e-05,
      "loss": 0.0343,
      "step": 7057
    },
    {
      "epoch": 0.5115048737181578,
      "grad_norm": 2.1749649047851562,
      "learning_rate": 9.771722588593378e-05,
      "loss": 0.0964,
      "step": 7058
    },
    {
      "epoch": 0.5115773453636265,
      "grad_norm": 0.23819619417190552,
      "learning_rate": 9.770273208203493e-05,
      "loss": 0.0064,
      "step": 7059
    },
    {
      "epoch": 0.5116498170090952,
      "grad_norm": 2.1232407093048096,
      "learning_rate": 9.76882382781361e-05,
      "loss": 0.0643,
      "step": 7060
    },
    {
      "epoch": 0.5117222886545639,
      "grad_norm": 1.2876673936843872,
      "learning_rate": 9.767374447423727e-05,
      "loss": 0.0383,
      "step": 7061
    },
    {
      "epoch": 0.5117947603000326,
      "grad_norm": 0.748605489730835,
      "learning_rate": 9.765925067033843e-05,
      "loss": 0.0255,
      "step": 7062
    },
    {
      "epoch": 0.5118672319455013,
      "grad_norm": 4.3979268074035645,
      "learning_rate": 9.76447568664396e-05,
      "loss": 0.0503,
      "step": 7063
    },
    {
      "epoch": 0.5119397035909701,
      "grad_norm": 2.483757257461548,
      "learning_rate": 9.763026306254077e-05,
      "loss": 0.0593,
      "step": 7064
    },
    {
      "epoch": 0.5120121752364387,
      "grad_norm": 0.5953128933906555,
      "learning_rate": 9.761576925864193e-05,
      "loss": 0.015,
      "step": 7065
    },
    {
      "epoch": 0.5120846468819075,
      "grad_norm": 1.8160110712051392,
      "learning_rate": 9.76012754547431e-05,
      "loss": 0.0751,
      "step": 7066
    },
    {
      "epoch": 0.5121571185273761,
      "grad_norm": 1.1415823698043823,
      "learning_rate": 9.758678165084427e-05,
      "loss": 0.0398,
      "step": 7067
    },
    {
      "epoch": 0.5122295901728449,
      "grad_norm": 0.7982195019721985,
      "learning_rate": 9.757228784694544e-05,
      "loss": 0.0409,
      "step": 7068
    },
    {
      "epoch": 0.5123020618183136,
      "grad_norm": 5.985077857971191,
      "learning_rate": 9.755779404304661e-05,
      "loss": 0.1076,
      "step": 7069
    },
    {
      "epoch": 0.5123745334637823,
      "grad_norm": 5.507136344909668,
      "learning_rate": 9.754330023914778e-05,
      "loss": 0.1151,
      "step": 7070
    },
    {
      "epoch": 0.512447005109251,
      "grad_norm": 6.467580318450928,
      "learning_rate": 9.752880643524893e-05,
      "loss": 0.1157,
      "step": 7071
    },
    {
      "epoch": 0.5125194767547198,
      "grad_norm": 2.6920852661132812,
      "learning_rate": 9.75143126313501e-05,
      "loss": 0.1215,
      "step": 7072
    },
    {
      "epoch": 0.5125919484001884,
      "grad_norm": 1.657406210899353,
      "learning_rate": 9.749981882745127e-05,
      "loss": 0.0832,
      "step": 7073
    },
    {
      "epoch": 0.5126644200456572,
      "grad_norm": 1.8559163808822632,
      "learning_rate": 9.748532502355243e-05,
      "loss": 0.0771,
      "step": 7074
    },
    {
      "epoch": 0.5127368916911258,
      "grad_norm": 2.3784408569335938,
      "learning_rate": 9.74708312196536e-05,
      "loss": 0.0784,
      "step": 7075
    },
    {
      "epoch": 0.5128093633365945,
      "grad_norm": 2.9281656742095947,
      "learning_rate": 9.745633741575477e-05,
      "loss": 0.0547,
      "step": 7076
    },
    {
      "epoch": 0.5128818349820633,
      "grad_norm": 1.9085569381713867,
      "learning_rate": 9.744184361185593e-05,
      "loss": 0.0426,
      "step": 7077
    },
    {
      "epoch": 0.5129543066275319,
      "grad_norm": 0.9727180600166321,
      "learning_rate": 9.74273498079571e-05,
      "loss": 0.058,
      "step": 7078
    },
    {
      "epoch": 0.5130267782730007,
      "grad_norm": 1.8966628313064575,
      "learning_rate": 9.741285600405827e-05,
      "loss": 0.1059,
      "step": 7079
    },
    {
      "epoch": 0.5130992499184694,
      "grad_norm": 3.948863983154297,
      "learning_rate": 9.739836220015944e-05,
      "loss": 0.0509,
      "step": 7080
    },
    {
      "epoch": 0.5131717215639381,
      "grad_norm": 1.172275424003601,
      "learning_rate": 9.738386839626061e-05,
      "loss": 0.0312,
      "step": 7081
    },
    {
      "epoch": 0.5132441932094068,
      "grad_norm": 1.9848724603652954,
      "learning_rate": 9.736937459236178e-05,
      "loss": 0.1172,
      "step": 7082
    },
    {
      "epoch": 0.5133166648548755,
      "grad_norm": 0.7569612264633179,
      "learning_rate": 9.735488078846293e-05,
      "loss": 0.0559,
      "step": 7083
    },
    {
      "epoch": 0.5133891365003442,
      "grad_norm": 1.0940741300582886,
      "learning_rate": 9.73403869845641e-05,
      "loss": 0.0483,
      "step": 7084
    },
    {
      "epoch": 0.513461608145813,
      "grad_norm": 3.143648862838745,
      "learning_rate": 9.732589318066527e-05,
      "loss": 0.1713,
      "step": 7085
    },
    {
      "epoch": 0.5135340797912816,
      "grad_norm": 1.5904066562652588,
      "learning_rate": 9.731139937676643e-05,
      "loss": 0.0752,
      "step": 7086
    },
    {
      "epoch": 0.5136065514367504,
      "grad_norm": 5.30422306060791,
      "learning_rate": 9.72969055728676e-05,
      "loss": 0.0439,
      "step": 7087
    },
    {
      "epoch": 0.5136790230822191,
      "grad_norm": 0.15958446264266968,
      "learning_rate": 9.728241176896877e-05,
      "loss": 0.0063,
      "step": 7088
    },
    {
      "epoch": 0.5137514947276878,
      "grad_norm": 7.022158622741699,
      "learning_rate": 9.726791796506993e-05,
      "loss": 0.0645,
      "step": 7089
    },
    {
      "epoch": 0.5138239663731565,
      "grad_norm": 1.2687065601348877,
      "learning_rate": 9.72534241611711e-05,
      "loss": 0.132,
      "step": 7090
    },
    {
      "epoch": 0.5138964380186252,
      "grad_norm": 3.356851816177368,
      "learning_rate": 9.723893035727227e-05,
      "loss": 0.0489,
      "step": 7091
    },
    {
      "epoch": 0.5139689096640939,
      "grad_norm": 2.601994037628174,
      "learning_rate": 9.722443655337344e-05,
      "loss": 0.1449,
      "step": 7092
    },
    {
      "epoch": 0.5140413813095627,
      "grad_norm": 1.920231819152832,
      "learning_rate": 9.720994274947461e-05,
      "loss": 0.0483,
      "step": 7093
    },
    {
      "epoch": 0.5141138529550313,
      "grad_norm": 1.326079249382019,
      "learning_rate": 9.719544894557578e-05,
      "loss": 0.062,
      "step": 7094
    },
    {
      "epoch": 0.5141863246005001,
      "grad_norm": 1.1631414890289307,
      "learning_rate": 9.718095514167693e-05,
      "loss": 0.0554,
      "step": 7095
    },
    {
      "epoch": 0.5142587962459688,
      "grad_norm": 1.629331350326538,
      "learning_rate": 9.71664613377781e-05,
      "loss": 0.0804,
      "step": 7096
    },
    {
      "epoch": 0.5143312678914375,
      "grad_norm": 1.4262298345565796,
      "learning_rate": 9.715196753387927e-05,
      "loss": 0.0403,
      "step": 7097
    },
    {
      "epoch": 0.5144037395369062,
      "grad_norm": 0.4110907316207886,
      "learning_rate": 9.713747372998043e-05,
      "loss": 0.0087,
      "step": 7098
    },
    {
      "epoch": 0.5144762111823749,
      "grad_norm": 0.6205878257751465,
      "learning_rate": 9.71229799260816e-05,
      "loss": 0.0329,
      "step": 7099
    },
    {
      "epoch": 0.5145486828278436,
      "grad_norm": 0.2436363399028778,
      "learning_rate": 9.710848612218277e-05,
      "loss": 0.0156,
      "step": 7100
    },
    {
      "epoch": 0.5146211544733124,
      "grad_norm": 3.5701777935028076,
      "learning_rate": 9.709399231828393e-05,
      "loss": 0.1035,
      "step": 7101
    },
    {
      "epoch": 0.514693626118781,
      "grad_norm": 3.218465566635132,
      "learning_rate": 9.70794985143851e-05,
      "loss": 0.051,
      "step": 7102
    },
    {
      "epoch": 0.5147660977642498,
      "grad_norm": 1.8837743997573853,
      "learning_rate": 9.706500471048628e-05,
      "loss": 0.0703,
      "step": 7103
    },
    {
      "epoch": 0.5148385694097184,
      "grad_norm": 2.274993896484375,
      "learning_rate": 9.705051090658745e-05,
      "loss": 0.0786,
      "step": 7104
    },
    {
      "epoch": 0.5149110410551871,
      "grad_norm": 1.9139450788497925,
      "learning_rate": 9.70360171026886e-05,
      "loss": 0.136,
      "step": 7105
    },
    {
      "epoch": 0.5149835127006559,
      "grad_norm": 2.928616762161255,
      "learning_rate": 9.702152329878978e-05,
      "loss": 0.1325,
      "step": 7106
    },
    {
      "epoch": 0.5150559843461245,
      "grad_norm": 1.138228416442871,
      "learning_rate": 9.700702949489095e-05,
      "loss": 0.0621,
      "step": 7107
    },
    {
      "epoch": 0.5151284559915933,
      "grad_norm": 1.0478131771087646,
      "learning_rate": 9.69925356909921e-05,
      "loss": 0.0371,
      "step": 7108
    },
    {
      "epoch": 0.515200927637062,
      "grad_norm": 0.6365157961845398,
      "learning_rate": 9.697804188709327e-05,
      "loss": 0.0192,
      "step": 7109
    },
    {
      "epoch": 0.5152733992825307,
      "grad_norm": 1.112958550453186,
      "learning_rate": 9.696354808319444e-05,
      "loss": 0.0528,
      "step": 7110
    },
    {
      "epoch": 0.5153458709279994,
      "grad_norm": 1.2007248401641846,
      "learning_rate": 9.69490542792956e-05,
      "loss": 0.0319,
      "step": 7111
    },
    {
      "epoch": 0.5154183425734681,
      "grad_norm": 3.085867404937744,
      "learning_rate": 9.693456047539677e-05,
      "loss": 0.0891,
      "step": 7112
    },
    {
      "epoch": 0.5154908142189368,
      "grad_norm": 0.2803567051887512,
      "learning_rate": 9.692006667149794e-05,
      "loss": 0.0179,
      "step": 7113
    },
    {
      "epoch": 0.5155632858644056,
      "grad_norm": 0.41015464067459106,
      "learning_rate": 9.690557286759911e-05,
      "loss": 0.0148,
      "step": 7114
    },
    {
      "epoch": 0.5156357575098742,
      "grad_norm": 2.0351529121398926,
      "learning_rate": 9.689107906370028e-05,
      "loss": 0.1101,
      "step": 7115
    },
    {
      "epoch": 0.515708229155343,
      "grad_norm": 1.7494432926177979,
      "learning_rate": 9.687658525980145e-05,
      "loss": 0.0359,
      "step": 7116
    },
    {
      "epoch": 0.5157807008008117,
      "grad_norm": 0.6692002415657043,
      "learning_rate": 9.68620914559026e-05,
      "loss": 0.0414,
      "step": 7117
    },
    {
      "epoch": 0.5158531724462804,
      "grad_norm": 0.488335520029068,
      "learning_rate": 9.684759765200378e-05,
      "loss": 0.032,
      "step": 7118
    },
    {
      "epoch": 0.5159256440917491,
      "grad_norm": 1.5113043785095215,
      "learning_rate": 9.683310384810495e-05,
      "loss": 0.0608,
      "step": 7119
    },
    {
      "epoch": 0.5159981157372178,
      "grad_norm": 3.5164706707000732,
      "learning_rate": 9.68186100442061e-05,
      "loss": 0.1486,
      "step": 7120
    },
    {
      "epoch": 0.5160705873826865,
      "grad_norm": 2.242882490158081,
      "learning_rate": 9.680411624030727e-05,
      "loss": 0.065,
      "step": 7121
    },
    {
      "epoch": 0.5161430590281553,
      "grad_norm": 0.8183522820472717,
      "learning_rate": 9.678962243640844e-05,
      "loss": 0.0131,
      "step": 7122
    },
    {
      "epoch": 0.5162155306736239,
      "grad_norm": 3.453747272491455,
      "learning_rate": 9.67751286325096e-05,
      "loss": 0.0906,
      "step": 7123
    },
    {
      "epoch": 0.5162880023190927,
      "grad_norm": 0.995651125907898,
      "learning_rate": 9.676063482861077e-05,
      "loss": 0.044,
      "step": 7124
    },
    {
      "epoch": 0.5163604739645614,
      "grad_norm": 1.7618136405944824,
      "learning_rate": 9.674614102471194e-05,
      "loss": 0.0558,
      "step": 7125
    },
    {
      "epoch": 0.5164329456100301,
      "grad_norm": 0.5003054738044739,
      "learning_rate": 9.673164722081311e-05,
      "loss": 0.0306,
      "step": 7126
    },
    {
      "epoch": 0.5165054172554988,
      "grad_norm": 4.4672136306762695,
      "learning_rate": 9.671715341691428e-05,
      "loss": 0.1161,
      "step": 7127
    },
    {
      "epoch": 0.5165778889009675,
      "grad_norm": 1.130833387374878,
      "learning_rate": 9.670265961301545e-05,
      "loss": 0.0203,
      "step": 7128
    },
    {
      "epoch": 0.5166503605464362,
      "grad_norm": 0.4009424149990082,
      "learning_rate": 9.66881658091166e-05,
      "loss": 0.0062,
      "step": 7129
    },
    {
      "epoch": 0.516722832191905,
      "grad_norm": 0.4016469717025757,
      "learning_rate": 9.667367200521778e-05,
      "loss": 0.0129,
      "step": 7130
    },
    {
      "epoch": 0.5167953038373736,
      "grad_norm": 2.3135876655578613,
      "learning_rate": 9.665917820131895e-05,
      "loss": 0.034,
      "step": 7131
    },
    {
      "epoch": 0.5168677754828424,
      "grad_norm": 8.730052947998047,
      "learning_rate": 9.66446843974201e-05,
      "loss": 0.2327,
      "step": 7132
    },
    {
      "epoch": 0.5169402471283111,
      "grad_norm": 3.8195717334747314,
      "learning_rate": 9.663019059352127e-05,
      "loss": 0.0902,
      "step": 7133
    },
    {
      "epoch": 0.5170127187737797,
      "grad_norm": 2.9913647174835205,
      "learning_rate": 9.661569678962244e-05,
      "loss": 0.1158,
      "step": 7134
    },
    {
      "epoch": 0.5170851904192485,
      "grad_norm": 2.3079030513763428,
      "learning_rate": 9.66012029857236e-05,
      "loss": 0.0544,
      "step": 7135
    },
    {
      "epoch": 0.5171576620647171,
      "grad_norm": 1.2212326526641846,
      "learning_rate": 9.658670918182477e-05,
      "loss": 0.0543,
      "step": 7136
    },
    {
      "epoch": 0.5172301337101859,
      "grad_norm": 1.260883092880249,
      "learning_rate": 9.657221537792594e-05,
      "loss": 0.0877,
      "step": 7137
    },
    {
      "epoch": 0.5173026053556546,
      "grad_norm": 1.1107345819473267,
      "learning_rate": 9.655772157402711e-05,
      "loss": 0.063,
      "step": 7138
    },
    {
      "epoch": 0.5173750770011233,
      "grad_norm": 1.6760183572769165,
      "learning_rate": 9.654322777012828e-05,
      "loss": 0.0533,
      "step": 7139
    },
    {
      "epoch": 0.517447548646592,
      "grad_norm": 2.128511428833008,
      "learning_rate": 9.652873396622945e-05,
      "loss": 0.1251,
      "step": 7140
    },
    {
      "epoch": 0.5175200202920607,
      "grad_norm": 1.7764233350753784,
      "learning_rate": 9.65142401623306e-05,
      "loss": 0.0796,
      "step": 7141
    },
    {
      "epoch": 0.5175924919375294,
      "grad_norm": 4.9463934898376465,
      "learning_rate": 9.649974635843178e-05,
      "loss": 0.0318,
      "step": 7142
    },
    {
      "epoch": 0.5176649635829982,
      "grad_norm": 2.240849494934082,
      "learning_rate": 9.648525255453295e-05,
      "loss": 0.0919,
      "step": 7143
    },
    {
      "epoch": 0.5177374352284668,
      "grad_norm": 1.9928067922592163,
      "learning_rate": 9.64707587506341e-05,
      "loss": 0.1317,
      "step": 7144
    },
    {
      "epoch": 0.5178099068739356,
      "grad_norm": 4.733988285064697,
      "learning_rate": 9.645626494673527e-05,
      "loss": 0.1006,
      "step": 7145
    },
    {
      "epoch": 0.5178823785194043,
      "grad_norm": 2.653249979019165,
      "learning_rate": 9.644177114283644e-05,
      "loss": 0.1072,
      "step": 7146
    },
    {
      "epoch": 0.517954850164873,
      "grad_norm": 2.4861083030700684,
      "learning_rate": 9.64272773389376e-05,
      "loss": 0.0799,
      "step": 7147
    },
    {
      "epoch": 0.5180273218103417,
      "grad_norm": 0.5338848829269409,
      "learning_rate": 9.641278353503877e-05,
      "loss": 0.0125,
      "step": 7148
    },
    {
      "epoch": 0.5180997934558104,
      "grad_norm": 1.6483534574508667,
      "learning_rate": 9.639828973113994e-05,
      "loss": 0.1228,
      "step": 7149
    },
    {
      "epoch": 0.5181722651012791,
      "grad_norm": 1.3616080284118652,
      "learning_rate": 9.638379592724111e-05,
      "loss": 0.0879,
      "step": 7150
    },
    {
      "epoch": 0.5182447367467479,
      "grad_norm": 2.5277864933013916,
      "learning_rate": 9.636930212334228e-05,
      "loss": 0.1449,
      "step": 7151
    },
    {
      "epoch": 0.5183172083922165,
      "grad_norm": 0.2254648357629776,
      "learning_rate": 9.635480831944345e-05,
      "loss": 0.0155,
      "step": 7152
    },
    {
      "epoch": 0.5183896800376853,
      "grad_norm": 0.5410270690917969,
      "learning_rate": 9.63403145155446e-05,
      "loss": 0.0294,
      "step": 7153
    },
    {
      "epoch": 0.518462151683154,
      "grad_norm": 0.42299729585647583,
      "learning_rate": 9.632582071164578e-05,
      "loss": 0.0251,
      "step": 7154
    },
    {
      "epoch": 0.5185346233286227,
      "grad_norm": 0.8600656390190125,
      "learning_rate": 9.631132690774695e-05,
      "loss": 0.0322,
      "step": 7155
    },
    {
      "epoch": 0.5186070949740914,
      "grad_norm": 6.076005935668945,
      "learning_rate": 9.62968331038481e-05,
      "loss": 0.0648,
      "step": 7156
    },
    {
      "epoch": 0.51867956661956,
      "grad_norm": 1.199514627456665,
      "learning_rate": 9.628233929994927e-05,
      "loss": 0.0792,
      "step": 7157
    },
    {
      "epoch": 0.5187520382650288,
      "grad_norm": 0.492051362991333,
      "learning_rate": 9.626784549605044e-05,
      "loss": 0.0476,
      "step": 7158
    },
    {
      "epoch": 0.5188245099104976,
      "grad_norm": 2.24841046333313,
      "learning_rate": 9.62533516921516e-05,
      "loss": 0.058,
      "step": 7159
    },
    {
      "epoch": 0.5188969815559662,
      "grad_norm": 0.3550395369529724,
      "learning_rate": 9.623885788825278e-05,
      "loss": 0.0149,
      "step": 7160
    },
    {
      "epoch": 0.518969453201435,
      "grad_norm": 0.8351487517356873,
      "learning_rate": 9.622436408435395e-05,
      "loss": 0.0189,
      "step": 7161
    },
    {
      "epoch": 0.5190419248469037,
      "grad_norm": 1.1499969959259033,
      "learning_rate": 9.620987028045511e-05,
      "loss": 0.0703,
      "step": 7162
    },
    {
      "epoch": 0.5191143964923723,
      "grad_norm": 0.5367436408996582,
      "learning_rate": 9.619537647655628e-05,
      "loss": 0.0426,
      "step": 7163
    },
    {
      "epoch": 0.5191868681378411,
      "grad_norm": 0.964329183101654,
      "learning_rate": 9.618088267265745e-05,
      "loss": 0.0605,
      "step": 7164
    },
    {
      "epoch": 0.5192593397833097,
      "grad_norm": 3.026352643966675,
      "learning_rate": 9.61663888687586e-05,
      "loss": 0.0167,
      "step": 7165
    },
    {
      "epoch": 0.5193318114287785,
      "grad_norm": 0.8724679946899414,
      "learning_rate": 9.615189506485978e-05,
      "loss": 0.0491,
      "step": 7166
    },
    {
      "epoch": 0.5194042830742472,
      "grad_norm": 0.4563696086406708,
      "learning_rate": 9.613740126096095e-05,
      "loss": 0.0273,
      "step": 7167
    },
    {
      "epoch": 0.5194767547197159,
      "grad_norm": 1.0484200716018677,
      "learning_rate": 9.61229074570621e-05,
      "loss": 0.0424,
      "step": 7168
    },
    {
      "epoch": 0.5195492263651846,
      "grad_norm": 1.4560784101486206,
      "learning_rate": 9.610841365316327e-05,
      "loss": 0.0489,
      "step": 7169
    },
    {
      "epoch": 0.5196216980106533,
      "grad_norm": 1.4187147617340088,
      "learning_rate": 9.609391984926444e-05,
      "loss": 0.1117,
      "step": 7170
    },
    {
      "epoch": 0.519694169656122,
      "grad_norm": 3.515101671218872,
      "learning_rate": 9.607942604536561e-05,
      "loss": 0.0384,
      "step": 7171
    },
    {
      "epoch": 0.5197666413015908,
      "grad_norm": 1.5895304679870605,
      "learning_rate": 9.606493224146678e-05,
      "loss": 0.0422,
      "step": 7172
    },
    {
      "epoch": 0.5198391129470594,
      "grad_norm": 2.0381035804748535,
      "learning_rate": 9.605043843756795e-05,
      "loss": 0.0946,
      "step": 7173
    },
    {
      "epoch": 0.5199115845925282,
      "grad_norm": 1.8623872995376587,
      "learning_rate": 9.603594463366911e-05,
      "loss": 0.0439,
      "step": 7174
    },
    {
      "epoch": 0.5199840562379969,
      "grad_norm": 3.5756843090057373,
      "learning_rate": 9.602145082977028e-05,
      "loss": 0.0973,
      "step": 7175
    },
    {
      "epoch": 0.5200565278834656,
      "grad_norm": 1.5961302518844604,
      "learning_rate": 9.600695702587145e-05,
      "loss": 0.0636,
      "step": 7176
    },
    {
      "epoch": 0.5201289995289343,
      "grad_norm": 0.35502588748931885,
      "learning_rate": 9.59924632219726e-05,
      "loss": 0.0051,
      "step": 7177
    },
    {
      "epoch": 0.520201471174403,
      "grad_norm": 1.0517504215240479,
      "learning_rate": 9.597796941807378e-05,
      "loss": 0.0613,
      "step": 7178
    },
    {
      "epoch": 0.5202739428198717,
      "grad_norm": 0.6084445118904114,
      "learning_rate": 9.596347561417495e-05,
      "loss": 0.0442,
      "step": 7179
    },
    {
      "epoch": 0.5203464144653405,
      "grad_norm": 1.1595314741134644,
      "learning_rate": 9.59489818102761e-05,
      "loss": 0.0723,
      "step": 7180
    },
    {
      "epoch": 0.5204188861108091,
      "grad_norm": 1.0223197937011719,
      "learning_rate": 9.593448800637727e-05,
      "loss": 0.055,
      "step": 7181
    },
    {
      "epoch": 0.5204913577562779,
      "grad_norm": 5.366363525390625,
      "learning_rate": 9.591999420247844e-05,
      "loss": 0.1434,
      "step": 7182
    },
    {
      "epoch": 0.5205638294017466,
      "grad_norm": 0.7125110626220703,
      "learning_rate": 9.590550039857961e-05,
      "loss": 0.0408,
      "step": 7183
    },
    {
      "epoch": 0.5206363010472153,
      "grad_norm": 1.814663290977478,
      "learning_rate": 9.589100659468078e-05,
      "loss": 0.0515,
      "step": 7184
    },
    {
      "epoch": 0.520708772692684,
      "grad_norm": 1.8063329458236694,
      "learning_rate": 9.587651279078195e-05,
      "loss": 0.0876,
      "step": 7185
    },
    {
      "epoch": 0.5207812443381526,
      "grad_norm": 1.1844793558120728,
      "learning_rate": 9.586201898688312e-05,
      "loss": 0.0202,
      "step": 7186
    },
    {
      "epoch": 0.5208537159836214,
      "grad_norm": 4.905855178833008,
      "learning_rate": 9.584752518298428e-05,
      "loss": 0.0826,
      "step": 7187
    },
    {
      "epoch": 0.5209261876290902,
      "grad_norm": 2.1978321075439453,
      "learning_rate": 9.583303137908545e-05,
      "loss": 0.0934,
      "step": 7188
    },
    {
      "epoch": 0.5209986592745588,
      "grad_norm": 0.682470440864563,
      "learning_rate": 9.581853757518662e-05,
      "loss": 0.0379,
      "step": 7189
    },
    {
      "epoch": 0.5210711309200275,
      "grad_norm": 1.8165050745010376,
      "learning_rate": 9.580404377128778e-05,
      "loss": 0.1294,
      "step": 7190
    },
    {
      "epoch": 0.5211436025654963,
      "grad_norm": 7.7394208908081055,
      "learning_rate": 9.578954996738895e-05,
      "loss": 0.2047,
      "step": 7191
    },
    {
      "epoch": 0.5212160742109649,
      "grad_norm": 2.0162148475646973,
      "learning_rate": 9.577505616349012e-05,
      "loss": 0.0561,
      "step": 7192
    },
    {
      "epoch": 0.5212885458564337,
      "grad_norm": 1.6153250932693481,
      "learning_rate": 9.576056235959127e-05,
      "loss": 0.0345,
      "step": 7193
    },
    {
      "epoch": 0.5213610175019023,
      "grad_norm": 1.5700558423995972,
      "learning_rate": 9.574606855569244e-05,
      "loss": 0.0923,
      "step": 7194
    },
    {
      "epoch": 0.5214334891473711,
      "grad_norm": 1.3896392583847046,
      "learning_rate": 9.573157475179361e-05,
      "loss": 0.0906,
      "step": 7195
    },
    {
      "epoch": 0.5215059607928398,
      "grad_norm": 0.8320673108100891,
      "learning_rate": 9.571708094789478e-05,
      "loss": 0.055,
      "step": 7196
    },
    {
      "epoch": 0.5215784324383085,
      "grad_norm": 1.6453773975372314,
      "learning_rate": 9.570258714399595e-05,
      "loss": 0.2172,
      "step": 7197
    },
    {
      "epoch": 0.5216509040837772,
      "grad_norm": 1.2337831258773804,
      "learning_rate": 9.568809334009712e-05,
      "loss": 0.0917,
      "step": 7198
    },
    {
      "epoch": 0.521723375729246,
      "grad_norm": 0.9115802645683289,
      "learning_rate": 9.567359953619828e-05,
      "loss": 0.0246,
      "step": 7199
    },
    {
      "epoch": 0.5217958473747146,
      "grad_norm": 0.22845369577407837,
      "learning_rate": 9.565910573229945e-05,
      "loss": 0.0105,
      "step": 7200
    },
    {
      "epoch": 0.5218683190201834,
      "grad_norm": 0.3376517593860626,
      "learning_rate": 9.564461192840062e-05,
      "loss": 0.0079,
      "step": 7201
    },
    {
      "epoch": 0.521940790665652,
      "grad_norm": 1.2014464139938354,
      "learning_rate": 9.563011812450178e-05,
      "loss": 0.0458,
      "step": 7202
    },
    {
      "epoch": 0.5220132623111208,
      "grad_norm": 2.045966625213623,
      "learning_rate": 9.561562432060295e-05,
      "loss": 0.0526,
      "step": 7203
    },
    {
      "epoch": 0.5220857339565895,
      "grad_norm": 0.6151227355003357,
      "learning_rate": 9.560113051670412e-05,
      "loss": 0.042,
      "step": 7204
    },
    {
      "epoch": 0.5221582056020582,
      "grad_norm": 2.385709285736084,
      "learning_rate": 9.558663671280527e-05,
      "loss": 0.1175,
      "step": 7205
    },
    {
      "epoch": 0.5222306772475269,
      "grad_norm": 2.6132731437683105,
      "learning_rate": 9.557214290890644e-05,
      "loss": 0.0839,
      "step": 7206
    },
    {
      "epoch": 0.5223031488929956,
      "grad_norm": 3.608898878097534,
      "learning_rate": 9.555764910500761e-05,
      "loss": 0.1729,
      "step": 7207
    },
    {
      "epoch": 0.5223756205384643,
      "grad_norm": 2.151498317718506,
      "learning_rate": 9.554315530110878e-05,
      "loss": 0.1118,
      "step": 7208
    },
    {
      "epoch": 0.5224480921839331,
      "grad_norm": 0.6047739386558533,
      "learning_rate": 9.552866149720995e-05,
      "loss": 0.0242,
      "step": 7209
    },
    {
      "epoch": 0.5225205638294017,
      "grad_norm": 3.337742567062378,
      "learning_rate": 9.551416769331112e-05,
      "loss": 0.2131,
      "step": 7210
    },
    {
      "epoch": 0.5225930354748705,
      "grad_norm": 1.1123936176300049,
      "learning_rate": 9.549967388941228e-05,
      "loss": 0.0808,
      "step": 7211
    },
    {
      "epoch": 0.5226655071203392,
      "grad_norm": 2.150195360183716,
      "learning_rate": 9.548518008551345e-05,
      "loss": 0.1302,
      "step": 7212
    },
    {
      "epoch": 0.5227379787658079,
      "grad_norm": 2.9291927814483643,
      "learning_rate": 9.547068628161462e-05,
      "loss": 0.0722,
      "step": 7213
    },
    {
      "epoch": 0.5228104504112766,
      "grad_norm": 0.7299742698669434,
      "learning_rate": 9.545619247771577e-05,
      "loss": 0.0321,
      "step": 7214
    },
    {
      "epoch": 0.5228829220567452,
      "grad_norm": 0.6567638516426086,
      "learning_rate": 9.544169867381694e-05,
      "loss": 0.063,
      "step": 7215
    },
    {
      "epoch": 0.522955393702214,
      "grad_norm": 2.6404976844787598,
      "learning_rate": 9.542720486991811e-05,
      "loss": 0.1034,
      "step": 7216
    },
    {
      "epoch": 0.5230278653476828,
      "grad_norm": 1.608048677444458,
      "learning_rate": 9.541271106601927e-05,
      "loss": 0.1052,
      "step": 7217
    },
    {
      "epoch": 0.5231003369931514,
      "grad_norm": 0.6506344676017761,
      "learning_rate": 9.539821726212046e-05,
      "loss": 0.0301,
      "step": 7218
    },
    {
      "epoch": 0.5231728086386201,
      "grad_norm": 0.4321652352809906,
      "learning_rate": 9.538372345822163e-05,
      "loss": 0.0422,
      "step": 7219
    },
    {
      "epoch": 0.5232452802840889,
      "grad_norm": 1.4271736145019531,
      "learning_rate": 9.536922965432278e-05,
      "loss": 0.0137,
      "step": 7220
    },
    {
      "epoch": 0.5233177519295575,
      "grad_norm": 0.12511494755744934,
      "learning_rate": 9.535473585042395e-05,
      "loss": 0.0037,
      "step": 7221
    },
    {
      "epoch": 0.5233902235750263,
      "grad_norm": 0.7665463089942932,
      "learning_rate": 9.534024204652512e-05,
      "loss": 0.0498,
      "step": 7222
    },
    {
      "epoch": 0.5234626952204949,
      "grad_norm": 0.8359471559524536,
      "learning_rate": 9.532574824262628e-05,
      "loss": 0.0437,
      "step": 7223
    },
    {
      "epoch": 0.5235351668659637,
      "grad_norm": 1.093802809715271,
      "learning_rate": 9.531125443872745e-05,
      "loss": 0.096,
      "step": 7224
    },
    {
      "epoch": 0.5236076385114324,
      "grad_norm": 1.8606505393981934,
      "learning_rate": 9.529676063482862e-05,
      "loss": 0.052,
      "step": 7225
    },
    {
      "epoch": 0.5236801101569011,
      "grad_norm": 1.504725694656372,
      "learning_rate": 9.528226683092977e-05,
      "loss": 0.0671,
      "step": 7226
    },
    {
      "epoch": 0.5237525818023698,
      "grad_norm": 0.41559112071990967,
      "learning_rate": 9.526777302703094e-05,
      "loss": 0.0163,
      "step": 7227
    },
    {
      "epoch": 0.5238250534478386,
      "grad_norm": 2.9556338787078857,
      "learning_rate": 9.525327922313211e-05,
      "loss": 0.077,
      "step": 7228
    },
    {
      "epoch": 0.5238975250933072,
      "grad_norm": 1.0387282371520996,
      "learning_rate": 9.523878541923328e-05,
      "loss": 0.0901,
      "step": 7229
    },
    {
      "epoch": 0.523969996738776,
      "grad_norm": 2.374864339828491,
      "learning_rate": 9.522429161533445e-05,
      "loss": 0.0643,
      "step": 7230
    },
    {
      "epoch": 0.5240424683842446,
      "grad_norm": 1.5274631977081299,
      "learning_rate": 9.520979781143562e-05,
      "loss": 0.0499,
      "step": 7231
    },
    {
      "epoch": 0.5241149400297134,
      "grad_norm": 0.7342658042907715,
      "learning_rate": 9.519530400753678e-05,
      "loss": 0.031,
      "step": 7232
    },
    {
      "epoch": 0.5241874116751821,
      "grad_norm": 1.6295143365859985,
      "learning_rate": 9.518081020363795e-05,
      "loss": 0.1047,
      "step": 7233
    },
    {
      "epoch": 0.5242598833206508,
      "grad_norm": 1.1901229619979858,
      "learning_rate": 9.516631639973912e-05,
      "loss": 0.0706,
      "step": 7234
    },
    {
      "epoch": 0.5243323549661195,
      "grad_norm": 4.782123565673828,
      "learning_rate": 9.515182259584028e-05,
      "loss": 0.0499,
      "step": 7235
    },
    {
      "epoch": 0.5244048266115883,
      "grad_norm": 4.463305473327637,
      "learning_rate": 9.513732879194145e-05,
      "loss": 0.1346,
      "step": 7236
    },
    {
      "epoch": 0.5244772982570569,
      "grad_norm": 2.41898512840271,
      "learning_rate": 9.512283498804262e-05,
      "loss": 0.1319,
      "step": 7237
    },
    {
      "epoch": 0.5245497699025257,
      "grad_norm": 0.746376633644104,
      "learning_rate": 9.510834118414377e-05,
      "loss": 0.0094,
      "step": 7238
    },
    {
      "epoch": 0.5246222415479943,
      "grad_norm": 0.3752020597457886,
      "learning_rate": 9.509384738024494e-05,
      "loss": 0.0259,
      "step": 7239
    },
    {
      "epoch": 0.5246947131934631,
      "grad_norm": 1.0087147951126099,
      "learning_rate": 9.507935357634611e-05,
      "loss": 0.0207,
      "step": 7240
    },
    {
      "epoch": 0.5247671848389318,
      "grad_norm": 2.29435133934021,
      "learning_rate": 9.506485977244728e-05,
      "loss": 0.1309,
      "step": 7241
    },
    {
      "epoch": 0.5248396564844005,
      "grad_norm": 1.3378748893737793,
      "learning_rate": 9.505036596854845e-05,
      "loss": 0.0422,
      "step": 7242
    },
    {
      "epoch": 0.5249121281298692,
      "grad_norm": 4.548930644989014,
      "learning_rate": 9.503587216464962e-05,
      "loss": 0.1476,
      "step": 7243
    },
    {
      "epoch": 0.5249845997753378,
      "grad_norm": 0.48497259616851807,
      "learning_rate": 9.502137836075078e-05,
      "loss": 0.0175,
      "step": 7244
    },
    {
      "epoch": 0.5250570714208066,
      "grad_norm": 1.5854800939559937,
      "learning_rate": 9.500688455685195e-05,
      "loss": 0.0371,
      "step": 7245
    },
    {
      "epoch": 0.5251295430662754,
      "grad_norm": 1.2228840589523315,
      "learning_rate": 9.499239075295312e-05,
      "loss": 0.0663,
      "step": 7246
    },
    {
      "epoch": 0.525202014711744,
      "grad_norm": 0.5760540962219238,
      "learning_rate": 9.497789694905428e-05,
      "loss": 0.0219,
      "step": 7247
    },
    {
      "epoch": 0.5252744863572127,
      "grad_norm": 0.21605713665485382,
      "learning_rate": 9.496340314515545e-05,
      "loss": 0.0031,
      "step": 7248
    },
    {
      "epoch": 0.5253469580026815,
      "grad_norm": 0.7322644591331482,
      "learning_rate": 9.494890934125662e-05,
      "loss": 0.0294,
      "step": 7249
    },
    {
      "epoch": 0.5254194296481501,
      "grad_norm": 2.8412065505981445,
      "learning_rate": 9.493441553735777e-05,
      "loss": 0.0926,
      "step": 7250
    },
    {
      "epoch": 0.5254919012936189,
      "grad_norm": 2.5941414833068848,
      "learning_rate": 9.491992173345894e-05,
      "loss": 0.0367,
      "step": 7251
    },
    {
      "epoch": 0.5255643729390875,
      "grad_norm": 1.186707854270935,
      "learning_rate": 9.490542792956011e-05,
      "loss": 0.03,
      "step": 7252
    },
    {
      "epoch": 0.5256368445845563,
      "grad_norm": 1.2059173583984375,
      "learning_rate": 9.489093412566128e-05,
      "loss": 0.0609,
      "step": 7253
    },
    {
      "epoch": 0.525709316230025,
      "grad_norm": 1.170152187347412,
      "learning_rate": 9.487644032176245e-05,
      "loss": 0.0415,
      "step": 7254
    },
    {
      "epoch": 0.5257817878754937,
      "grad_norm": 1.615403175354004,
      "learning_rate": 9.486194651786362e-05,
      "loss": 0.039,
      "step": 7255
    },
    {
      "epoch": 0.5258542595209624,
      "grad_norm": 1.0601540803909302,
      "learning_rate": 9.484745271396478e-05,
      "loss": 0.0266,
      "step": 7256
    },
    {
      "epoch": 0.5259267311664312,
      "grad_norm": 3.821296453475952,
      "learning_rate": 9.483295891006595e-05,
      "loss": 0.1538,
      "step": 7257
    },
    {
      "epoch": 0.5259992028118998,
      "grad_norm": 4.207837104797363,
      "learning_rate": 9.481846510616712e-05,
      "loss": 0.2103,
      "step": 7258
    },
    {
      "epoch": 0.5260716744573686,
      "grad_norm": 4.373970031738281,
      "learning_rate": 9.480397130226828e-05,
      "loss": 0.0544,
      "step": 7259
    },
    {
      "epoch": 0.5261441461028372,
      "grad_norm": 0.6958318948745728,
      "learning_rate": 9.478947749836945e-05,
      "loss": 0.014,
      "step": 7260
    },
    {
      "epoch": 0.526216617748306,
      "grad_norm": 0.08241399377584457,
      "learning_rate": 9.477498369447062e-05,
      "loss": 0.0018,
      "step": 7261
    },
    {
      "epoch": 0.5262890893937747,
      "grad_norm": 2.5535199642181396,
      "learning_rate": 9.476048989057177e-05,
      "loss": 0.0331,
      "step": 7262
    },
    {
      "epoch": 0.5263615610392434,
      "grad_norm": 3.201629638671875,
      "learning_rate": 9.474599608667294e-05,
      "loss": 0.2055,
      "step": 7263
    },
    {
      "epoch": 0.5264340326847121,
      "grad_norm": 2.615665912628174,
      "learning_rate": 9.473150228277411e-05,
      "loss": 0.103,
      "step": 7264
    },
    {
      "epoch": 0.5265065043301809,
      "grad_norm": 3.0891082286834717,
      "learning_rate": 9.471700847887528e-05,
      "loss": 0.1281,
      "step": 7265
    },
    {
      "epoch": 0.5265789759756495,
      "grad_norm": 2.409301519393921,
      "learning_rate": 9.470251467497645e-05,
      "loss": 0.1022,
      "step": 7266
    },
    {
      "epoch": 0.5266514476211183,
      "grad_norm": 6.089095592498779,
      "learning_rate": 9.468802087107762e-05,
      "loss": 0.0876,
      "step": 7267
    },
    {
      "epoch": 0.5267239192665869,
      "grad_norm": 1.6525405645370483,
      "learning_rate": 9.46735270671788e-05,
      "loss": 0.0975,
      "step": 7268
    },
    {
      "epoch": 0.5267963909120557,
      "grad_norm": 4.179037570953369,
      "learning_rate": 9.465903326327995e-05,
      "loss": 0.0846,
      "step": 7269
    },
    {
      "epoch": 0.5268688625575244,
      "grad_norm": 6.657250881195068,
      "learning_rate": 9.464453945938112e-05,
      "loss": 0.1234,
      "step": 7270
    },
    {
      "epoch": 0.526941334202993,
      "grad_norm": 0.21365933120250702,
      "learning_rate": 9.463004565548229e-05,
      "loss": 0.0056,
      "step": 7271
    },
    {
      "epoch": 0.5270138058484618,
      "grad_norm": 0.48719632625579834,
      "learning_rate": 9.461555185158345e-05,
      "loss": 0.0161,
      "step": 7272
    },
    {
      "epoch": 0.5270862774939306,
      "grad_norm": 0.22499124705791473,
      "learning_rate": 9.460105804768462e-05,
      "loss": 0.0074,
      "step": 7273
    },
    {
      "epoch": 0.5271587491393992,
      "grad_norm": 5.121241569519043,
      "learning_rate": 9.458656424378579e-05,
      "loss": 0.2994,
      "step": 7274
    },
    {
      "epoch": 0.527231220784868,
      "grad_norm": 0.9297705888748169,
      "learning_rate": 9.457207043988694e-05,
      "loss": 0.0621,
      "step": 7275
    },
    {
      "epoch": 0.5273036924303366,
      "grad_norm": 2.6648709774017334,
      "learning_rate": 9.455757663598813e-05,
      "loss": 0.159,
      "step": 7276
    },
    {
      "epoch": 0.5273761640758053,
      "grad_norm": 2.6727535724639893,
      "learning_rate": 9.45430828320893e-05,
      "loss": 0.1448,
      "step": 7277
    },
    {
      "epoch": 0.5274486357212741,
      "grad_norm": 1.6268844604492188,
      "learning_rate": 9.452858902819045e-05,
      "loss": 0.0582,
      "step": 7278
    },
    {
      "epoch": 0.5275211073667427,
      "grad_norm": 2.5455102920532227,
      "learning_rate": 9.451409522429162e-05,
      "loss": 0.0981,
      "step": 7279
    },
    {
      "epoch": 0.5275935790122115,
      "grad_norm": 2.5340840816497803,
      "learning_rate": 9.44996014203928e-05,
      "loss": 0.1878,
      "step": 7280
    },
    {
      "epoch": 0.5276660506576801,
      "grad_norm": 1.4717469215393066,
      "learning_rate": 9.448510761649395e-05,
      "loss": 0.0524,
      "step": 7281
    },
    {
      "epoch": 0.5277385223031489,
      "grad_norm": 2.4261839389801025,
      "learning_rate": 9.447061381259512e-05,
      "loss": 0.0853,
      "step": 7282
    },
    {
      "epoch": 0.5278109939486176,
      "grad_norm": 1.6068331003189087,
      "learning_rate": 9.445612000869629e-05,
      "loss": 0.062,
      "step": 7283
    },
    {
      "epoch": 0.5278834655940863,
      "grad_norm": 0.691423773765564,
      "learning_rate": 9.444162620479745e-05,
      "loss": 0.031,
      "step": 7284
    },
    {
      "epoch": 0.527955937239555,
      "grad_norm": 1.4609345197677612,
      "learning_rate": 9.442713240089862e-05,
      "loss": 0.1322,
      "step": 7285
    },
    {
      "epoch": 0.5280284088850238,
      "grad_norm": 1.196784496307373,
      "learning_rate": 9.441263859699979e-05,
      "loss": 0.0531,
      "step": 7286
    },
    {
      "epoch": 0.5281008805304924,
      "grad_norm": 0.20459671318531036,
      "learning_rate": 9.439814479310096e-05,
      "loss": 0.0051,
      "step": 7287
    },
    {
      "epoch": 0.5281733521759612,
      "grad_norm": 1.0671417713165283,
      "learning_rate": 9.438365098920213e-05,
      "loss": 0.059,
      "step": 7288
    },
    {
      "epoch": 0.5282458238214298,
      "grad_norm": 0.7298215627670288,
      "learning_rate": 9.43691571853033e-05,
      "loss": 0.019,
      "step": 7289
    },
    {
      "epoch": 0.5283182954668986,
      "grad_norm": 0.9512020945549011,
      "learning_rate": 9.435466338140445e-05,
      "loss": 0.0843,
      "step": 7290
    },
    {
      "epoch": 0.5283907671123673,
      "grad_norm": 1.0768274068832397,
      "learning_rate": 9.434016957750562e-05,
      "loss": 0.0922,
      "step": 7291
    },
    {
      "epoch": 0.528463238757836,
      "grad_norm": 1.18889319896698,
      "learning_rate": 9.43256757736068e-05,
      "loss": 0.0468,
      "step": 7292
    },
    {
      "epoch": 0.5285357104033047,
      "grad_norm": 3.278219223022461,
      "learning_rate": 9.431118196970795e-05,
      "loss": 0.087,
      "step": 7293
    },
    {
      "epoch": 0.5286081820487735,
      "grad_norm": 1.6340200901031494,
      "learning_rate": 9.429668816580912e-05,
      "loss": 0.0776,
      "step": 7294
    },
    {
      "epoch": 0.5286806536942421,
      "grad_norm": 1.2770296335220337,
      "learning_rate": 9.428219436191029e-05,
      "loss": 0.0926,
      "step": 7295
    },
    {
      "epoch": 0.5287531253397109,
      "grad_norm": 2.555450677871704,
      "learning_rate": 9.426770055801145e-05,
      "loss": 0.0249,
      "step": 7296
    },
    {
      "epoch": 0.5288255969851795,
      "grad_norm": 1.0975053310394287,
      "learning_rate": 9.425320675411262e-05,
      "loss": 0.061,
      "step": 7297
    },
    {
      "epoch": 0.5288980686306483,
      "grad_norm": 3.137320041656494,
      "learning_rate": 9.423871295021379e-05,
      "loss": 0.1459,
      "step": 7298
    },
    {
      "epoch": 0.528970540276117,
      "grad_norm": 1.9301561117172241,
      "learning_rate": 9.422421914631496e-05,
      "loss": 0.0621,
      "step": 7299
    },
    {
      "epoch": 0.5290430119215856,
      "grad_norm": 3.417111396789551,
      "learning_rate": 9.420972534241613e-05,
      "loss": 0.1027,
      "step": 7300
    },
    {
      "epoch": 0.5291154835670544,
      "grad_norm": 0.9585831165313721,
      "learning_rate": 9.41952315385173e-05,
      "loss": 0.0371,
      "step": 7301
    },
    {
      "epoch": 0.5291879552125232,
      "grad_norm": 0.7094593048095703,
      "learning_rate": 9.418073773461845e-05,
      "loss": 0.0209,
      "step": 7302
    },
    {
      "epoch": 0.5292604268579918,
      "grad_norm": 1.3514492511749268,
      "learning_rate": 9.416624393071962e-05,
      "loss": 0.0628,
      "step": 7303
    },
    {
      "epoch": 0.5293328985034605,
      "grad_norm": 0.45093977451324463,
      "learning_rate": 9.41517501268208e-05,
      "loss": 0.0265,
      "step": 7304
    },
    {
      "epoch": 0.5294053701489292,
      "grad_norm": 0.21013791859149933,
      "learning_rate": 9.413725632292195e-05,
      "loss": 0.0067,
      "step": 7305
    },
    {
      "epoch": 0.5294778417943979,
      "grad_norm": 0.714474081993103,
      "learning_rate": 9.412276251902312e-05,
      "loss": 0.0396,
      "step": 7306
    },
    {
      "epoch": 0.5295503134398667,
      "grad_norm": 0.5922716856002808,
      "learning_rate": 9.410826871512429e-05,
      "loss": 0.0173,
      "step": 7307
    },
    {
      "epoch": 0.5296227850853353,
      "grad_norm": 1.8078629970550537,
      "learning_rate": 9.409377491122545e-05,
      "loss": 0.0624,
      "step": 7308
    },
    {
      "epoch": 0.5296952567308041,
      "grad_norm": 1.5189893245697021,
      "learning_rate": 9.407928110732662e-05,
      "loss": 0.0939,
      "step": 7309
    },
    {
      "epoch": 0.5297677283762727,
      "grad_norm": 1.3528871536254883,
      "learning_rate": 9.406478730342779e-05,
      "loss": 0.0614,
      "step": 7310
    },
    {
      "epoch": 0.5298402000217415,
      "grad_norm": 0.7172861695289612,
      "learning_rate": 9.405029349952896e-05,
      "loss": 0.0659,
      "step": 7311
    },
    {
      "epoch": 0.5299126716672102,
      "grad_norm": 1.9493948221206665,
      "learning_rate": 9.403579969563013e-05,
      "loss": 0.0606,
      "step": 7312
    },
    {
      "epoch": 0.5299851433126789,
      "grad_norm": 1.1096152067184448,
      "learning_rate": 9.40213058917313e-05,
      "loss": 0.0605,
      "step": 7313
    },
    {
      "epoch": 0.5300576149581476,
      "grad_norm": 0.7883574366569519,
      "learning_rate": 9.400681208783245e-05,
      "loss": 0.0455,
      "step": 7314
    },
    {
      "epoch": 0.5301300866036164,
      "grad_norm": 0.6049588918685913,
      "learning_rate": 9.399231828393362e-05,
      "loss": 0.0415,
      "step": 7315
    },
    {
      "epoch": 0.530202558249085,
      "grad_norm": 1.263352632522583,
      "learning_rate": 9.39778244800348e-05,
      "loss": 0.0729,
      "step": 7316
    },
    {
      "epoch": 0.5302750298945538,
      "grad_norm": 0.7122117877006531,
      "learning_rate": 9.396333067613595e-05,
      "loss": 0.0281,
      "step": 7317
    },
    {
      "epoch": 0.5303475015400224,
      "grad_norm": 0.6698083877563477,
      "learning_rate": 9.394883687223712e-05,
      "loss": 0.0386,
      "step": 7318
    },
    {
      "epoch": 0.5304199731854912,
      "grad_norm": 3.8751347064971924,
      "learning_rate": 9.393434306833829e-05,
      "loss": 0.0799,
      "step": 7319
    },
    {
      "epoch": 0.5304924448309599,
      "grad_norm": 0.5006252527236938,
      "learning_rate": 9.391984926443945e-05,
      "loss": 0.0333,
      "step": 7320
    },
    {
      "epoch": 0.5305649164764286,
      "grad_norm": 0.5836161375045776,
      "learning_rate": 9.390535546054062e-05,
      "loss": 0.0357,
      "step": 7321
    },
    {
      "epoch": 0.5306373881218973,
      "grad_norm": 1.117471694946289,
      "learning_rate": 9.389086165664179e-05,
      "loss": 0.0267,
      "step": 7322
    },
    {
      "epoch": 0.5307098597673661,
      "grad_norm": 0.7118715643882751,
      "learning_rate": 9.387636785274296e-05,
      "loss": 0.0138,
      "step": 7323
    },
    {
      "epoch": 0.5307823314128347,
      "grad_norm": 0.5979272127151489,
      "learning_rate": 9.386187404884413e-05,
      "loss": 0.0171,
      "step": 7324
    },
    {
      "epoch": 0.5308548030583035,
      "grad_norm": 2.2265055179595947,
      "learning_rate": 9.38473802449453e-05,
      "loss": 0.0892,
      "step": 7325
    },
    {
      "epoch": 0.5309272747037721,
      "grad_norm": 0.7342835664749146,
      "learning_rate": 9.383288644104645e-05,
      "loss": 0.0606,
      "step": 7326
    },
    {
      "epoch": 0.5309997463492409,
      "grad_norm": 2.0130860805511475,
      "learning_rate": 9.381839263714762e-05,
      "loss": 0.0648,
      "step": 7327
    },
    {
      "epoch": 0.5310722179947096,
      "grad_norm": 1.9176331758499146,
      "learning_rate": 9.38038988332488e-05,
      "loss": 0.0896,
      "step": 7328
    },
    {
      "epoch": 0.5311446896401782,
      "grad_norm": 0.6125084757804871,
      "learning_rate": 9.378940502934995e-05,
      "loss": 0.0427,
      "step": 7329
    },
    {
      "epoch": 0.531217161285647,
      "grad_norm": 0.8430200815200806,
      "learning_rate": 9.377491122545112e-05,
      "loss": 0.0547,
      "step": 7330
    },
    {
      "epoch": 0.5312896329311158,
      "grad_norm": 1.1416696310043335,
      "learning_rate": 9.376041742155229e-05,
      "loss": 0.0491,
      "step": 7331
    },
    {
      "epoch": 0.5313621045765844,
      "grad_norm": 1.3619784116744995,
      "learning_rate": 9.374592361765345e-05,
      "loss": 0.0746,
      "step": 7332
    },
    {
      "epoch": 0.5314345762220531,
      "grad_norm": 0.3865720331668854,
      "learning_rate": 9.373142981375463e-05,
      "loss": 0.0175,
      "step": 7333
    },
    {
      "epoch": 0.5315070478675218,
      "grad_norm": 2.9519026279449463,
      "learning_rate": 9.37169360098558e-05,
      "loss": 0.098,
      "step": 7334
    },
    {
      "epoch": 0.5315795195129905,
      "grad_norm": 2.981611967086792,
      "learning_rate": 9.370244220595696e-05,
      "loss": 0.1403,
      "step": 7335
    },
    {
      "epoch": 0.5316519911584593,
      "grad_norm": 2.2106268405914307,
      "learning_rate": 9.368794840205813e-05,
      "loss": 0.0414,
      "step": 7336
    },
    {
      "epoch": 0.5317244628039279,
      "grad_norm": 0.7093416452407837,
      "learning_rate": 9.36734545981593e-05,
      "loss": 0.0472,
      "step": 7337
    },
    {
      "epoch": 0.5317969344493967,
      "grad_norm": 1.9623621702194214,
      "learning_rate": 9.365896079426045e-05,
      "loss": 0.0594,
      "step": 7338
    },
    {
      "epoch": 0.5318694060948654,
      "grad_norm": 0.13763023912906647,
      "learning_rate": 9.364446699036162e-05,
      "loss": 0.0037,
      "step": 7339
    },
    {
      "epoch": 0.5319418777403341,
      "grad_norm": 0.7583975791931152,
      "learning_rate": 9.362997318646279e-05,
      "loss": 0.0411,
      "step": 7340
    },
    {
      "epoch": 0.5320143493858028,
      "grad_norm": 0.13490308821201324,
      "learning_rate": 9.361547938256395e-05,
      "loss": 0.0041,
      "step": 7341
    },
    {
      "epoch": 0.5320868210312715,
      "grad_norm": 0.9678626656532288,
      "learning_rate": 9.360098557866512e-05,
      "loss": 0.0446,
      "step": 7342
    },
    {
      "epoch": 0.5321592926767402,
      "grad_norm": 2.5006892681121826,
      "learning_rate": 9.358649177476629e-05,
      "loss": 0.0822,
      "step": 7343
    },
    {
      "epoch": 0.532231764322209,
      "grad_norm": 1.291449785232544,
      "learning_rate": 9.357199797086746e-05,
      "loss": 0.0625,
      "step": 7344
    },
    {
      "epoch": 0.5323042359676776,
      "grad_norm": 4.560752868652344,
      "learning_rate": 9.355750416696863e-05,
      "loss": 0.1642,
      "step": 7345
    },
    {
      "epoch": 0.5323767076131464,
      "grad_norm": 1.7953038215637207,
      "learning_rate": 9.35430103630698e-05,
      "loss": 0.0574,
      "step": 7346
    },
    {
      "epoch": 0.532449179258615,
      "grad_norm": 1.3531602621078491,
      "learning_rate": 9.352851655917097e-05,
      "loss": 0.0131,
      "step": 7347
    },
    {
      "epoch": 0.5325216509040838,
      "grad_norm": 2.232940435409546,
      "learning_rate": 9.351402275527213e-05,
      "loss": 0.1178,
      "step": 7348
    },
    {
      "epoch": 0.5325941225495525,
      "grad_norm": 2.508176326751709,
      "learning_rate": 9.34995289513733e-05,
      "loss": 0.1314,
      "step": 7349
    },
    {
      "epoch": 0.5326665941950212,
      "grad_norm": 2.683556318283081,
      "learning_rate": 9.348503514747447e-05,
      "loss": 0.0666,
      "step": 7350
    },
    {
      "epoch": 0.5327390658404899,
      "grad_norm": 0.6857286691665649,
      "learning_rate": 9.347054134357562e-05,
      "loss": 0.0496,
      "step": 7351
    },
    {
      "epoch": 0.5328115374859587,
      "grad_norm": 3.4922046661376953,
      "learning_rate": 9.345604753967679e-05,
      "loss": 0.2015,
      "step": 7352
    },
    {
      "epoch": 0.5328840091314273,
      "grad_norm": 2.469984292984009,
      "learning_rate": 9.344155373577796e-05,
      "loss": 0.0769,
      "step": 7353
    },
    {
      "epoch": 0.5329564807768961,
      "grad_norm": 0.7703973650932312,
      "learning_rate": 9.342705993187912e-05,
      "loss": 0.0548,
      "step": 7354
    },
    {
      "epoch": 0.5330289524223647,
      "grad_norm": 0.11574618518352509,
      "learning_rate": 9.341256612798029e-05,
      "loss": 0.002,
      "step": 7355
    },
    {
      "epoch": 0.5331014240678335,
      "grad_norm": 1.7084258794784546,
      "learning_rate": 9.339807232408146e-05,
      "loss": 0.0495,
      "step": 7356
    },
    {
      "epoch": 0.5331738957133022,
      "grad_norm": 0.42896631360054016,
      "learning_rate": 9.338357852018263e-05,
      "loss": 0.0153,
      "step": 7357
    },
    {
      "epoch": 0.5332463673587708,
      "grad_norm": 0.5228095650672913,
      "learning_rate": 9.33690847162838e-05,
      "loss": 0.0324,
      "step": 7358
    },
    {
      "epoch": 0.5333188390042396,
      "grad_norm": 0.6790809035301208,
      "learning_rate": 9.335459091238497e-05,
      "loss": 0.0409,
      "step": 7359
    },
    {
      "epoch": 0.5333913106497084,
      "grad_norm": 1.4035003185272217,
      "learning_rate": 9.334009710848613e-05,
      "loss": 0.0856,
      "step": 7360
    },
    {
      "epoch": 0.533463782295177,
      "grad_norm": 1.0765107870101929,
      "learning_rate": 9.33256033045873e-05,
      "loss": 0.0405,
      "step": 7361
    },
    {
      "epoch": 0.5335362539406457,
      "grad_norm": 0.42849719524383545,
      "learning_rate": 9.331110950068847e-05,
      "loss": 0.0557,
      "step": 7362
    },
    {
      "epoch": 0.5336087255861144,
      "grad_norm": 2.7866852283477783,
      "learning_rate": 9.329661569678962e-05,
      "loss": 0.0656,
      "step": 7363
    },
    {
      "epoch": 0.5336811972315831,
      "grad_norm": 0.7094112038612366,
      "learning_rate": 9.328212189289079e-05,
      "loss": 0.051,
      "step": 7364
    },
    {
      "epoch": 0.5337536688770519,
      "grad_norm": 1.6158052682876587,
      "learning_rate": 9.326762808899196e-05,
      "loss": 0.0718,
      "step": 7365
    },
    {
      "epoch": 0.5338261405225205,
      "grad_norm": 0.8953075408935547,
      "learning_rate": 9.325313428509312e-05,
      "loss": 0.0563,
      "step": 7366
    },
    {
      "epoch": 0.5338986121679893,
      "grad_norm": 0.441152423620224,
      "learning_rate": 9.323864048119429e-05,
      "loss": 0.0214,
      "step": 7367
    },
    {
      "epoch": 0.533971083813458,
      "grad_norm": 1.494591474533081,
      "learning_rate": 9.322414667729546e-05,
      "loss": 0.0879,
      "step": 7368
    },
    {
      "epoch": 0.5340435554589267,
      "grad_norm": 1.9312022924423218,
      "learning_rate": 9.320965287339663e-05,
      "loss": 0.2021,
      "step": 7369
    },
    {
      "epoch": 0.5341160271043954,
      "grad_norm": 0.5479752421379089,
      "learning_rate": 9.31951590694978e-05,
      "loss": 0.03,
      "step": 7370
    },
    {
      "epoch": 0.5341884987498641,
      "grad_norm": 0.6220763921737671,
      "learning_rate": 9.318066526559897e-05,
      "loss": 0.0658,
      "step": 7371
    },
    {
      "epoch": 0.5342609703953328,
      "grad_norm": 1.484498381614685,
      "learning_rate": 9.316617146170013e-05,
      "loss": 0.1047,
      "step": 7372
    },
    {
      "epoch": 0.5343334420408016,
      "grad_norm": 0.5534788370132446,
      "learning_rate": 9.31516776578013e-05,
      "loss": 0.0442,
      "step": 7373
    },
    {
      "epoch": 0.5344059136862702,
      "grad_norm": 0.3118498921394348,
      "learning_rate": 9.313718385390247e-05,
      "loss": 0.0108,
      "step": 7374
    },
    {
      "epoch": 0.534478385331739,
      "grad_norm": 2.586709499359131,
      "learning_rate": 9.312269005000362e-05,
      "loss": 0.1782,
      "step": 7375
    },
    {
      "epoch": 0.5345508569772077,
      "grad_norm": 1.6963839530944824,
      "learning_rate": 9.310819624610479e-05,
      "loss": 0.0447,
      "step": 7376
    },
    {
      "epoch": 0.5346233286226764,
      "grad_norm": 0.8945173025131226,
      "learning_rate": 9.309370244220596e-05,
      "loss": 0.0581,
      "step": 7377
    },
    {
      "epoch": 0.5346958002681451,
      "grad_norm": 0.4288965165615082,
      "learning_rate": 9.307920863830712e-05,
      "loss": 0.0293,
      "step": 7378
    },
    {
      "epoch": 0.5347682719136138,
      "grad_norm": 1.3690959215164185,
      "learning_rate": 9.306471483440829e-05,
      "loss": 0.0643,
      "step": 7379
    },
    {
      "epoch": 0.5348407435590825,
      "grad_norm": 2.468449115753174,
      "learning_rate": 9.305022103050946e-05,
      "loss": 0.1092,
      "step": 7380
    },
    {
      "epoch": 0.5349132152045513,
      "grad_norm": 0.6446006298065186,
      "learning_rate": 9.303572722661063e-05,
      "loss": 0.0583,
      "step": 7381
    },
    {
      "epoch": 0.5349856868500199,
      "grad_norm": 0.7795251607894897,
      "learning_rate": 9.30212334227118e-05,
      "loss": 0.0707,
      "step": 7382
    },
    {
      "epoch": 0.5350581584954887,
      "grad_norm": 0.8890417814254761,
      "learning_rate": 9.300673961881297e-05,
      "loss": 0.0235,
      "step": 7383
    },
    {
      "epoch": 0.5351306301409573,
      "grad_norm": 0.7698363065719604,
      "learning_rate": 9.299224581491413e-05,
      "loss": 0.0325,
      "step": 7384
    },
    {
      "epoch": 0.535203101786426,
      "grad_norm": 1.0382466316223145,
      "learning_rate": 9.29777520110153e-05,
      "loss": 0.0421,
      "step": 7385
    },
    {
      "epoch": 0.5352755734318948,
      "grad_norm": 2.221665620803833,
      "learning_rate": 9.296325820711647e-05,
      "loss": 0.088,
      "step": 7386
    },
    {
      "epoch": 0.5353480450773634,
      "grad_norm": 2.74739670753479,
      "learning_rate": 9.294876440321762e-05,
      "loss": 0.1276,
      "step": 7387
    },
    {
      "epoch": 0.5354205167228322,
      "grad_norm": 1.10555100440979,
      "learning_rate": 9.293427059931879e-05,
      "loss": 0.0235,
      "step": 7388
    },
    {
      "epoch": 0.535492988368301,
      "grad_norm": 0.8886178731918335,
      "learning_rate": 9.291977679541996e-05,
      "loss": 0.0505,
      "step": 7389
    },
    {
      "epoch": 0.5355654600137696,
      "grad_norm": 1.4134221076965332,
      "learning_rate": 9.290528299152112e-05,
      "loss": 0.066,
      "step": 7390
    },
    {
      "epoch": 0.5356379316592383,
      "grad_norm": 1.5367342233657837,
      "learning_rate": 9.28907891876223e-05,
      "loss": 0.0994,
      "step": 7391
    },
    {
      "epoch": 0.535710403304707,
      "grad_norm": 1.5882841348648071,
      "learning_rate": 9.287629538372347e-05,
      "loss": 0.1209,
      "step": 7392
    },
    {
      "epoch": 0.5357828749501757,
      "grad_norm": 2.1446688175201416,
      "learning_rate": 9.286180157982463e-05,
      "loss": 0.1399,
      "step": 7393
    },
    {
      "epoch": 0.5358553465956445,
      "grad_norm": 3.460031509399414,
      "learning_rate": 9.28473077759258e-05,
      "loss": 0.1012,
      "step": 7394
    },
    {
      "epoch": 0.5359278182411131,
      "grad_norm": 1.1787837743759155,
      "learning_rate": 9.283281397202697e-05,
      "loss": 0.0567,
      "step": 7395
    },
    {
      "epoch": 0.5360002898865819,
      "grad_norm": 9.497556686401367,
      "learning_rate": 9.281832016812813e-05,
      "loss": 0.0829,
      "step": 7396
    },
    {
      "epoch": 0.5360727615320506,
      "grad_norm": 0.7730222940444946,
      "learning_rate": 9.28038263642293e-05,
      "loss": 0.009,
      "step": 7397
    },
    {
      "epoch": 0.5361452331775193,
      "grad_norm": 1.2794984579086304,
      "learning_rate": 9.278933256033047e-05,
      "loss": 0.0473,
      "step": 7398
    },
    {
      "epoch": 0.536217704822988,
      "grad_norm": 1.7697842121124268,
      "learning_rate": 9.277483875643162e-05,
      "loss": 0.1005,
      "step": 7399
    },
    {
      "epoch": 0.5362901764684567,
      "grad_norm": 0.8160019516944885,
      "learning_rate": 9.276034495253279e-05,
      "loss": 0.0249,
      "step": 7400
    },
    {
      "epoch": 0.5363626481139254,
      "grad_norm": 0.21929121017456055,
      "learning_rate": 9.274585114863396e-05,
      "loss": 0.0087,
      "step": 7401
    },
    {
      "epoch": 0.5364351197593942,
      "grad_norm": 2.092139482498169,
      "learning_rate": 9.273135734473513e-05,
      "loss": 0.144,
      "step": 7402
    },
    {
      "epoch": 0.5365075914048628,
      "grad_norm": 0.9771652221679688,
      "learning_rate": 9.27168635408363e-05,
      "loss": 0.0357,
      "step": 7403
    },
    {
      "epoch": 0.5365800630503316,
      "grad_norm": 1.345162034034729,
      "learning_rate": 9.270236973693747e-05,
      "loss": 0.0716,
      "step": 7404
    },
    {
      "epoch": 0.5366525346958003,
      "grad_norm": 0.1882943958044052,
      "learning_rate": 9.268787593303863e-05,
      "loss": 0.0059,
      "step": 7405
    },
    {
      "epoch": 0.536725006341269,
      "grad_norm": 0.2298259735107422,
      "learning_rate": 9.26733821291398e-05,
      "loss": 0.0096,
      "step": 7406
    },
    {
      "epoch": 0.5367974779867377,
      "grad_norm": 2.397109031677246,
      "learning_rate": 9.265888832524097e-05,
      "loss": 0.105,
      "step": 7407
    },
    {
      "epoch": 0.5368699496322064,
      "grad_norm": 0.9901050329208374,
      "learning_rate": 9.264439452134213e-05,
      "loss": 0.0373,
      "step": 7408
    },
    {
      "epoch": 0.5369424212776751,
      "grad_norm": 0.7848366498947144,
      "learning_rate": 9.26299007174433e-05,
      "loss": 0.0526,
      "step": 7409
    },
    {
      "epoch": 0.5370148929231439,
      "grad_norm": 1.8595576286315918,
      "learning_rate": 9.261540691354447e-05,
      "loss": 0.0433,
      "step": 7410
    },
    {
      "epoch": 0.5370873645686125,
      "grad_norm": 2.3705344200134277,
      "learning_rate": 9.260091310964562e-05,
      "loss": 0.0588,
      "step": 7411
    },
    {
      "epoch": 0.5371598362140813,
      "grad_norm": 0.7243467569351196,
      "learning_rate": 9.258641930574679e-05,
      "loss": 0.0327,
      "step": 7412
    },
    {
      "epoch": 0.5372323078595499,
      "grad_norm": 0.9527950286865234,
      "learning_rate": 9.257192550184796e-05,
      "loss": 0.036,
      "step": 7413
    },
    {
      "epoch": 0.5373047795050186,
      "grad_norm": 1.1289106607437134,
      "learning_rate": 9.255743169794913e-05,
      "loss": 0.0809,
      "step": 7414
    },
    {
      "epoch": 0.5373772511504874,
      "grad_norm": 3.263385772705078,
      "learning_rate": 9.25429378940503e-05,
      "loss": 0.2047,
      "step": 7415
    },
    {
      "epoch": 0.537449722795956,
      "grad_norm": 2.899857997894287,
      "learning_rate": 9.252844409015147e-05,
      "loss": 0.1898,
      "step": 7416
    },
    {
      "epoch": 0.5375221944414248,
      "grad_norm": 0.7519789934158325,
      "learning_rate": 9.251395028625263e-05,
      "loss": 0.0314,
      "step": 7417
    },
    {
      "epoch": 0.5375946660868935,
      "grad_norm": 1.3960723876953125,
      "learning_rate": 9.24994564823538e-05,
      "loss": 0.0486,
      "step": 7418
    },
    {
      "epoch": 0.5376671377323622,
      "grad_norm": 2.214447259902954,
      "learning_rate": 9.248496267845497e-05,
      "loss": 0.0333,
      "step": 7419
    },
    {
      "epoch": 0.5377396093778309,
      "grad_norm": 1.6644790172576904,
      "learning_rate": 9.247046887455613e-05,
      "loss": 0.0621,
      "step": 7420
    },
    {
      "epoch": 0.5378120810232996,
      "grad_norm": 1.1798734664916992,
      "learning_rate": 9.24559750706573e-05,
      "loss": 0.1388,
      "step": 7421
    },
    {
      "epoch": 0.5378845526687683,
      "grad_norm": 0.4954085648059845,
      "learning_rate": 9.244148126675847e-05,
      "loss": 0.0134,
      "step": 7422
    },
    {
      "epoch": 0.5379570243142371,
      "grad_norm": 2.0023317337036133,
      "learning_rate": 9.242698746285962e-05,
      "loss": 0.1501,
      "step": 7423
    },
    {
      "epoch": 0.5380294959597057,
      "grad_norm": 2.106083393096924,
      "learning_rate": 9.241249365896079e-05,
      "loss": 0.0839,
      "step": 7424
    },
    {
      "epoch": 0.5381019676051745,
      "grad_norm": 0.7384114861488342,
      "learning_rate": 9.239799985506196e-05,
      "loss": 0.0363,
      "step": 7425
    },
    {
      "epoch": 0.5381744392506432,
      "grad_norm": 0.8311973214149475,
      "learning_rate": 9.238350605116313e-05,
      "loss": 0.0364,
      "step": 7426
    },
    {
      "epoch": 0.5382469108961119,
      "grad_norm": 1.936645746231079,
      "learning_rate": 9.23690122472643e-05,
      "loss": 0.0853,
      "step": 7427
    },
    {
      "epoch": 0.5383193825415806,
      "grad_norm": 1.440732717514038,
      "learning_rate": 9.235451844336547e-05,
      "loss": 0.0597,
      "step": 7428
    },
    {
      "epoch": 0.5383918541870493,
      "grad_norm": 1.9356715679168701,
      "learning_rate": 9.234002463946664e-05,
      "loss": 0.0666,
      "step": 7429
    },
    {
      "epoch": 0.538464325832518,
      "grad_norm": 1.5810121297836304,
      "learning_rate": 9.23255308355678e-05,
      "loss": 0.0735,
      "step": 7430
    },
    {
      "epoch": 0.5385367974779868,
      "grad_norm": 0.15679322183132172,
      "learning_rate": 9.231103703166897e-05,
      "loss": 0.0046,
      "step": 7431
    },
    {
      "epoch": 0.5386092691234554,
      "grad_norm": 0.30205485224723816,
      "learning_rate": 9.229654322777014e-05,
      "loss": 0.0109,
      "step": 7432
    },
    {
      "epoch": 0.5386817407689242,
      "grad_norm": 1.1437351703643799,
      "learning_rate": 9.22820494238713e-05,
      "loss": 0.0391,
      "step": 7433
    },
    {
      "epoch": 0.5387542124143929,
      "grad_norm": 0.5144479274749756,
      "learning_rate": 9.226755561997246e-05,
      "loss": 0.0133,
      "step": 7434
    },
    {
      "epoch": 0.5388266840598616,
      "grad_norm": 0.7594423294067383,
      "learning_rate": 9.225306181607363e-05,
      "loss": 0.0336,
      "step": 7435
    },
    {
      "epoch": 0.5388991557053303,
      "grad_norm": 2.843696117401123,
      "learning_rate": 9.223856801217479e-05,
      "loss": 0.1357,
      "step": 7436
    },
    {
      "epoch": 0.538971627350799,
      "grad_norm": 2.397096872329712,
      "learning_rate": 9.222407420827596e-05,
      "loss": 0.1386,
      "step": 7437
    },
    {
      "epoch": 0.5390440989962677,
      "grad_norm": 0.40437036752700806,
      "learning_rate": 9.220958040437715e-05,
      "loss": 0.0161,
      "step": 7438
    },
    {
      "epoch": 0.5391165706417365,
      "grad_norm": 1.005315899848938,
      "learning_rate": 9.21950866004783e-05,
      "loss": 0.0529,
      "step": 7439
    },
    {
      "epoch": 0.5391890422872051,
      "grad_norm": 0.6992915272712708,
      "learning_rate": 9.218059279657947e-05,
      "loss": 0.0408,
      "step": 7440
    },
    {
      "epoch": 0.5392615139326739,
      "grad_norm": 0.24182140827178955,
      "learning_rate": 9.216609899268064e-05,
      "loss": 0.0037,
      "step": 7441
    },
    {
      "epoch": 0.5393339855781426,
      "grad_norm": 1.120004415512085,
      "learning_rate": 9.21516051887818e-05,
      "loss": 0.0542,
      "step": 7442
    },
    {
      "epoch": 0.5394064572236112,
      "grad_norm": 2.7330336570739746,
      "learning_rate": 9.213711138488297e-05,
      "loss": 0.0613,
      "step": 7443
    },
    {
      "epoch": 0.53947892886908,
      "grad_norm": 2.115800142288208,
      "learning_rate": 9.212261758098414e-05,
      "loss": 0.0403,
      "step": 7444
    },
    {
      "epoch": 0.5395514005145486,
      "grad_norm": 1.0287957191467285,
      "learning_rate": 9.21081237770853e-05,
      "loss": 0.0792,
      "step": 7445
    },
    {
      "epoch": 0.5396238721600174,
      "grad_norm": 1.8791722059249878,
      "learning_rate": 9.209362997318646e-05,
      "loss": 0.0994,
      "step": 7446
    },
    {
      "epoch": 0.5396963438054861,
      "grad_norm": 1.0755457878112793,
      "learning_rate": 9.207913616928763e-05,
      "loss": 0.0537,
      "step": 7447
    },
    {
      "epoch": 0.5397688154509548,
      "grad_norm": 0.11579576879739761,
      "learning_rate": 9.206464236538879e-05,
      "loss": 0.0039,
      "step": 7448
    },
    {
      "epoch": 0.5398412870964235,
      "grad_norm": 0.18391096591949463,
      "learning_rate": 9.205014856148997e-05,
      "loss": 0.0054,
      "step": 7449
    },
    {
      "epoch": 0.5399137587418922,
      "grad_norm": 0.688727080821991,
      "learning_rate": 9.203565475759114e-05,
      "loss": 0.0286,
      "step": 7450
    },
    {
      "epoch": 0.5399862303873609,
      "grad_norm": 0.7442773580551147,
      "learning_rate": 9.20211609536923e-05,
      "loss": 0.0457,
      "step": 7451
    },
    {
      "epoch": 0.5400587020328297,
      "grad_norm": 1.3215514421463013,
      "learning_rate": 9.200666714979347e-05,
      "loss": 0.0414,
      "step": 7452
    },
    {
      "epoch": 0.5401311736782983,
      "grad_norm": 0.5242297649383545,
      "learning_rate": 9.199217334589464e-05,
      "loss": 0.0132,
      "step": 7453
    },
    {
      "epoch": 0.5402036453237671,
      "grad_norm": 1.2991935014724731,
      "learning_rate": 9.19776795419958e-05,
      "loss": 0.0579,
      "step": 7454
    },
    {
      "epoch": 0.5402761169692358,
      "grad_norm": 2.0824246406555176,
      "learning_rate": 9.196318573809697e-05,
      "loss": 0.1861,
      "step": 7455
    },
    {
      "epoch": 0.5403485886147045,
      "grad_norm": 8.019798278808594,
      "learning_rate": 9.194869193419814e-05,
      "loss": 0.1135,
      "step": 7456
    },
    {
      "epoch": 0.5404210602601732,
      "grad_norm": 1.6080368757247925,
      "learning_rate": 9.19341981302993e-05,
      "loss": 0.0474,
      "step": 7457
    },
    {
      "epoch": 0.5404935319056419,
      "grad_norm": 0.48516419529914856,
      "learning_rate": 9.191970432640046e-05,
      "loss": 0.0229,
      "step": 7458
    },
    {
      "epoch": 0.5405660035511106,
      "grad_norm": 0.5823118686676025,
      "learning_rate": 9.190521052250163e-05,
      "loss": 0.0361,
      "step": 7459
    },
    {
      "epoch": 0.5406384751965794,
      "grad_norm": 0.5010038018226624,
      "learning_rate": 9.18907167186028e-05,
      "loss": 0.0205,
      "step": 7460
    },
    {
      "epoch": 0.540710946842048,
      "grad_norm": 2.2871720790863037,
      "learning_rate": 9.187622291470397e-05,
      "loss": 0.0466,
      "step": 7461
    },
    {
      "epoch": 0.5407834184875168,
      "grad_norm": 1.2153496742248535,
      "learning_rate": 9.186172911080514e-05,
      "loss": 0.0428,
      "step": 7462
    },
    {
      "epoch": 0.5408558901329855,
      "grad_norm": 4.12033748626709,
      "learning_rate": 9.18472353069063e-05,
      "loss": 0.1371,
      "step": 7463
    },
    {
      "epoch": 0.5409283617784542,
      "grad_norm": 1.9066299200057983,
      "learning_rate": 9.183274150300747e-05,
      "loss": 0.0611,
      "step": 7464
    },
    {
      "epoch": 0.5410008334239229,
      "grad_norm": 0.44819435477256775,
      "learning_rate": 9.181824769910864e-05,
      "loss": 0.0104,
      "step": 7465
    },
    {
      "epoch": 0.5410733050693916,
      "grad_norm": 0.7388924360275269,
      "learning_rate": 9.18037538952098e-05,
      "loss": 0.0475,
      "step": 7466
    },
    {
      "epoch": 0.5411457767148603,
      "grad_norm": 1.0626486539840698,
      "learning_rate": 9.178926009131097e-05,
      "loss": 0.0495,
      "step": 7467
    },
    {
      "epoch": 0.5412182483603291,
      "grad_norm": 1.4556735754013062,
      "learning_rate": 9.177476628741214e-05,
      "loss": 0.075,
      "step": 7468
    },
    {
      "epoch": 0.5412907200057977,
      "grad_norm": 1.3649022579193115,
      "learning_rate": 9.17602724835133e-05,
      "loss": 0.048,
      "step": 7469
    },
    {
      "epoch": 0.5413631916512665,
      "grad_norm": 0.3822195827960968,
      "learning_rate": 9.174577867961446e-05,
      "loss": 0.026,
      "step": 7470
    },
    {
      "epoch": 0.5414356632967352,
      "grad_norm": 4.039794921875,
      "learning_rate": 9.173128487571563e-05,
      "loss": 0.1408,
      "step": 7471
    },
    {
      "epoch": 0.5415081349422038,
      "grad_norm": 0.5447558760643005,
      "learning_rate": 9.17167910718168e-05,
      "loss": 0.0167,
      "step": 7472
    },
    {
      "epoch": 0.5415806065876726,
      "grad_norm": 2.7306478023529053,
      "learning_rate": 9.170229726791797e-05,
      "loss": 0.056,
      "step": 7473
    },
    {
      "epoch": 0.5416530782331412,
      "grad_norm": 2.715766429901123,
      "learning_rate": 9.168780346401914e-05,
      "loss": 0.0132,
      "step": 7474
    },
    {
      "epoch": 0.54172554987861,
      "grad_norm": 1.3613651990890503,
      "learning_rate": 9.16733096601203e-05,
      "loss": 0.0404,
      "step": 7475
    },
    {
      "epoch": 0.5417980215240787,
      "grad_norm": 1.1891252994537354,
      "learning_rate": 9.165881585622147e-05,
      "loss": 0.0416,
      "step": 7476
    },
    {
      "epoch": 0.5418704931695474,
      "grad_norm": 4.903158664703369,
      "learning_rate": 9.164432205232264e-05,
      "loss": 0.1609,
      "step": 7477
    },
    {
      "epoch": 0.5419429648150161,
      "grad_norm": 4.664937973022461,
      "learning_rate": 9.16298282484238e-05,
      "loss": 0.3101,
      "step": 7478
    },
    {
      "epoch": 0.5420154364604849,
      "grad_norm": 1.5989696979522705,
      "learning_rate": 9.161533444452497e-05,
      "loss": 0.0259,
      "step": 7479
    },
    {
      "epoch": 0.5420879081059535,
      "grad_norm": 1.3927029371261597,
      "learning_rate": 9.160084064062614e-05,
      "loss": 0.0555,
      "step": 7480
    },
    {
      "epoch": 0.5421603797514223,
      "grad_norm": 0.6526361107826233,
      "learning_rate": 9.15863468367273e-05,
      "loss": 0.016,
      "step": 7481
    },
    {
      "epoch": 0.5422328513968909,
      "grad_norm": 3.5360188484191895,
      "learning_rate": 9.157185303282846e-05,
      "loss": 0.1795,
      "step": 7482
    },
    {
      "epoch": 0.5423053230423597,
      "grad_norm": 0.16081169247627258,
      "learning_rate": 9.155735922892963e-05,
      "loss": 0.0046,
      "step": 7483
    },
    {
      "epoch": 0.5423777946878284,
      "grad_norm": 1.4081001281738281,
      "learning_rate": 9.15428654250308e-05,
      "loss": 0.0895,
      "step": 7484
    },
    {
      "epoch": 0.5424502663332971,
      "grad_norm": 1.2726689577102661,
      "learning_rate": 9.152837162113197e-05,
      "loss": 0.0721,
      "step": 7485
    },
    {
      "epoch": 0.5425227379787658,
      "grad_norm": 3.222475051879883,
      "learning_rate": 9.151387781723314e-05,
      "loss": 0.0783,
      "step": 7486
    },
    {
      "epoch": 0.5425952096242345,
      "grad_norm": 1.0796500444412231,
      "learning_rate": 9.14993840133343e-05,
      "loss": 0.1101,
      "step": 7487
    },
    {
      "epoch": 0.5426676812697032,
      "grad_norm": 0.8811275362968445,
      "learning_rate": 9.148489020943547e-05,
      "loss": 0.0226,
      "step": 7488
    },
    {
      "epoch": 0.542740152915172,
      "grad_norm": 0.9324185848236084,
      "learning_rate": 9.147039640553664e-05,
      "loss": 0.0754,
      "step": 7489
    },
    {
      "epoch": 0.5428126245606406,
      "grad_norm": 1.2296125888824463,
      "learning_rate": 9.14559026016378e-05,
      "loss": 0.0551,
      "step": 7490
    },
    {
      "epoch": 0.5428850962061094,
      "grad_norm": 0.2038521021604538,
      "learning_rate": 9.144140879773897e-05,
      "loss": 0.0058,
      "step": 7491
    },
    {
      "epoch": 0.5429575678515781,
      "grad_norm": 1.598842740058899,
      "learning_rate": 9.142691499384014e-05,
      "loss": 0.0322,
      "step": 7492
    },
    {
      "epoch": 0.5430300394970468,
      "grad_norm": 0.35330930352211,
      "learning_rate": 9.14124211899413e-05,
      "loss": 0.0077,
      "step": 7493
    },
    {
      "epoch": 0.5431025111425155,
      "grad_norm": 1.8721599578857422,
      "learning_rate": 9.139792738604246e-05,
      "loss": 0.1516,
      "step": 7494
    },
    {
      "epoch": 0.5431749827879842,
      "grad_norm": 0.615583062171936,
      "learning_rate": 9.138343358214363e-05,
      "loss": 0.028,
      "step": 7495
    },
    {
      "epoch": 0.5432474544334529,
      "grad_norm": 0.9218135476112366,
      "learning_rate": 9.13689397782448e-05,
      "loss": 0.0296,
      "step": 7496
    },
    {
      "epoch": 0.5433199260789217,
      "grad_norm": 3.313338041305542,
      "learning_rate": 9.135444597434597e-05,
      "loss": 0.1137,
      "step": 7497
    },
    {
      "epoch": 0.5433923977243903,
      "grad_norm": 1.368346929550171,
      "learning_rate": 9.133995217044714e-05,
      "loss": 0.0496,
      "step": 7498
    },
    {
      "epoch": 0.543464869369859,
      "grad_norm": 2.4857213497161865,
      "learning_rate": 9.13254583665483e-05,
      "loss": 0.1175,
      "step": 7499
    },
    {
      "epoch": 0.5435373410153278,
      "grad_norm": 0.9521236419677734,
      "learning_rate": 9.131096456264947e-05,
      "loss": 0.0581,
      "step": 7500
    },
    {
      "epoch": 0.5436098126607964,
      "grad_norm": 3.5971105098724365,
      "learning_rate": 9.129647075875064e-05,
      "loss": 0.1549,
      "step": 7501
    },
    {
      "epoch": 0.5436822843062652,
      "grad_norm": 1.6847504377365112,
      "learning_rate": 9.12819769548518e-05,
      "loss": 0.0734,
      "step": 7502
    },
    {
      "epoch": 0.5437547559517338,
      "grad_norm": 0.8817546963691711,
      "learning_rate": 9.126748315095297e-05,
      "loss": 0.0212,
      "step": 7503
    },
    {
      "epoch": 0.5438272275972026,
      "grad_norm": 3.4956135749816895,
      "learning_rate": 9.125298934705414e-05,
      "loss": 0.0463,
      "step": 7504
    },
    {
      "epoch": 0.5438996992426713,
      "grad_norm": 0.20766502618789673,
      "learning_rate": 9.12384955431553e-05,
      "loss": 0.0078,
      "step": 7505
    },
    {
      "epoch": 0.54397217088814,
      "grad_norm": 0.493257075548172,
      "learning_rate": 9.122400173925648e-05,
      "loss": 0.0239,
      "step": 7506
    },
    {
      "epoch": 0.5440446425336087,
      "grad_norm": 1.6087300777435303,
      "learning_rate": 9.120950793535765e-05,
      "loss": 0.0507,
      "step": 7507
    },
    {
      "epoch": 0.5441171141790775,
      "grad_norm": 0.8796727061271667,
      "learning_rate": 9.11950141314588e-05,
      "loss": 0.0341,
      "step": 7508
    },
    {
      "epoch": 0.5441895858245461,
      "grad_norm": 1.678139090538025,
      "learning_rate": 9.118052032755997e-05,
      "loss": 0.0289,
      "step": 7509
    },
    {
      "epoch": 0.5442620574700149,
      "grad_norm": 1.240903377532959,
      "learning_rate": 9.116602652366114e-05,
      "loss": 0.0476,
      "step": 7510
    },
    {
      "epoch": 0.5443345291154835,
      "grad_norm": 1.3883191347122192,
      "learning_rate": 9.115153271976231e-05,
      "loss": 0.0267,
      "step": 7511
    },
    {
      "epoch": 0.5444070007609523,
      "grad_norm": 1.3414889574050903,
      "learning_rate": 9.113703891586347e-05,
      "loss": 0.0251,
      "step": 7512
    },
    {
      "epoch": 0.544479472406421,
      "grad_norm": 3.804436445236206,
      "learning_rate": 9.112254511196464e-05,
      "loss": 0.1634,
      "step": 7513
    },
    {
      "epoch": 0.5445519440518897,
      "grad_norm": 3.0079638957977295,
      "learning_rate": 9.110805130806581e-05,
      "loss": 0.1532,
      "step": 7514
    },
    {
      "epoch": 0.5446244156973584,
      "grad_norm": 3.1810197830200195,
      "learning_rate": 9.109355750416697e-05,
      "loss": 0.105,
      "step": 7515
    },
    {
      "epoch": 0.5446968873428272,
      "grad_norm": 1.4453245401382446,
      "learning_rate": 9.107906370026814e-05,
      "loss": 0.0546,
      "step": 7516
    },
    {
      "epoch": 0.5447693589882958,
      "grad_norm": 1.594006061553955,
      "learning_rate": 9.106456989636931e-05,
      "loss": 0.0443,
      "step": 7517
    },
    {
      "epoch": 0.5448418306337646,
      "grad_norm": 2.461568593978882,
      "learning_rate": 9.105007609247048e-05,
      "loss": 0.1333,
      "step": 7518
    },
    {
      "epoch": 0.5449143022792332,
      "grad_norm": 0.425587922334671,
      "learning_rate": 9.103558228857165e-05,
      "loss": 0.0102,
      "step": 7519
    },
    {
      "epoch": 0.544986773924702,
      "grad_norm": 2.306520462036133,
      "learning_rate": 9.102108848467282e-05,
      "loss": 0.0592,
      "step": 7520
    },
    {
      "epoch": 0.5450592455701707,
      "grad_norm": 6.549415111541748,
      "learning_rate": 9.100659468077397e-05,
      "loss": 0.1817,
      "step": 7521
    },
    {
      "epoch": 0.5451317172156394,
      "grad_norm": 2.1457574367523193,
      "learning_rate": 9.099210087687514e-05,
      "loss": 0.046,
      "step": 7522
    },
    {
      "epoch": 0.5452041888611081,
      "grad_norm": 2.4550933837890625,
      "learning_rate": 9.097760707297631e-05,
      "loss": 0.057,
      "step": 7523
    },
    {
      "epoch": 0.5452766605065767,
      "grad_norm": 4.870779514312744,
      "learning_rate": 9.096311326907747e-05,
      "loss": 0.1345,
      "step": 7524
    },
    {
      "epoch": 0.5453491321520455,
      "grad_norm": 0.4557136595249176,
      "learning_rate": 9.094861946517864e-05,
      "loss": 0.0178,
      "step": 7525
    },
    {
      "epoch": 0.5454216037975143,
      "grad_norm": 1.8733294010162354,
      "learning_rate": 9.093412566127981e-05,
      "loss": 0.0345,
      "step": 7526
    },
    {
      "epoch": 0.5454940754429829,
      "grad_norm": 4.259544372558594,
      "learning_rate": 9.091963185738097e-05,
      "loss": 0.0996,
      "step": 7527
    },
    {
      "epoch": 0.5455665470884516,
      "grad_norm": 1.849373698234558,
      "learning_rate": 9.090513805348214e-05,
      "loss": 0.0857,
      "step": 7528
    },
    {
      "epoch": 0.5456390187339204,
      "grad_norm": 1.892528772354126,
      "learning_rate": 9.08906442495833e-05,
      "loss": 0.1471,
      "step": 7529
    },
    {
      "epoch": 0.545711490379389,
      "grad_norm": 0.6170573830604553,
      "learning_rate": 9.087615044568448e-05,
      "loss": 0.0273,
      "step": 7530
    },
    {
      "epoch": 0.5457839620248578,
      "grad_norm": 1.1043663024902344,
      "learning_rate": 9.086165664178565e-05,
      "loss": 0.0716,
      "step": 7531
    },
    {
      "epoch": 0.5458564336703264,
      "grad_norm": 0.3981553912162781,
      "learning_rate": 9.084716283788682e-05,
      "loss": 0.0375,
      "step": 7532
    },
    {
      "epoch": 0.5459289053157952,
      "grad_norm": 1.3262691497802734,
      "learning_rate": 9.083266903398797e-05,
      "loss": 0.0399,
      "step": 7533
    },
    {
      "epoch": 0.5460013769612639,
      "grad_norm": 4.297170639038086,
      "learning_rate": 9.081817523008914e-05,
      "loss": 0.1698,
      "step": 7534
    },
    {
      "epoch": 0.5460738486067326,
      "grad_norm": 2.0904297828674316,
      "learning_rate": 9.080368142619031e-05,
      "loss": 0.0708,
      "step": 7535
    },
    {
      "epoch": 0.5461463202522013,
      "grad_norm": 1.9214363098144531,
      "learning_rate": 9.078918762229147e-05,
      "loss": 0.02,
      "step": 7536
    },
    {
      "epoch": 0.5462187918976701,
      "grad_norm": 7.6552228927612305,
      "learning_rate": 9.077469381839264e-05,
      "loss": 0.1751,
      "step": 7537
    },
    {
      "epoch": 0.5462912635431387,
      "grad_norm": 0.8897026777267456,
      "learning_rate": 9.076020001449381e-05,
      "loss": 0.0569,
      "step": 7538
    },
    {
      "epoch": 0.5463637351886075,
      "grad_norm": 0.9794752597808838,
      "learning_rate": 9.074570621059497e-05,
      "loss": 0.0638,
      "step": 7539
    },
    {
      "epoch": 0.5464362068340761,
      "grad_norm": 0.818226158618927,
      "learning_rate": 9.073121240669614e-05,
      "loss": 0.0445,
      "step": 7540
    },
    {
      "epoch": 0.5465086784795449,
      "grad_norm": 2.814298629760742,
      "learning_rate": 9.07167186027973e-05,
      "loss": 0.1104,
      "step": 7541
    },
    {
      "epoch": 0.5465811501250136,
      "grad_norm": 1.0667415857315063,
      "learning_rate": 9.070222479889848e-05,
      "loss": 0.0408,
      "step": 7542
    },
    {
      "epoch": 0.5466536217704823,
      "grad_norm": 5.389958381652832,
      "learning_rate": 9.068773099499965e-05,
      "loss": 0.0407,
      "step": 7543
    },
    {
      "epoch": 0.546726093415951,
      "grad_norm": 0.3632371127605438,
      "learning_rate": 9.067323719110082e-05,
      "loss": 0.0096,
      "step": 7544
    },
    {
      "epoch": 0.5467985650614198,
      "grad_norm": 1.5542597770690918,
      "learning_rate": 9.065874338720197e-05,
      "loss": 0.0274,
      "step": 7545
    },
    {
      "epoch": 0.5468710367068884,
      "grad_norm": 5.236068248748779,
      "learning_rate": 9.064424958330314e-05,
      "loss": 0.0922,
      "step": 7546
    },
    {
      "epoch": 0.5469435083523572,
      "grad_norm": 0.4769197106361389,
      "learning_rate": 9.062975577940431e-05,
      "loss": 0.024,
      "step": 7547
    },
    {
      "epoch": 0.5470159799978258,
      "grad_norm": 2.737917423248291,
      "learning_rate": 9.061526197550547e-05,
      "loss": 0.0407,
      "step": 7548
    },
    {
      "epoch": 0.5470884516432946,
      "grad_norm": 0.9651889801025391,
      "learning_rate": 9.060076817160664e-05,
      "loss": 0.0482,
      "step": 7549
    },
    {
      "epoch": 0.5471609232887633,
      "grad_norm": 0.22610409557819366,
      "learning_rate": 9.058627436770781e-05,
      "loss": 0.0036,
      "step": 7550
    },
    {
      "epoch": 0.547233394934232,
      "grad_norm": 1.7354656457901,
      "learning_rate": 9.057178056380897e-05,
      "loss": 0.0528,
      "step": 7551
    },
    {
      "epoch": 0.5473058665797007,
      "grad_norm": 1.426550030708313,
      "learning_rate": 9.055728675991014e-05,
      "loss": 0.0497,
      "step": 7552
    },
    {
      "epoch": 0.5473783382251693,
      "grad_norm": 2.3382678031921387,
      "learning_rate": 9.05427929560113e-05,
      "loss": 0.0803,
      "step": 7553
    },
    {
      "epoch": 0.5474508098706381,
      "grad_norm": 2.5538811683654785,
      "learning_rate": 9.052829915211248e-05,
      "loss": 0.0691,
      "step": 7554
    },
    {
      "epoch": 0.5475232815161069,
      "grad_norm": 2.9910202026367188,
      "learning_rate": 9.051380534821365e-05,
      "loss": 0.0714,
      "step": 7555
    },
    {
      "epoch": 0.5475957531615755,
      "grad_norm": 2.566805124282837,
      "learning_rate": 9.049931154431482e-05,
      "loss": 0.1196,
      "step": 7556
    },
    {
      "epoch": 0.5476682248070442,
      "grad_norm": 2.080986261367798,
      "learning_rate": 9.048481774041597e-05,
      "loss": 0.1084,
      "step": 7557
    },
    {
      "epoch": 0.547740696452513,
      "grad_norm": 0.4724992513656616,
      "learning_rate": 9.047032393651714e-05,
      "loss": 0.0112,
      "step": 7558
    },
    {
      "epoch": 0.5478131680979816,
      "grad_norm": 2.690871000289917,
      "learning_rate": 9.045583013261831e-05,
      "loss": 0.0782,
      "step": 7559
    },
    {
      "epoch": 0.5478856397434504,
      "grad_norm": 1.0488715171813965,
      "learning_rate": 9.044133632871947e-05,
      "loss": 0.0407,
      "step": 7560
    },
    {
      "epoch": 0.547958111388919,
      "grad_norm": 2.3354392051696777,
      "learning_rate": 9.042684252482064e-05,
      "loss": 0.1202,
      "step": 7561
    },
    {
      "epoch": 0.5480305830343878,
      "grad_norm": 0.91224604845047,
      "learning_rate": 9.041234872092181e-05,
      "loss": 0.0183,
      "step": 7562
    },
    {
      "epoch": 0.5481030546798565,
      "grad_norm": 3.224337339401245,
      "learning_rate": 9.039785491702297e-05,
      "loss": 0.105,
      "step": 7563
    },
    {
      "epoch": 0.5481755263253252,
      "grad_norm": 2.1435890197753906,
      "learning_rate": 9.038336111312415e-05,
      "loss": 0.0658,
      "step": 7564
    },
    {
      "epoch": 0.5482479979707939,
      "grad_norm": 2.230435609817505,
      "learning_rate": 9.036886730922532e-05,
      "loss": 0.1221,
      "step": 7565
    },
    {
      "epoch": 0.5483204696162627,
      "grad_norm": 3.168987274169922,
      "learning_rate": 9.035437350532648e-05,
      "loss": 0.0858,
      "step": 7566
    },
    {
      "epoch": 0.5483929412617313,
      "grad_norm": 1.736550211906433,
      "learning_rate": 9.033987970142765e-05,
      "loss": 0.0343,
      "step": 7567
    },
    {
      "epoch": 0.5484654129072001,
      "grad_norm": 2.621232509613037,
      "learning_rate": 9.032538589752882e-05,
      "loss": 0.1173,
      "step": 7568
    },
    {
      "epoch": 0.5485378845526687,
      "grad_norm": 1.4557311534881592,
      "learning_rate": 9.031089209362997e-05,
      "loss": 0.0281,
      "step": 7569
    },
    {
      "epoch": 0.5486103561981375,
      "grad_norm": 1.1815561056137085,
      "learning_rate": 9.029639828973114e-05,
      "loss": 0.0735,
      "step": 7570
    },
    {
      "epoch": 0.5486828278436062,
      "grad_norm": 4.000062942504883,
      "learning_rate": 9.028190448583231e-05,
      "loss": 0.1888,
      "step": 7571
    },
    {
      "epoch": 0.5487552994890749,
      "grad_norm": 2.0266616344451904,
      "learning_rate": 9.026741068193347e-05,
      "loss": 0.0869,
      "step": 7572
    },
    {
      "epoch": 0.5488277711345436,
      "grad_norm": 0.4786773920059204,
      "learning_rate": 9.025291687803464e-05,
      "loss": 0.0226,
      "step": 7573
    },
    {
      "epoch": 0.5489002427800124,
      "grad_norm": 0.8165311813354492,
      "learning_rate": 9.023842307413581e-05,
      "loss": 0.0251,
      "step": 7574
    },
    {
      "epoch": 0.548972714425481,
      "grad_norm": 1.2372239828109741,
      "learning_rate": 9.022392927023698e-05,
      "loss": 0.0606,
      "step": 7575
    },
    {
      "epoch": 0.5490451860709498,
      "grad_norm": 1.416420578956604,
      "learning_rate": 9.020943546633815e-05,
      "loss": 0.064,
      "step": 7576
    },
    {
      "epoch": 0.5491176577164184,
      "grad_norm": 1.285563349723816,
      "learning_rate": 9.019494166243932e-05,
      "loss": 0.066,
      "step": 7577
    },
    {
      "epoch": 0.5491901293618872,
      "grad_norm": 4.060821533203125,
      "learning_rate": 9.018044785854048e-05,
      "loss": 0.0653,
      "step": 7578
    },
    {
      "epoch": 0.5492626010073559,
      "grad_norm": 1.0844290256500244,
      "learning_rate": 9.016595405464165e-05,
      "loss": 0.0589,
      "step": 7579
    },
    {
      "epoch": 0.5493350726528246,
      "grad_norm": 3.85398268699646,
      "learning_rate": 9.015146025074282e-05,
      "loss": 0.1084,
      "step": 7580
    },
    {
      "epoch": 0.5494075442982933,
      "grad_norm": 1.0460708141326904,
      "learning_rate": 9.013696644684397e-05,
      "loss": 0.0475,
      "step": 7581
    },
    {
      "epoch": 0.5494800159437621,
      "grad_norm": 1.1435784101486206,
      "learning_rate": 9.012247264294514e-05,
      "loss": 0.0676,
      "step": 7582
    },
    {
      "epoch": 0.5495524875892307,
      "grad_norm": 1.8524789810180664,
      "learning_rate": 9.010797883904631e-05,
      "loss": 0.1284,
      "step": 7583
    },
    {
      "epoch": 0.5496249592346995,
      "grad_norm": 1.20695161819458,
      "learning_rate": 9.009348503514747e-05,
      "loss": 0.0431,
      "step": 7584
    },
    {
      "epoch": 0.5496974308801681,
      "grad_norm": 1.663161039352417,
      "learning_rate": 9.007899123124864e-05,
      "loss": 0.0942,
      "step": 7585
    },
    {
      "epoch": 0.5497699025256368,
      "grad_norm": 3.5381686687469482,
      "learning_rate": 9.006449742734981e-05,
      "loss": 0.1073,
      "step": 7586
    },
    {
      "epoch": 0.5498423741711056,
      "grad_norm": 2.080026865005493,
      "learning_rate": 9.005000362345098e-05,
      "loss": 0.0881,
      "step": 7587
    },
    {
      "epoch": 0.5499148458165742,
      "grad_norm": 1.2125226259231567,
      "learning_rate": 9.003550981955215e-05,
      "loss": 0.0324,
      "step": 7588
    },
    {
      "epoch": 0.549987317462043,
      "grad_norm": 0.8958337306976318,
      "learning_rate": 9.002101601565332e-05,
      "loss": 0.0367,
      "step": 7589
    },
    {
      "epoch": 0.5500597891075116,
      "grad_norm": 1.0129404067993164,
      "learning_rate": 9.000652221175448e-05,
      "loss": 0.0747,
      "step": 7590
    },
    {
      "epoch": 0.5501322607529804,
      "grad_norm": 0.8561475276947021,
      "learning_rate": 8.999202840785565e-05,
      "loss": 0.0477,
      "step": 7591
    },
    {
      "epoch": 0.5502047323984491,
      "grad_norm": 0.8183426856994629,
      "learning_rate": 8.997753460395682e-05,
      "loss": 0.0223,
      "step": 7592
    },
    {
      "epoch": 0.5502772040439178,
      "grad_norm": 0.8851414322853088,
      "learning_rate": 8.996304080005799e-05,
      "loss": 0.0641,
      "step": 7593
    },
    {
      "epoch": 0.5503496756893865,
      "grad_norm": 1.5082764625549316,
      "learning_rate": 8.994854699615914e-05,
      "loss": 0.0429,
      "step": 7594
    },
    {
      "epoch": 0.5504221473348553,
      "grad_norm": 4.03945255279541,
      "learning_rate": 8.993405319226031e-05,
      "loss": 0.1631,
      "step": 7595
    },
    {
      "epoch": 0.5504946189803239,
      "grad_norm": 2.385711193084717,
      "learning_rate": 8.991955938836148e-05,
      "loss": 0.0774,
      "step": 7596
    },
    {
      "epoch": 0.5505670906257927,
      "grad_norm": 3.2516260147094727,
      "learning_rate": 8.990506558446264e-05,
      "loss": 0.0622,
      "step": 7597
    },
    {
      "epoch": 0.5506395622712613,
      "grad_norm": 2.7739641666412354,
      "learning_rate": 8.989057178056381e-05,
      "loss": 0.158,
      "step": 7598
    },
    {
      "epoch": 0.5507120339167301,
      "grad_norm": 1.4202624559402466,
      "learning_rate": 8.987607797666498e-05,
      "loss": 0.0738,
      "step": 7599
    },
    {
      "epoch": 0.5507845055621988,
      "grad_norm": 1.2607611417770386,
      "learning_rate": 8.986158417276615e-05,
      "loss": 0.0319,
      "step": 7600
    },
    {
      "epoch": 0.5508569772076675,
      "grad_norm": 1.1495281457901,
      "learning_rate": 8.984709036886732e-05,
      "loss": 0.0482,
      "step": 7601
    },
    {
      "epoch": 0.5509294488531362,
      "grad_norm": 1.2093790769577026,
      "learning_rate": 8.983259656496849e-05,
      "loss": 0.0437,
      "step": 7602
    },
    {
      "epoch": 0.551001920498605,
      "grad_norm": 1.2241675853729248,
      "learning_rate": 8.981810276106965e-05,
      "loss": 0.0584,
      "step": 7603
    },
    {
      "epoch": 0.5510743921440736,
      "grad_norm": 2.139116048812866,
      "learning_rate": 8.980360895717082e-05,
      "loss": 0.0586,
      "step": 7604
    },
    {
      "epoch": 0.5511468637895424,
      "grad_norm": 0.5785090923309326,
      "learning_rate": 8.978911515327199e-05,
      "loss": 0.0215,
      "step": 7605
    },
    {
      "epoch": 0.551219335435011,
      "grad_norm": 0.9479586482048035,
      "learning_rate": 8.977462134937314e-05,
      "loss": 0.0328,
      "step": 7606
    },
    {
      "epoch": 0.5512918070804798,
      "grad_norm": 1.0738065242767334,
      "learning_rate": 8.976012754547431e-05,
      "loss": 0.0242,
      "step": 7607
    },
    {
      "epoch": 0.5513642787259485,
      "grad_norm": 0.96648108959198,
      "learning_rate": 8.974563374157548e-05,
      "loss": 0.0755,
      "step": 7608
    },
    {
      "epoch": 0.5514367503714172,
      "grad_norm": 1.4612765312194824,
      "learning_rate": 8.973113993767664e-05,
      "loss": 0.0441,
      "step": 7609
    },
    {
      "epoch": 0.5515092220168859,
      "grad_norm": 1.5718119144439697,
      "learning_rate": 8.971664613377781e-05,
      "loss": 0.0925,
      "step": 7610
    },
    {
      "epoch": 0.5515816936623547,
      "grad_norm": 0.03207482770085335,
      "learning_rate": 8.970215232987899e-05,
      "loss": 0.0005,
      "step": 7611
    },
    {
      "epoch": 0.5516541653078233,
      "grad_norm": 1.3967000246047974,
      "learning_rate": 8.968765852598015e-05,
      "loss": 0.0655,
      "step": 7612
    },
    {
      "epoch": 0.551726636953292,
      "grad_norm": 0.9904488921165466,
      "learning_rate": 8.967316472208132e-05,
      "loss": 0.0486,
      "step": 7613
    },
    {
      "epoch": 0.5517991085987607,
      "grad_norm": 0.8097946047782898,
      "learning_rate": 8.965867091818249e-05,
      "loss": 0.0174,
      "step": 7614
    },
    {
      "epoch": 0.5518715802442294,
      "grad_norm": 0.5047768354415894,
      "learning_rate": 8.964417711428365e-05,
      "loss": 0.0133,
      "step": 7615
    },
    {
      "epoch": 0.5519440518896982,
      "grad_norm": 2.5867178440093994,
      "learning_rate": 8.962968331038482e-05,
      "loss": 0.1633,
      "step": 7616
    },
    {
      "epoch": 0.5520165235351668,
      "grad_norm": 2.212446451187134,
      "learning_rate": 8.961518950648599e-05,
      "loss": 0.0942,
      "step": 7617
    },
    {
      "epoch": 0.5520889951806356,
      "grad_norm": 0.9009815454483032,
      "learning_rate": 8.960069570258714e-05,
      "loss": 0.0675,
      "step": 7618
    },
    {
      "epoch": 0.5521614668261043,
      "grad_norm": 4.680032730102539,
      "learning_rate": 8.958620189868831e-05,
      "loss": 0.1354,
      "step": 7619
    },
    {
      "epoch": 0.552233938471573,
      "grad_norm": 3.8927791118621826,
      "learning_rate": 8.957170809478948e-05,
      "loss": 0.0883,
      "step": 7620
    },
    {
      "epoch": 0.5523064101170417,
      "grad_norm": 1.6761164665222168,
      "learning_rate": 8.955721429089065e-05,
      "loss": 0.0857,
      "step": 7621
    },
    {
      "epoch": 0.5523788817625104,
      "grad_norm": 1.9013375043869019,
      "learning_rate": 8.954272048699182e-05,
      "loss": 0.1921,
      "step": 7622
    },
    {
      "epoch": 0.5524513534079791,
      "grad_norm": 3.833016872406006,
      "learning_rate": 8.952822668309299e-05,
      "loss": 0.1216,
      "step": 7623
    },
    {
      "epoch": 0.5525238250534479,
      "grad_norm": 0.7078176736831665,
      "learning_rate": 8.951373287919415e-05,
      "loss": 0.0231,
      "step": 7624
    },
    {
      "epoch": 0.5525962966989165,
      "grad_norm": 2.6290953159332275,
      "learning_rate": 8.949923907529532e-05,
      "loss": 0.1977,
      "step": 7625
    },
    {
      "epoch": 0.5526687683443853,
      "grad_norm": 1.2107771635055542,
      "learning_rate": 8.948474527139649e-05,
      "loss": 0.0175,
      "step": 7626
    },
    {
      "epoch": 0.5527412399898539,
      "grad_norm": 3.5617854595184326,
      "learning_rate": 8.947025146749765e-05,
      "loss": 0.2703,
      "step": 7627
    },
    {
      "epoch": 0.5528137116353227,
      "grad_norm": 2.668595314025879,
      "learning_rate": 8.945575766359882e-05,
      "loss": 0.1645,
      "step": 7628
    },
    {
      "epoch": 0.5528861832807914,
      "grad_norm": 0.4714755415916443,
      "learning_rate": 8.944126385969999e-05,
      "loss": 0.0328,
      "step": 7629
    },
    {
      "epoch": 0.5529586549262601,
      "grad_norm": 0.6908825039863586,
      "learning_rate": 8.942677005580114e-05,
      "loss": 0.0539,
      "step": 7630
    },
    {
      "epoch": 0.5530311265717288,
      "grad_norm": 0.560119092464447,
      "learning_rate": 8.941227625190231e-05,
      "loss": 0.0178,
      "step": 7631
    },
    {
      "epoch": 0.5531035982171976,
      "grad_norm": 1.6083885431289673,
      "learning_rate": 8.939778244800348e-05,
      "loss": 0.1142,
      "step": 7632
    },
    {
      "epoch": 0.5531760698626662,
      "grad_norm": 0.42239195108413696,
      "learning_rate": 8.938328864410465e-05,
      "loss": 0.0173,
      "step": 7633
    },
    {
      "epoch": 0.553248541508135,
      "grad_norm": 2.0862576961517334,
      "learning_rate": 8.936879484020582e-05,
      "loss": 0.0667,
      "step": 7634
    },
    {
      "epoch": 0.5533210131536036,
      "grad_norm": 1.1495095491409302,
      "learning_rate": 8.935430103630699e-05,
      "loss": 0.0669,
      "step": 7635
    },
    {
      "epoch": 0.5533934847990724,
      "grad_norm": 0.3999437093734741,
      "learning_rate": 8.933980723240815e-05,
      "loss": 0.0137,
      "step": 7636
    },
    {
      "epoch": 0.5534659564445411,
      "grad_norm": 2.0074479579925537,
      "learning_rate": 8.932531342850932e-05,
      "loss": 0.0899,
      "step": 7637
    },
    {
      "epoch": 0.5535384280900097,
      "grad_norm": 2.8019275665283203,
      "learning_rate": 8.931081962461049e-05,
      "loss": 0.1267,
      "step": 7638
    },
    {
      "epoch": 0.5536108997354785,
      "grad_norm": 1.1958540678024292,
      "learning_rate": 8.929632582071164e-05,
      "loss": 0.1091,
      "step": 7639
    },
    {
      "epoch": 0.5536833713809473,
      "grad_norm": 1.113114356994629,
      "learning_rate": 8.928183201681282e-05,
      "loss": 0.0484,
      "step": 7640
    },
    {
      "epoch": 0.5537558430264159,
      "grad_norm": 1.2630207538604736,
      "learning_rate": 8.926733821291399e-05,
      "loss": 0.0858,
      "step": 7641
    },
    {
      "epoch": 0.5538283146718846,
      "grad_norm": 0.3121994435787201,
      "learning_rate": 8.925284440901514e-05,
      "loss": 0.0201,
      "step": 7642
    },
    {
      "epoch": 0.5539007863173533,
      "grad_norm": 1.3253763914108276,
      "learning_rate": 8.923835060511631e-05,
      "loss": 0.0593,
      "step": 7643
    },
    {
      "epoch": 0.553973257962822,
      "grad_norm": 2.3043384552001953,
      "learning_rate": 8.922385680121748e-05,
      "loss": 0.0608,
      "step": 7644
    },
    {
      "epoch": 0.5540457296082908,
      "grad_norm": 3.203045129776001,
      "learning_rate": 8.920936299731865e-05,
      "loss": 0.1894,
      "step": 7645
    },
    {
      "epoch": 0.5541182012537594,
      "grad_norm": 0.8038747310638428,
      "learning_rate": 8.919486919341982e-05,
      "loss": 0.0563,
      "step": 7646
    },
    {
      "epoch": 0.5541906728992282,
      "grad_norm": 6.995975494384766,
      "learning_rate": 8.918037538952099e-05,
      "loss": 0.0808,
      "step": 7647
    },
    {
      "epoch": 0.5542631445446969,
      "grad_norm": 1.5869617462158203,
      "learning_rate": 8.916588158562215e-05,
      "loss": 0.1012,
      "step": 7648
    },
    {
      "epoch": 0.5543356161901656,
      "grad_norm": 1.1960541009902954,
      "learning_rate": 8.915138778172332e-05,
      "loss": 0.056,
      "step": 7649
    },
    {
      "epoch": 0.5544080878356343,
      "grad_norm": 0.32091715931892395,
      "learning_rate": 8.913689397782449e-05,
      "loss": 0.0254,
      "step": 7650
    },
    {
      "epoch": 0.554480559481103,
      "grad_norm": 1.5545485019683838,
      "learning_rate": 8.912240017392564e-05,
      "loss": 0.0463,
      "step": 7651
    },
    {
      "epoch": 0.5545530311265717,
      "grad_norm": 0.18433648347854614,
      "learning_rate": 8.910790637002681e-05,
      "loss": 0.0041,
      "step": 7652
    },
    {
      "epoch": 0.5546255027720405,
      "grad_norm": 0.7285558581352234,
      "learning_rate": 8.909341256612798e-05,
      "loss": 0.009,
      "step": 7653
    },
    {
      "epoch": 0.5546979744175091,
      "grad_norm": 0.9478522539138794,
      "learning_rate": 8.907891876222914e-05,
      "loss": 0.069,
      "step": 7654
    },
    {
      "epoch": 0.5547704460629779,
      "grad_norm": 1.4360694885253906,
      "learning_rate": 8.906442495833031e-05,
      "loss": 0.0862,
      "step": 7655
    },
    {
      "epoch": 0.5548429177084466,
      "grad_norm": 1.259256362915039,
      "learning_rate": 8.904993115443148e-05,
      "loss": 0.0865,
      "step": 7656
    },
    {
      "epoch": 0.5549153893539153,
      "grad_norm": 1.0484893321990967,
      "learning_rate": 8.903543735053265e-05,
      "loss": 0.0393,
      "step": 7657
    },
    {
      "epoch": 0.554987860999384,
      "grad_norm": 0.5537317395210266,
      "learning_rate": 8.902094354663382e-05,
      "loss": 0.0365,
      "step": 7658
    },
    {
      "epoch": 0.5550603326448527,
      "grad_norm": 0.8058419227600098,
      "learning_rate": 8.900644974273499e-05,
      "loss": 0.0196,
      "step": 7659
    },
    {
      "epoch": 0.5551328042903214,
      "grad_norm": 1.4953926801681519,
      "learning_rate": 8.899195593883615e-05,
      "loss": 0.073,
      "step": 7660
    },
    {
      "epoch": 0.5552052759357902,
      "grad_norm": 5.141266822814941,
      "learning_rate": 8.897746213493732e-05,
      "loss": 0.1481,
      "step": 7661
    },
    {
      "epoch": 0.5552777475812588,
      "grad_norm": 1.077854871749878,
      "learning_rate": 8.896296833103849e-05,
      "loss": 0.0276,
      "step": 7662
    },
    {
      "epoch": 0.5553502192267276,
      "grad_norm": 1.343795657157898,
      "learning_rate": 8.894847452713964e-05,
      "loss": 0.0599,
      "step": 7663
    },
    {
      "epoch": 0.5554226908721962,
      "grad_norm": 0.7974751591682434,
      "learning_rate": 8.893398072324081e-05,
      "loss": 0.0395,
      "step": 7664
    },
    {
      "epoch": 0.555495162517665,
      "grad_norm": 0.6574011445045471,
      "learning_rate": 8.891948691934198e-05,
      "loss": 0.0156,
      "step": 7665
    },
    {
      "epoch": 0.5555676341631337,
      "grad_norm": 0.6729216575622559,
      "learning_rate": 8.890499311544314e-05,
      "loss": 0.0216,
      "step": 7666
    },
    {
      "epoch": 0.5556401058086023,
      "grad_norm": 0.48548275232315063,
      "learning_rate": 8.889049931154431e-05,
      "loss": 0.03,
      "step": 7667
    },
    {
      "epoch": 0.5557125774540711,
      "grad_norm": 2.415126323699951,
      "learning_rate": 8.887600550764548e-05,
      "loss": 0.1937,
      "step": 7668
    },
    {
      "epoch": 0.5557850490995399,
      "grad_norm": 0.6302942633628845,
      "learning_rate": 8.886151170374665e-05,
      "loss": 0.0555,
      "step": 7669
    },
    {
      "epoch": 0.5558575207450085,
      "grad_norm": 1.168186068534851,
      "learning_rate": 8.884701789984782e-05,
      "loss": 0.0641,
      "step": 7670
    },
    {
      "epoch": 0.5559299923904772,
      "grad_norm": 1.0380768775939941,
      "learning_rate": 8.883252409594899e-05,
      "loss": 0.0293,
      "step": 7671
    },
    {
      "epoch": 0.5560024640359459,
      "grad_norm": 1.472756266593933,
      "learning_rate": 8.881803029205016e-05,
      "loss": 0.0545,
      "step": 7672
    },
    {
      "epoch": 0.5560749356814146,
      "grad_norm": 1.3121933937072754,
      "learning_rate": 8.880353648815132e-05,
      "loss": 0.0827,
      "step": 7673
    },
    {
      "epoch": 0.5561474073268834,
      "grad_norm": 1.2660610675811768,
      "learning_rate": 8.878904268425249e-05,
      "loss": 0.0799,
      "step": 7674
    },
    {
      "epoch": 0.556219878972352,
      "grad_norm": 1.128501534461975,
      "learning_rate": 8.877454888035366e-05,
      "loss": 0.0809,
      "step": 7675
    },
    {
      "epoch": 0.5562923506178208,
      "grad_norm": 3.399766206741333,
      "learning_rate": 8.876005507645481e-05,
      "loss": 0.1167,
      "step": 7676
    },
    {
      "epoch": 0.5563648222632895,
      "grad_norm": 3.2742788791656494,
      "learning_rate": 8.874556127255598e-05,
      "loss": 0.1504,
      "step": 7677
    },
    {
      "epoch": 0.5564372939087582,
      "grad_norm": 0.7081295847892761,
      "learning_rate": 8.873106746865715e-05,
      "loss": 0.023,
      "step": 7678
    },
    {
      "epoch": 0.5565097655542269,
      "grad_norm": 1.8362352848052979,
      "learning_rate": 8.871657366475832e-05,
      "loss": 0.0711,
      "step": 7679
    },
    {
      "epoch": 0.5565822371996956,
      "grad_norm": 1.3934402465820312,
      "learning_rate": 8.87020798608595e-05,
      "loss": 0.04,
      "step": 7680
    },
    {
      "epoch": 0.5566547088451643,
      "grad_norm": 0.5147593021392822,
      "learning_rate": 8.868758605696066e-05,
      "loss": 0.0211,
      "step": 7681
    },
    {
      "epoch": 0.5567271804906331,
      "grad_norm": 2.5352563858032227,
      "learning_rate": 8.867309225306182e-05,
      "loss": 0.0919,
      "step": 7682
    },
    {
      "epoch": 0.5567996521361017,
      "grad_norm": 1.4980695247650146,
      "learning_rate": 8.865859844916299e-05,
      "loss": 0.0653,
      "step": 7683
    },
    {
      "epoch": 0.5568721237815705,
      "grad_norm": 0.7183986902236938,
      "learning_rate": 8.864410464526416e-05,
      "loss": 0.0626,
      "step": 7684
    },
    {
      "epoch": 0.5569445954270392,
      "grad_norm": 0.7914062738418579,
      "learning_rate": 8.862961084136532e-05,
      "loss": 0.0311,
      "step": 7685
    },
    {
      "epoch": 0.5570170670725079,
      "grad_norm": 3.738295316696167,
      "learning_rate": 8.861511703746649e-05,
      "loss": 0.2314,
      "step": 7686
    },
    {
      "epoch": 0.5570895387179766,
      "grad_norm": 0.5608258843421936,
      "learning_rate": 8.860062323356766e-05,
      "loss": 0.0123,
      "step": 7687
    },
    {
      "epoch": 0.5571620103634453,
      "grad_norm": 1.5815637111663818,
      "learning_rate": 8.858612942966881e-05,
      "loss": 0.0418,
      "step": 7688
    },
    {
      "epoch": 0.557234482008914,
      "grad_norm": 0.7999376654624939,
      "learning_rate": 8.857163562576998e-05,
      "loss": 0.0315,
      "step": 7689
    },
    {
      "epoch": 0.5573069536543828,
      "grad_norm": 1.933714747428894,
      "learning_rate": 8.855714182187115e-05,
      "loss": 0.0737,
      "step": 7690
    },
    {
      "epoch": 0.5573794252998514,
      "grad_norm": 1.3201966285705566,
      "learning_rate": 8.854264801797232e-05,
      "loss": 0.0539,
      "step": 7691
    },
    {
      "epoch": 0.5574518969453202,
      "grad_norm": 1.232764720916748,
      "learning_rate": 8.85281542140735e-05,
      "loss": 0.0614,
      "step": 7692
    },
    {
      "epoch": 0.5575243685907888,
      "grad_norm": 1.7270694971084595,
      "learning_rate": 8.851366041017466e-05,
      "loss": 0.1395,
      "step": 7693
    },
    {
      "epoch": 0.5575968402362576,
      "grad_norm": 1.4686781167984009,
      "learning_rate": 8.849916660627582e-05,
      "loss": 0.0936,
      "step": 7694
    },
    {
      "epoch": 0.5576693118817263,
      "grad_norm": 1.8545728921890259,
      "learning_rate": 8.848467280237699e-05,
      "loss": 0.0647,
      "step": 7695
    },
    {
      "epoch": 0.557741783527195,
      "grad_norm": 0.33499905467033386,
      "learning_rate": 8.847017899847816e-05,
      "loss": 0.0096,
      "step": 7696
    },
    {
      "epoch": 0.5578142551726637,
      "grad_norm": 1.449558138847351,
      "learning_rate": 8.845568519457932e-05,
      "loss": 0.0689,
      "step": 7697
    },
    {
      "epoch": 0.5578867268181325,
      "grad_norm": 4.006623268127441,
      "learning_rate": 8.844119139068049e-05,
      "loss": 0.0407,
      "step": 7698
    },
    {
      "epoch": 0.5579591984636011,
      "grad_norm": 0.7778308987617493,
      "learning_rate": 8.842669758678166e-05,
      "loss": 0.027,
      "step": 7699
    },
    {
      "epoch": 0.5580316701090698,
      "grad_norm": 1.2353218793869019,
      "learning_rate": 8.841220378288281e-05,
      "loss": 0.0658,
      "step": 7700
    },
    {
      "epoch": 0.5581041417545385,
      "grad_norm": 2.1763241291046143,
      "learning_rate": 8.839770997898398e-05,
      "loss": 0.0598,
      "step": 7701
    },
    {
      "epoch": 0.5581766134000072,
      "grad_norm": 1.7500258684158325,
      "learning_rate": 8.838321617508515e-05,
      "loss": 0.049,
      "step": 7702
    },
    {
      "epoch": 0.558249085045476,
      "grad_norm": 1.3061860799789429,
      "learning_rate": 8.836872237118632e-05,
      "loss": 0.0441,
      "step": 7703
    },
    {
      "epoch": 0.5583215566909446,
      "grad_norm": 1.1079113483428955,
      "learning_rate": 8.83542285672875e-05,
      "loss": 0.0386,
      "step": 7704
    },
    {
      "epoch": 0.5583940283364134,
      "grad_norm": 4.2508063316345215,
      "learning_rate": 8.833973476338866e-05,
      "loss": 0.0497,
      "step": 7705
    },
    {
      "epoch": 0.5584664999818821,
      "grad_norm": 2.7553133964538574,
      "learning_rate": 8.832524095948982e-05,
      "loss": 0.1019,
      "step": 7706
    },
    {
      "epoch": 0.5585389716273508,
      "grad_norm": 1.5973219871520996,
      "learning_rate": 8.831074715559099e-05,
      "loss": 0.0876,
      "step": 7707
    },
    {
      "epoch": 0.5586114432728195,
      "grad_norm": 2.695981979370117,
      "learning_rate": 8.829625335169216e-05,
      "loss": 0.1632,
      "step": 7708
    },
    {
      "epoch": 0.5586839149182882,
      "grad_norm": 2.2126479148864746,
      "learning_rate": 8.828175954779332e-05,
      "loss": 0.109,
      "step": 7709
    },
    {
      "epoch": 0.5587563865637569,
      "grad_norm": 0.4858322739601135,
      "learning_rate": 8.826726574389449e-05,
      "loss": 0.0398,
      "step": 7710
    },
    {
      "epoch": 0.5588288582092257,
      "grad_norm": 1.5080631971359253,
      "learning_rate": 8.825277193999566e-05,
      "loss": 0.0393,
      "step": 7711
    },
    {
      "epoch": 0.5589013298546943,
      "grad_norm": 1.4160879850387573,
      "learning_rate": 8.823827813609681e-05,
      "loss": 0.0419,
      "step": 7712
    },
    {
      "epoch": 0.5589738015001631,
      "grad_norm": 1.8436177968978882,
      "learning_rate": 8.822378433219798e-05,
      "loss": 0.0528,
      "step": 7713
    },
    {
      "epoch": 0.5590462731456318,
      "grad_norm": 0.5652194023132324,
      "learning_rate": 8.820929052829915e-05,
      "loss": 0.034,
      "step": 7714
    },
    {
      "epoch": 0.5591187447911005,
      "grad_norm": 0.304178386926651,
      "learning_rate": 8.819479672440032e-05,
      "loss": 0.0075,
      "step": 7715
    },
    {
      "epoch": 0.5591912164365692,
      "grad_norm": 1.3611572980880737,
      "learning_rate": 8.81803029205015e-05,
      "loss": 0.1384,
      "step": 7716
    },
    {
      "epoch": 0.5592636880820379,
      "grad_norm": 1.8614720106124878,
      "learning_rate": 8.816580911660266e-05,
      "loss": 0.1108,
      "step": 7717
    },
    {
      "epoch": 0.5593361597275066,
      "grad_norm": 0.9155673384666443,
      "learning_rate": 8.815131531270382e-05,
      "loss": 0.0375,
      "step": 7718
    },
    {
      "epoch": 0.5594086313729754,
      "grad_norm": 1.3651379346847534,
      "learning_rate": 8.813682150880499e-05,
      "loss": 0.0968,
      "step": 7719
    },
    {
      "epoch": 0.559481103018444,
      "grad_norm": 0.31516528129577637,
      "learning_rate": 8.812232770490616e-05,
      "loss": 0.0051,
      "step": 7720
    },
    {
      "epoch": 0.5595535746639128,
      "grad_norm": 0.7758187651634216,
      "learning_rate": 8.810783390100732e-05,
      "loss": 0.0408,
      "step": 7721
    },
    {
      "epoch": 0.5596260463093815,
      "grad_norm": 1.489161729812622,
      "learning_rate": 8.809334009710849e-05,
      "loss": 0.0295,
      "step": 7722
    },
    {
      "epoch": 0.5596985179548501,
      "grad_norm": 1.0433317422866821,
      "learning_rate": 8.807884629320966e-05,
      "loss": 0.0199,
      "step": 7723
    },
    {
      "epoch": 0.5597709896003189,
      "grad_norm": 1.4796302318572998,
      "learning_rate": 8.806435248931081e-05,
      "loss": 0.0939,
      "step": 7724
    },
    {
      "epoch": 0.5598434612457875,
      "grad_norm": 1.8096942901611328,
      "learning_rate": 8.804985868541198e-05,
      "loss": 0.067,
      "step": 7725
    },
    {
      "epoch": 0.5599159328912563,
      "grad_norm": 3.372598886489868,
      "learning_rate": 8.803536488151315e-05,
      "loss": 0.1336,
      "step": 7726
    },
    {
      "epoch": 0.559988404536725,
      "grad_norm": 3.1584253311157227,
      "learning_rate": 8.802087107761432e-05,
      "loss": 0.1941,
      "step": 7727
    },
    {
      "epoch": 0.5600608761821937,
      "grad_norm": 0.41232573986053467,
      "learning_rate": 8.80063772737155e-05,
      "loss": 0.0154,
      "step": 7728
    },
    {
      "epoch": 0.5601333478276624,
      "grad_norm": 2.962430953979492,
      "learning_rate": 8.799188346981666e-05,
      "loss": 0.0527,
      "step": 7729
    },
    {
      "epoch": 0.5602058194731311,
      "grad_norm": 0.47028908133506775,
      "learning_rate": 8.797738966591782e-05,
      "loss": 0.0167,
      "step": 7730
    },
    {
      "epoch": 0.5602782911185998,
      "grad_norm": 1.4775062799453735,
      "learning_rate": 8.796289586201899e-05,
      "loss": 0.0737,
      "step": 7731
    },
    {
      "epoch": 0.5603507627640686,
      "grad_norm": 1.440487027168274,
      "learning_rate": 8.794840205812016e-05,
      "loss": 0.0582,
      "step": 7732
    },
    {
      "epoch": 0.5604232344095372,
      "grad_norm": 0.670096755027771,
      "learning_rate": 8.793390825422132e-05,
      "loss": 0.0404,
      "step": 7733
    },
    {
      "epoch": 0.560495706055006,
      "grad_norm": 0.7137922048568726,
      "learning_rate": 8.791941445032249e-05,
      "loss": 0.0362,
      "step": 7734
    },
    {
      "epoch": 0.5605681777004747,
      "grad_norm": 0.02000659517943859,
      "learning_rate": 8.790492064642366e-05,
      "loss": 0.0005,
      "step": 7735
    },
    {
      "epoch": 0.5606406493459434,
      "grad_norm": 2.748957633972168,
      "learning_rate": 8.789042684252481e-05,
      "loss": 0.1874,
      "step": 7736
    },
    {
      "epoch": 0.5607131209914121,
      "grad_norm": 0.57478928565979,
      "learning_rate": 8.7875933038626e-05,
      "loss": 0.0185,
      "step": 7737
    },
    {
      "epoch": 0.5607855926368808,
      "grad_norm": 0.4468405544757843,
      "learning_rate": 8.786143923472717e-05,
      "loss": 0.0184,
      "step": 7738
    },
    {
      "epoch": 0.5608580642823495,
      "grad_norm": 0.5047467947006226,
      "learning_rate": 8.784694543082832e-05,
      "loss": 0.0135,
      "step": 7739
    },
    {
      "epoch": 0.5609305359278183,
      "grad_norm": 2.744396686553955,
      "learning_rate": 8.78324516269295e-05,
      "loss": 0.1158,
      "step": 7740
    },
    {
      "epoch": 0.5610030075732869,
      "grad_norm": 2.427300453186035,
      "learning_rate": 8.781795782303066e-05,
      "loss": 0.0516,
      "step": 7741
    },
    {
      "epoch": 0.5610754792187557,
      "grad_norm": 1.7948917150497437,
      "learning_rate": 8.780346401913182e-05,
      "loss": 0.0839,
      "step": 7742
    },
    {
      "epoch": 0.5611479508642244,
      "grad_norm": 1.0702728033065796,
      "learning_rate": 8.778897021523299e-05,
      "loss": 0.0238,
      "step": 7743
    },
    {
      "epoch": 0.5612204225096931,
      "grad_norm": 0.7594680190086365,
      "learning_rate": 8.777447641133416e-05,
      "loss": 0.0427,
      "step": 7744
    },
    {
      "epoch": 0.5612928941551618,
      "grad_norm": 0.5694240927696228,
      "learning_rate": 8.775998260743532e-05,
      "loss": 0.0203,
      "step": 7745
    },
    {
      "epoch": 0.5613653658006305,
      "grad_norm": 0.727875292301178,
      "learning_rate": 8.774548880353649e-05,
      "loss": 0.0189,
      "step": 7746
    },
    {
      "epoch": 0.5614378374460992,
      "grad_norm": 0.7692326903343201,
      "learning_rate": 8.773099499963766e-05,
      "loss": 0.031,
      "step": 7747
    },
    {
      "epoch": 0.561510309091568,
      "grad_norm": 2.9543297290802,
      "learning_rate": 8.771650119573883e-05,
      "loss": 0.0594,
      "step": 7748
    },
    {
      "epoch": 0.5615827807370366,
      "grad_norm": 0.8303922414779663,
      "learning_rate": 8.770200739184e-05,
      "loss": 0.0219,
      "step": 7749
    },
    {
      "epoch": 0.5616552523825054,
      "grad_norm": 1.5993499755859375,
      "learning_rate": 8.768751358794117e-05,
      "loss": 0.0839,
      "step": 7750
    },
    {
      "epoch": 0.5617277240279741,
      "grad_norm": 1.2922496795654297,
      "learning_rate": 8.767301978404232e-05,
      "loss": 0.1009,
      "step": 7751
    },
    {
      "epoch": 0.5618001956734427,
      "grad_norm": 1.4900319576263428,
      "learning_rate": 8.76585259801435e-05,
      "loss": 0.0822,
      "step": 7752
    },
    {
      "epoch": 0.5618726673189115,
      "grad_norm": 3.022230863571167,
      "learning_rate": 8.764403217624466e-05,
      "loss": 0.127,
      "step": 7753
    },
    {
      "epoch": 0.5619451389643801,
      "grad_norm": 0.5836079120635986,
      "learning_rate": 8.762953837234583e-05,
      "loss": 0.0199,
      "step": 7754
    },
    {
      "epoch": 0.5620176106098489,
      "grad_norm": 2.707015037536621,
      "learning_rate": 8.761504456844699e-05,
      "loss": 0.0327,
      "step": 7755
    },
    {
      "epoch": 0.5620900822553176,
      "grad_norm": 0.47097012400627136,
      "learning_rate": 8.760055076454816e-05,
      "loss": 0.0134,
      "step": 7756
    },
    {
      "epoch": 0.5621625539007863,
      "grad_norm": 2.592137098312378,
      "learning_rate": 8.758605696064933e-05,
      "loss": 0.124,
      "step": 7757
    },
    {
      "epoch": 0.562235025546255,
      "grad_norm": 1.532038688659668,
      "learning_rate": 8.757156315675049e-05,
      "loss": 0.0351,
      "step": 7758
    },
    {
      "epoch": 0.5623074971917238,
      "grad_norm": 1.4996713399887085,
      "learning_rate": 8.755706935285166e-05,
      "loss": 0.0627,
      "step": 7759
    },
    {
      "epoch": 0.5623799688371924,
      "grad_norm": 0.034890513867139816,
      "learning_rate": 8.754257554895283e-05,
      "loss": 0.0011,
      "step": 7760
    },
    {
      "epoch": 0.5624524404826612,
      "grad_norm": 1.0862208604812622,
      "learning_rate": 8.7528081745054e-05,
      "loss": 0.0504,
      "step": 7761
    },
    {
      "epoch": 0.5625249121281298,
      "grad_norm": 2.672034740447998,
      "learning_rate": 8.751358794115517e-05,
      "loss": 0.0684,
      "step": 7762
    },
    {
      "epoch": 0.5625973837735986,
      "grad_norm": 1.745031476020813,
      "learning_rate": 8.749909413725634e-05,
      "loss": 0.0531,
      "step": 7763
    },
    {
      "epoch": 0.5626698554190673,
      "grad_norm": 0.8841762542724609,
      "learning_rate": 8.748460033335749e-05,
      "loss": 0.0536,
      "step": 7764
    },
    {
      "epoch": 0.562742327064536,
      "grad_norm": 1.084470510482788,
      "learning_rate": 8.747010652945866e-05,
      "loss": 0.0584,
      "step": 7765
    },
    {
      "epoch": 0.5628147987100047,
      "grad_norm": 1.55600106716156,
      "learning_rate": 8.745561272555983e-05,
      "loss": 0.1586,
      "step": 7766
    },
    {
      "epoch": 0.5628872703554734,
      "grad_norm": 1.7960851192474365,
      "learning_rate": 8.744111892166099e-05,
      "loss": 0.0498,
      "step": 7767
    },
    {
      "epoch": 0.5629597420009421,
      "grad_norm": 1.797610878944397,
      "learning_rate": 8.742662511776216e-05,
      "loss": 0.0704,
      "step": 7768
    },
    {
      "epoch": 0.5630322136464109,
      "grad_norm": 0.3445276916027069,
      "learning_rate": 8.741213131386333e-05,
      "loss": 0.0059,
      "step": 7769
    },
    {
      "epoch": 0.5631046852918795,
      "grad_norm": 3.8813374042510986,
      "learning_rate": 8.739763750996449e-05,
      "loss": 0.0676,
      "step": 7770
    },
    {
      "epoch": 0.5631771569373483,
      "grad_norm": 3.1735122203826904,
      "learning_rate": 8.738314370606566e-05,
      "loss": 0.0908,
      "step": 7771
    },
    {
      "epoch": 0.563249628582817,
      "grad_norm": 1.2572598457336426,
      "learning_rate": 8.736864990216683e-05,
      "loss": 0.0452,
      "step": 7772
    },
    {
      "epoch": 0.5633221002282857,
      "grad_norm": 0.9333128333091736,
      "learning_rate": 8.7354156098268e-05,
      "loss": 0.0325,
      "step": 7773
    },
    {
      "epoch": 0.5633945718737544,
      "grad_norm": 0.2434193342924118,
      "learning_rate": 8.733966229436917e-05,
      "loss": 0.0055,
      "step": 7774
    },
    {
      "epoch": 0.563467043519223,
      "grad_norm": 0.40418800711631775,
      "learning_rate": 8.732516849047034e-05,
      "loss": 0.0298,
      "step": 7775
    },
    {
      "epoch": 0.5635395151646918,
      "grad_norm": 2.6279923915863037,
      "learning_rate": 8.731067468657149e-05,
      "loss": 0.1307,
      "step": 7776
    },
    {
      "epoch": 0.5636119868101606,
      "grad_norm": 0.21184979379177094,
      "learning_rate": 8.729618088267266e-05,
      "loss": 0.0063,
      "step": 7777
    },
    {
      "epoch": 0.5636844584556292,
      "grad_norm": 0.5069242715835571,
      "learning_rate": 8.728168707877383e-05,
      "loss": 0.0177,
      "step": 7778
    },
    {
      "epoch": 0.563756930101098,
      "grad_norm": 0.6804307699203491,
      "learning_rate": 8.726719327487499e-05,
      "loss": 0.0239,
      "step": 7779
    },
    {
      "epoch": 0.5638294017465667,
      "grad_norm": 1.6674830913543701,
      "learning_rate": 8.725269947097616e-05,
      "loss": 0.033,
      "step": 7780
    },
    {
      "epoch": 0.5639018733920353,
      "grad_norm": 1.0726300477981567,
      "learning_rate": 8.723820566707733e-05,
      "loss": 0.0718,
      "step": 7781
    },
    {
      "epoch": 0.5639743450375041,
      "grad_norm": 1.5717209577560425,
      "learning_rate": 8.722371186317849e-05,
      "loss": 0.0886,
      "step": 7782
    },
    {
      "epoch": 0.5640468166829727,
      "grad_norm": 0.23403514921665192,
      "learning_rate": 8.720921805927966e-05,
      "loss": 0.0043,
      "step": 7783
    },
    {
      "epoch": 0.5641192883284415,
      "grad_norm": 2.3513147830963135,
      "learning_rate": 8.719472425538084e-05,
      "loss": 0.0811,
      "step": 7784
    },
    {
      "epoch": 0.5641917599739102,
      "grad_norm": 0.14236047863960266,
      "learning_rate": 8.7180230451482e-05,
      "loss": 0.0021,
      "step": 7785
    },
    {
      "epoch": 0.5642642316193789,
      "grad_norm": 1.3023765087127686,
      "learning_rate": 8.716573664758317e-05,
      "loss": 0.0249,
      "step": 7786
    },
    {
      "epoch": 0.5643367032648476,
      "grad_norm": 0.4418155252933502,
      "learning_rate": 8.715124284368434e-05,
      "loss": 0.0139,
      "step": 7787
    },
    {
      "epoch": 0.5644091749103164,
      "grad_norm": 1.8134288787841797,
      "learning_rate": 8.713674903978549e-05,
      "loss": 0.0422,
      "step": 7788
    },
    {
      "epoch": 0.564481646555785,
      "grad_norm": 2.143314838409424,
      "learning_rate": 8.712225523588666e-05,
      "loss": 0.189,
      "step": 7789
    },
    {
      "epoch": 0.5645541182012538,
      "grad_norm": 1.81417977809906,
      "learning_rate": 8.710776143198783e-05,
      "loss": 0.0897,
      "step": 7790
    },
    {
      "epoch": 0.5646265898467224,
      "grad_norm": 0.8682869076728821,
      "learning_rate": 8.709326762808899e-05,
      "loss": 0.0609,
      "step": 7791
    },
    {
      "epoch": 0.5646990614921912,
      "grad_norm": 1.2992514371871948,
      "learning_rate": 8.707877382419016e-05,
      "loss": 0.1285,
      "step": 7792
    },
    {
      "epoch": 0.5647715331376599,
      "grad_norm": 3.215067148208618,
      "learning_rate": 8.706428002029133e-05,
      "loss": 0.0762,
      "step": 7793
    },
    {
      "epoch": 0.5648440047831286,
      "grad_norm": 9.654101371765137,
      "learning_rate": 8.70497862163925e-05,
      "loss": 0.0857,
      "step": 7794
    },
    {
      "epoch": 0.5649164764285973,
      "grad_norm": 0.5530556440353394,
      "learning_rate": 8.703529241249367e-05,
      "loss": 0.0229,
      "step": 7795
    },
    {
      "epoch": 0.564988948074066,
      "grad_norm": 1.689558982849121,
      "learning_rate": 8.702079860859484e-05,
      "loss": 0.0627,
      "step": 7796
    },
    {
      "epoch": 0.5650614197195347,
      "grad_norm": 1.0765745639801025,
      "learning_rate": 8.7006304804696e-05,
      "loss": 0.0743,
      "step": 7797
    },
    {
      "epoch": 0.5651338913650035,
      "grad_norm": 1.2023506164550781,
      "learning_rate": 8.699181100079717e-05,
      "loss": 0.0981,
      "step": 7798
    },
    {
      "epoch": 0.5652063630104721,
      "grad_norm": 1.5294957160949707,
      "learning_rate": 8.697731719689834e-05,
      "loss": 0.1413,
      "step": 7799
    },
    {
      "epoch": 0.5652788346559409,
      "grad_norm": 1.4541484117507935,
      "learning_rate": 8.696282339299949e-05,
      "loss": 0.0494,
      "step": 7800
    },
    {
      "epoch": 0.5653513063014096,
      "grad_norm": 1.0426584482192993,
      "learning_rate": 8.694832958910066e-05,
      "loss": 0.0411,
      "step": 7801
    },
    {
      "epoch": 0.5654237779468783,
      "grad_norm": 0.592904269695282,
      "learning_rate": 8.693383578520183e-05,
      "loss": 0.0326,
      "step": 7802
    },
    {
      "epoch": 0.565496249592347,
      "grad_norm": 1.9877731800079346,
      "learning_rate": 8.691934198130299e-05,
      "loss": 0.0958,
      "step": 7803
    },
    {
      "epoch": 0.5655687212378157,
      "grad_norm": 3.234778642654419,
      "learning_rate": 8.690484817740416e-05,
      "loss": 0.1187,
      "step": 7804
    },
    {
      "epoch": 0.5656411928832844,
      "grad_norm": 0.6839091777801514,
      "learning_rate": 8.689035437350533e-05,
      "loss": 0.0203,
      "step": 7805
    },
    {
      "epoch": 0.5657136645287532,
      "grad_norm": 0.6472151875495911,
      "learning_rate": 8.68758605696065e-05,
      "loss": 0.0233,
      "step": 7806
    },
    {
      "epoch": 0.5657861361742218,
      "grad_norm": 0.6698794960975647,
      "learning_rate": 8.686136676570767e-05,
      "loss": 0.0234,
      "step": 7807
    },
    {
      "epoch": 0.5658586078196906,
      "grad_norm": 0.8947628736495972,
      "learning_rate": 8.684687296180884e-05,
      "loss": 0.0288,
      "step": 7808
    },
    {
      "epoch": 0.5659310794651593,
      "grad_norm": 0.6481756567955017,
      "learning_rate": 8.683237915791e-05,
      "loss": 0.0137,
      "step": 7809
    },
    {
      "epoch": 0.566003551110628,
      "grad_norm": 0.7174015045166016,
      "learning_rate": 8.681788535401117e-05,
      "loss": 0.017,
      "step": 7810
    },
    {
      "epoch": 0.5660760227560967,
      "grad_norm": 0.8783297538757324,
      "learning_rate": 8.680339155011234e-05,
      "loss": 0.0582,
      "step": 7811
    },
    {
      "epoch": 0.5661484944015653,
      "grad_norm": 3.9219138622283936,
      "learning_rate": 8.678889774621349e-05,
      "loss": 0.0377,
      "step": 7812
    },
    {
      "epoch": 0.5662209660470341,
      "grad_norm": 0.6288392543792725,
      "learning_rate": 8.677440394231466e-05,
      "loss": 0.0247,
      "step": 7813
    },
    {
      "epoch": 0.5662934376925028,
      "grad_norm": 2.8540196418762207,
      "learning_rate": 8.675991013841583e-05,
      "loss": 0.0668,
      "step": 7814
    },
    {
      "epoch": 0.5663659093379715,
      "grad_norm": 2.5703301429748535,
      "learning_rate": 8.674541633451699e-05,
      "loss": 0.0764,
      "step": 7815
    },
    {
      "epoch": 0.5664383809834402,
      "grad_norm": 0.6177444458007812,
      "learning_rate": 8.673092253061816e-05,
      "loss": 0.0087,
      "step": 7816
    },
    {
      "epoch": 0.566510852628909,
      "grad_norm": 1.1611982583999634,
      "learning_rate": 8.671642872671933e-05,
      "loss": 0.0314,
      "step": 7817
    },
    {
      "epoch": 0.5665833242743776,
      "grad_norm": 2.477245807647705,
      "learning_rate": 8.67019349228205e-05,
      "loss": 0.095,
      "step": 7818
    },
    {
      "epoch": 0.5666557959198464,
      "grad_norm": 1.200566053390503,
      "learning_rate": 8.668744111892167e-05,
      "loss": 0.0176,
      "step": 7819
    },
    {
      "epoch": 0.566728267565315,
      "grad_norm": 3.062652587890625,
      "learning_rate": 8.667294731502284e-05,
      "loss": 0.1204,
      "step": 7820
    },
    {
      "epoch": 0.5668007392107838,
      "grad_norm": 1.5425251722335815,
      "learning_rate": 8.6658453511124e-05,
      "loss": 0.1181,
      "step": 7821
    },
    {
      "epoch": 0.5668732108562525,
      "grad_norm": 2.170799732208252,
      "learning_rate": 8.664395970722517e-05,
      "loss": 0.0425,
      "step": 7822
    },
    {
      "epoch": 0.5669456825017212,
      "grad_norm": 1.0775010585784912,
      "learning_rate": 8.662946590332634e-05,
      "loss": 0.0328,
      "step": 7823
    },
    {
      "epoch": 0.5670181541471899,
      "grad_norm": 1.2059794664382935,
      "learning_rate": 8.661497209942749e-05,
      "loss": 0.0474,
      "step": 7824
    },
    {
      "epoch": 0.5670906257926587,
      "grad_norm": 0.21878044307231903,
      "learning_rate": 8.660047829552866e-05,
      "loss": 0.0077,
      "step": 7825
    },
    {
      "epoch": 0.5671630974381273,
      "grad_norm": 1.192018747329712,
      "learning_rate": 8.658598449162983e-05,
      "loss": 0.0683,
      "step": 7826
    },
    {
      "epoch": 0.5672355690835961,
      "grad_norm": 1.2757571935653687,
      "learning_rate": 8.657149068773099e-05,
      "loss": 0.0362,
      "step": 7827
    },
    {
      "epoch": 0.5673080407290647,
      "grad_norm": 1.4606730937957764,
      "learning_rate": 8.655699688383216e-05,
      "loss": 0.085,
      "step": 7828
    },
    {
      "epoch": 0.5673805123745335,
      "grad_norm": 1.6285451650619507,
      "learning_rate": 8.654250307993333e-05,
      "loss": 0.0726,
      "step": 7829
    },
    {
      "epoch": 0.5674529840200022,
      "grad_norm": 0.9258453249931335,
      "learning_rate": 8.65280092760345e-05,
      "loss": 0.0617,
      "step": 7830
    },
    {
      "epoch": 0.5675254556654709,
      "grad_norm": 0.15406863391399384,
      "learning_rate": 8.651351547213567e-05,
      "loss": 0.0026,
      "step": 7831
    },
    {
      "epoch": 0.5675979273109396,
      "grad_norm": 0.08141963183879852,
      "learning_rate": 8.649902166823684e-05,
      "loss": 0.0024,
      "step": 7832
    },
    {
      "epoch": 0.5676703989564083,
      "grad_norm": 0.9917072653770447,
      "learning_rate": 8.6484527864338e-05,
      "loss": 0.0576,
      "step": 7833
    },
    {
      "epoch": 0.567742870601877,
      "grad_norm": 1.5799061059951782,
      "learning_rate": 8.647003406043917e-05,
      "loss": 0.0532,
      "step": 7834
    },
    {
      "epoch": 0.5678153422473458,
      "grad_norm": 4.651021480560303,
      "learning_rate": 8.645554025654034e-05,
      "loss": 0.0551,
      "step": 7835
    },
    {
      "epoch": 0.5678878138928144,
      "grad_norm": 0.6536256670951843,
      "learning_rate": 8.64410464526415e-05,
      "loss": 0.0394,
      "step": 7836
    },
    {
      "epoch": 0.5679602855382831,
      "grad_norm": 2.304483652114868,
      "learning_rate": 8.642655264874266e-05,
      "loss": 0.1497,
      "step": 7837
    },
    {
      "epoch": 0.5680327571837519,
      "grad_norm": 0.37103432416915894,
      "learning_rate": 8.641205884484383e-05,
      "loss": 0.0094,
      "step": 7838
    },
    {
      "epoch": 0.5681052288292205,
      "grad_norm": 1.3724006414413452,
      "learning_rate": 8.6397565040945e-05,
      "loss": 0.0246,
      "step": 7839
    },
    {
      "epoch": 0.5681777004746893,
      "grad_norm": 1.3482459783554077,
      "learning_rate": 8.638307123704616e-05,
      "loss": 0.0521,
      "step": 7840
    },
    {
      "epoch": 0.5682501721201579,
      "grad_norm": 1.1189253330230713,
      "learning_rate": 8.636857743314733e-05,
      "loss": 0.0385,
      "step": 7841
    },
    {
      "epoch": 0.5683226437656267,
      "grad_norm": 0.4568502902984619,
      "learning_rate": 8.635408362924851e-05,
      "loss": 0.0318,
      "step": 7842
    },
    {
      "epoch": 0.5683951154110954,
      "grad_norm": 0.6585304737091064,
      "learning_rate": 8.633958982534967e-05,
      "loss": 0.0449,
      "step": 7843
    },
    {
      "epoch": 0.5684675870565641,
      "grad_norm": 1.8085951805114746,
      "learning_rate": 8.632509602145084e-05,
      "loss": 0.1069,
      "step": 7844
    },
    {
      "epoch": 0.5685400587020328,
      "grad_norm": 1.283566951751709,
      "learning_rate": 8.631060221755201e-05,
      "loss": 0.0633,
      "step": 7845
    },
    {
      "epoch": 0.5686125303475016,
      "grad_norm": 2.595341205596924,
      "learning_rate": 8.629610841365317e-05,
      "loss": 0.1216,
      "step": 7846
    },
    {
      "epoch": 0.5686850019929702,
      "grad_norm": 0.6918138861656189,
      "learning_rate": 8.628161460975434e-05,
      "loss": 0.0098,
      "step": 7847
    },
    {
      "epoch": 0.568757473638439,
      "grad_norm": 5.392898082733154,
      "learning_rate": 8.62671208058555e-05,
      "loss": 0.0484,
      "step": 7848
    },
    {
      "epoch": 0.5688299452839076,
      "grad_norm": 0.6174790263175964,
      "learning_rate": 8.625262700195666e-05,
      "loss": 0.0414,
      "step": 7849
    },
    {
      "epoch": 0.5689024169293764,
      "grad_norm": 1.4338527917861938,
      "learning_rate": 8.623813319805783e-05,
      "loss": 0.02,
      "step": 7850
    },
    {
      "epoch": 0.5689748885748451,
      "grad_norm": 0.3372625410556793,
      "learning_rate": 8.6223639394159e-05,
      "loss": 0.0137,
      "step": 7851
    },
    {
      "epoch": 0.5690473602203138,
      "grad_norm": 0.6278892159461975,
      "learning_rate": 8.620914559026017e-05,
      "loss": 0.0281,
      "step": 7852
    },
    {
      "epoch": 0.5691198318657825,
      "grad_norm": 0.8064271807670593,
      "learning_rate": 8.619465178636134e-05,
      "loss": 0.0184,
      "step": 7853
    },
    {
      "epoch": 0.5691923035112513,
      "grad_norm": 0.5009435415267944,
      "learning_rate": 8.618015798246251e-05,
      "loss": 0.022,
      "step": 7854
    },
    {
      "epoch": 0.5692647751567199,
      "grad_norm": 1.8789492845535278,
      "learning_rate": 8.616566417856367e-05,
      "loss": 0.1302,
      "step": 7855
    },
    {
      "epoch": 0.5693372468021887,
      "grad_norm": 1.0157750844955444,
      "learning_rate": 8.615117037466484e-05,
      "loss": 0.0618,
      "step": 7856
    },
    {
      "epoch": 0.5694097184476573,
      "grad_norm": 0.06519767642021179,
      "learning_rate": 8.613667657076601e-05,
      "loss": 0.0008,
      "step": 7857
    },
    {
      "epoch": 0.5694821900931261,
      "grad_norm": 0.6276580095291138,
      "learning_rate": 8.612218276686716e-05,
      "loss": 0.0226,
      "step": 7858
    },
    {
      "epoch": 0.5695546617385948,
      "grad_norm": 0.2750042974948883,
      "learning_rate": 8.610768896296833e-05,
      "loss": 0.019,
      "step": 7859
    },
    {
      "epoch": 0.5696271333840635,
      "grad_norm": 1.1736385822296143,
      "learning_rate": 8.60931951590695e-05,
      "loss": 0.0596,
      "step": 7860
    },
    {
      "epoch": 0.5696996050295322,
      "grad_norm": 1.5032724142074585,
      "learning_rate": 8.607870135517066e-05,
      "loss": 0.0879,
      "step": 7861
    },
    {
      "epoch": 0.569772076675001,
      "grad_norm": 1.7368838787078857,
      "learning_rate": 8.606420755127183e-05,
      "loss": 0.0559,
      "step": 7862
    },
    {
      "epoch": 0.5698445483204696,
      "grad_norm": 0.8925333023071289,
      "learning_rate": 8.6049713747373e-05,
      "loss": 0.0341,
      "step": 7863
    },
    {
      "epoch": 0.5699170199659384,
      "grad_norm": 0.7532642483711243,
      "learning_rate": 8.603521994347417e-05,
      "loss": 0.0379,
      "step": 7864
    },
    {
      "epoch": 0.569989491611407,
      "grad_norm": 3.272204637527466,
      "learning_rate": 8.602072613957534e-05,
      "loss": 0.1513,
      "step": 7865
    },
    {
      "epoch": 0.5700619632568757,
      "grad_norm": 0.37856143712997437,
      "learning_rate": 8.600623233567651e-05,
      "loss": 0.014,
      "step": 7866
    },
    {
      "epoch": 0.5701344349023445,
      "grad_norm": 0.8130233883857727,
      "learning_rate": 8.599173853177767e-05,
      "loss": 0.0633,
      "step": 7867
    },
    {
      "epoch": 0.5702069065478131,
      "grad_norm": 2.3133974075317383,
      "learning_rate": 8.597724472787884e-05,
      "loss": 0.1317,
      "step": 7868
    },
    {
      "epoch": 0.5702793781932819,
      "grad_norm": 0.5330259203910828,
      "learning_rate": 8.596275092398001e-05,
      "loss": 0.0269,
      "step": 7869
    },
    {
      "epoch": 0.5703518498387505,
      "grad_norm": 0.6157671213150024,
      "learning_rate": 8.594825712008116e-05,
      "loss": 0.0419,
      "step": 7870
    },
    {
      "epoch": 0.5704243214842193,
      "grad_norm": 1.7529327869415283,
      "learning_rate": 8.593376331618233e-05,
      "loss": 0.0801,
      "step": 7871
    },
    {
      "epoch": 0.570496793129688,
      "grad_norm": 0.8730716109275818,
      "learning_rate": 8.59192695122835e-05,
      "loss": 0.057,
      "step": 7872
    },
    {
      "epoch": 0.5705692647751567,
      "grad_norm": 1.2537425756454468,
      "learning_rate": 8.590477570838466e-05,
      "loss": 0.0357,
      "step": 7873
    },
    {
      "epoch": 0.5706417364206254,
      "grad_norm": 1.5121750831604004,
      "learning_rate": 8.589028190448583e-05,
      "loss": 0.0447,
      "step": 7874
    },
    {
      "epoch": 0.5707142080660942,
      "grad_norm": 0.8886197209358215,
      "learning_rate": 8.5875788100587e-05,
      "loss": 0.0339,
      "step": 7875
    },
    {
      "epoch": 0.5707866797115628,
      "grad_norm": 5.092526435852051,
      "learning_rate": 8.586129429668817e-05,
      "loss": 0.1474,
      "step": 7876
    },
    {
      "epoch": 0.5708591513570316,
      "grad_norm": 2.003856897354126,
      "learning_rate": 8.584680049278934e-05,
      "loss": 0.0928,
      "step": 7877
    },
    {
      "epoch": 0.5709316230025002,
      "grad_norm": 2.9959611892700195,
      "learning_rate": 8.583230668889051e-05,
      "loss": 0.1798,
      "step": 7878
    },
    {
      "epoch": 0.571004094647969,
      "grad_norm": 1.3932994604110718,
      "learning_rate": 8.581781288499167e-05,
      "loss": 0.0677,
      "step": 7879
    },
    {
      "epoch": 0.5710765662934377,
      "grad_norm": 0.25753530859947205,
      "learning_rate": 8.580331908109284e-05,
      "loss": 0.0111,
      "step": 7880
    },
    {
      "epoch": 0.5711490379389064,
      "grad_norm": 1.1644518375396729,
      "learning_rate": 8.578882527719401e-05,
      "loss": 0.0874,
      "step": 7881
    },
    {
      "epoch": 0.5712215095843751,
      "grad_norm": 0.6749065518379211,
      "learning_rate": 8.577433147329516e-05,
      "loss": 0.0271,
      "step": 7882
    },
    {
      "epoch": 0.5712939812298439,
      "grad_norm": 1.363265037536621,
      "learning_rate": 8.575983766939633e-05,
      "loss": 0.0616,
      "step": 7883
    },
    {
      "epoch": 0.5713664528753125,
      "grad_norm": 1.027809739112854,
      "learning_rate": 8.57453438654975e-05,
      "loss": 0.037,
      "step": 7884
    },
    {
      "epoch": 0.5714389245207813,
      "grad_norm": 0.2098654806613922,
      "learning_rate": 8.573085006159866e-05,
      "loss": 0.0044,
      "step": 7885
    },
    {
      "epoch": 0.5715113961662499,
      "grad_norm": 1.0849202871322632,
      "learning_rate": 8.571635625769983e-05,
      "loss": 0.0639,
      "step": 7886
    },
    {
      "epoch": 0.5715838678117187,
      "grad_norm": 2.615915536880493,
      "learning_rate": 8.5701862453801e-05,
      "loss": 0.1035,
      "step": 7887
    },
    {
      "epoch": 0.5716563394571874,
      "grad_norm": 2.265342950820923,
      "learning_rate": 8.568736864990217e-05,
      "loss": 0.1178,
      "step": 7888
    },
    {
      "epoch": 0.571728811102656,
      "grad_norm": 1.1086138486862183,
      "learning_rate": 8.567287484600334e-05,
      "loss": 0.0737,
      "step": 7889
    },
    {
      "epoch": 0.5718012827481248,
      "grad_norm": 0.7021770477294922,
      "learning_rate": 8.565838104210451e-05,
      "loss": 0.0197,
      "step": 7890
    },
    {
      "epoch": 0.5718737543935936,
      "grad_norm": 0.6858908534049988,
      "learning_rate": 8.564388723820567e-05,
      "loss": 0.0404,
      "step": 7891
    },
    {
      "epoch": 0.5719462260390622,
      "grad_norm": 2.1780850887298584,
      "learning_rate": 8.562939343430684e-05,
      "loss": 0.0773,
      "step": 7892
    },
    {
      "epoch": 0.572018697684531,
      "grad_norm": 4.385932922363281,
      "learning_rate": 8.561489963040801e-05,
      "loss": 0.1058,
      "step": 7893
    },
    {
      "epoch": 0.5720911693299996,
      "grad_norm": 0.6676837801933289,
      "learning_rate": 8.560040582650916e-05,
      "loss": 0.0597,
      "step": 7894
    },
    {
      "epoch": 0.5721636409754683,
      "grad_norm": 0.39485999941825867,
      "learning_rate": 8.558591202261033e-05,
      "loss": 0.0077,
      "step": 7895
    },
    {
      "epoch": 0.5722361126209371,
      "grad_norm": 2.1758460998535156,
      "learning_rate": 8.55714182187115e-05,
      "loss": 0.1296,
      "step": 7896
    },
    {
      "epoch": 0.5723085842664057,
      "grad_norm": 0.9339151382446289,
      "learning_rate": 8.555692441481266e-05,
      "loss": 0.0351,
      "step": 7897
    },
    {
      "epoch": 0.5723810559118745,
      "grad_norm": 1.7533024549484253,
      "learning_rate": 8.554243061091383e-05,
      "loss": 0.0856,
      "step": 7898
    },
    {
      "epoch": 0.5724535275573432,
      "grad_norm": 0.937999963760376,
      "learning_rate": 8.552793680701501e-05,
      "loss": 0.0168,
      "step": 7899
    },
    {
      "epoch": 0.5725259992028119,
      "grad_norm": 0.962554931640625,
      "learning_rate": 8.551344300311617e-05,
      "loss": 0.0525,
      "step": 7900
    },
    {
      "epoch": 0.5725984708482806,
      "grad_norm": 0.6430878639221191,
      "learning_rate": 8.549894919921734e-05,
      "loss": 0.0218,
      "step": 7901
    },
    {
      "epoch": 0.5726709424937493,
      "grad_norm": 0.8987334966659546,
      "learning_rate": 8.548445539531851e-05,
      "loss": 0.0749,
      "step": 7902
    },
    {
      "epoch": 0.572743414139218,
      "grad_norm": 0.7923049330711365,
      "learning_rate": 8.546996159141967e-05,
      "loss": 0.0501,
      "step": 7903
    },
    {
      "epoch": 0.5728158857846868,
      "grad_norm": 1.2408571243286133,
      "learning_rate": 8.545546778752084e-05,
      "loss": 0.0426,
      "step": 7904
    },
    {
      "epoch": 0.5728883574301554,
      "grad_norm": 1.7185918092727661,
      "learning_rate": 8.544097398362201e-05,
      "loss": 0.0957,
      "step": 7905
    },
    {
      "epoch": 0.5729608290756242,
      "grad_norm": 0.29889485239982605,
      "learning_rate": 8.542648017972316e-05,
      "loss": 0.0166,
      "step": 7906
    },
    {
      "epoch": 0.5730333007210928,
      "grad_norm": 0.6327939629554749,
      "learning_rate": 8.541198637582433e-05,
      "loss": 0.037,
      "step": 7907
    },
    {
      "epoch": 0.5731057723665616,
      "grad_norm": 2.50258731842041,
      "learning_rate": 8.53974925719255e-05,
      "loss": 0.086,
      "step": 7908
    },
    {
      "epoch": 0.5731782440120303,
      "grad_norm": 2.498795747756958,
      "learning_rate": 8.538299876802666e-05,
      "loss": 0.141,
      "step": 7909
    },
    {
      "epoch": 0.573250715657499,
      "grad_norm": 3.0466036796569824,
      "learning_rate": 8.536850496412784e-05,
      "loss": 0.0688,
      "step": 7910
    },
    {
      "epoch": 0.5733231873029677,
      "grad_norm": 0.8217052221298218,
      "learning_rate": 8.535401116022901e-05,
      "loss": 0.0421,
      "step": 7911
    },
    {
      "epoch": 0.5733956589484365,
      "grad_norm": 1.2446417808532715,
      "learning_rate": 8.533951735633017e-05,
      "loss": 0.0507,
      "step": 7912
    },
    {
      "epoch": 0.5734681305939051,
      "grad_norm": 0.8432127237319946,
      "learning_rate": 8.532502355243134e-05,
      "loss": 0.0246,
      "step": 7913
    },
    {
      "epoch": 0.5735406022393739,
      "grad_norm": 1.3434298038482666,
      "learning_rate": 8.531052974853251e-05,
      "loss": 0.0632,
      "step": 7914
    },
    {
      "epoch": 0.5736130738848425,
      "grad_norm": 1.0873490571975708,
      "learning_rate": 8.529603594463367e-05,
      "loss": 0.0544,
      "step": 7915
    },
    {
      "epoch": 0.5736855455303113,
      "grad_norm": 4.423877716064453,
      "learning_rate": 8.528154214073484e-05,
      "loss": 0.026,
      "step": 7916
    },
    {
      "epoch": 0.57375801717578,
      "grad_norm": 0.6380071043968201,
      "learning_rate": 8.526704833683601e-05,
      "loss": 0.0177,
      "step": 7917
    },
    {
      "epoch": 0.5738304888212487,
      "grad_norm": 2.056847095489502,
      "learning_rate": 8.525255453293718e-05,
      "loss": 0.1058,
      "step": 7918
    },
    {
      "epoch": 0.5739029604667174,
      "grad_norm": 1.1663663387298584,
      "learning_rate": 8.523806072903833e-05,
      "loss": 0.0686,
      "step": 7919
    },
    {
      "epoch": 0.5739754321121862,
      "grad_norm": 1.1145695447921753,
      "learning_rate": 8.52235669251395e-05,
      "loss": 0.0719,
      "step": 7920
    },
    {
      "epoch": 0.5740479037576548,
      "grad_norm": 3.1597063541412354,
      "learning_rate": 8.520907312124067e-05,
      "loss": 0.0346,
      "step": 7921
    },
    {
      "epoch": 0.5741203754031236,
      "grad_norm": 1.0008784532546997,
      "learning_rate": 8.519457931734184e-05,
      "loss": 0.0666,
      "step": 7922
    },
    {
      "epoch": 0.5741928470485922,
      "grad_norm": 4.64469051361084,
      "learning_rate": 8.518008551344301e-05,
      "loss": 0.0302,
      "step": 7923
    },
    {
      "epoch": 0.5742653186940609,
      "grad_norm": 0.5469198226928711,
      "learning_rate": 8.516559170954418e-05,
      "loss": 0.0214,
      "step": 7924
    },
    {
      "epoch": 0.5743377903395297,
      "grad_norm": 0.6276328563690186,
      "learning_rate": 8.515109790564534e-05,
      "loss": 0.0401,
      "step": 7925
    },
    {
      "epoch": 0.5744102619849983,
      "grad_norm": 1.717923879623413,
      "learning_rate": 8.513660410174651e-05,
      "loss": 0.059,
      "step": 7926
    },
    {
      "epoch": 0.5744827336304671,
      "grad_norm": 0.5215171575546265,
      "learning_rate": 8.512211029784768e-05,
      "loss": 0.0093,
      "step": 7927
    },
    {
      "epoch": 0.5745552052759358,
      "grad_norm": 2.0133843421936035,
      "learning_rate": 8.510761649394884e-05,
      "loss": 0.1002,
      "step": 7928
    },
    {
      "epoch": 0.5746276769214045,
      "grad_norm": 1.8643351793289185,
      "learning_rate": 8.509312269005001e-05,
      "loss": 0.1232,
      "step": 7929
    },
    {
      "epoch": 0.5747001485668732,
      "grad_norm": 2.5052967071533203,
      "learning_rate": 8.507862888615118e-05,
      "loss": 0.1213,
      "step": 7930
    },
    {
      "epoch": 0.5747726202123419,
      "grad_norm": 0.4036039710044861,
      "learning_rate": 8.506413508225233e-05,
      "loss": 0.0295,
      "step": 7931
    },
    {
      "epoch": 0.5748450918578106,
      "grad_norm": 0.7410197257995605,
      "learning_rate": 8.50496412783535e-05,
      "loss": 0.034,
      "step": 7932
    },
    {
      "epoch": 0.5749175635032794,
      "grad_norm": 1.574131965637207,
      "learning_rate": 8.503514747445467e-05,
      "loss": 0.041,
      "step": 7933
    },
    {
      "epoch": 0.574990035148748,
      "grad_norm": 1.0663243532180786,
      "learning_rate": 8.502065367055584e-05,
      "loss": 0.0356,
      "step": 7934
    },
    {
      "epoch": 0.5750625067942168,
      "grad_norm": 1.7591800689697266,
      "learning_rate": 8.500615986665701e-05,
      "loss": 0.1337,
      "step": 7935
    },
    {
      "epoch": 0.5751349784396854,
      "grad_norm": 4.578554630279541,
      "learning_rate": 8.499166606275818e-05,
      "loss": 0.0977,
      "step": 7936
    },
    {
      "epoch": 0.5752074500851542,
      "grad_norm": 1.3202494382858276,
      "learning_rate": 8.497717225885934e-05,
      "loss": 0.0484,
      "step": 7937
    },
    {
      "epoch": 0.5752799217306229,
      "grad_norm": 2.282013177871704,
      "learning_rate": 8.496267845496051e-05,
      "loss": 0.1219,
      "step": 7938
    },
    {
      "epoch": 0.5753523933760916,
      "grad_norm": 0.26614999771118164,
      "learning_rate": 8.494818465106168e-05,
      "loss": 0.0059,
      "step": 7939
    },
    {
      "epoch": 0.5754248650215603,
      "grad_norm": 1.3125158548355103,
      "learning_rate": 8.493369084716284e-05,
      "loss": 0.0223,
      "step": 7940
    },
    {
      "epoch": 0.5754973366670291,
      "grad_norm": 0.6857269406318665,
      "learning_rate": 8.491919704326401e-05,
      "loss": 0.021,
      "step": 7941
    },
    {
      "epoch": 0.5755698083124977,
      "grad_norm": 3.009793281555176,
      "learning_rate": 8.490470323936518e-05,
      "loss": 0.1063,
      "step": 7942
    },
    {
      "epoch": 0.5756422799579665,
      "grad_norm": 5.832761287689209,
      "learning_rate": 8.489020943546633e-05,
      "loss": 0.119,
      "step": 7943
    },
    {
      "epoch": 0.5757147516034351,
      "grad_norm": 0.999110996723175,
      "learning_rate": 8.48757156315675e-05,
      "loss": 0.0176,
      "step": 7944
    },
    {
      "epoch": 0.5757872232489039,
      "grad_norm": 0.697930097579956,
      "learning_rate": 8.486122182766867e-05,
      "loss": 0.0747,
      "step": 7945
    },
    {
      "epoch": 0.5758596948943726,
      "grad_norm": 0.3467465341091156,
      "learning_rate": 8.484672802376984e-05,
      "loss": 0.0211,
      "step": 7946
    },
    {
      "epoch": 0.5759321665398413,
      "grad_norm": 0.3884243667125702,
      "learning_rate": 8.483223421987101e-05,
      "loss": 0.0228,
      "step": 7947
    },
    {
      "epoch": 0.57600463818531,
      "grad_norm": 3.789445161819458,
      "learning_rate": 8.481774041597218e-05,
      "loss": 0.1773,
      "step": 7948
    },
    {
      "epoch": 0.5760771098307788,
      "grad_norm": 4.391983985900879,
      "learning_rate": 8.480324661207334e-05,
      "loss": 0.2363,
      "step": 7949
    },
    {
      "epoch": 0.5761495814762474,
      "grad_norm": 1.168217658996582,
      "learning_rate": 8.478875280817451e-05,
      "loss": 0.058,
      "step": 7950
    },
    {
      "epoch": 0.5762220531217161,
      "grad_norm": 2.6778101921081543,
      "learning_rate": 8.477425900427568e-05,
      "loss": 0.0449,
      "step": 7951
    },
    {
      "epoch": 0.5762945247671848,
      "grad_norm": 1.2915980815887451,
      "learning_rate": 8.475976520037684e-05,
      "loss": 0.0202,
      "step": 7952
    },
    {
      "epoch": 0.5763669964126535,
      "grad_norm": 0.5936521887779236,
      "learning_rate": 8.474527139647801e-05,
      "loss": 0.0172,
      "step": 7953
    },
    {
      "epoch": 0.5764394680581223,
      "grad_norm": 4.3292341232299805,
      "learning_rate": 8.473077759257918e-05,
      "loss": 0.0885,
      "step": 7954
    },
    {
      "epoch": 0.5765119397035909,
      "grad_norm": 1.4028732776641846,
      "learning_rate": 8.471628378868033e-05,
      "loss": 0.0444,
      "step": 7955
    },
    {
      "epoch": 0.5765844113490597,
      "grad_norm": 1.5629032850265503,
      "learning_rate": 8.47017899847815e-05,
      "loss": 0.0898,
      "step": 7956
    },
    {
      "epoch": 0.5766568829945284,
      "grad_norm": 1.9913413524627686,
      "learning_rate": 8.468729618088269e-05,
      "loss": 0.0622,
      "step": 7957
    },
    {
      "epoch": 0.5767293546399971,
      "grad_norm": 1.033583402633667,
      "learning_rate": 8.467280237698384e-05,
      "loss": 0.0975,
      "step": 7958
    },
    {
      "epoch": 0.5768018262854658,
      "grad_norm": 4.347800254821777,
      "learning_rate": 8.465830857308501e-05,
      "loss": 0.068,
      "step": 7959
    },
    {
      "epoch": 0.5768742979309345,
      "grad_norm": 2.759610176086426,
      "learning_rate": 8.464381476918618e-05,
      "loss": 0.0569,
      "step": 7960
    },
    {
      "epoch": 0.5769467695764032,
      "grad_norm": 1.162400722503662,
      "learning_rate": 8.462932096528734e-05,
      "loss": 0.0365,
      "step": 7961
    },
    {
      "epoch": 0.577019241221872,
      "grad_norm": 0.3728315234184265,
      "learning_rate": 8.461482716138851e-05,
      "loss": 0.0293,
      "step": 7962
    },
    {
      "epoch": 0.5770917128673406,
      "grad_norm": 1.5161995887756348,
      "learning_rate": 8.460033335748968e-05,
      "loss": 0.0328,
      "step": 7963
    },
    {
      "epoch": 0.5771641845128094,
      "grad_norm": 0.919556736946106,
      "learning_rate": 8.458583955359084e-05,
      "loss": 0.036,
      "step": 7964
    },
    {
      "epoch": 0.5772366561582781,
      "grad_norm": 0.9942534565925598,
      "learning_rate": 8.4571345749692e-05,
      "loss": 0.0421,
      "step": 7965
    },
    {
      "epoch": 0.5773091278037468,
      "grad_norm": 1.0315502882003784,
      "learning_rate": 8.455685194579318e-05,
      "loss": 0.0557,
      "step": 7966
    },
    {
      "epoch": 0.5773815994492155,
      "grad_norm": 1.6713743209838867,
      "learning_rate": 8.454235814189435e-05,
      "loss": 0.0355,
      "step": 7967
    },
    {
      "epoch": 0.5774540710946842,
      "grad_norm": 1.1566284894943237,
      "learning_rate": 8.452786433799552e-05,
      "loss": 0.0594,
      "step": 7968
    },
    {
      "epoch": 0.5775265427401529,
      "grad_norm": 1.6502504348754883,
      "learning_rate": 8.451337053409669e-05,
      "loss": 0.0963,
      "step": 7969
    },
    {
      "epoch": 0.5775990143856217,
      "grad_norm": 0.9596791863441467,
      "learning_rate": 8.449887673019784e-05,
      "loss": 0.0457,
      "step": 7970
    },
    {
      "epoch": 0.5776714860310903,
      "grad_norm": 4.707578659057617,
      "learning_rate": 8.448438292629901e-05,
      "loss": 0.0877,
      "step": 7971
    },
    {
      "epoch": 0.5777439576765591,
      "grad_norm": 0.9847723841667175,
      "learning_rate": 8.446988912240018e-05,
      "loss": 0.0562,
      "step": 7972
    },
    {
      "epoch": 0.5778164293220277,
      "grad_norm": 0.588304877281189,
      "learning_rate": 8.445539531850134e-05,
      "loss": 0.0209,
      "step": 7973
    },
    {
      "epoch": 0.5778889009674965,
      "grad_norm": 0.5863988995552063,
      "learning_rate": 8.444090151460251e-05,
      "loss": 0.0128,
      "step": 7974
    },
    {
      "epoch": 0.5779613726129652,
      "grad_norm": 0.9798517823219299,
      "learning_rate": 8.442640771070368e-05,
      "loss": 0.0478,
      "step": 7975
    },
    {
      "epoch": 0.5780338442584338,
      "grad_norm": 1.3503737449645996,
      "learning_rate": 8.441191390680484e-05,
      "loss": 0.0301,
      "step": 7976
    },
    {
      "epoch": 0.5781063159039026,
      "grad_norm": 0.5020012855529785,
      "learning_rate": 8.4397420102906e-05,
      "loss": 0.013,
      "step": 7977
    },
    {
      "epoch": 0.5781787875493714,
      "grad_norm": 1.691516637802124,
      "learning_rate": 8.438292629900718e-05,
      "loss": 0.0822,
      "step": 7978
    },
    {
      "epoch": 0.57825125919484,
      "grad_norm": 1.8519515991210938,
      "learning_rate": 8.436843249510835e-05,
      "loss": 0.0187,
      "step": 7979
    },
    {
      "epoch": 0.5783237308403087,
      "grad_norm": 1.1176419258117676,
      "learning_rate": 8.435393869120952e-05,
      "loss": 0.0317,
      "step": 7980
    },
    {
      "epoch": 0.5783962024857774,
      "grad_norm": 0.5734792351722717,
      "learning_rate": 8.433944488731069e-05,
      "loss": 0.0345,
      "step": 7981
    },
    {
      "epoch": 0.5784686741312461,
      "grad_norm": 0.8675744533538818,
      "learning_rate": 8.432495108341184e-05,
      "loss": 0.0281,
      "step": 7982
    },
    {
      "epoch": 0.5785411457767149,
      "grad_norm": 1.7706323862075806,
      "learning_rate": 8.431045727951301e-05,
      "loss": 0.0831,
      "step": 7983
    },
    {
      "epoch": 0.5786136174221835,
      "grad_norm": 3.4391798973083496,
      "learning_rate": 8.429596347561418e-05,
      "loss": 0.0469,
      "step": 7984
    },
    {
      "epoch": 0.5786860890676523,
      "grad_norm": 1.5040398836135864,
      "learning_rate": 8.428146967171534e-05,
      "loss": 0.0433,
      "step": 7985
    },
    {
      "epoch": 0.578758560713121,
      "grad_norm": 1.7280908823013306,
      "learning_rate": 8.426697586781651e-05,
      "loss": 0.0163,
      "step": 7986
    },
    {
      "epoch": 0.5788310323585897,
      "grad_norm": 1.89378023147583,
      "learning_rate": 8.425248206391768e-05,
      "loss": 0.1052,
      "step": 7987
    },
    {
      "epoch": 0.5789035040040584,
      "grad_norm": 0.8205853700637817,
      "learning_rate": 8.423798826001884e-05,
      "loss": 0.0264,
      "step": 7988
    },
    {
      "epoch": 0.5789759756495271,
      "grad_norm": 1.6185133457183838,
      "learning_rate": 8.422349445612e-05,
      "loss": 0.1254,
      "step": 7989
    },
    {
      "epoch": 0.5790484472949958,
      "grad_norm": 4.298930644989014,
      "learning_rate": 8.420900065222118e-05,
      "loss": 0.1069,
      "step": 7990
    },
    {
      "epoch": 0.5791209189404646,
      "grad_norm": 1.3302830457687378,
      "learning_rate": 8.419450684832235e-05,
      "loss": 0.0652,
      "step": 7991
    },
    {
      "epoch": 0.5791933905859332,
      "grad_norm": 0.5538172721862793,
      "learning_rate": 8.418001304442352e-05,
      "loss": 0.037,
      "step": 7992
    },
    {
      "epoch": 0.579265862231402,
      "grad_norm": 0.09226822108030319,
      "learning_rate": 8.416551924052469e-05,
      "loss": 0.0022,
      "step": 7993
    },
    {
      "epoch": 0.5793383338768707,
      "grad_norm": 1.3372682332992554,
      "learning_rate": 8.415102543662584e-05,
      "loss": 0.0122,
      "step": 7994
    },
    {
      "epoch": 0.5794108055223394,
      "grad_norm": 1.448290467262268,
      "learning_rate": 8.413653163272701e-05,
      "loss": 0.0663,
      "step": 7995
    },
    {
      "epoch": 0.5794832771678081,
      "grad_norm": 3.602712392807007,
      "learning_rate": 8.412203782882818e-05,
      "loss": 0.1621,
      "step": 7996
    },
    {
      "epoch": 0.5795557488132768,
      "grad_norm": 1.3983540534973145,
      "learning_rate": 8.410754402492935e-05,
      "loss": 0.0299,
      "step": 7997
    },
    {
      "epoch": 0.5796282204587455,
      "grad_norm": 1.0754261016845703,
      "learning_rate": 8.409305022103051e-05,
      "loss": 0.0572,
      "step": 7998
    },
    {
      "epoch": 0.5797006921042143,
      "grad_norm": 2.026606559753418,
      "learning_rate": 8.407855641713168e-05,
      "loss": 0.1025,
      "step": 7999
    },
    {
      "epoch": 0.5797731637496829,
      "grad_norm": 1.370384931564331,
      "learning_rate": 8.406406261323285e-05,
      "loss": 0.0626,
      "step": 8000
    },
    {
      "epoch": 0.5798456353951517,
      "grad_norm": 3.311645984649658,
      "learning_rate": 8.4049568809334e-05,
      "loss": 0.0367,
      "step": 8001
    },
    {
      "epoch": 0.5799181070406204,
      "grad_norm": 0.6019037961959839,
      "learning_rate": 8.403507500543518e-05,
      "loss": 0.0054,
      "step": 8002
    },
    {
      "epoch": 0.579990578686089,
      "grad_norm": 5.457226753234863,
      "learning_rate": 8.402058120153635e-05,
      "loss": 0.0372,
      "step": 8003
    },
    {
      "epoch": 0.5800630503315578,
      "grad_norm": 0.6143249869346619,
      "learning_rate": 8.400608739763752e-05,
      "loss": 0.0277,
      "step": 8004
    },
    {
      "epoch": 0.5801355219770264,
      "grad_norm": 0.6763757467269897,
      "learning_rate": 8.399159359373869e-05,
      "loss": 0.02,
      "step": 8005
    },
    {
      "epoch": 0.5802079936224952,
      "grad_norm": 0.6489367485046387,
      "learning_rate": 8.397709978983986e-05,
      "loss": 0.0636,
      "step": 8006
    },
    {
      "epoch": 0.580280465267964,
      "grad_norm": 0.5806789994239807,
      "learning_rate": 8.396260598594101e-05,
      "loss": 0.0179,
      "step": 8007
    },
    {
      "epoch": 0.5803529369134326,
      "grad_norm": 2.546191930770874,
      "learning_rate": 8.394811218204218e-05,
      "loss": 0.116,
      "step": 8008
    },
    {
      "epoch": 0.5804254085589013,
      "grad_norm": 2.6221704483032227,
      "learning_rate": 8.393361837814335e-05,
      "loss": 0.0705,
      "step": 8009
    },
    {
      "epoch": 0.58049788020437,
      "grad_norm": 0.7906970977783203,
      "learning_rate": 8.391912457424451e-05,
      "loss": 0.0311,
      "step": 8010
    },
    {
      "epoch": 0.5805703518498387,
      "grad_norm": 0.9699594378471375,
      "learning_rate": 8.390463077034568e-05,
      "loss": 0.0795,
      "step": 8011
    },
    {
      "epoch": 0.5806428234953075,
      "grad_norm": 2.078646659851074,
      "learning_rate": 8.389013696644685e-05,
      "loss": 0.1837,
      "step": 8012
    },
    {
      "epoch": 0.5807152951407761,
      "grad_norm": 1.1782774925231934,
      "learning_rate": 8.3875643162548e-05,
      "loss": 0.0289,
      "step": 8013
    },
    {
      "epoch": 0.5807877667862449,
      "grad_norm": 0.6679137349128723,
      "learning_rate": 8.386114935864918e-05,
      "loss": 0.0138,
      "step": 8014
    },
    {
      "epoch": 0.5808602384317136,
      "grad_norm": 2.549736499786377,
      "learning_rate": 8.384665555475036e-05,
      "loss": 0.0761,
      "step": 8015
    },
    {
      "epoch": 0.5809327100771823,
      "grad_norm": 2.5773255825042725,
      "learning_rate": 8.383216175085152e-05,
      "loss": 0.036,
      "step": 8016
    },
    {
      "epoch": 0.581005181722651,
      "grad_norm": 3.411973237991333,
      "learning_rate": 8.381766794695269e-05,
      "loss": 0.0514,
      "step": 8017
    },
    {
      "epoch": 0.5810776533681197,
      "grad_norm": 1.6588454246520996,
      "learning_rate": 8.380317414305386e-05,
      "loss": 0.0808,
      "step": 8018
    },
    {
      "epoch": 0.5811501250135884,
      "grad_norm": 1.8299145698547363,
      "learning_rate": 8.378868033915501e-05,
      "loss": 0.0974,
      "step": 8019
    },
    {
      "epoch": 0.5812225966590572,
      "grad_norm": 0.8172644972801208,
      "learning_rate": 8.377418653525618e-05,
      "loss": 0.036,
      "step": 8020
    },
    {
      "epoch": 0.5812950683045258,
      "grad_norm": 1.0343244075775146,
      "learning_rate": 8.375969273135735e-05,
      "loss": 0.0587,
      "step": 8021
    },
    {
      "epoch": 0.5813675399499946,
      "grad_norm": 0.7536203861236572,
      "learning_rate": 8.374519892745851e-05,
      "loss": 0.0532,
      "step": 8022
    },
    {
      "epoch": 0.5814400115954633,
      "grad_norm": 1.6089863777160645,
      "learning_rate": 8.373070512355968e-05,
      "loss": 0.0699,
      "step": 8023
    },
    {
      "epoch": 0.581512483240932,
      "grad_norm": 0.8032965660095215,
      "learning_rate": 8.371621131966085e-05,
      "loss": 0.0165,
      "step": 8024
    },
    {
      "epoch": 0.5815849548864007,
      "grad_norm": 0.5231802463531494,
      "learning_rate": 8.370171751576202e-05,
      "loss": 0.0208,
      "step": 8025
    },
    {
      "epoch": 0.5816574265318694,
      "grad_norm": 0.12866491079330444,
      "learning_rate": 8.368722371186319e-05,
      "loss": 0.0031,
      "step": 8026
    },
    {
      "epoch": 0.5817298981773381,
      "grad_norm": 2.441263437271118,
      "learning_rate": 8.367272990796436e-05,
      "loss": 0.1292,
      "step": 8027
    },
    {
      "epoch": 0.5818023698228069,
      "grad_norm": 1.502668023109436,
      "learning_rate": 8.365823610406552e-05,
      "loss": 0.0431,
      "step": 8028
    },
    {
      "epoch": 0.5818748414682755,
      "grad_norm": 0.013948260806500912,
      "learning_rate": 8.364374230016669e-05,
      "loss": 0.0003,
      "step": 8029
    },
    {
      "epoch": 0.5819473131137443,
      "grad_norm": 2.062370538711548,
      "learning_rate": 8.362924849626786e-05,
      "loss": 0.1207,
      "step": 8030
    },
    {
      "epoch": 0.582019784759213,
      "grad_norm": 1.4514496326446533,
      "learning_rate": 8.361475469236901e-05,
      "loss": 0.054,
      "step": 8031
    },
    {
      "epoch": 0.5820922564046817,
      "grad_norm": 1.9900424480438232,
      "learning_rate": 8.360026088847018e-05,
      "loss": 0.1476,
      "step": 8032
    },
    {
      "epoch": 0.5821647280501504,
      "grad_norm": 2.110795736312866,
      "learning_rate": 8.358576708457135e-05,
      "loss": 0.1298,
      "step": 8033
    },
    {
      "epoch": 0.582237199695619,
      "grad_norm": 1.5603998899459839,
      "learning_rate": 8.357127328067251e-05,
      "loss": 0.0316,
      "step": 8034
    },
    {
      "epoch": 0.5823096713410878,
      "grad_norm": 0.3079909384250641,
      "learning_rate": 8.355677947677368e-05,
      "loss": 0.0117,
      "step": 8035
    },
    {
      "epoch": 0.5823821429865566,
      "grad_norm": 5.7241740226745605,
      "learning_rate": 8.354228567287485e-05,
      "loss": 0.2841,
      "step": 8036
    },
    {
      "epoch": 0.5824546146320252,
      "grad_norm": 2.0363094806671143,
      "learning_rate": 8.352779186897602e-05,
      "loss": 0.0745,
      "step": 8037
    },
    {
      "epoch": 0.5825270862774939,
      "grad_norm": 1.1648544073104858,
      "learning_rate": 8.351329806507719e-05,
      "loss": 0.0737,
      "step": 8038
    },
    {
      "epoch": 0.5825995579229626,
      "grad_norm": 1.953312635421753,
      "learning_rate": 8.349880426117836e-05,
      "loss": 0.098,
      "step": 8039
    },
    {
      "epoch": 0.5826720295684313,
      "grad_norm": 0.7111101746559143,
      "learning_rate": 8.348431045727952e-05,
      "loss": 0.0338,
      "step": 8040
    },
    {
      "epoch": 0.5827445012139001,
      "grad_norm": 2.019818067550659,
      "learning_rate": 8.346981665338069e-05,
      "loss": 0.0531,
      "step": 8041
    },
    {
      "epoch": 0.5828169728593687,
      "grad_norm": 0.8748447895050049,
      "learning_rate": 8.345532284948186e-05,
      "loss": 0.0416,
      "step": 8042
    },
    {
      "epoch": 0.5828894445048375,
      "grad_norm": 1.1610536575317383,
      "learning_rate": 8.344082904558301e-05,
      "loss": 0.0379,
      "step": 8043
    },
    {
      "epoch": 0.5829619161503062,
      "grad_norm": 0.42732343077659607,
      "learning_rate": 8.342633524168418e-05,
      "loss": 0.013,
      "step": 8044
    },
    {
      "epoch": 0.5830343877957749,
      "grad_norm": 1.189127802848816,
      "learning_rate": 8.341184143778535e-05,
      "loss": 0.0443,
      "step": 8045
    },
    {
      "epoch": 0.5831068594412436,
      "grad_norm": 1.5084635019302368,
      "learning_rate": 8.339734763388651e-05,
      "loss": 0.1146,
      "step": 8046
    },
    {
      "epoch": 0.5831793310867123,
      "grad_norm": 0.2551102638244629,
      "learning_rate": 8.338285382998768e-05,
      "loss": 0.004,
      "step": 8047
    },
    {
      "epoch": 0.583251802732181,
      "grad_norm": 3.6151864528656006,
      "learning_rate": 8.336836002608885e-05,
      "loss": 0.0587,
      "step": 8048
    },
    {
      "epoch": 0.5833242743776498,
      "grad_norm": 1.4771395921707153,
      "learning_rate": 8.335386622219002e-05,
      "loss": 0.0264,
      "step": 8049
    },
    {
      "epoch": 0.5833967460231184,
      "grad_norm": 1.2866355180740356,
      "learning_rate": 8.333937241829119e-05,
      "loss": 0.0288,
      "step": 8050
    },
    {
      "epoch": 0.5834692176685872,
      "grad_norm": 0.7873898148536682,
      "learning_rate": 8.332487861439236e-05,
      "loss": 0.052,
      "step": 8051
    },
    {
      "epoch": 0.5835416893140559,
      "grad_norm": 0.8793804049491882,
      "learning_rate": 8.331038481049352e-05,
      "loss": 0.067,
      "step": 8052
    },
    {
      "epoch": 0.5836141609595246,
      "grad_norm": 1.6356933116912842,
      "learning_rate": 8.329589100659469e-05,
      "loss": 0.027,
      "step": 8053
    },
    {
      "epoch": 0.5836866326049933,
      "grad_norm": 1.184927225112915,
      "learning_rate": 8.328139720269586e-05,
      "loss": 0.0846,
      "step": 8054
    },
    {
      "epoch": 0.583759104250462,
      "grad_norm": 1.4632179737091064,
      "learning_rate": 8.326690339879701e-05,
      "loss": 0.0925,
      "step": 8055
    },
    {
      "epoch": 0.5838315758959307,
      "grad_norm": 1.3173470497131348,
      "learning_rate": 8.325240959489818e-05,
      "loss": 0.0444,
      "step": 8056
    },
    {
      "epoch": 0.5839040475413995,
      "grad_norm": 2.0406594276428223,
      "learning_rate": 8.323791579099935e-05,
      "loss": 0.0987,
      "step": 8057
    },
    {
      "epoch": 0.5839765191868681,
      "grad_norm": 1.7526874542236328,
      "learning_rate": 8.322342198710051e-05,
      "loss": 0.1001,
      "step": 8058
    },
    {
      "epoch": 0.5840489908323369,
      "grad_norm": 0.8645708560943604,
      "learning_rate": 8.320892818320168e-05,
      "loss": 0.0336,
      "step": 8059
    },
    {
      "epoch": 0.5841214624778056,
      "grad_norm": 0.2510972023010254,
      "learning_rate": 8.319443437930285e-05,
      "loss": 0.0101,
      "step": 8060
    },
    {
      "epoch": 0.5841939341232742,
      "grad_norm": 2.461637258529663,
      "learning_rate": 8.317994057540402e-05,
      "loss": 0.0949,
      "step": 8061
    },
    {
      "epoch": 0.584266405768743,
      "grad_norm": 2.5366711616516113,
      "learning_rate": 8.316544677150519e-05,
      "loss": 0.0623,
      "step": 8062
    },
    {
      "epoch": 0.5843388774142116,
      "grad_norm": 0.3118610382080078,
      "learning_rate": 8.315095296760636e-05,
      "loss": 0.0165,
      "step": 8063
    },
    {
      "epoch": 0.5844113490596804,
      "grad_norm": 3.7650277614593506,
      "learning_rate": 8.313645916370752e-05,
      "loss": 0.2128,
      "step": 8064
    },
    {
      "epoch": 0.5844838207051491,
      "grad_norm": 0.017749899998307228,
      "learning_rate": 8.312196535980869e-05,
      "loss": 0.0006,
      "step": 8065
    },
    {
      "epoch": 0.5845562923506178,
      "grad_norm": 1.947794795036316,
      "learning_rate": 8.310747155590986e-05,
      "loss": 0.0326,
      "step": 8066
    },
    {
      "epoch": 0.5846287639960865,
      "grad_norm": 1.7547190189361572,
      "learning_rate": 8.309297775201101e-05,
      "loss": 0.1205,
      "step": 8067
    },
    {
      "epoch": 0.5847012356415553,
      "grad_norm": 3.475729465484619,
      "learning_rate": 8.307848394811218e-05,
      "loss": 0.1171,
      "step": 8068
    },
    {
      "epoch": 0.5847737072870239,
      "grad_norm": 1.414478063583374,
      "learning_rate": 8.306399014421335e-05,
      "loss": 0.0658,
      "step": 8069
    },
    {
      "epoch": 0.5848461789324927,
      "grad_norm": 1.042825698852539,
      "learning_rate": 8.304949634031451e-05,
      "loss": 0.0305,
      "step": 8070
    },
    {
      "epoch": 0.5849186505779613,
      "grad_norm": 1.1765291690826416,
      "learning_rate": 8.303500253641568e-05,
      "loss": 0.0883,
      "step": 8071
    },
    {
      "epoch": 0.5849911222234301,
      "grad_norm": 1.4261401891708374,
      "learning_rate": 8.302050873251686e-05,
      "loss": 0.0948,
      "step": 8072
    },
    {
      "epoch": 0.5850635938688988,
      "grad_norm": 1.4368932247161865,
      "learning_rate": 8.300601492861802e-05,
      "loss": 0.0268,
      "step": 8073
    },
    {
      "epoch": 0.5851360655143675,
      "grad_norm": 1.1807365417480469,
      "learning_rate": 8.299152112471919e-05,
      "loss": 0.0313,
      "step": 8074
    },
    {
      "epoch": 0.5852085371598362,
      "grad_norm": 1.9043587446212769,
      "learning_rate": 8.297702732082036e-05,
      "loss": 0.0931,
      "step": 8075
    },
    {
      "epoch": 0.5852810088053049,
      "grad_norm": 6.87352991104126,
      "learning_rate": 8.296253351692151e-05,
      "loss": 0.0721,
      "step": 8076
    },
    {
      "epoch": 0.5853534804507736,
      "grad_norm": 4.916194438934326,
      "learning_rate": 8.294803971302268e-05,
      "loss": 0.0875,
      "step": 8077
    },
    {
      "epoch": 0.5854259520962424,
      "grad_norm": 1.4223772287368774,
      "learning_rate": 8.293354590912385e-05,
      "loss": 0.0392,
      "step": 8078
    },
    {
      "epoch": 0.585498423741711,
      "grad_norm": 1.7160005569458008,
      "learning_rate": 8.291905210522503e-05,
      "loss": 0.1012,
      "step": 8079
    },
    {
      "epoch": 0.5855708953871798,
      "grad_norm": 1.3579181432724,
      "learning_rate": 8.290455830132618e-05,
      "loss": 0.0888,
      "step": 8080
    },
    {
      "epoch": 0.5856433670326485,
      "grad_norm": 1.7049559354782104,
      "learning_rate": 8.289006449742735e-05,
      "loss": 0.017,
      "step": 8081
    },
    {
      "epoch": 0.5857158386781172,
      "grad_norm": 0.4868112802505493,
      "learning_rate": 8.287557069352852e-05,
      "loss": 0.0162,
      "step": 8082
    },
    {
      "epoch": 0.5857883103235859,
      "grad_norm": 0.7207531929016113,
      "learning_rate": 8.286107688962969e-05,
      "loss": 0.0458,
      "step": 8083
    },
    {
      "epoch": 0.5858607819690546,
      "grad_norm": 2.0048410892486572,
      "learning_rate": 8.284658308573086e-05,
      "loss": 0.0435,
      "step": 8084
    },
    {
      "epoch": 0.5859332536145233,
      "grad_norm": 1.2721554040908813,
      "learning_rate": 8.283208928183203e-05,
      "loss": 0.0544,
      "step": 8085
    },
    {
      "epoch": 0.5860057252599921,
      "grad_norm": 1.1185134649276733,
      "learning_rate": 8.281759547793319e-05,
      "loss": 0.0843,
      "step": 8086
    },
    {
      "epoch": 0.5860781969054607,
      "grad_norm": 1.3197009563446045,
      "learning_rate": 8.280310167403436e-05,
      "loss": 0.0893,
      "step": 8087
    },
    {
      "epoch": 0.5861506685509295,
      "grad_norm": 1.5029809474945068,
      "learning_rate": 8.278860787013553e-05,
      "loss": 0.0392,
      "step": 8088
    },
    {
      "epoch": 0.5862231401963982,
      "grad_norm": 2.244985818862915,
      "learning_rate": 8.277411406623668e-05,
      "loss": 0.0248,
      "step": 8089
    },
    {
      "epoch": 0.5862956118418668,
      "grad_norm": 0.48952749371528625,
      "learning_rate": 8.275962026233785e-05,
      "loss": 0.0127,
      "step": 8090
    },
    {
      "epoch": 0.5863680834873356,
      "grad_norm": 0.6617026329040527,
      "learning_rate": 8.274512645843902e-05,
      "loss": 0.01,
      "step": 8091
    },
    {
      "epoch": 0.5864405551328042,
      "grad_norm": 20.512046813964844,
      "learning_rate": 8.273063265454018e-05,
      "loss": 0.1571,
      "step": 8092
    },
    {
      "epoch": 0.586513026778273,
      "grad_norm": 1.5583547353744507,
      "learning_rate": 8.271613885064135e-05,
      "loss": 0.0893,
      "step": 8093
    },
    {
      "epoch": 0.5865854984237417,
      "grad_norm": 0.9836980104446411,
      "learning_rate": 8.270164504674252e-05,
      "loss": 0.0233,
      "step": 8094
    },
    {
      "epoch": 0.5866579700692104,
      "grad_norm": 1.9244743585586548,
      "learning_rate": 8.268715124284369e-05,
      "loss": 0.1485,
      "step": 8095
    },
    {
      "epoch": 0.5867304417146791,
      "grad_norm": 3.3783717155456543,
      "learning_rate": 8.267265743894486e-05,
      "loss": 0.1186,
      "step": 8096
    },
    {
      "epoch": 0.5868029133601479,
      "grad_norm": 1.6362286806106567,
      "learning_rate": 8.265816363504603e-05,
      "loss": 0.0256,
      "step": 8097
    },
    {
      "epoch": 0.5868753850056165,
      "grad_norm": 1.6544016599655151,
      "learning_rate": 8.264366983114719e-05,
      "loss": 0.0816,
      "step": 8098
    },
    {
      "epoch": 0.5869478566510853,
      "grad_norm": 1.891752004623413,
      "learning_rate": 8.262917602724836e-05,
      "loss": 0.0399,
      "step": 8099
    },
    {
      "epoch": 0.5870203282965539,
      "grad_norm": 2.5646934509277344,
      "learning_rate": 8.261468222334953e-05,
      "loss": 0.1486,
      "step": 8100
    },
    {
      "epoch": 0.5870927999420227,
      "grad_norm": 0.30219507217407227,
      "learning_rate": 8.260018841945068e-05,
      "loss": 0.0073,
      "step": 8101
    },
    {
      "epoch": 0.5871652715874914,
      "grad_norm": 0.2740462124347687,
      "learning_rate": 8.258569461555185e-05,
      "loss": 0.014,
      "step": 8102
    },
    {
      "epoch": 0.5872377432329601,
      "grad_norm": 1.8753108978271484,
      "learning_rate": 8.257120081165302e-05,
      "loss": 0.0571,
      "step": 8103
    },
    {
      "epoch": 0.5873102148784288,
      "grad_norm": 0.22799476981163025,
      "learning_rate": 8.255670700775418e-05,
      "loss": 0.0105,
      "step": 8104
    },
    {
      "epoch": 0.5873826865238976,
      "grad_norm": 1.2975870370864868,
      "learning_rate": 8.254221320385535e-05,
      "loss": 0.0584,
      "step": 8105
    },
    {
      "epoch": 0.5874551581693662,
      "grad_norm": 2.0370612144470215,
      "learning_rate": 8.252771939995652e-05,
      "loss": 0.037,
      "step": 8106
    },
    {
      "epoch": 0.587527629814835,
      "grad_norm": 2.245941638946533,
      "learning_rate": 8.251322559605769e-05,
      "loss": 0.0681,
      "step": 8107
    },
    {
      "epoch": 0.5876001014603036,
      "grad_norm": 3.2488784790039062,
      "learning_rate": 8.249873179215886e-05,
      "loss": 0.0586,
      "step": 8108
    },
    {
      "epoch": 0.5876725731057724,
      "grad_norm": 2.4643537998199463,
      "learning_rate": 8.248423798826003e-05,
      "loss": 0.1936,
      "step": 8109
    },
    {
      "epoch": 0.5877450447512411,
      "grad_norm": 0.48981255292892456,
      "learning_rate": 8.246974418436119e-05,
      "loss": 0.0387,
      "step": 8110
    },
    {
      "epoch": 0.5878175163967098,
      "grad_norm": 1.503605842590332,
      "learning_rate": 8.245525038046236e-05,
      "loss": 0.0283,
      "step": 8111
    },
    {
      "epoch": 0.5878899880421785,
      "grad_norm": 1.386561632156372,
      "learning_rate": 8.244075657656353e-05,
      "loss": 0.0572,
      "step": 8112
    },
    {
      "epoch": 0.5879624596876472,
      "grad_norm": 4.762025833129883,
      "learning_rate": 8.242626277266468e-05,
      "loss": 0.0583,
      "step": 8113
    },
    {
      "epoch": 0.5880349313331159,
      "grad_norm": 1.789790391921997,
      "learning_rate": 8.241176896876585e-05,
      "loss": 0.089,
      "step": 8114
    },
    {
      "epoch": 0.5881074029785847,
      "grad_norm": 2.296877145767212,
      "learning_rate": 8.239727516486702e-05,
      "loss": 0.1115,
      "step": 8115
    },
    {
      "epoch": 0.5881798746240533,
      "grad_norm": 0.4560668468475342,
      "learning_rate": 8.238278136096818e-05,
      "loss": 0.0668,
      "step": 8116
    },
    {
      "epoch": 0.588252346269522,
      "grad_norm": 4.19767951965332,
      "learning_rate": 8.236828755706935e-05,
      "loss": 0.0812,
      "step": 8117
    },
    {
      "epoch": 0.5883248179149908,
      "grad_norm": 1.4440280199050903,
      "learning_rate": 8.235379375317052e-05,
      "loss": 0.0527,
      "step": 8118
    },
    {
      "epoch": 0.5883972895604594,
      "grad_norm": 4.849611282348633,
      "learning_rate": 8.233929994927169e-05,
      "loss": 0.0715,
      "step": 8119
    },
    {
      "epoch": 0.5884697612059282,
      "grad_norm": 1.3134864568710327,
      "learning_rate": 8.232480614537286e-05,
      "loss": 0.0226,
      "step": 8120
    },
    {
      "epoch": 0.5885422328513968,
      "grad_norm": 0.998643159866333,
      "learning_rate": 8.231031234147403e-05,
      "loss": 0.0522,
      "step": 8121
    },
    {
      "epoch": 0.5886147044968656,
      "grad_norm": 2.249065399169922,
      "learning_rate": 8.229581853757519e-05,
      "loss": 0.0503,
      "step": 8122
    },
    {
      "epoch": 0.5886871761423343,
      "grad_norm": 0.969302237033844,
      "learning_rate": 8.228132473367636e-05,
      "loss": 0.0489,
      "step": 8123
    },
    {
      "epoch": 0.588759647787803,
      "grad_norm": 2.7353005409240723,
      "learning_rate": 8.226683092977753e-05,
      "loss": 0.1497,
      "step": 8124
    },
    {
      "epoch": 0.5888321194332717,
      "grad_norm": 0.5299973487854004,
      "learning_rate": 8.225233712587868e-05,
      "loss": 0.0172,
      "step": 8125
    },
    {
      "epoch": 0.5889045910787405,
      "grad_norm": 1.3753396272659302,
      "learning_rate": 8.223784332197985e-05,
      "loss": 0.105,
      "step": 8126
    },
    {
      "epoch": 0.5889770627242091,
      "grad_norm": 0.4281463027000427,
      "learning_rate": 8.222334951808102e-05,
      "loss": 0.0156,
      "step": 8127
    },
    {
      "epoch": 0.5890495343696779,
      "grad_norm": 1.1983639001846313,
      "learning_rate": 8.220885571418218e-05,
      "loss": 0.0506,
      "step": 8128
    },
    {
      "epoch": 0.5891220060151465,
      "grad_norm": 1.4080126285552979,
      "learning_rate": 8.219436191028335e-05,
      "loss": 0.0376,
      "step": 8129
    },
    {
      "epoch": 0.5891944776606153,
      "grad_norm": 0.14058610796928406,
      "learning_rate": 8.217986810638453e-05,
      "loss": 0.0015,
      "step": 8130
    },
    {
      "epoch": 0.589266949306084,
      "grad_norm": 2.7242753505706787,
      "learning_rate": 8.216537430248569e-05,
      "loss": 0.0578,
      "step": 8131
    },
    {
      "epoch": 0.5893394209515527,
      "grad_norm": 2.0438621044158936,
      "learning_rate": 8.215088049858686e-05,
      "loss": 0.0147,
      "step": 8132
    },
    {
      "epoch": 0.5894118925970214,
      "grad_norm": 0.6773396134376526,
      "learning_rate": 8.213638669468803e-05,
      "loss": 0.0358,
      "step": 8133
    },
    {
      "epoch": 0.5894843642424902,
      "grad_norm": 1.4219181537628174,
      "learning_rate": 8.212189289078919e-05,
      "loss": 0.0308,
      "step": 8134
    },
    {
      "epoch": 0.5895568358879588,
      "grad_norm": 0.44093558192253113,
      "learning_rate": 8.210739908689036e-05,
      "loss": 0.0267,
      "step": 8135
    },
    {
      "epoch": 0.5896293075334276,
      "grad_norm": 1.3813284635543823,
      "learning_rate": 8.209290528299153e-05,
      "loss": 0.0448,
      "step": 8136
    },
    {
      "epoch": 0.5897017791788962,
      "grad_norm": 1.083797812461853,
      "learning_rate": 8.207841147909268e-05,
      "loss": 0.0561,
      "step": 8137
    },
    {
      "epoch": 0.589774250824365,
      "grad_norm": 1.0705219507217407,
      "learning_rate": 8.206391767519385e-05,
      "loss": 0.0311,
      "step": 8138
    },
    {
      "epoch": 0.5898467224698337,
      "grad_norm": 2.892542600631714,
      "learning_rate": 8.204942387129502e-05,
      "loss": 0.0711,
      "step": 8139
    },
    {
      "epoch": 0.5899191941153024,
      "grad_norm": 0.5774400234222412,
      "learning_rate": 8.20349300673962e-05,
      "loss": 0.0382,
      "step": 8140
    },
    {
      "epoch": 0.5899916657607711,
      "grad_norm": 2.8996152877807617,
      "learning_rate": 8.202043626349736e-05,
      "loss": 0.1815,
      "step": 8141
    },
    {
      "epoch": 0.5900641374062399,
      "grad_norm": 0.43436992168426514,
      "learning_rate": 8.200594245959853e-05,
      "loss": 0.0265,
      "step": 8142
    },
    {
      "epoch": 0.5901366090517085,
      "grad_norm": 1.292476773262024,
      "learning_rate": 8.199144865569969e-05,
      "loss": 0.0607,
      "step": 8143
    },
    {
      "epoch": 0.5902090806971773,
      "grad_norm": 2.538278341293335,
      "learning_rate": 8.197695485180086e-05,
      "loss": 0.1375,
      "step": 8144
    },
    {
      "epoch": 0.5902815523426459,
      "grad_norm": 1.7297567129135132,
      "learning_rate": 8.196246104790203e-05,
      "loss": 0.1302,
      "step": 8145
    },
    {
      "epoch": 0.5903540239881147,
      "grad_norm": 0.7695304155349731,
      "learning_rate": 8.194796724400319e-05,
      "loss": 0.0229,
      "step": 8146
    },
    {
      "epoch": 0.5904264956335834,
      "grad_norm": 0.2414717674255371,
      "learning_rate": 8.193347344010436e-05,
      "loss": 0.0053,
      "step": 8147
    },
    {
      "epoch": 0.590498967279052,
      "grad_norm": 1.1418120861053467,
      "learning_rate": 8.191897963620553e-05,
      "loss": 0.0552,
      "step": 8148
    },
    {
      "epoch": 0.5905714389245208,
      "grad_norm": 0.3899613320827484,
      "learning_rate": 8.190448583230668e-05,
      "loss": 0.0184,
      "step": 8149
    },
    {
      "epoch": 0.5906439105699894,
      "grad_norm": 1.3916140794754028,
      "learning_rate": 8.188999202840785e-05,
      "loss": 0.0807,
      "step": 8150
    },
    {
      "epoch": 0.5907163822154582,
      "grad_norm": 0.22321361303329468,
      "learning_rate": 8.187549822450902e-05,
      "loss": 0.0067,
      "step": 8151
    },
    {
      "epoch": 0.5907888538609269,
      "grad_norm": 1.9649953842163086,
      "learning_rate": 8.18610044206102e-05,
      "loss": 0.0482,
      "step": 8152
    },
    {
      "epoch": 0.5908613255063956,
      "grad_norm": 2.2665445804595947,
      "learning_rate": 8.184651061671136e-05,
      "loss": 0.1148,
      "step": 8153
    },
    {
      "epoch": 0.5909337971518643,
      "grad_norm": 1.5365033149719238,
      "learning_rate": 8.183201681281253e-05,
      "loss": 0.0321,
      "step": 8154
    },
    {
      "epoch": 0.5910062687973331,
      "grad_norm": 0.7981497645378113,
      "learning_rate": 8.181752300891369e-05,
      "loss": 0.0148,
      "step": 8155
    },
    {
      "epoch": 0.5910787404428017,
      "grad_norm": 0.16326330602169037,
      "learning_rate": 8.180302920501486e-05,
      "loss": 0.005,
      "step": 8156
    },
    {
      "epoch": 0.5911512120882705,
      "grad_norm": 2.5425729751586914,
      "learning_rate": 8.178853540111603e-05,
      "loss": 0.0959,
      "step": 8157
    },
    {
      "epoch": 0.5912236837337391,
      "grad_norm": 5.513278007507324,
      "learning_rate": 8.177404159721719e-05,
      "loss": 0.1335,
      "step": 8158
    },
    {
      "epoch": 0.5912961553792079,
      "grad_norm": 1.4197463989257812,
      "learning_rate": 8.175954779331836e-05,
      "loss": 0.0369,
      "step": 8159
    },
    {
      "epoch": 0.5913686270246766,
      "grad_norm": 0.2736009955406189,
      "learning_rate": 8.174505398941953e-05,
      "loss": 0.0072,
      "step": 8160
    },
    {
      "epoch": 0.5914410986701453,
      "grad_norm": 1.358839750289917,
      "learning_rate": 8.17305601855207e-05,
      "loss": 0.0151,
      "step": 8161
    },
    {
      "epoch": 0.591513570315614,
      "grad_norm": 0.6998830437660217,
      "learning_rate": 8.171606638162185e-05,
      "loss": 0.0526,
      "step": 8162
    },
    {
      "epoch": 0.5915860419610828,
      "grad_norm": 0.020334020256996155,
      "learning_rate": 8.170157257772302e-05,
      "loss": 0.0003,
      "step": 8163
    },
    {
      "epoch": 0.5916585136065514,
      "grad_norm": 0.6268686652183533,
      "learning_rate": 8.16870787738242e-05,
      "loss": 0.0143,
      "step": 8164
    },
    {
      "epoch": 0.5917309852520202,
      "grad_norm": 0.7536228895187378,
      "learning_rate": 8.167258496992536e-05,
      "loss": 0.0152,
      "step": 8165
    },
    {
      "epoch": 0.5918034568974888,
      "grad_norm": 1.9668457508087158,
      "learning_rate": 8.165809116602653e-05,
      "loss": 0.0649,
      "step": 8166
    },
    {
      "epoch": 0.5918759285429576,
      "grad_norm": 0.570339024066925,
      "learning_rate": 8.16435973621277e-05,
      "loss": 0.0129,
      "step": 8167
    },
    {
      "epoch": 0.5919484001884263,
      "grad_norm": 1.235650658607483,
      "learning_rate": 8.162910355822886e-05,
      "loss": 0.0383,
      "step": 8168
    },
    {
      "epoch": 0.592020871833895,
      "grad_norm": 1.8252474069595337,
      "learning_rate": 8.161460975433003e-05,
      "loss": 0.0561,
      "step": 8169
    },
    {
      "epoch": 0.5920933434793637,
      "grad_norm": 1.0716534852981567,
      "learning_rate": 8.16001159504312e-05,
      "loss": 0.0595,
      "step": 8170
    },
    {
      "epoch": 0.5921658151248325,
      "grad_norm": 0.5405865907669067,
      "learning_rate": 8.158562214653236e-05,
      "loss": 0.0056,
      "step": 8171
    },
    {
      "epoch": 0.5922382867703011,
      "grad_norm": 0.3739599585533142,
      "learning_rate": 8.157112834263353e-05,
      "loss": 0.0219,
      "step": 8172
    },
    {
      "epoch": 0.5923107584157699,
      "grad_norm": 0.5504112839698792,
      "learning_rate": 8.15566345387347e-05,
      "loss": 0.0184,
      "step": 8173
    },
    {
      "epoch": 0.5923832300612385,
      "grad_norm": 0.5833795070648193,
      "learning_rate": 8.154214073483585e-05,
      "loss": 0.0222,
      "step": 8174
    },
    {
      "epoch": 0.5924557017067072,
      "grad_norm": 0.26819196343421936,
      "learning_rate": 8.152764693093702e-05,
      "loss": 0.0034,
      "step": 8175
    },
    {
      "epoch": 0.592528173352176,
      "grad_norm": 0.21337199211120605,
      "learning_rate": 8.15131531270382e-05,
      "loss": 0.0034,
      "step": 8176
    },
    {
      "epoch": 0.5926006449976446,
      "grad_norm": 0.3464239239692688,
      "learning_rate": 8.149865932313936e-05,
      "loss": 0.0048,
      "step": 8177
    },
    {
      "epoch": 0.5926731166431134,
      "grad_norm": 2.0412416458129883,
      "learning_rate": 8.148416551924053e-05,
      "loss": 0.1047,
      "step": 8178
    },
    {
      "epoch": 0.592745588288582,
      "grad_norm": 4.226248741149902,
      "learning_rate": 8.14696717153417e-05,
      "loss": 0.1465,
      "step": 8179
    },
    {
      "epoch": 0.5928180599340508,
      "grad_norm": 0.3887929916381836,
      "learning_rate": 8.145517791144286e-05,
      "loss": 0.0027,
      "step": 8180
    },
    {
      "epoch": 0.5928905315795195,
      "grad_norm": 0.6965314745903015,
      "learning_rate": 8.144068410754403e-05,
      "loss": 0.0115,
      "step": 8181
    },
    {
      "epoch": 0.5929630032249882,
      "grad_norm": 0.257958322763443,
      "learning_rate": 8.14261903036452e-05,
      "loss": 0.0054,
      "step": 8182
    },
    {
      "epoch": 0.5930354748704569,
      "grad_norm": 1.4140106439590454,
      "learning_rate": 8.141169649974636e-05,
      "loss": 0.0674,
      "step": 8183
    },
    {
      "epoch": 0.5931079465159257,
      "grad_norm": 1.6462873220443726,
      "learning_rate": 8.139720269584753e-05,
      "loss": 0.0824,
      "step": 8184
    },
    {
      "epoch": 0.5931804181613943,
      "grad_norm": 2.6589269638061523,
      "learning_rate": 8.13827088919487e-05,
      "loss": 0.0479,
      "step": 8185
    },
    {
      "epoch": 0.5932528898068631,
      "grad_norm": 2.3302299976348877,
      "learning_rate": 8.136821508804985e-05,
      "loss": 0.0621,
      "step": 8186
    },
    {
      "epoch": 0.5933253614523317,
      "grad_norm": 0.3056422472000122,
      "learning_rate": 8.135372128415102e-05,
      "loss": 0.0076,
      "step": 8187
    },
    {
      "epoch": 0.5933978330978005,
      "grad_norm": 2.49552845954895,
      "learning_rate": 8.13392274802522e-05,
      "loss": 0.137,
      "step": 8188
    },
    {
      "epoch": 0.5934703047432692,
      "grad_norm": 0.6327280402183533,
      "learning_rate": 8.132473367635336e-05,
      "loss": 0.0166,
      "step": 8189
    },
    {
      "epoch": 0.5935427763887379,
      "grad_norm": 1.0501168966293335,
      "learning_rate": 8.131023987245453e-05,
      "loss": 0.0369,
      "step": 8190
    },
    {
      "epoch": 0.5936152480342066,
      "grad_norm": 1.3032841682434082,
      "learning_rate": 8.12957460685557e-05,
      "loss": 0.0412,
      "step": 8191
    },
    {
      "epoch": 0.5936877196796754,
      "grad_norm": 0.6695605516433716,
      "learning_rate": 8.128125226465686e-05,
      "loss": 0.0148,
      "step": 8192
    },
    {
      "epoch": 0.593760191325144,
      "grad_norm": 0.12459201365709305,
      "learning_rate": 8.126675846075803e-05,
      "loss": 0.0051,
      "step": 8193
    },
    {
      "epoch": 0.5938326629706128,
      "grad_norm": 2.2164435386657715,
      "learning_rate": 8.12522646568592e-05,
      "loss": 0.0732,
      "step": 8194
    },
    {
      "epoch": 0.5939051346160814,
      "grad_norm": 1.2444210052490234,
      "learning_rate": 8.123777085296036e-05,
      "loss": 0.0306,
      "step": 8195
    },
    {
      "epoch": 0.5939776062615502,
      "grad_norm": 0.7305142879486084,
      "learning_rate": 8.122327704906153e-05,
      "loss": 0.0315,
      "step": 8196
    },
    {
      "epoch": 0.5940500779070189,
      "grad_norm": 1.3336018323898315,
      "learning_rate": 8.12087832451627e-05,
      "loss": 0.0896,
      "step": 8197
    },
    {
      "epoch": 0.5941225495524876,
      "grad_norm": 3.567431688308716,
      "learning_rate": 8.119428944126387e-05,
      "loss": 0.0788,
      "step": 8198
    },
    {
      "epoch": 0.5941950211979563,
      "grad_norm": 3.7471892833709717,
      "learning_rate": 8.117979563736504e-05,
      "loss": 0.0455,
      "step": 8199
    },
    {
      "epoch": 0.5942674928434251,
      "grad_norm": 2.27585768699646,
      "learning_rate": 8.11653018334662e-05,
      "loss": 0.1367,
      "step": 8200
    },
    {
      "epoch": 0.5943399644888937,
      "grad_norm": 1.218611478805542,
      "learning_rate": 8.115080802956736e-05,
      "loss": 0.0451,
      "step": 8201
    },
    {
      "epoch": 0.5944124361343625,
      "grad_norm": 0.6915700435638428,
      "learning_rate": 8.113631422566853e-05,
      "loss": 0.0242,
      "step": 8202
    },
    {
      "epoch": 0.5944849077798311,
      "grad_norm": 1.1900138854980469,
      "learning_rate": 8.11218204217697e-05,
      "loss": 0.0775,
      "step": 8203
    },
    {
      "epoch": 0.5945573794252998,
      "grad_norm": 1.2032262086868286,
      "learning_rate": 8.110732661787086e-05,
      "loss": 0.0692,
      "step": 8204
    },
    {
      "epoch": 0.5946298510707686,
      "grad_norm": 0.8811492323875427,
      "learning_rate": 8.109283281397203e-05,
      "loss": 0.0507,
      "step": 8205
    },
    {
      "epoch": 0.5947023227162372,
      "grad_norm": 4.492916107177734,
      "learning_rate": 8.10783390100732e-05,
      "loss": 0.0808,
      "step": 8206
    },
    {
      "epoch": 0.594774794361706,
      "grad_norm": 1.83120858669281,
      "learning_rate": 8.106384520617436e-05,
      "loss": 0.1188,
      "step": 8207
    },
    {
      "epoch": 0.5948472660071747,
      "grad_norm": 2.2037858963012695,
      "learning_rate": 8.104935140227553e-05,
      "loss": 0.1012,
      "step": 8208
    },
    {
      "epoch": 0.5949197376526434,
      "grad_norm": 1.3802173137664795,
      "learning_rate": 8.10348575983767e-05,
      "loss": 0.0882,
      "step": 8209
    },
    {
      "epoch": 0.5949922092981121,
      "grad_norm": 1.817172884941101,
      "learning_rate": 8.102036379447787e-05,
      "loss": 0.0497,
      "step": 8210
    },
    {
      "epoch": 0.5950646809435808,
      "grad_norm": 1.8790408372879028,
      "learning_rate": 8.100586999057904e-05,
      "loss": 0.0909,
      "step": 8211
    },
    {
      "epoch": 0.5951371525890495,
      "grad_norm": 0.773734450340271,
      "learning_rate": 8.09913761866802e-05,
      "loss": 0.0319,
      "step": 8212
    },
    {
      "epoch": 0.5952096242345183,
      "grad_norm": 3.7362163066864014,
      "learning_rate": 8.097688238278136e-05,
      "loss": 0.0575,
      "step": 8213
    },
    {
      "epoch": 0.5952820958799869,
      "grad_norm": 0.8451134562492371,
      "learning_rate": 8.096238857888253e-05,
      "loss": 0.0469,
      "step": 8214
    },
    {
      "epoch": 0.5953545675254557,
      "grad_norm": 0.1486569046974182,
      "learning_rate": 8.09478947749837e-05,
      "loss": 0.0033,
      "step": 8215
    },
    {
      "epoch": 0.5954270391709243,
      "grad_norm": 1.732951045036316,
      "learning_rate": 8.093340097108486e-05,
      "loss": 0.1079,
      "step": 8216
    },
    {
      "epoch": 0.5954995108163931,
      "grad_norm": 3.8006350994110107,
      "learning_rate": 8.091890716718603e-05,
      "loss": 0.038,
      "step": 8217
    },
    {
      "epoch": 0.5955719824618618,
      "grad_norm": 4.896560192108154,
      "learning_rate": 8.09044133632872e-05,
      "loss": 0.1569,
      "step": 8218
    },
    {
      "epoch": 0.5956444541073305,
      "grad_norm": 0.2546200752258301,
      "learning_rate": 8.088991955938836e-05,
      "loss": 0.0102,
      "step": 8219
    },
    {
      "epoch": 0.5957169257527992,
      "grad_norm": 1.9353954792022705,
      "learning_rate": 8.087542575548953e-05,
      "loss": 0.1392,
      "step": 8220
    },
    {
      "epoch": 0.595789397398268,
      "grad_norm": 2.217715263366699,
      "learning_rate": 8.08609319515907e-05,
      "loss": 0.0678,
      "step": 8221
    },
    {
      "epoch": 0.5958618690437366,
      "grad_norm": 1.9645636081695557,
      "learning_rate": 8.084643814769187e-05,
      "loss": 0.0334,
      "step": 8222
    },
    {
      "epoch": 0.5959343406892054,
      "grad_norm": 1.1820303201675415,
      "learning_rate": 8.083194434379304e-05,
      "loss": 0.0273,
      "step": 8223
    },
    {
      "epoch": 0.596006812334674,
      "grad_norm": 1.6995742321014404,
      "learning_rate": 8.08174505398942e-05,
      "loss": 0.0438,
      "step": 8224
    },
    {
      "epoch": 0.5960792839801428,
      "grad_norm": 0.5014294385910034,
      "learning_rate": 8.080295673599536e-05,
      "loss": 0.0215,
      "step": 8225
    },
    {
      "epoch": 0.5961517556256115,
      "grad_norm": 1.9192508459091187,
      "learning_rate": 8.078846293209653e-05,
      "loss": 0.0555,
      "step": 8226
    },
    {
      "epoch": 0.5962242272710802,
      "grad_norm": 0.26686424016952515,
      "learning_rate": 8.07739691281977e-05,
      "loss": 0.0082,
      "step": 8227
    },
    {
      "epoch": 0.5962966989165489,
      "grad_norm": 0.02863270230591297,
      "learning_rate": 8.075947532429886e-05,
      "loss": 0.0009,
      "step": 8228
    },
    {
      "epoch": 0.5963691705620177,
      "grad_norm": 0.3993360996246338,
      "learning_rate": 8.074498152040003e-05,
      "loss": 0.0091,
      "step": 8229
    },
    {
      "epoch": 0.5964416422074863,
      "grad_norm": 2.669649600982666,
      "learning_rate": 8.07304877165012e-05,
      "loss": 0.0786,
      "step": 8230
    },
    {
      "epoch": 0.596514113852955,
      "grad_norm": 1.645726203918457,
      "learning_rate": 8.071599391260236e-05,
      "loss": 0.0547,
      "step": 8231
    },
    {
      "epoch": 0.5965865854984237,
      "grad_norm": 2.8092539310455322,
      "learning_rate": 8.070150010870353e-05,
      "loss": 0.1403,
      "step": 8232
    },
    {
      "epoch": 0.5966590571438924,
      "grad_norm": 0.8353164792060852,
      "learning_rate": 8.06870063048047e-05,
      "loss": 0.0219,
      "step": 8233
    },
    {
      "epoch": 0.5967315287893612,
      "grad_norm": 1.4017407894134521,
      "learning_rate": 8.067251250090587e-05,
      "loss": 0.0644,
      "step": 8234
    },
    {
      "epoch": 0.5968040004348298,
      "grad_norm": 0.2522512972354889,
      "learning_rate": 8.065801869700704e-05,
      "loss": 0.0063,
      "step": 8235
    },
    {
      "epoch": 0.5968764720802986,
      "grad_norm": 0.8443014621734619,
      "learning_rate": 8.06435248931082e-05,
      "loss": 0.0285,
      "step": 8236
    },
    {
      "epoch": 0.5969489437257673,
      "grad_norm": 1.893662452697754,
      "learning_rate": 8.062903108920936e-05,
      "loss": 0.1511,
      "step": 8237
    },
    {
      "epoch": 0.597021415371236,
      "grad_norm": 1.690563678741455,
      "learning_rate": 8.061453728531053e-05,
      "loss": 0.0555,
      "step": 8238
    },
    {
      "epoch": 0.5970938870167047,
      "grad_norm": 2.3528263568878174,
      "learning_rate": 8.06000434814117e-05,
      "loss": 0.1127,
      "step": 8239
    },
    {
      "epoch": 0.5971663586621734,
      "grad_norm": 0.7504419684410095,
      "learning_rate": 8.058554967751287e-05,
      "loss": 0.0201,
      "step": 8240
    },
    {
      "epoch": 0.5972388303076421,
      "grad_norm": 1.4841437339782715,
      "learning_rate": 8.057105587361403e-05,
      "loss": 0.0429,
      "step": 8241
    },
    {
      "epoch": 0.5973113019531109,
      "grad_norm": 0.03722507879137993,
      "learning_rate": 8.05565620697152e-05,
      "loss": 0.0008,
      "step": 8242
    },
    {
      "epoch": 0.5973837735985795,
      "grad_norm": 0.5942121744155884,
      "learning_rate": 8.054206826581637e-05,
      "loss": 0.0095,
      "step": 8243
    },
    {
      "epoch": 0.5974562452440483,
      "grad_norm": 1.9971506595611572,
      "learning_rate": 8.052757446191753e-05,
      "loss": 0.0235,
      "step": 8244
    },
    {
      "epoch": 0.597528716889517,
      "grad_norm": 4.574682712554932,
      "learning_rate": 8.051308065801871e-05,
      "loss": 0.1419,
      "step": 8245
    },
    {
      "epoch": 0.5976011885349857,
      "grad_norm": 2.9732463359832764,
      "learning_rate": 8.049858685411988e-05,
      "loss": 0.0632,
      "step": 8246
    },
    {
      "epoch": 0.5976736601804544,
      "grad_norm": 0.04628608748316765,
      "learning_rate": 8.048409305022104e-05,
      "loss": 0.0007,
      "step": 8247
    },
    {
      "epoch": 0.5977461318259231,
      "grad_norm": 1.4751582145690918,
      "learning_rate": 8.04695992463222e-05,
      "loss": 0.0121,
      "step": 8248
    },
    {
      "epoch": 0.5978186034713918,
      "grad_norm": 1.9809833765029907,
      "learning_rate": 8.045510544242338e-05,
      "loss": 0.0332,
      "step": 8249
    },
    {
      "epoch": 0.5978910751168606,
      "grad_norm": 1.797495722770691,
      "learning_rate": 8.044061163852453e-05,
      "loss": 0.0985,
      "step": 8250
    },
    {
      "epoch": 0.5979635467623292,
      "grad_norm": 3.6837332248687744,
      "learning_rate": 8.04261178346257e-05,
      "loss": 0.0868,
      "step": 8251
    },
    {
      "epoch": 0.598036018407798,
      "grad_norm": 2.1263797283172607,
      "learning_rate": 8.041162403072687e-05,
      "loss": 0.0281,
      "step": 8252
    },
    {
      "epoch": 0.5981084900532666,
      "grad_norm": 1.4173539876937866,
      "learning_rate": 8.039713022682803e-05,
      "loss": 0.058,
      "step": 8253
    },
    {
      "epoch": 0.5981809616987354,
      "grad_norm": 1.2109185457229614,
      "learning_rate": 8.03826364229292e-05,
      "loss": 0.046,
      "step": 8254
    },
    {
      "epoch": 0.5982534333442041,
      "grad_norm": 1.8182644844055176,
      "learning_rate": 8.036814261903037e-05,
      "loss": 0.0778,
      "step": 8255
    },
    {
      "epoch": 0.5983259049896728,
      "grad_norm": 0.8714362978935242,
      "learning_rate": 8.035364881513154e-05,
      "loss": 0.0344,
      "step": 8256
    },
    {
      "epoch": 0.5983983766351415,
      "grad_norm": 1.5621724128723145,
      "learning_rate": 8.033915501123271e-05,
      "loss": 0.0586,
      "step": 8257
    },
    {
      "epoch": 0.5984708482806103,
      "grad_norm": 2.925015687942505,
      "learning_rate": 8.032466120733388e-05,
      "loss": 0.0487,
      "step": 8258
    },
    {
      "epoch": 0.5985433199260789,
      "grad_norm": 0.2714942693710327,
      "learning_rate": 8.031016740343504e-05,
      "loss": 0.0044,
      "step": 8259
    },
    {
      "epoch": 0.5986157915715477,
      "grad_norm": 1.7799853086471558,
      "learning_rate": 8.02956735995362e-05,
      "loss": 0.1015,
      "step": 8260
    },
    {
      "epoch": 0.5986882632170163,
      "grad_norm": 1.6722354888916016,
      "learning_rate": 8.028117979563738e-05,
      "loss": 0.0469,
      "step": 8261
    },
    {
      "epoch": 0.598760734862485,
      "grad_norm": 0.45707809925079346,
      "learning_rate": 8.026668599173853e-05,
      "loss": 0.0102,
      "step": 8262
    },
    {
      "epoch": 0.5988332065079538,
      "grad_norm": 2.44972825050354,
      "learning_rate": 8.02521921878397e-05,
      "loss": 0.0805,
      "step": 8263
    },
    {
      "epoch": 0.5989056781534224,
      "grad_norm": 3.8654041290283203,
      "learning_rate": 8.023769838394087e-05,
      "loss": 0.1193,
      "step": 8264
    },
    {
      "epoch": 0.5989781497988912,
      "grad_norm": 1.7800467014312744,
      "learning_rate": 8.022320458004203e-05,
      "loss": 0.1655,
      "step": 8265
    },
    {
      "epoch": 0.5990506214443599,
      "grad_norm": 0.28775274753570557,
      "learning_rate": 8.02087107761432e-05,
      "loss": 0.0039,
      "step": 8266
    },
    {
      "epoch": 0.5991230930898286,
      "grad_norm": 2.372328281402588,
      "learning_rate": 8.019421697224437e-05,
      "loss": 0.0533,
      "step": 8267
    },
    {
      "epoch": 0.5991955647352973,
      "grad_norm": 0.45614975690841675,
      "learning_rate": 8.017972316834554e-05,
      "loss": 0.0205,
      "step": 8268
    },
    {
      "epoch": 0.599268036380766,
      "grad_norm": 3.59995698928833,
      "learning_rate": 8.016522936444671e-05,
      "loss": 0.1359,
      "step": 8269
    },
    {
      "epoch": 0.5993405080262347,
      "grad_norm": 1.8033829927444458,
      "learning_rate": 8.015073556054788e-05,
      "loss": 0.061,
      "step": 8270
    },
    {
      "epoch": 0.5994129796717035,
      "grad_norm": 3.1063828468322754,
      "learning_rate": 8.013624175664904e-05,
      "loss": 0.1227,
      "step": 8271
    },
    {
      "epoch": 0.5994854513171721,
      "grad_norm": 1.8256314992904663,
      "learning_rate": 8.01217479527502e-05,
      "loss": 0.0555,
      "step": 8272
    },
    {
      "epoch": 0.5995579229626409,
      "grad_norm": 1.5189884901046753,
      "learning_rate": 8.010725414885138e-05,
      "loss": 0.106,
      "step": 8273
    },
    {
      "epoch": 0.5996303946081096,
      "grad_norm": 1.480711579322815,
      "learning_rate": 8.009276034495253e-05,
      "loss": 0.0251,
      "step": 8274
    },
    {
      "epoch": 0.5997028662535783,
      "grad_norm": 0.5189473032951355,
      "learning_rate": 8.00782665410537e-05,
      "loss": 0.0224,
      "step": 8275
    },
    {
      "epoch": 0.599775337899047,
      "grad_norm": 1.7068403959274292,
      "learning_rate": 8.006377273715487e-05,
      "loss": 0.0453,
      "step": 8276
    },
    {
      "epoch": 0.5998478095445157,
      "grad_norm": 0.9892042279243469,
      "learning_rate": 8.004927893325603e-05,
      "loss": 0.0315,
      "step": 8277
    },
    {
      "epoch": 0.5999202811899844,
      "grad_norm": 2.0641958713531494,
      "learning_rate": 8.00347851293572e-05,
      "loss": 0.0559,
      "step": 8278
    },
    {
      "epoch": 0.5999927528354532,
      "grad_norm": 1.2593588829040527,
      "learning_rate": 8.002029132545837e-05,
      "loss": 0.0437,
      "step": 8279
    },
    {
      "epoch": 0.6000652244809218,
      "grad_norm": 0.5439130067825317,
      "learning_rate": 8.000579752155954e-05,
      "loss": 0.019,
      "step": 8280
    },
    {
      "epoch": 0.6001376961263906,
      "grad_norm": 0.5470234751701355,
      "learning_rate": 7.999130371766071e-05,
      "loss": 0.0173,
      "step": 8281
    },
    {
      "epoch": 0.6002101677718593,
      "grad_norm": 3.0967750549316406,
      "learning_rate": 7.997680991376188e-05,
      "loss": 0.1496,
      "step": 8282
    },
    {
      "epoch": 0.600282639417328,
      "grad_norm": 0.884083092212677,
      "learning_rate": 7.996231610986304e-05,
      "loss": 0.0109,
      "step": 8283
    },
    {
      "epoch": 0.6003551110627967,
      "grad_norm": 1.6089504957199097,
      "learning_rate": 7.99478223059642e-05,
      "loss": 0.081,
      "step": 8284
    },
    {
      "epoch": 0.6004275827082654,
      "grad_norm": 1.435132622718811,
      "learning_rate": 7.993332850206538e-05,
      "loss": 0.0351,
      "step": 8285
    },
    {
      "epoch": 0.6005000543537341,
      "grad_norm": 1.1521029472351074,
      "learning_rate": 7.991883469816653e-05,
      "loss": 0.0356,
      "step": 8286
    },
    {
      "epoch": 0.6005725259992029,
      "grad_norm": 1.212416410446167,
      "learning_rate": 7.99043408942677e-05,
      "loss": 0.0517,
      "step": 8287
    },
    {
      "epoch": 0.6006449976446715,
      "grad_norm": 1.5566504001617432,
      "learning_rate": 7.988984709036887e-05,
      "loss": 0.0449,
      "step": 8288
    },
    {
      "epoch": 0.6007174692901402,
      "grad_norm": 1.2520742416381836,
      "learning_rate": 7.987535328647003e-05,
      "loss": 0.0484,
      "step": 8289
    },
    {
      "epoch": 0.6007899409356089,
      "grad_norm": 1.77234947681427,
      "learning_rate": 7.98608594825712e-05,
      "loss": 0.0479,
      "step": 8290
    },
    {
      "epoch": 0.6008624125810776,
      "grad_norm": 1.0740485191345215,
      "learning_rate": 7.984636567867237e-05,
      "loss": 0.0484,
      "step": 8291
    },
    {
      "epoch": 0.6009348842265464,
      "grad_norm": 0.7929145693778992,
      "learning_rate": 7.983187187477354e-05,
      "loss": 0.0512,
      "step": 8292
    },
    {
      "epoch": 0.601007355872015,
      "grad_norm": 1.9111183881759644,
      "learning_rate": 7.981737807087471e-05,
      "loss": 0.098,
      "step": 8293
    },
    {
      "epoch": 0.6010798275174838,
      "grad_norm": 0.10790398716926575,
      "learning_rate": 7.980288426697588e-05,
      "loss": 0.0015,
      "step": 8294
    },
    {
      "epoch": 0.6011522991629525,
      "grad_norm": 0.6982431411743164,
      "learning_rate": 7.978839046307703e-05,
      "loss": 0.0196,
      "step": 8295
    },
    {
      "epoch": 0.6012247708084212,
      "grad_norm": 1.3497545719146729,
      "learning_rate": 7.97738966591782e-05,
      "loss": 0.0826,
      "step": 8296
    },
    {
      "epoch": 0.6012972424538899,
      "grad_norm": 0.22083359956741333,
      "learning_rate": 7.975940285527937e-05,
      "loss": 0.0105,
      "step": 8297
    },
    {
      "epoch": 0.6013697140993586,
      "grad_norm": 2.9866058826446533,
      "learning_rate": 7.974490905138053e-05,
      "loss": 0.0991,
      "step": 8298
    },
    {
      "epoch": 0.6014421857448273,
      "grad_norm": 1.0436447858810425,
      "learning_rate": 7.97304152474817e-05,
      "loss": 0.0276,
      "step": 8299
    },
    {
      "epoch": 0.6015146573902961,
      "grad_norm": 1.1128922700881958,
      "learning_rate": 7.971592144358287e-05,
      "loss": 0.0586,
      "step": 8300
    },
    {
      "epoch": 0.6015871290357647,
      "grad_norm": 1.389528512954712,
      "learning_rate": 7.970142763968403e-05,
      "loss": 0.0416,
      "step": 8301
    },
    {
      "epoch": 0.6016596006812335,
      "grad_norm": 1.5544323921203613,
      "learning_rate": 7.96869338357852e-05,
      "loss": 0.053,
      "step": 8302
    },
    {
      "epoch": 0.6017320723267022,
      "grad_norm": 1.3954631090164185,
      "learning_rate": 7.967244003188638e-05,
      "loss": 0.0489,
      "step": 8303
    },
    {
      "epoch": 0.6018045439721709,
      "grad_norm": 1.1418081521987915,
      "learning_rate": 7.965794622798754e-05,
      "loss": 0.0991,
      "step": 8304
    },
    {
      "epoch": 0.6018770156176396,
      "grad_norm": 1.169487476348877,
      "learning_rate": 7.964345242408871e-05,
      "loss": 0.0245,
      "step": 8305
    },
    {
      "epoch": 0.6019494872631083,
      "grad_norm": 3.203953742980957,
      "learning_rate": 7.962895862018988e-05,
      "loss": 0.0354,
      "step": 8306
    },
    {
      "epoch": 0.602021958908577,
      "grad_norm": 0.6102490425109863,
      "learning_rate": 7.961446481629103e-05,
      "loss": 0.0081,
      "step": 8307
    },
    {
      "epoch": 0.6020944305540458,
      "grad_norm": 1.0565513372421265,
      "learning_rate": 7.95999710123922e-05,
      "loss": 0.0361,
      "step": 8308
    },
    {
      "epoch": 0.6021669021995144,
      "grad_norm": 3.517394542694092,
      "learning_rate": 7.958547720849337e-05,
      "loss": 0.0688,
      "step": 8309
    },
    {
      "epoch": 0.6022393738449832,
      "grad_norm": 0.812649667263031,
      "learning_rate": 7.957098340459453e-05,
      "loss": 0.0139,
      "step": 8310
    },
    {
      "epoch": 0.6023118454904519,
      "grad_norm": 10.534844398498535,
      "learning_rate": 7.95564896006957e-05,
      "loss": 0.2077,
      "step": 8311
    },
    {
      "epoch": 0.6023843171359206,
      "grad_norm": 1.1425330638885498,
      "learning_rate": 7.954199579679687e-05,
      "loss": 0.0145,
      "step": 8312
    },
    {
      "epoch": 0.6024567887813893,
      "grad_norm": 0.3552234470844269,
      "learning_rate": 7.952750199289804e-05,
      "loss": 0.0035,
      "step": 8313
    },
    {
      "epoch": 0.602529260426858,
      "grad_norm": 1.7788994312286377,
      "learning_rate": 7.951300818899921e-05,
      "loss": 0.0631,
      "step": 8314
    },
    {
      "epoch": 0.6026017320723267,
      "grad_norm": 3.217379093170166,
      "learning_rate": 7.949851438510038e-05,
      "loss": 0.0985,
      "step": 8315
    },
    {
      "epoch": 0.6026742037177955,
      "grad_norm": 0.6767854690551758,
      "learning_rate": 7.948402058120154e-05,
      "loss": 0.037,
      "step": 8316
    },
    {
      "epoch": 0.6027466753632641,
      "grad_norm": 2.0269768238067627,
      "learning_rate": 7.946952677730271e-05,
      "loss": 0.0562,
      "step": 8317
    },
    {
      "epoch": 0.6028191470087328,
      "grad_norm": 0.7644542455673218,
      "learning_rate": 7.945503297340388e-05,
      "loss": 0.0508,
      "step": 8318
    },
    {
      "epoch": 0.6028916186542015,
      "grad_norm": 0.12308341264724731,
      "learning_rate": 7.944053916950503e-05,
      "loss": 0.0038,
      "step": 8319
    },
    {
      "epoch": 0.6029640902996702,
      "grad_norm": 1.9602446556091309,
      "learning_rate": 7.94260453656062e-05,
      "loss": 0.0825,
      "step": 8320
    },
    {
      "epoch": 0.603036561945139,
      "grad_norm": 2.160468578338623,
      "learning_rate": 7.941155156170737e-05,
      "loss": 0.0695,
      "step": 8321
    },
    {
      "epoch": 0.6031090335906076,
      "grad_norm": 1.037051796913147,
      "learning_rate": 7.939705775780854e-05,
      "loss": 0.0367,
      "step": 8322
    },
    {
      "epoch": 0.6031815052360764,
      "grad_norm": 2.8637218475341797,
      "learning_rate": 7.93825639539097e-05,
      "loss": 0.0495,
      "step": 8323
    },
    {
      "epoch": 0.6032539768815451,
      "grad_norm": 2.3878395557403564,
      "learning_rate": 7.936807015001087e-05,
      "loss": 0.1017,
      "step": 8324
    },
    {
      "epoch": 0.6033264485270138,
      "grad_norm": 1.3124264478683472,
      "learning_rate": 7.935357634611204e-05,
      "loss": 0.0565,
      "step": 8325
    },
    {
      "epoch": 0.6033989201724825,
      "grad_norm": 3.509127616882324,
      "learning_rate": 7.933908254221321e-05,
      "loss": 0.1879,
      "step": 8326
    },
    {
      "epoch": 0.6034713918179512,
      "grad_norm": 5.042222499847412,
      "learning_rate": 7.932458873831438e-05,
      "loss": 0.0602,
      "step": 8327
    },
    {
      "epoch": 0.6035438634634199,
      "grad_norm": 1.0594810247421265,
      "learning_rate": 7.931009493441555e-05,
      "loss": 0.0573,
      "step": 8328
    },
    {
      "epoch": 0.6036163351088887,
      "grad_norm": 0.8419143557548523,
      "learning_rate": 7.929560113051671e-05,
      "loss": 0.028,
      "step": 8329
    },
    {
      "epoch": 0.6036888067543573,
      "grad_norm": 0.7532942891120911,
      "learning_rate": 7.928110732661788e-05,
      "loss": 0.0242,
      "step": 8330
    },
    {
      "epoch": 0.6037612783998261,
      "grad_norm": 4.07343053817749,
      "learning_rate": 7.926661352271905e-05,
      "loss": 0.0924,
      "step": 8331
    },
    {
      "epoch": 0.6038337500452948,
      "grad_norm": 3.9709556102752686,
      "learning_rate": 7.92521197188202e-05,
      "loss": 0.0928,
      "step": 8332
    },
    {
      "epoch": 0.6039062216907635,
      "grad_norm": 1.6796644926071167,
      "learning_rate": 7.923762591492137e-05,
      "loss": 0.0474,
      "step": 8333
    },
    {
      "epoch": 0.6039786933362322,
      "grad_norm": 0.8740758895874023,
      "learning_rate": 7.922313211102254e-05,
      "loss": 0.0221,
      "step": 8334
    },
    {
      "epoch": 0.6040511649817009,
      "grad_norm": 1.8917969465255737,
      "learning_rate": 7.92086383071237e-05,
      "loss": 0.1143,
      "step": 8335
    },
    {
      "epoch": 0.6041236366271696,
      "grad_norm": 0.6240339875221252,
      "learning_rate": 7.919414450322487e-05,
      "loss": 0.0119,
      "step": 8336
    },
    {
      "epoch": 0.6041961082726384,
      "grad_norm": 3.210984468460083,
      "learning_rate": 7.917965069932604e-05,
      "loss": 0.0334,
      "step": 8337
    },
    {
      "epoch": 0.604268579918107,
      "grad_norm": 0.4448145627975464,
      "learning_rate": 7.916515689542721e-05,
      "loss": 0.0298,
      "step": 8338
    },
    {
      "epoch": 0.6043410515635758,
      "grad_norm": 1.5755579471588135,
      "learning_rate": 7.915066309152838e-05,
      "loss": 0.0369,
      "step": 8339
    },
    {
      "epoch": 0.6044135232090445,
      "grad_norm": 1.452478051185608,
      "learning_rate": 7.913616928762955e-05,
      "loss": 0.0432,
      "step": 8340
    },
    {
      "epoch": 0.6044859948545132,
      "grad_norm": 1.4283320903778076,
      "learning_rate": 7.912167548373071e-05,
      "loss": 0.0577,
      "step": 8341
    },
    {
      "epoch": 0.6045584664999819,
      "grad_norm": 1.2785941362380981,
      "learning_rate": 7.910718167983188e-05,
      "loss": 0.0657,
      "step": 8342
    },
    {
      "epoch": 0.6046309381454505,
      "grad_norm": 3.784799575805664,
      "learning_rate": 7.909268787593305e-05,
      "loss": 0.1527,
      "step": 8343
    },
    {
      "epoch": 0.6047034097909193,
      "grad_norm": 1.931634545326233,
      "learning_rate": 7.90781940720342e-05,
      "loss": 0.0149,
      "step": 8344
    },
    {
      "epoch": 0.604775881436388,
      "grad_norm": 0.8702957034111023,
      "learning_rate": 7.906370026813537e-05,
      "loss": 0.0484,
      "step": 8345
    },
    {
      "epoch": 0.6048483530818567,
      "grad_norm": 2.75966215133667,
      "learning_rate": 7.904920646423654e-05,
      "loss": 0.1251,
      "step": 8346
    },
    {
      "epoch": 0.6049208247273254,
      "grad_norm": 0.2605481743812561,
      "learning_rate": 7.90347126603377e-05,
      "loss": 0.0027,
      "step": 8347
    },
    {
      "epoch": 0.6049932963727942,
      "grad_norm": 1.1939479112625122,
      "learning_rate": 7.902021885643887e-05,
      "loss": 0.0203,
      "step": 8348
    },
    {
      "epoch": 0.6050657680182628,
      "grad_norm": 0.790033757686615,
      "learning_rate": 7.900572505254004e-05,
      "loss": 0.0428,
      "step": 8349
    },
    {
      "epoch": 0.6051382396637316,
      "grad_norm": 1.2095935344696045,
      "learning_rate": 7.899123124864121e-05,
      "loss": 0.0153,
      "step": 8350
    },
    {
      "epoch": 0.6052107113092002,
      "grad_norm": 2.1518990993499756,
      "learning_rate": 7.897673744474238e-05,
      "loss": 0.0512,
      "step": 8351
    },
    {
      "epoch": 0.605283182954669,
      "grad_norm": 1.4347009658813477,
      "learning_rate": 7.896224364084355e-05,
      "loss": 0.1241,
      "step": 8352
    },
    {
      "epoch": 0.6053556546001377,
      "grad_norm": 1.5056943893432617,
      "learning_rate": 7.894774983694471e-05,
      "loss": 0.0288,
      "step": 8353
    },
    {
      "epoch": 0.6054281262456064,
      "grad_norm": 0.7084208726882935,
      "learning_rate": 7.893325603304588e-05,
      "loss": 0.0571,
      "step": 8354
    },
    {
      "epoch": 0.6055005978910751,
      "grad_norm": 5.006173610687256,
      "learning_rate": 7.891876222914705e-05,
      "loss": 0.1488,
      "step": 8355
    },
    {
      "epoch": 0.6055730695365438,
      "grad_norm": 3.6139793395996094,
      "learning_rate": 7.89042684252482e-05,
      "loss": 0.224,
      "step": 8356
    },
    {
      "epoch": 0.6056455411820125,
      "grad_norm": 0.9130201935768127,
      "learning_rate": 7.888977462134937e-05,
      "loss": 0.0268,
      "step": 8357
    },
    {
      "epoch": 0.6057180128274813,
      "grad_norm": 1.2074497938156128,
      "learning_rate": 7.887528081745054e-05,
      "loss": 0.0572,
      "step": 8358
    },
    {
      "epoch": 0.6057904844729499,
      "grad_norm": 0.6281431317329407,
      "learning_rate": 7.88607870135517e-05,
      "loss": 0.0094,
      "step": 8359
    },
    {
      "epoch": 0.6058629561184187,
      "grad_norm": 0.9301313161849976,
      "learning_rate": 7.884629320965287e-05,
      "loss": 0.0605,
      "step": 8360
    },
    {
      "epoch": 0.6059354277638874,
      "grad_norm": 1.2499960660934448,
      "learning_rate": 7.883179940575405e-05,
      "loss": 0.0366,
      "step": 8361
    },
    {
      "epoch": 0.6060078994093561,
      "grad_norm": 1.2519841194152832,
      "learning_rate": 7.881730560185521e-05,
      "loss": 0.099,
      "step": 8362
    },
    {
      "epoch": 0.6060803710548248,
      "grad_norm": 0.7638953328132629,
      "learning_rate": 7.880281179795638e-05,
      "loss": 0.0324,
      "step": 8363
    },
    {
      "epoch": 0.6061528427002935,
      "grad_norm": 2.1018435955047607,
      "learning_rate": 7.878831799405755e-05,
      "loss": 0.0617,
      "step": 8364
    },
    {
      "epoch": 0.6062253143457622,
      "grad_norm": 0.43830129504203796,
      "learning_rate": 7.877382419015871e-05,
      "loss": 0.0123,
      "step": 8365
    },
    {
      "epoch": 0.606297785991231,
      "grad_norm": 0.4611153304576874,
      "learning_rate": 7.875933038625988e-05,
      "loss": 0.0193,
      "step": 8366
    },
    {
      "epoch": 0.6063702576366996,
      "grad_norm": 1.2267478704452515,
      "learning_rate": 7.874483658236105e-05,
      "loss": 0.0391,
      "step": 8367
    },
    {
      "epoch": 0.6064427292821684,
      "grad_norm": 1.0200715065002441,
      "learning_rate": 7.87303427784622e-05,
      "loss": 0.067,
      "step": 8368
    },
    {
      "epoch": 0.6065152009276371,
      "grad_norm": 1.1897664070129395,
      "learning_rate": 7.871584897456337e-05,
      "loss": 0.0307,
      "step": 8369
    },
    {
      "epoch": 0.6065876725731058,
      "grad_norm": 4.823784828186035,
      "learning_rate": 7.870135517066454e-05,
      "loss": 0.1013,
      "step": 8370
    },
    {
      "epoch": 0.6066601442185745,
      "grad_norm": 0.8025864958763123,
      "learning_rate": 7.868686136676571e-05,
      "loss": 0.0441,
      "step": 8371
    },
    {
      "epoch": 0.6067326158640431,
      "grad_norm": 1.5484498739242554,
      "learning_rate": 7.867236756286688e-05,
      "loss": 0.0423,
      "step": 8372
    },
    {
      "epoch": 0.6068050875095119,
      "grad_norm": 1.1311088800430298,
      "learning_rate": 7.865787375896805e-05,
      "loss": 0.068,
      "step": 8373
    },
    {
      "epoch": 0.6068775591549807,
      "grad_norm": 1.1682569980621338,
      "learning_rate": 7.864337995506921e-05,
      "loss": 0.0706,
      "step": 8374
    },
    {
      "epoch": 0.6069500308004493,
      "grad_norm": 1.1962307691574097,
      "learning_rate": 7.862888615117038e-05,
      "loss": 0.0736,
      "step": 8375
    },
    {
      "epoch": 0.607022502445918,
      "grad_norm": 1.4049105644226074,
      "learning_rate": 7.861439234727155e-05,
      "loss": 0.0281,
      "step": 8376
    },
    {
      "epoch": 0.6070949740913868,
      "grad_norm": 0.7580956220626831,
      "learning_rate": 7.859989854337271e-05,
      "loss": 0.0376,
      "step": 8377
    },
    {
      "epoch": 0.6071674457368554,
      "grad_norm": 5.086014270782471,
      "learning_rate": 7.858540473947388e-05,
      "loss": 0.0785,
      "step": 8378
    },
    {
      "epoch": 0.6072399173823242,
      "grad_norm": 0.8796153664588928,
      "learning_rate": 7.857091093557505e-05,
      "loss": 0.0184,
      "step": 8379
    },
    {
      "epoch": 0.6073123890277928,
      "grad_norm": 4.2993597984313965,
      "learning_rate": 7.85564171316762e-05,
      "loss": 0.0359,
      "step": 8380
    },
    {
      "epoch": 0.6073848606732616,
      "grad_norm": 1.5618185997009277,
      "learning_rate": 7.854192332777737e-05,
      "loss": 0.0474,
      "step": 8381
    },
    {
      "epoch": 0.6074573323187303,
      "grad_norm": 1.0436806678771973,
      "learning_rate": 7.852742952387854e-05,
      "loss": 0.0581,
      "step": 8382
    },
    {
      "epoch": 0.607529803964199,
      "grad_norm": 2.1122171878814697,
      "learning_rate": 7.851293571997971e-05,
      "loss": 0.0894,
      "step": 8383
    },
    {
      "epoch": 0.6076022756096677,
      "grad_norm": 3.6314361095428467,
      "learning_rate": 7.849844191608088e-05,
      "loss": 0.1102,
      "step": 8384
    },
    {
      "epoch": 0.6076747472551365,
      "grad_norm": 1.8096023797988892,
      "learning_rate": 7.848394811218205e-05,
      "loss": 0.041,
      "step": 8385
    },
    {
      "epoch": 0.6077472189006051,
      "grad_norm": 2.998352289199829,
      "learning_rate": 7.846945430828321e-05,
      "loss": 0.1172,
      "step": 8386
    },
    {
      "epoch": 0.6078196905460739,
      "grad_norm": 1.7496337890625,
      "learning_rate": 7.845496050438438e-05,
      "loss": 0.0263,
      "step": 8387
    },
    {
      "epoch": 0.6078921621915425,
      "grad_norm": 0.2942379117012024,
      "learning_rate": 7.844046670048555e-05,
      "loss": 0.0064,
      "step": 8388
    },
    {
      "epoch": 0.6079646338370113,
      "grad_norm": 1.6367900371551514,
      "learning_rate": 7.84259728965867e-05,
      "loss": 0.0848,
      "step": 8389
    },
    {
      "epoch": 0.60803710548248,
      "grad_norm": 1.5724880695343018,
      "learning_rate": 7.841147909268788e-05,
      "loss": 0.0508,
      "step": 8390
    },
    {
      "epoch": 0.6081095771279487,
      "grad_norm": 1.659781575202942,
      "learning_rate": 7.839698528878905e-05,
      "loss": 0.0825,
      "step": 8391
    },
    {
      "epoch": 0.6081820487734174,
      "grad_norm": 1.8850033283233643,
      "learning_rate": 7.83824914848902e-05,
      "loss": 0.041,
      "step": 8392
    },
    {
      "epoch": 0.6082545204188861,
      "grad_norm": 1.206225037574768,
      "learning_rate": 7.836799768099137e-05,
      "loss": 0.0276,
      "step": 8393
    },
    {
      "epoch": 0.6083269920643548,
      "grad_norm": 1.1386570930480957,
      "learning_rate": 7.835350387709254e-05,
      "loss": 0.0496,
      "step": 8394
    },
    {
      "epoch": 0.6083994637098236,
      "grad_norm": 0.23196479678153992,
      "learning_rate": 7.833901007319371e-05,
      "loss": 0.0057,
      "step": 8395
    },
    {
      "epoch": 0.6084719353552922,
      "grad_norm": 0.6910642385482788,
      "learning_rate": 7.832451626929488e-05,
      "loss": 0.0331,
      "step": 8396
    },
    {
      "epoch": 0.608544407000761,
      "grad_norm": 0.8981395363807678,
      "learning_rate": 7.831002246539605e-05,
      "loss": 0.0465,
      "step": 8397
    },
    {
      "epoch": 0.6086168786462297,
      "grad_norm": 1.2531778812408447,
      "learning_rate": 7.829552866149721e-05,
      "loss": 0.0556,
      "step": 8398
    },
    {
      "epoch": 0.6086893502916984,
      "grad_norm": 0.7233240008354187,
      "learning_rate": 7.828103485759838e-05,
      "loss": 0.0286,
      "step": 8399
    },
    {
      "epoch": 0.6087618219371671,
      "grad_norm": 2.657691478729248,
      "learning_rate": 7.826654105369955e-05,
      "loss": 0.0831,
      "step": 8400
    },
    {
      "epoch": 0.6088342935826357,
      "grad_norm": 0.9983685612678528,
      "learning_rate": 7.82520472498007e-05,
      "loss": 0.0587,
      "step": 8401
    },
    {
      "epoch": 0.6089067652281045,
      "grad_norm": 1.080909252166748,
      "learning_rate": 7.823755344590188e-05,
      "loss": 0.043,
      "step": 8402
    },
    {
      "epoch": 0.6089792368735732,
      "grad_norm": 3.5710959434509277,
      "learning_rate": 7.822305964200305e-05,
      "loss": 0.0757,
      "step": 8403
    },
    {
      "epoch": 0.6090517085190419,
      "grad_norm": 2.2606706619262695,
      "learning_rate": 7.820856583810422e-05,
      "loss": 0.0715,
      "step": 8404
    },
    {
      "epoch": 0.6091241801645106,
      "grad_norm": 0.8063356280326843,
      "learning_rate": 7.819407203420537e-05,
      "loss": 0.0389,
      "step": 8405
    },
    {
      "epoch": 0.6091966518099794,
      "grad_norm": 1.599231481552124,
      "learning_rate": 7.817957823030654e-05,
      "loss": 0.0997,
      "step": 8406
    },
    {
      "epoch": 0.609269123455448,
      "grad_norm": 7.051661014556885,
      "learning_rate": 7.816508442640771e-05,
      "loss": 0.1524,
      "step": 8407
    },
    {
      "epoch": 0.6093415951009168,
      "grad_norm": 2.624586820602417,
      "learning_rate": 7.815059062250888e-05,
      "loss": 0.1077,
      "step": 8408
    },
    {
      "epoch": 0.6094140667463854,
      "grad_norm": 1.6722813844680786,
      "learning_rate": 7.813609681861005e-05,
      "loss": 0.0267,
      "step": 8409
    },
    {
      "epoch": 0.6094865383918542,
      "grad_norm": 1.7119826078414917,
      "learning_rate": 7.812160301471122e-05,
      "loss": 0.0492,
      "step": 8410
    },
    {
      "epoch": 0.6095590100373229,
      "grad_norm": 1.6847091913223267,
      "learning_rate": 7.810710921081238e-05,
      "loss": 0.0114,
      "step": 8411
    },
    {
      "epoch": 0.6096314816827916,
      "grad_norm": 0.7442879676818848,
      "learning_rate": 7.809261540691355e-05,
      "loss": 0.0503,
      "step": 8412
    },
    {
      "epoch": 0.6097039533282603,
      "grad_norm": 1.7459195852279663,
      "learning_rate": 7.807812160301472e-05,
      "loss": 0.0444,
      "step": 8413
    },
    {
      "epoch": 0.6097764249737291,
      "grad_norm": 1.761945128440857,
      "learning_rate": 7.806362779911588e-05,
      "loss": 0.0487,
      "step": 8414
    },
    {
      "epoch": 0.6098488966191977,
      "grad_norm": 1.815927267074585,
      "learning_rate": 7.804913399521705e-05,
      "loss": 0.0545,
      "step": 8415
    },
    {
      "epoch": 0.6099213682646665,
      "grad_norm": 1.0347117185592651,
      "learning_rate": 7.803464019131822e-05,
      "loss": 0.0407,
      "step": 8416
    },
    {
      "epoch": 0.6099938399101351,
      "grad_norm": 2.887108325958252,
      "learning_rate": 7.802014638741937e-05,
      "loss": 0.1332,
      "step": 8417
    },
    {
      "epoch": 0.6100663115556039,
      "grad_norm": 3.537806987762451,
      "learning_rate": 7.800565258352056e-05,
      "loss": 0.0504,
      "step": 8418
    },
    {
      "epoch": 0.6101387832010726,
      "grad_norm": 1.7010489702224731,
      "learning_rate": 7.799115877962173e-05,
      "loss": 0.1015,
      "step": 8419
    },
    {
      "epoch": 0.6102112548465413,
      "grad_norm": 1.7497057914733887,
      "learning_rate": 7.797666497572288e-05,
      "loss": 0.0361,
      "step": 8420
    },
    {
      "epoch": 0.61028372649201,
      "grad_norm": 0.3611801266670227,
      "learning_rate": 7.796217117182405e-05,
      "loss": 0.0139,
      "step": 8421
    },
    {
      "epoch": 0.6103561981374787,
      "grad_norm": 1.0205368995666504,
      "learning_rate": 7.794767736792522e-05,
      "loss": 0.0398,
      "step": 8422
    },
    {
      "epoch": 0.6104286697829474,
      "grad_norm": 2.2153449058532715,
      "learning_rate": 7.793318356402638e-05,
      "loss": 0.1379,
      "step": 8423
    },
    {
      "epoch": 0.6105011414284162,
      "grad_norm": 1.8746215105056763,
      "learning_rate": 7.791868976012755e-05,
      "loss": 0.0555,
      "step": 8424
    },
    {
      "epoch": 0.6105736130738848,
      "grad_norm": 0.9957247972488403,
      "learning_rate": 7.790419595622872e-05,
      "loss": 0.0489,
      "step": 8425
    },
    {
      "epoch": 0.6106460847193536,
      "grad_norm": 2.06209135055542,
      "learning_rate": 7.788970215232988e-05,
      "loss": 0.1301,
      "step": 8426
    },
    {
      "epoch": 0.6107185563648223,
      "grad_norm": 0.4579005539417267,
      "learning_rate": 7.787520834843105e-05,
      "loss": 0.0096,
      "step": 8427
    },
    {
      "epoch": 0.610791028010291,
      "grad_norm": 1.1513584852218628,
      "learning_rate": 7.786071454453222e-05,
      "loss": 0.089,
      "step": 8428
    },
    {
      "epoch": 0.6108634996557597,
      "grad_norm": 4.5223774909973145,
      "learning_rate": 7.784622074063339e-05,
      "loss": 0.1164,
      "step": 8429
    },
    {
      "epoch": 0.6109359713012283,
      "grad_norm": 2.382441997528076,
      "learning_rate": 7.783172693673456e-05,
      "loss": 0.1253,
      "step": 8430
    },
    {
      "epoch": 0.6110084429466971,
      "grad_norm": 0.7264803647994995,
      "learning_rate": 7.781723313283573e-05,
      "loss": 0.016,
      "step": 8431
    },
    {
      "epoch": 0.6110809145921658,
      "grad_norm": 0.8813525438308716,
      "learning_rate": 7.780273932893688e-05,
      "loss": 0.0229,
      "step": 8432
    },
    {
      "epoch": 0.6111533862376345,
      "grad_norm": 1.3852131366729736,
      "learning_rate": 7.778824552503805e-05,
      "loss": 0.0568,
      "step": 8433
    },
    {
      "epoch": 0.6112258578831032,
      "grad_norm": 2.2962729930877686,
      "learning_rate": 7.777375172113922e-05,
      "loss": 0.1572,
      "step": 8434
    },
    {
      "epoch": 0.611298329528572,
      "grad_norm": 8.299564361572266,
      "learning_rate": 7.775925791724038e-05,
      "loss": 0.1317,
      "step": 8435
    },
    {
      "epoch": 0.6113708011740406,
      "grad_norm": 1.0510849952697754,
      "learning_rate": 7.774476411334155e-05,
      "loss": 0.0389,
      "step": 8436
    },
    {
      "epoch": 0.6114432728195094,
      "grad_norm": 1.5407230854034424,
      "learning_rate": 7.773027030944272e-05,
      "loss": 0.0425,
      "step": 8437
    },
    {
      "epoch": 0.611515744464978,
      "grad_norm": 1.2412846088409424,
      "learning_rate": 7.771577650554388e-05,
      "loss": 0.0668,
      "step": 8438
    },
    {
      "epoch": 0.6115882161104468,
      "grad_norm": 2.824594259262085,
      "learning_rate": 7.770128270164505e-05,
      "loss": 0.1088,
      "step": 8439
    },
    {
      "epoch": 0.6116606877559155,
      "grad_norm": 2.0273237228393555,
      "learning_rate": 7.768678889774622e-05,
      "loss": 0.1427,
      "step": 8440
    },
    {
      "epoch": 0.6117331594013842,
      "grad_norm": 1.8949120044708252,
      "learning_rate": 7.767229509384739e-05,
      "loss": 0.062,
      "step": 8441
    },
    {
      "epoch": 0.6118056310468529,
      "grad_norm": 3.110085964202881,
      "learning_rate": 7.765780128994856e-05,
      "loss": 0.1629,
      "step": 8442
    },
    {
      "epoch": 0.6118781026923217,
      "grad_norm": 0.102986641228199,
      "learning_rate": 7.764330748604973e-05,
      "loss": 0.0033,
      "step": 8443
    },
    {
      "epoch": 0.6119505743377903,
      "grad_norm": 0.2633412480354309,
      "learning_rate": 7.762881368215088e-05,
      "loss": 0.0095,
      "step": 8444
    },
    {
      "epoch": 0.6120230459832591,
      "grad_norm": 3.795980453491211,
      "learning_rate": 7.761431987825205e-05,
      "loss": 0.0959,
      "step": 8445
    },
    {
      "epoch": 0.6120955176287277,
      "grad_norm": 1.0391209125518799,
      "learning_rate": 7.759982607435322e-05,
      "loss": 0.0838,
      "step": 8446
    },
    {
      "epoch": 0.6121679892741965,
      "grad_norm": 3.5747671127319336,
      "learning_rate": 7.758533227045438e-05,
      "loss": 0.1073,
      "step": 8447
    },
    {
      "epoch": 0.6122404609196652,
      "grad_norm": 6.681830406188965,
      "learning_rate": 7.757083846655555e-05,
      "loss": 0.0492,
      "step": 8448
    },
    {
      "epoch": 0.6123129325651339,
      "grad_norm": 0.548869252204895,
      "learning_rate": 7.755634466265672e-05,
      "loss": 0.0329,
      "step": 8449
    },
    {
      "epoch": 0.6123854042106026,
      "grad_norm": 1.2446739673614502,
      "learning_rate": 7.754185085875788e-05,
      "loss": 0.0884,
      "step": 8450
    },
    {
      "epoch": 0.6124578758560714,
      "grad_norm": 1.099053144454956,
      "learning_rate": 7.752735705485905e-05,
      "loss": 0.0498,
      "step": 8451
    },
    {
      "epoch": 0.61253034750154,
      "grad_norm": 0.3948059380054474,
      "learning_rate": 7.751286325096022e-05,
      "loss": 0.0136,
      "step": 8452
    },
    {
      "epoch": 0.6126028191470088,
      "grad_norm": 3.7529337406158447,
      "learning_rate": 7.749836944706139e-05,
      "loss": 0.1073,
      "step": 8453
    },
    {
      "epoch": 0.6126752907924774,
      "grad_norm": 0.8162716031074524,
      "learning_rate": 7.748387564316256e-05,
      "loss": 0.0272,
      "step": 8454
    },
    {
      "epoch": 0.6127477624379462,
      "grad_norm": 1.4026551246643066,
      "learning_rate": 7.746938183926373e-05,
      "loss": 0.0735,
      "step": 8455
    },
    {
      "epoch": 0.6128202340834149,
      "grad_norm": 1.165659785270691,
      "learning_rate": 7.745488803536488e-05,
      "loss": 0.0898,
      "step": 8456
    },
    {
      "epoch": 0.6128927057288835,
      "grad_norm": 1.0083814859390259,
      "learning_rate": 7.744039423146605e-05,
      "loss": 0.0232,
      "step": 8457
    },
    {
      "epoch": 0.6129651773743523,
      "grad_norm": 0.8854866623878479,
      "learning_rate": 7.742590042756722e-05,
      "loss": 0.0267,
      "step": 8458
    },
    {
      "epoch": 0.6130376490198209,
      "grad_norm": 0.46453943848609924,
      "learning_rate": 7.741140662366838e-05,
      "loss": 0.0229,
      "step": 8459
    },
    {
      "epoch": 0.6131101206652897,
      "grad_norm": 0.8987646698951721,
      "learning_rate": 7.739691281976955e-05,
      "loss": 0.0435,
      "step": 8460
    },
    {
      "epoch": 0.6131825923107584,
      "grad_norm": 0.9209908843040466,
      "learning_rate": 7.738241901587072e-05,
      "loss": 0.0237,
      "step": 8461
    },
    {
      "epoch": 0.6132550639562271,
      "grad_norm": 0.7568380832672119,
      "learning_rate": 7.736792521197188e-05,
      "loss": 0.0459,
      "step": 8462
    },
    {
      "epoch": 0.6133275356016958,
      "grad_norm": 1.0660455226898193,
      "learning_rate": 7.735343140807305e-05,
      "loss": 0.0369,
      "step": 8463
    },
    {
      "epoch": 0.6134000072471646,
      "grad_norm": 1.3321006298065186,
      "learning_rate": 7.733893760417422e-05,
      "loss": 0.0601,
      "step": 8464
    },
    {
      "epoch": 0.6134724788926332,
      "grad_norm": 0.6562698483467102,
      "learning_rate": 7.732444380027539e-05,
      "loss": 0.013,
      "step": 8465
    },
    {
      "epoch": 0.613544950538102,
      "grad_norm": 1.5829678773880005,
      "learning_rate": 7.730994999637656e-05,
      "loss": 0.0849,
      "step": 8466
    },
    {
      "epoch": 0.6136174221835706,
      "grad_norm": 1.1789140701293945,
      "learning_rate": 7.729545619247773e-05,
      "loss": 0.0669,
      "step": 8467
    },
    {
      "epoch": 0.6136898938290394,
      "grad_norm": 3.1122124195098877,
      "learning_rate": 7.728096238857888e-05,
      "loss": 0.0701,
      "step": 8468
    },
    {
      "epoch": 0.6137623654745081,
      "grad_norm": 0.6370724439620972,
      "learning_rate": 7.726646858468005e-05,
      "loss": 0.0506,
      "step": 8469
    },
    {
      "epoch": 0.6138348371199768,
      "grad_norm": 3.267138957977295,
      "learning_rate": 7.725197478078122e-05,
      "loss": 0.1897,
      "step": 8470
    },
    {
      "epoch": 0.6139073087654455,
      "grad_norm": 0.8206954598426819,
      "learning_rate": 7.723748097688238e-05,
      "loss": 0.0212,
      "step": 8471
    },
    {
      "epoch": 0.6139797804109143,
      "grad_norm": 0.40478235483169556,
      "learning_rate": 7.722298717298355e-05,
      "loss": 0.0146,
      "step": 8472
    },
    {
      "epoch": 0.6140522520563829,
      "grad_norm": 1.74695885181427,
      "learning_rate": 7.720849336908472e-05,
      "loss": 0.1037,
      "step": 8473
    },
    {
      "epoch": 0.6141247237018517,
      "grad_norm": 0.4518534541130066,
      "learning_rate": 7.719399956518588e-05,
      "loss": 0.0203,
      "step": 8474
    },
    {
      "epoch": 0.6141971953473203,
      "grad_norm": 1.990596055984497,
      "learning_rate": 7.717950576128705e-05,
      "loss": 0.0076,
      "step": 8475
    },
    {
      "epoch": 0.6142696669927891,
      "grad_norm": 2.5749144554138184,
      "learning_rate": 7.716501195738823e-05,
      "loss": 0.1205,
      "step": 8476
    },
    {
      "epoch": 0.6143421386382578,
      "grad_norm": 1.2565360069274902,
      "learning_rate": 7.715051815348939e-05,
      "loss": 0.0314,
      "step": 8477
    },
    {
      "epoch": 0.6144146102837265,
      "grad_norm": 3.86844801902771,
      "learning_rate": 7.713602434959056e-05,
      "loss": 0.2147,
      "step": 8478
    },
    {
      "epoch": 0.6144870819291952,
      "grad_norm": 1.5504862070083618,
      "learning_rate": 7.712153054569173e-05,
      "loss": 0.0641,
      "step": 8479
    },
    {
      "epoch": 0.614559553574664,
      "grad_norm": 1.0163861513137817,
      "learning_rate": 7.710703674179288e-05,
      "loss": 0.0488,
      "step": 8480
    },
    {
      "epoch": 0.6146320252201326,
      "grad_norm": 0.40041467547416687,
      "learning_rate": 7.709254293789405e-05,
      "loss": 0.0138,
      "step": 8481
    },
    {
      "epoch": 0.6147044968656014,
      "grad_norm": 1.0813597440719604,
      "learning_rate": 7.707804913399522e-05,
      "loss": 0.0487,
      "step": 8482
    },
    {
      "epoch": 0.61477696851107,
      "grad_norm": 3.12935733795166,
      "learning_rate": 7.706355533009638e-05,
      "loss": 0.1558,
      "step": 8483
    },
    {
      "epoch": 0.6148494401565388,
      "grad_norm": 3.055424690246582,
      "learning_rate": 7.704906152619755e-05,
      "loss": 0.1791,
      "step": 8484
    },
    {
      "epoch": 0.6149219118020075,
      "grad_norm": 0.23218731582164764,
      "learning_rate": 7.703456772229872e-05,
      "loss": 0.0063,
      "step": 8485
    },
    {
      "epoch": 0.6149943834474761,
      "grad_norm": 0.8705688714981079,
      "learning_rate": 7.702007391839989e-05,
      "loss": 0.0383,
      "step": 8486
    },
    {
      "epoch": 0.6150668550929449,
      "grad_norm": 0.5426195859909058,
      "learning_rate": 7.700558011450106e-05,
      "loss": 0.014,
      "step": 8487
    },
    {
      "epoch": 0.6151393267384136,
      "grad_norm": 0.8496838212013245,
      "learning_rate": 7.699108631060223e-05,
      "loss": 0.0514,
      "step": 8488
    },
    {
      "epoch": 0.6152117983838823,
      "grad_norm": 2.110583782196045,
      "learning_rate": 7.69765925067034e-05,
      "loss": 0.1709,
      "step": 8489
    },
    {
      "epoch": 0.615284270029351,
      "grad_norm": 2.7830822467803955,
      "learning_rate": 7.696209870280456e-05,
      "loss": 0.1703,
      "step": 8490
    },
    {
      "epoch": 0.6153567416748197,
      "grad_norm": 1.344171166419983,
      "learning_rate": 7.694760489890573e-05,
      "loss": 0.058,
      "step": 8491
    },
    {
      "epoch": 0.6154292133202884,
      "grad_norm": 1.5193058252334595,
      "learning_rate": 7.69331110950069e-05,
      "loss": 0.077,
      "step": 8492
    },
    {
      "epoch": 0.6155016849657572,
      "grad_norm": 0.6564120650291443,
      "learning_rate": 7.691861729110805e-05,
      "loss": 0.0278,
      "step": 8493
    },
    {
      "epoch": 0.6155741566112258,
      "grad_norm": 1.3325660228729248,
      "learning_rate": 7.690412348720922e-05,
      "loss": 0.087,
      "step": 8494
    },
    {
      "epoch": 0.6156466282566946,
      "grad_norm": 0.724139392375946,
      "learning_rate": 7.688962968331039e-05,
      "loss": 0.0435,
      "step": 8495
    },
    {
      "epoch": 0.6157190999021632,
      "grad_norm": 3.8771774768829346,
      "learning_rate": 7.687513587941155e-05,
      "loss": 0.1042,
      "step": 8496
    },
    {
      "epoch": 0.615791571547632,
      "grad_norm": 2.3235349655151367,
      "learning_rate": 7.686064207551272e-05,
      "loss": 0.0126,
      "step": 8497
    },
    {
      "epoch": 0.6158640431931007,
      "grad_norm": 1.3818409442901611,
      "learning_rate": 7.684614827161389e-05,
      "loss": 0.0366,
      "step": 8498
    },
    {
      "epoch": 0.6159365148385694,
      "grad_norm": 1.2342889308929443,
      "learning_rate": 7.683165446771506e-05,
      "loss": 0.0802,
      "step": 8499
    },
    {
      "epoch": 0.6160089864840381,
      "grad_norm": 2.8514535427093506,
      "learning_rate": 7.681716066381623e-05,
      "loss": 0.0943,
      "step": 8500
    },
    {
      "epoch": 0.6160814581295069,
      "grad_norm": 1.4077948331832886,
      "learning_rate": 7.68026668599174e-05,
      "loss": 0.0258,
      "step": 8501
    },
    {
      "epoch": 0.6161539297749755,
      "grad_norm": 1.3308666944503784,
      "learning_rate": 7.678817305601856e-05,
      "loss": 0.0451,
      "step": 8502
    },
    {
      "epoch": 0.6162264014204443,
      "grad_norm": 0.3603900671005249,
      "learning_rate": 7.677367925211973e-05,
      "loss": 0.0058,
      "step": 8503
    },
    {
      "epoch": 0.6162988730659129,
      "grad_norm": 0.42532429099082947,
      "learning_rate": 7.67591854482209e-05,
      "loss": 0.0079,
      "step": 8504
    },
    {
      "epoch": 0.6163713447113817,
      "grad_norm": 2.158444881439209,
      "learning_rate": 7.674469164432205e-05,
      "loss": 0.05,
      "step": 8505
    },
    {
      "epoch": 0.6164438163568504,
      "grad_norm": 0.22801250219345093,
      "learning_rate": 7.673019784042322e-05,
      "loss": 0.0048,
      "step": 8506
    },
    {
      "epoch": 0.6165162880023191,
      "grad_norm": 1.202398657798767,
      "learning_rate": 7.671570403652439e-05,
      "loss": 0.0708,
      "step": 8507
    },
    {
      "epoch": 0.6165887596477878,
      "grad_norm": 2.9436895847320557,
      "learning_rate": 7.670121023262555e-05,
      "loss": 0.0557,
      "step": 8508
    },
    {
      "epoch": 0.6166612312932566,
      "grad_norm": 2.8353588581085205,
      "learning_rate": 7.668671642872672e-05,
      "loss": 0.0538,
      "step": 8509
    },
    {
      "epoch": 0.6167337029387252,
      "grad_norm": 1.381208062171936,
      "learning_rate": 7.667222262482789e-05,
      "loss": 0.0452,
      "step": 8510
    },
    {
      "epoch": 0.616806174584194,
      "grad_norm": 2.173797607421875,
      "learning_rate": 7.665772882092906e-05,
      "loss": 0.0709,
      "step": 8511
    },
    {
      "epoch": 0.6168786462296626,
      "grad_norm": 1.3843015432357788,
      "learning_rate": 7.664323501703023e-05,
      "loss": 0.0486,
      "step": 8512
    },
    {
      "epoch": 0.6169511178751313,
      "grad_norm": 3.4301319122314453,
      "learning_rate": 7.66287412131314e-05,
      "loss": 0.0902,
      "step": 8513
    },
    {
      "epoch": 0.6170235895206001,
      "grad_norm": 1.4056462049484253,
      "learning_rate": 7.661424740923255e-05,
      "loss": 0.0347,
      "step": 8514
    },
    {
      "epoch": 0.6170960611660687,
      "grad_norm": 0.5080872774124146,
      "learning_rate": 7.659975360533372e-05,
      "loss": 0.0101,
      "step": 8515
    },
    {
      "epoch": 0.6171685328115375,
      "grad_norm": 1.0819487571716309,
      "learning_rate": 7.65852598014349e-05,
      "loss": 0.0389,
      "step": 8516
    },
    {
      "epoch": 0.6172410044570062,
      "grad_norm": 1.7222024202346802,
      "learning_rate": 7.657076599753605e-05,
      "loss": 0.1012,
      "step": 8517
    },
    {
      "epoch": 0.6173134761024749,
      "grad_norm": 0.3393801152706146,
      "learning_rate": 7.655627219363722e-05,
      "loss": 0.0269,
      "step": 8518
    },
    {
      "epoch": 0.6173859477479436,
      "grad_norm": 0.8492626547813416,
      "learning_rate": 7.654177838973839e-05,
      "loss": 0.0323,
      "step": 8519
    },
    {
      "epoch": 0.6174584193934123,
      "grad_norm": 1.4556797742843628,
      "learning_rate": 7.652728458583955e-05,
      "loss": 0.0942,
      "step": 8520
    },
    {
      "epoch": 0.617530891038881,
      "grad_norm": 1.018955111503601,
      "learning_rate": 7.651279078194072e-05,
      "loss": 0.0364,
      "step": 8521
    },
    {
      "epoch": 0.6176033626843498,
      "grad_norm": 2.1130568981170654,
      "learning_rate": 7.649829697804189e-05,
      "loss": 0.1234,
      "step": 8522
    },
    {
      "epoch": 0.6176758343298184,
      "grad_norm": 2.1014487743377686,
      "learning_rate": 7.648380317414306e-05,
      "loss": 0.0118,
      "step": 8523
    },
    {
      "epoch": 0.6177483059752872,
      "grad_norm": 0.9606815576553345,
      "learning_rate": 7.646930937024423e-05,
      "loss": 0.0225,
      "step": 8524
    },
    {
      "epoch": 0.6178207776207559,
      "grad_norm": 0.5523146986961365,
      "learning_rate": 7.64548155663454e-05,
      "loss": 0.0165,
      "step": 8525
    },
    {
      "epoch": 0.6178932492662246,
      "grad_norm": 0.7063032388687134,
      "learning_rate": 7.644032176244655e-05,
      "loss": 0.0144,
      "step": 8526
    },
    {
      "epoch": 0.6179657209116933,
      "grad_norm": 1.2718298435211182,
      "learning_rate": 7.642582795854772e-05,
      "loss": 0.0232,
      "step": 8527
    },
    {
      "epoch": 0.618038192557162,
      "grad_norm": 2.204587697982788,
      "learning_rate": 7.64113341546489e-05,
      "loss": 0.1274,
      "step": 8528
    },
    {
      "epoch": 0.6181106642026307,
      "grad_norm": 0.33355847001075745,
      "learning_rate": 7.639684035075005e-05,
      "loss": 0.0036,
      "step": 8529
    },
    {
      "epoch": 0.6181831358480995,
      "grad_norm": 0.6642289757728577,
      "learning_rate": 7.638234654685122e-05,
      "loss": 0.0072,
      "step": 8530
    },
    {
      "epoch": 0.6182556074935681,
      "grad_norm": 1.1387290954589844,
      "learning_rate": 7.636785274295239e-05,
      "loss": 0.0779,
      "step": 8531
    },
    {
      "epoch": 0.6183280791390369,
      "grad_norm": 3.397601842880249,
      "learning_rate": 7.635335893905355e-05,
      "loss": 0.1341,
      "step": 8532
    },
    {
      "epoch": 0.6184005507845055,
      "grad_norm": 1.1067495346069336,
      "learning_rate": 7.633886513515473e-05,
      "loss": 0.0515,
      "step": 8533
    },
    {
      "epoch": 0.6184730224299743,
      "grad_norm": 0.6243061423301697,
      "learning_rate": 7.63243713312559e-05,
      "loss": 0.0272,
      "step": 8534
    },
    {
      "epoch": 0.618545494075443,
      "grad_norm": 0.9015877842903137,
      "learning_rate": 7.630987752735706e-05,
      "loss": 0.0346,
      "step": 8535
    },
    {
      "epoch": 0.6186179657209117,
      "grad_norm": 0.5291297435760498,
      "learning_rate": 7.629538372345823e-05,
      "loss": 0.0109,
      "step": 8536
    },
    {
      "epoch": 0.6186904373663804,
      "grad_norm": 0.5925464630126953,
      "learning_rate": 7.62808899195594e-05,
      "loss": 0.0127,
      "step": 8537
    },
    {
      "epoch": 0.6187629090118492,
      "grad_norm": 2.625851631164551,
      "learning_rate": 7.626639611566055e-05,
      "loss": 0.0896,
      "step": 8538
    },
    {
      "epoch": 0.6188353806573178,
      "grad_norm": 1.655922293663025,
      "learning_rate": 7.625190231176172e-05,
      "loss": 0.0467,
      "step": 8539
    },
    {
      "epoch": 0.6189078523027866,
      "grad_norm": 0.4204518795013428,
      "learning_rate": 7.62374085078629e-05,
      "loss": 0.0122,
      "step": 8540
    },
    {
      "epoch": 0.6189803239482552,
      "grad_norm": 0.8665395975112915,
      "learning_rate": 7.622291470396405e-05,
      "loss": 0.0492,
      "step": 8541
    },
    {
      "epoch": 0.619052795593724,
      "grad_norm": 0.6417044997215271,
      "learning_rate": 7.620842090006522e-05,
      "loss": 0.0153,
      "step": 8542
    },
    {
      "epoch": 0.6191252672391927,
      "grad_norm": 1.19621741771698,
      "learning_rate": 7.619392709616639e-05,
      "loss": 0.0503,
      "step": 8543
    },
    {
      "epoch": 0.6191977388846613,
      "grad_norm": 0.8860924243927002,
      "learning_rate": 7.617943329226756e-05,
      "loss": 0.0352,
      "step": 8544
    },
    {
      "epoch": 0.6192702105301301,
      "grad_norm": 0.8496323227882385,
      "learning_rate": 7.616493948836873e-05,
      "loss": 0.0245,
      "step": 8545
    },
    {
      "epoch": 0.6193426821755988,
      "grad_norm": 3.3214733600616455,
      "learning_rate": 7.61504456844699e-05,
      "loss": 0.0397,
      "step": 8546
    },
    {
      "epoch": 0.6194151538210675,
      "grad_norm": 0.6002872586250305,
      "learning_rate": 7.613595188057106e-05,
      "loss": 0.0107,
      "step": 8547
    },
    {
      "epoch": 0.6194876254665362,
      "grad_norm": 0.7926135659217834,
      "learning_rate": 7.612145807667223e-05,
      "loss": 0.0141,
      "step": 8548
    },
    {
      "epoch": 0.6195600971120049,
      "grad_norm": 1.629237413406372,
      "learning_rate": 7.61069642727734e-05,
      "loss": 0.0443,
      "step": 8549
    },
    {
      "epoch": 0.6196325687574736,
      "grad_norm": 1.9249746799468994,
      "learning_rate": 7.609247046887455e-05,
      "loss": 0.0564,
      "step": 8550
    },
    {
      "epoch": 0.6197050404029424,
      "grad_norm": 1.0837987661361694,
      "learning_rate": 7.607797666497572e-05,
      "loss": 0.0332,
      "step": 8551
    },
    {
      "epoch": 0.619777512048411,
      "grad_norm": 0.28080806136131287,
      "learning_rate": 7.60634828610769e-05,
      "loss": 0.0113,
      "step": 8552
    },
    {
      "epoch": 0.6198499836938798,
      "grad_norm": 0.48698103427886963,
      "learning_rate": 7.604898905717805e-05,
      "loss": 0.0151,
      "step": 8553
    },
    {
      "epoch": 0.6199224553393485,
      "grad_norm": 2.7644412517547607,
      "learning_rate": 7.603449525327922e-05,
      "loss": 0.1066,
      "step": 8554
    },
    {
      "epoch": 0.6199949269848172,
      "grad_norm": 0.10205443203449249,
      "learning_rate": 7.602000144938039e-05,
      "loss": 0.0006,
      "step": 8555
    },
    {
      "epoch": 0.6200673986302859,
      "grad_norm": 0.5629282593727112,
      "learning_rate": 7.600550764548156e-05,
      "loss": 0.0054,
      "step": 8556
    },
    {
      "epoch": 0.6201398702757546,
      "grad_norm": 0.7937929034233093,
      "learning_rate": 7.599101384158273e-05,
      "loss": 0.0444,
      "step": 8557
    },
    {
      "epoch": 0.6202123419212233,
      "grad_norm": 2.2673516273498535,
      "learning_rate": 7.59765200376839e-05,
      "loss": 0.084,
      "step": 8558
    },
    {
      "epoch": 0.6202848135666921,
      "grad_norm": 1.8918259143829346,
      "learning_rate": 7.596202623378506e-05,
      "loss": 0.0709,
      "step": 8559
    },
    {
      "epoch": 0.6203572852121607,
      "grad_norm": 2.845642566680908,
      "learning_rate": 7.594753242988623e-05,
      "loss": 0.1781,
      "step": 8560
    },
    {
      "epoch": 0.6204297568576295,
      "grad_norm": 0.8755921721458435,
      "learning_rate": 7.59330386259874e-05,
      "loss": 0.0644,
      "step": 8561
    },
    {
      "epoch": 0.6205022285030981,
      "grad_norm": 2.5410962104797363,
      "learning_rate": 7.591854482208855e-05,
      "loss": 0.0619,
      "step": 8562
    },
    {
      "epoch": 0.6205747001485669,
      "grad_norm": 1.2251522541046143,
      "learning_rate": 7.590405101818972e-05,
      "loss": 0.0344,
      "step": 8563
    },
    {
      "epoch": 0.6206471717940356,
      "grad_norm": 0.18633578717708588,
      "learning_rate": 7.58895572142909e-05,
      "loss": 0.0023,
      "step": 8564
    },
    {
      "epoch": 0.6207196434395043,
      "grad_norm": 1.184025526046753,
      "learning_rate": 7.587506341039206e-05,
      "loss": 0.0318,
      "step": 8565
    },
    {
      "epoch": 0.620792115084973,
      "grad_norm": 1.1140049695968628,
      "learning_rate": 7.586056960649322e-05,
      "loss": 0.0219,
      "step": 8566
    },
    {
      "epoch": 0.6208645867304418,
      "grad_norm": 3.823632001876831,
      "learning_rate": 7.584607580259439e-05,
      "loss": 0.0983,
      "step": 8567
    },
    {
      "epoch": 0.6209370583759104,
      "grad_norm": 0.9626464247703552,
      "learning_rate": 7.583158199869556e-05,
      "loss": 0.0753,
      "step": 8568
    },
    {
      "epoch": 0.6210095300213792,
      "grad_norm": 0.35932618379592896,
      "learning_rate": 7.581708819479673e-05,
      "loss": 0.006,
      "step": 8569
    },
    {
      "epoch": 0.6210820016668478,
      "grad_norm": 2.9742581844329834,
      "learning_rate": 7.58025943908979e-05,
      "loss": 0.0897,
      "step": 8570
    },
    {
      "epoch": 0.6211544733123165,
      "grad_norm": 0.8109276294708252,
      "learning_rate": 7.578810058699907e-05,
      "loss": 0.0348,
      "step": 8571
    },
    {
      "epoch": 0.6212269449577853,
      "grad_norm": 1.626503348350525,
      "learning_rate": 7.577360678310023e-05,
      "loss": 0.0902,
      "step": 8572
    },
    {
      "epoch": 0.6212994166032539,
      "grad_norm": 1.9905893802642822,
      "learning_rate": 7.57591129792014e-05,
      "loss": 0.0878,
      "step": 8573
    },
    {
      "epoch": 0.6213718882487227,
      "grad_norm": 0.2681901454925537,
      "learning_rate": 7.574461917530257e-05,
      "loss": 0.0186,
      "step": 8574
    },
    {
      "epoch": 0.6214443598941914,
      "grad_norm": 1.1205583810806274,
      "learning_rate": 7.573012537140372e-05,
      "loss": 0.0294,
      "step": 8575
    },
    {
      "epoch": 0.6215168315396601,
      "grad_norm": 0.7937886714935303,
      "learning_rate": 7.57156315675049e-05,
      "loss": 0.0228,
      "step": 8576
    },
    {
      "epoch": 0.6215893031851288,
      "grad_norm": 1.2884591817855835,
      "learning_rate": 7.570113776360606e-05,
      "loss": 0.0492,
      "step": 8577
    },
    {
      "epoch": 0.6216617748305975,
      "grad_norm": 0.2655698359012604,
      "learning_rate": 7.568664395970722e-05,
      "loss": 0.0007,
      "step": 8578
    },
    {
      "epoch": 0.6217342464760662,
      "grad_norm": 2.8898231983184814,
      "learning_rate": 7.567215015580839e-05,
      "loss": 0.1057,
      "step": 8579
    },
    {
      "epoch": 0.621806718121535,
      "grad_norm": 1.1491179466247559,
      "learning_rate": 7.565765635190956e-05,
      "loss": 0.0155,
      "step": 8580
    },
    {
      "epoch": 0.6218791897670036,
      "grad_norm": 0.7292337417602539,
      "learning_rate": 7.564316254801073e-05,
      "loss": 0.0098,
      "step": 8581
    },
    {
      "epoch": 0.6219516614124724,
      "grad_norm": 2.9648585319519043,
      "learning_rate": 7.56286687441119e-05,
      "loss": 0.0937,
      "step": 8582
    },
    {
      "epoch": 0.6220241330579411,
      "grad_norm": 3.8053629398345947,
      "learning_rate": 7.561417494021307e-05,
      "loss": 0.151,
      "step": 8583
    },
    {
      "epoch": 0.6220966047034098,
      "grad_norm": 4.499545574188232,
      "learning_rate": 7.559968113631423e-05,
      "loss": 0.0368,
      "step": 8584
    },
    {
      "epoch": 0.6221690763488785,
      "grad_norm": 1.2494697570800781,
      "learning_rate": 7.55851873324154e-05,
      "loss": 0.021,
      "step": 8585
    },
    {
      "epoch": 0.6222415479943472,
      "grad_norm": 3.1333839893341064,
      "learning_rate": 7.557069352851657e-05,
      "loss": 0.0717,
      "step": 8586
    },
    {
      "epoch": 0.6223140196398159,
      "grad_norm": 2.9444756507873535,
      "learning_rate": 7.555619972461772e-05,
      "loss": 0.1019,
      "step": 8587
    },
    {
      "epoch": 0.6223864912852847,
      "grad_norm": 3.280601978302002,
      "learning_rate": 7.55417059207189e-05,
      "loss": 0.1016,
      "step": 8588
    },
    {
      "epoch": 0.6224589629307533,
      "grad_norm": 1.2462313175201416,
      "learning_rate": 7.552721211682006e-05,
      "loss": 0.0177,
      "step": 8589
    },
    {
      "epoch": 0.6225314345762221,
      "grad_norm": 2.4241943359375,
      "learning_rate": 7.551271831292122e-05,
      "loss": 0.0763,
      "step": 8590
    },
    {
      "epoch": 0.6226039062216908,
      "grad_norm": 2.47615122795105,
      "learning_rate": 7.54982245090224e-05,
      "loss": 0.0239,
      "step": 8591
    },
    {
      "epoch": 0.6226763778671595,
      "grad_norm": 0.9401907324790955,
      "learning_rate": 7.548373070512357e-05,
      "loss": 0.0184,
      "step": 8592
    },
    {
      "epoch": 0.6227488495126282,
      "grad_norm": 1.060985803604126,
      "learning_rate": 7.546923690122473e-05,
      "loss": 0.0243,
      "step": 8593
    },
    {
      "epoch": 0.6228213211580969,
      "grad_norm": 3.546138286590576,
      "learning_rate": 7.54547430973259e-05,
      "loss": 0.0132,
      "step": 8594
    },
    {
      "epoch": 0.6228937928035656,
      "grad_norm": 0.9846391677856445,
      "learning_rate": 7.544024929342707e-05,
      "loss": 0.0564,
      "step": 8595
    },
    {
      "epoch": 0.6229662644490344,
      "grad_norm": 2.8709821701049805,
      "learning_rate": 7.542575548952823e-05,
      "loss": 0.1692,
      "step": 8596
    },
    {
      "epoch": 0.623038736094503,
      "grad_norm": 1.7320743799209595,
      "learning_rate": 7.54112616856294e-05,
      "loss": 0.0768,
      "step": 8597
    },
    {
      "epoch": 0.6231112077399718,
      "grad_norm": 4.862502574920654,
      "learning_rate": 7.539676788173057e-05,
      "loss": 0.21,
      "step": 8598
    },
    {
      "epoch": 0.6231836793854404,
      "grad_norm": 0.10412631928920746,
      "learning_rate": 7.538227407783172e-05,
      "loss": 0.0022,
      "step": 8599
    },
    {
      "epoch": 0.6232561510309091,
      "grad_norm": 1.7450696229934692,
      "learning_rate": 7.53677802739329e-05,
      "loss": 0.0804,
      "step": 8600
    },
    {
      "epoch": 0.6233286226763779,
      "grad_norm": 0.8198056817054749,
      "learning_rate": 7.535328647003406e-05,
      "loss": 0.0253,
      "step": 8601
    },
    {
      "epoch": 0.6234010943218465,
      "grad_norm": 0.7563139200210571,
      "learning_rate": 7.533879266613523e-05,
      "loss": 0.0427,
      "step": 8602
    },
    {
      "epoch": 0.6234735659673153,
      "grad_norm": 1.0317984819412231,
      "learning_rate": 7.53242988622364e-05,
      "loss": 0.0413,
      "step": 8603
    },
    {
      "epoch": 0.623546037612784,
      "grad_norm": 0.4523499310016632,
      "learning_rate": 7.530980505833757e-05,
      "loss": 0.0231,
      "step": 8604
    },
    {
      "epoch": 0.6236185092582527,
      "grad_norm": 2.8621768951416016,
      "learning_rate": 7.529531125443873e-05,
      "loss": 0.0787,
      "step": 8605
    },
    {
      "epoch": 0.6236909809037214,
      "grad_norm": 1.0076130628585815,
      "learning_rate": 7.52808174505399e-05,
      "loss": 0.0325,
      "step": 8606
    },
    {
      "epoch": 0.6237634525491901,
      "grad_norm": 0.825942873954773,
      "learning_rate": 7.526632364664107e-05,
      "loss": 0.0209,
      "step": 8607
    },
    {
      "epoch": 0.6238359241946588,
      "grad_norm": 0.5897327065467834,
      "learning_rate": 7.525182984274223e-05,
      "loss": 0.0148,
      "step": 8608
    },
    {
      "epoch": 0.6239083958401276,
      "grad_norm": 1.3614550828933716,
      "learning_rate": 7.52373360388434e-05,
      "loss": 0.0889,
      "step": 8609
    },
    {
      "epoch": 0.6239808674855962,
      "grad_norm": 1.4724102020263672,
      "learning_rate": 7.522284223494457e-05,
      "loss": 0.0336,
      "step": 8610
    },
    {
      "epoch": 0.624053339131065,
      "grad_norm": 1.5141422748565674,
      "learning_rate": 7.520834843104572e-05,
      "loss": 0.0498,
      "step": 8611
    },
    {
      "epoch": 0.6241258107765337,
      "grad_norm": 1.968075156211853,
      "learning_rate": 7.51938546271469e-05,
      "loss": 0.083,
      "step": 8612
    },
    {
      "epoch": 0.6241982824220024,
      "grad_norm": 0.5121903419494629,
      "learning_rate": 7.517936082324806e-05,
      "loss": 0.008,
      "step": 8613
    },
    {
      "epoch": 0.6242707540674711,
      "grad_norm": 2.4172732830047607,
      "learning_rate": 7.516486701934923e-05,
      "loss": 0.0694,
      "step": 8614
    },
    {
      "epoch": 0.6243432257129398,
      "grad_norm": 0.13072195649147034,
      "learning_rate": 7.51503732154504e-05,
      "loss": 0.0029,
      "step": 8615
    },
    {
      "epoch": 0.6244156973584085,
      "grad_norm": 21.073925018310547,
      "learning_rate": 7.513587941155157e-05,
      "loss": 0.0876,
      "step": 8616
    },
    {
      "epoch": 0.6244881690038773,
      "grad_norm": 0.7895890474319458,
      "learning_rate": 7.512138560765273e-05,
      "loss": 0.0219,
      "step": 8617
    },
    {
      "epoch": 0.6245606406493459,
      "grad_norm": 2.792715549468994,
      "learning_rate": 7.51068918037539e-05,
      "loss": 0.0907,
      "step": 8618
    },
    {
      "epoch": 0.6246331122948147,
      "grad_norm": 5.3263258934021,
      "learning_rate": 7.509239799985507e-05,
      "loss": 0.1071,
      "step": 8619
    },
    {
      "epoch": 0.6247055839402834,
      "grad_norm": 1.4373173713684082,
      "learning_rate": 7.507790419595623e-05,
      "loss": 0.0387,
      "step": 8620
    },
    {
      "epoch": 0.6247780555857521,
      "grad_norm": 2.4389655590057373,
      "learning_rate": 7.50634103920574e-05,
      "loss": 0.0681,
      "step": 8621
    },
    {
      "epoch": 0.6248505272312208,
      "grad_norm": 1.9826332330703735,
      "learning_rate": 7.504891658815857e-05,
      "loss": 0.0934,
      "step": 8622
    },
    {
      "epoch": 0.6249229988766895,
      "grad_norm": 0.44271203875541687,
      "learning_rate": 7.503442278425972e-05,
      "loss": 0.024,
      "step": 8623
    },
    {
      "epoch": 0.6249954705221582,
      "grad_norm": 3.008716106414795,
      "learning_rate": 7.501992898036089e-05,
      "loss": 0.1032,
      "step": 8624
    },
    {
      "epoch": 0.625067942167627,
      "grad_norm": 1.704533576965332,
      "learning_rate": 7.500543517646206e-05,
      "loss": 0.0359,
      "step": 8625
    },
    {
      "epoch": 0.6251404138130956,
      "grad_norm": 1.6453440189361572,
      "learning_rate": 7.499094137256323e-05,
      "loss": 0.0926,
      "step": 8626
    },
    {
      "epoch": 0.6252128854585643,
      "grad_norm": 1.370705485343933,
      "learning_rate": 7.49764475686644e-05,
      "loss": 0.0423,
      "step": 8627
    },
    {
      "epoch": 0.6252853571040331,
      "grad_norm": 2.1105809211730957,
      "learning_rate": 7.496195376476557e-05,
      "loss": 0.0443,
      "step": 8628
    },
    {
      "epoch": 0.6253578287495017,
      "grad_norm": 1.224814534187317,
      "learning_rate": 7.494745996086673e-05,
      "loss": 0.0407,
      "step": 8629
    },
    {
      "epoch": 0.6254303003949705,
      "grad_norm": 0.6555613875389099,
      "learning_rate": 7.49329661569679e-05,
      "loss": 0.0381,
      "step": 8630
    },
    {
      "epoch": 0.6255027720404391,
      "grad_norm": 0.6071052551269531,
      "learning_rate": 7.491847235306907e-05,
      "loss": 0.025,
      "step": 8631
    },
    {
      "epoch": 0.6255752436859079,
      "grad_norm": 0.7018803954124451,
      "learning_rate": 7.490397854917023e-05,
      "loss": 0.038,
      "step": 8632
    },
    {
      "epoch": 0.6256477153313766,
      "grad_norm": 1.5891751050949097,
      "learning_rate": 7.48894847452714e-05,
      "loss": 0.0432,
      "step": 8633
    },
    {
      "epoch": 0.6257201869768453,
      "grad_norm": 0.9220591187477112,
      "learning_rate": 7.487499094137257e-05,
      "loss": 0.023,
      "step": 8634
    },
    {
      "epoch": 0.625792658622314,
      "grad_norm": 1.1930043697357178,
      "learning_rate": 7.486049713747372e-05,
      "loss": 0.0524,
      "step": 8635
    },
    {
      "epoch": 0.6258651302677827,
      "grad_norm": 1.950818419456482,
      "learning_rate": 7.484600333357489e-05,
      "loss": 0.0776,
      "step": 8636
    },
    {
      "epoch": 0.6259376019132514,
      "grad_norm": 2.0404930114746094,
      "learning_rate": 7.483150952967606e-05,
      "loss": 0.1251,
      "step": 8637
    },
    {
      "epoch": 0.6260100735587202,
      "grad_norm": 0.8805641531944275,
      "learning_rate": 7.481701572577723e-05,
      "loss": 0.0267,
      "step": 8638
    },
    {
      "epoch": 0.6260825452041888,
      "grad_norm": 1.723205327987671,
      "learning_rate": 7.48025219218784e-05,
      "loss": 0.1045,
      "step": 8639
    },
    {
      "epoch": 0.6261550168496576,
      "grad_norm": 1.8506214618682861,
      "learning_rate": 7.478802811797957e-05,
      "loss": 0.0441,
      "step": 8640
    },
    {
      "epoch": 0.6262274884951263,
      "grad_norm": 2.124793767929077,
      "learning_rate": 7.477353431408073e-05,
      "loss": 0.0821,
      "step": 8641
    },
    {
      "epoch": 0.626299960140595,
      "grad_norm": 8.11623477935791,
      "learning_rate": 7.47590405101819e-05,
      "loss": 0.1042,
      "step": 8642
    },
    {
      "epoch": 0.6263724317860637,
      "grad_norm": 0.6109521985054016,
      "learning_rate": 7.474454670628307e-05,
      "loss": 0.0093,
      "step": 8643
    },
    {
      "epoch": 0.6264449034315324,
      "grad_norm": 0.7061315774917603,
      "learning_rate": 7.473005290238423e-05,
      "loss": 0.0153,
      "step": 8644
    },
    {
      "epoch": 0.6265173750770011,
      "grad_norm": 0.6065433025360107,
      "learning_rate": 7.47155590984854e-05,
      "loss": 0.0071,
      "step": 8645
    },
    {
      "epoch": 0.6265898467224699,
      "grad_norm": 0.8855465650558472,
      "learning_rate": 7.470106529458657e-05,
      "loss": 0.0449,
      "step": 8646
    },
    {
      "epoch": 0.6266623183679385,
      "grad_norm": 2.495722770690918,
      "learning_rate": 7.468657149068774e-05,
      "loss": 0.1981,
      "step": 8647
    },
    {
      "epoch": 0.6267347900134073,
      "grad_norm": 1.8080310821533203,
      "learning_rate": 7.467207768678889e-05,
      "loss": 0.0612,
      "step": 8648
    },
    {
      "epoch": 0.626807261658876,
      "grad_norm": 2.2735543251037598,
      "learning_rate": 7.465758388289008e-05,
      "loss": 0.0568,
      "step": 8649
    },
    {
      "epoch": 0.6268797333043447,
      "grad_norm": 2.8760013580322266,
      "learning_rate": 7.464309007899125e-05,
      "loss": 0.0616,
      "step": 8650
    },
    {
      "epoch": 0.6269522049498134,
      "grad_norm": 0.3370758295059204,
      "learning_rate": 7.46285962750924e-05,
      "loss": 0.0031,
      "step": 8651
    },
    {
      "epoch": 0.627024676595282,
      "grad_norm": 1.2808506488800049,
      "learning_rate": 7.461410247119357e-05,
      "loss": 0.0335,
      "step": 8652
    },
    {
      "epoch": 0.6270971482407508,
      "grad_norm": 0.6501632332801819,
      "learning_rate": 7.459960866729474e-05,
      "loss": 0.0369,
      "step": 8653
    },
    {
      "epoch": 0.6271696198862196,
      "grad_norm": 1.6928046941757202,
      "learning_rate": 7.45851148633959e-05,
      "loss": 0.0383,
      "step": 8654
    },
    {
      "epoch": 0.6272420915316882,
      "grad_norm": 0.8096922039985657,
      "learning_rate": 7.457062105949707e-05,
      "loss": 0.0292,
      "step": 8655
    },
    {
      "epoch": 0.627314563177157,
      "grad_norm": 0.9197596311569214,
      "learning_rate": 7.455612725559824e-05,
      "loss": 0.0301,
      "step": 8656
    },
    {
      "epoch": 0.6273870348226257,
      "grad_norm": 3.495081901550293,
      "learning_rate": 7.45416334516994e-05,
      "loss": 0.0577,
      "step": 8657
    },
    {
      "epoch": 0.6274595064680943,
      "grad_norm": 1.8264520168304443,
      "learning_rate": 7.452713964780057e-05,
      "loss": 0.0406,
      "step": 8658
    },
    {
      "epoch": 0.6275319781135631,
      "grad_norm": 0.4768219590187073,
      "learning_rate": 7.451264584390174e-05,
      "loss": 0.029,
      "step": 8659
    },
    {
      "epoch": 0.6276044497590317,
      "grad_norm": 2.277392625808716,
      "learning_rate": 7.44981520400029e-05,
      "loss": 0.1112,
      "step": 8660
    },
    {
      "epoch": 0.6276769214045005,
      "grad_norm": 1.4206736087799072,
      "learning_rate": 7.448365823610408e-05,
      "loss": 0.0349,
      "step": 8661
    },
    {
      "epoch": 0.6277493930499692,
      "grad_norm": 0.5788813829421997,
      "learning_rate": 7.446916443220525e-05,
      "loss": 0.0164,
      "step": 8662
    },
    {
      "epoch": 0.6278218646954379,
      "grad_norm": 0.4437607228755951,
      "learning_rate": 7.44546706283064e-05,
      "loss": 0.0182,
      "step": 8663
    },
    {
      "epoch": 0.6278943363409066,
      "grad_norm": 1.5078144073486328,
      "learning_rate": 7.444017682440757e-05,
      "loss": 0.0474,
      "step": 8664
    },
    {
      "epoch": 0.6279668079863754,
      "grad_norm": 1.6222881078720093,
      "learning_rate": 7.442568302050874e-05,
      "loss": 0.0205,
      "step": 8665
    },
    {
      "epoch": 0.628039279631844,
      "grad_norm": 1.2287242412567139,
      "learning_rate": 7.44111892166099e-05,
      "loss": 0.0257,
      "step": 8666
    },
    {
      "epoch": 0.6281117512773128,
      "grad_norm": 1.9327731132507324,
      "learning_rate": 7.439669541271107e-05,
      "loss": 0.1136,
      "step": 8667
    },
    {
      "epoch": 0.6281842229227814,
      "grad_norm": 2.2134604454040527,
      "learning_rate": 7.438220160881224e-05,
      "loss": 0.0688,
      "step": 8668
    },
    {
      "epoch": 0.6282566945682502,
      "grad_norm": 0.9590696096420288,
      "learning_rate": 7.43677078049134e-05,
      "loss": 0.0459,
      "step": 8669
    },
    {
      "epoch": 0.6283291662137189,
      "grad_norm": 2.4152750968933105,
      "learning_rate": 7.435321400101457e-05,
      "loss": 0.1002,
      "step": 8670
    },
    {
      "epoch": 0.6284016378591876,
      "grad_norm": 0.3171268701553345,
      "learning_rate": 7.433872019711574e-05,
      "loss": 0.0092,
      "step": 8671
    },
    {
      "epoch": 0.6284741095046563,
      "grad_norm": 0.7293108701705933,
      "learning_rate": 7.43242263932169e-05,
      "loss": 0.0185,
      "step": 8672
    },
    {
      "epoch": 0.628546581150125,
      "grad_norm": 0.04690448194742203,
      "learning_rate": 7.430973258931808e-05,
      "loss": 0.0005,
      "step": 8673
    },
    {
      "epoch": 0.6286190527955937,
      "grad_norm": 0.4624890089035034,
      "learning_rate": 7.429523878541925e-05,
      "loss": 0.0111,
      "step": 8674
    },
    {
      "epoch": 0.6286915244410625,
      "grad_norm": 0.5529585480690002,
      "learning_rate": 7.42807449815204e-05,
      "loss": 0.0141,
      "step": 8675
    },
    {
      "epoch": 0.6287639960865311,
      "grad_norm": 2.33732271194458,
      "learning_rate": 7.426625117762157e-05,
      "loss": 0.0807,
      "step": 8676
    },
    {
      "epoch": 0.6288364677319999,
      "grad_norm": 1.961612582206726,
      "learning_rate": 7.425175737372274e-05,
      "loss": 0.017,
      "step": 8677
    },
    {
      "epoch": 0.6289089393774686,
      "grad_norm": 1.9935380220413208,
      "learning_rate": 7.42372635698239e-05,
      "loss": 0.0453,
      "step": 8678
    },
    {
      "epoch": 0.6289814110229373,
      "grad_norm": 3.6541218757629395,
      "learning_rate": 7.422276976592507e-05,
      "loss": 0.0199,
      "step": 8679
    },
    {
      "epoch": 0.629053882668406,
      "grad_norm": 2.9688968658447266,
      "learning_rate": 7.420827596202624e-05,
      "loss": 0.0492,
      "step": 8680
    },
    {
      "epoch": 0.6291263543138746,
      "grad_norm": 0.7511793375015259,
      "learning_rate": 7.41937821581274e-05,
      "loss": 0.0272,
      "step": 8681
    },
    {
      "epoch": 0.6291988259593434,
      "grad_norm": 1.0734137296676636,
      "learning_rate": 7.417928835422857e-05,
      "loss": 0.0221,
      "step": 8682
    },
    {
      "epoch": 0.6292712976048122,
      "grad_norm": 2.9422085285186768,
      "learning_rate": 7.416479455032974e-05,
      "loss": 0.0766,
      "step": 8683
    },
    {
      "epoch": 0.6293437692502808,
      "grad_norm": 1.2650692462921143,
      "learning_rate": 7.41503007464309e-05,
      "loss": 0.0471,
      "step": 8684
    },
    {
      "epoch": 0.6294162408957495,
      "grad_norm": 1.6720186471939087,
      "learning_rate": 7.413580694253208e-05,
      "loss": 0.0397,
      "step": 8685
    },
    {
      "epoch": 0.6294887125412183,
      "grad_norm": 2.8934402465820312,
      "learning_rate": 7.412131313863325e-05,
      "loss": 0.0673,
      "step": 8686
    },
    {
      "epoch": 0.6295611841866869,
      "grad_norm": 0.3440230190753937,
      "learning_rate": 7.41068193347344e-05,
      "loss": 0.0081,
      "step": 8687
    },
    {
      "epoch": 0.6296336558321557,
      "grad_norm": 1.3935892581939697,
      "learning_rate": 7.409232553083557e-05,
      "loss": 0.0495,
      "step": 8688
    },
    {
      "epoch": 0.6297061274776243,
      "grad_norm": 0.7838525176048279,
      "learning_rate": 7.407783172693674e-05,
      "loss": 0.0129,
      "step": 8689
    },
    {
      "epoch": 0.6297785991230931,
      "grad_norm": 1.4553853273391724,
      "learning_rate": 7.40633379230379e-05,
      "loss": 0.0714,
      "step": 8690
    },
    {
      "epoch": 0.6298510707685618,
      "grad_norm": 2.0978472232818604,
      "learning_rate": 7.404884411913907e-05,
      "loss": 0.0492,
      "step": 8691
    },
    {
      "epoch": 0.6299235424140305,
      "grad_norm": 7.484043598175049,
      "learning_rate": 7.403435031524024e-05,
      "loss": 0.0894,
      "step": 8692
    },
    {
      "epoch": 0.6299960140594992,
      "grad_norm": 0.8175088763237,
      "learning_rate": 7.40198565113414e-05,
      "loss": 0.0286,
      "step": 8693
    },
    {
      "epoch": 0.630068485704968,
      "grad_norm": 0.6009973287582397,
      "learning_rate": 7.400536270744257e-05,
      "loss": 0.0114,
      "step": 8694
    },
    {
      "epoch": 0.6301409573504366,
      "grad_norm": 0.26471272110939026,
      "learning_rate": 7.399086890354374e-05,
      "loss": 0.009,
      "step": 8695
    },
    {
      "epoch": 0.6302134289959054,
      "grad_norm": 1.42259681224823,
      "learning_rate": 7.39763750996449e-05,
      "loss": 0.094,
      "step": 8696
    },
    {
      "epoch": 0.630285900641374,
      "grad_norm": 4.776512622833252,
      "learning_rate": 7.396188129574608e-05,
      "loss": 0.1321,
      "step": 8697
    },
    {
      "epoch": 0.6303583722868428,
      "grad_norm": 1.6039727926254272,
      "learning_rate": 7.394738749184725e-05,
      "loss": 0.0435,
      "step": 8698
    },
    {
      "epoch": 0.6304308439323115,
      "grad_norm": 1.3687735795974731,
      "learning_rate": 7.39328936879484e-05,
      "loss": 0.0483,
      "step": 8699
    },
    {
      "epoch": 0.6305033155777802,
      "grad_norm": 1.2280219793319702,
      "learning_rate": 7.391839988404957e-05,
      "loss": 0.0619,
      "step": 8700
    },
    {
      "epoch": 0.6305757872232489,
      "grad_norm": 0.7863322496414185,
      "learning_rate": 7.390390608015074e-05,
      "loss": 0.0243,
      "step": 8701
    },
    {
      "epoch": 0.6306482588687176,
      "grad_norm": 0.3681635856628418,
      "learning_rate": 7.38894122762519e-05,
      "loss": 0.0098,
      "step": 8702
    },
    {
      "epoch": 0.6307207305141863,
      "grad_norm": 0.07551006227731705,
      "learning_rate": 7.387491847235307e-05,
      "loss": 0.0026,
      "step": 8703
    },
    {
      "epoch": 0.6307932021596551,
      "grad_norm": 0.8578993678092957,
      "learning_rate": 7.386042466845424e-05,
      "loss": 0.0083,
      "step": 8704
    },
    {
      "epoch": 0.6308656738051237,
      "grad_norm": 0.9147275686264038,
      "learning_rate": 7.38459308645554e-05,
      "loss": 0.0483,
      "step": 8705
    },
    {
      "epoch": 0.6309381454505925,
      "grad_norm": 0.6164571642875671,
      "learning_rate": 7.383143706065658e-05,
      "loss": 0.0277,
      "step": 8706
    },
    {
      "epoch": 0.6310106170960612,
      "grad_norm": 0.8231967687606812,
      "learning_rate": 7.381694325675775e-05,
      "loss": 0.0383,
      "step": 8707
    },
    {
      "epoch": 0.6310830887415299,
      "grad_norm": 1.492484211921692,
      "learning_rate": 7.38024494528589e-05,
      "loss": 0.0595,
      "step": 8708
    },
    {
      "epoch": 0.6311555603869986,
      "grad_norm": 0.4407499134540558,
      "learning_rate": 7.378795564896008e-05,
      "loss": 0.0283,
      "step": 8709
    },
    {
      "epoch": 0.6312280320324672,
      "grad_norm": 3.908808708190918,
      "learning_rate": 7.377346184506125e-05,
      "loss": 0.0659,
      "step": 8710
    },
    {
      "epoch": 0.631300503677936,
      "grad_norm": 1.0975782871246338,
      "learning_rate": 7.37589680411624e-05,
      "loss": 0.0558,
      "step": 8711
    },
    {
      "epoch": 0.6313729753234048,
      "grad_norm": 2.3918540477752686,
      "learning_rate": 7.374447423726357e-05,
      "loss": 0.1594,
      "step": 8712
    },
    {
      "epoch": 0.6314454469688734,
      "grad_norm": 1.1772432327270508,
      "learning_rate": 7.372998043336474e-05,
      "loss": 0.0367,
      "step": 8713
    },
    {
      "epoch": 0.6315179186143421,
      "grad_norm": 1.0676311254501343,
      "learning_rate": 7.37154866294659e-05,
      "loss": 0.04,
      "step": 8714
    },
    {
      "epoch": 0.6315903902598109,
      "grad_norm": 2.2101686000823975,
      "learning_rate": 7.370099282556707e-05,
      "loss": 0.0204,
      "step": 8715
    },
    {
      "epoch": 0.6316628619052795,
      "grad_norm": 0.6525952219963074,
      "learning_rate": 7.368649902166824e-05,
      "loss": 0.0134,
      "step": 8716
    },
    {
      "epoch": 0.6317353335507483,
      "grad_norm": 2.021132469177246,
      "learning_rate": 7.367200521776941e-05,
      "loss": 0.1171,
      "step": 8717
    },
    {
      "epoch": 0.6318078051962169,
      "grad_norm": 1.3771828413009644,
      "learning_rate": 7.365751141387058e-05,
      "loss": 0.0628,
      "step": 8718
    },
    {
      "epoch": 0.6318802768416857,
      "grad_norm": 1.0339562892913818,
      "learning_rate": 7.364301760997175e-05,
      "loss": 0.0318,
      "step": 8719
    },
    {
      "epoch": 0.6319527484871544,
      "grad_norm": 0.20162339508533478,
      "learning_rate": 7.36285238060729e-05,
      "loss": 0.0022,
      "step": 8720
    },
    {
      "epoch": 0.6320252201326231,
      "grad_norm": 1.94401216506958,
      "learning_rate": 7.361403000217408e-05,
      "loss": 0.0596,
      "step": 8721
    },
    {
      "epoch": 0.6320976917780918,
      "grad_norm": 0.9334463477134705,
      "learning_rate": 7.359953619827525e-05,
      "loss": 0.0385,
      "step": 8722
    },
    {
      "epoch": 0.6321701634235606,
      "grad_norm": 0.8453020453453064,
      "learning_rate": 7.35850423943764e-05,
      "loss": 0.0519,
      "step": 8723
    },
    {
      "epoch": 0.6322426350690292,
      "grad_norm": 1.0024335384368896,
      "learning_rate": 7.357054859047757e-05,
      "loss": 0.0375,
      "step": 8724
    },
    {
      "epoch": 0.632315106714498,
      "grad_norm": 1.0323717594146729,
      "learning_rate": 7.355605478657874e-05,
      "loss": 0.0423,
      "step": 8725
    },
    {
      "epoch": 0.6323875783599666,
      "grad_norm": 4.342995643615723,
      "learning_rate": 7.35415609826799e-05,
      "loss": 0.1024,
      "step": 8726
    },
    {
      "epoch": 0.6324600500054354,
      "grad_norm": 2.4839088916778564,
      "learning_rate": 7.352706717878107e-05,
      "loss": 0.0338,
      "step": 8727
    },
    {
      "epoch": 0.6325325216509041,
      "grad_norm": 0.7977150678634644,
      "learning_rate": 7.351257337488224e-05,
      "loss": 0.0396,
      "step": 8728
    },
    {
      "epoch": 0.6326049932963728,
      "grad_norm": 2.9782307147979736,
      "learning_rate": 7.349807957098341e-05,
      "loss": 0.0301,
      "step": 8729
    },
    {
      "epoch": 0.6326774649418415,
      "grad_norm": 1.6433912515640259,
      "learning_rate": 7.348358576708458e-05,
      "loss": 0.0815,
      "step": 8730
    },
    {
      "epoch": 0.6327499365873103,
      "grad_norm": 1.7363859415054321,
      "learning_rate": 7.346909196318575e-05,
      "loss": 0.0495,
      "step": 8731
    },
    {
      "epoch": 0.6328224082327789,
      "grad_norm": 1.3793314695358276,
      "learning_rate": 7.345459815928692e-05,
      "loss": 0.0619,
      "step": 8732
    },
    {
      "epoch": 0.6328948798782477,
      "grad_norm": 0.7958102226257324,
      "learning_rate": 7.344010435538807e-05,
      "loss": 0.0361,
      "step": 8733
    },
    {
      "epoch": 0.6329673515237163,
      "grad_norm": 0.8415050506591797,
      "learning_rate": 7.342561055148924e-05,
      "loss": 0.0276,
      "step": 8734
    },
    {
      "epoch": 0.6330398231691851,
      "grad_norm": 3.192265272140503,
      "learning_rate": 7.341111674759041e-05,
      "loss": 0.0717,
      "step": 8735
    },
    {
      "epoch": 0.6331122948146538,
      "grad_norm": 0.0069185965694487095,
      "learning_rate": 7.339662294369157e-05,
      "loss": 0.0001,
      "step": 8736
    },
    {
      "epoch": 0.6331847664601225,
      "grad_norm": 4.895935535430908,
      "learning_rate": 7.338212913979274e-05,
      "loss": 0.0853,
      "step": 8737
    },
    {
      "epoch": 0.6332572381055912,
      "grad_norm": 2.4310808181762695,
      "learning_rate": 7.336763533589391e-05,
      "loss": 0.0543,
      "step": 8738
    },
    {
      "epoch": 0.6333297097510598,
      "grad_norm": 0.32510143518447876,
      "learning_rate": 7.335314153199507e-05,
      "loss": 0.0061,
      "step": 8739
    },
    {
      "epoch": 0.6334021813965286,
      "grad_norm": 1.496756672859192,
      "learning_rate": 7.333864772809624e-05,
      "loss": 0.0568,
      "step": 8740
    },
    {
      "epoch": 0.6334746530419973,
      "grad_norm": 1.3164688348770142,
      "learning_rate": 7.332415392419741e-05,
      "loss": 0.035,
      "step": 8741
    },
    {
      "epoch": 0.633547124687466,
      "grad_norm": 1.5790890455245972,
      "learning_rate": 7.330966012029858e-05,
      "loss": 0.04,
      "step": 8742
    },
    {
      "epoch": 0.6336195963329347,
      "grad_norm": 2.4043068885803223,
      "learning_rate": 7.329516631639975e-05,
      "loss": 0.0389,
      "step": 8743
    },
    {
      "epoch": 0.6336920679784035,
      "grad_norm": 0.5159025192260742,
      "learning_rate": 7.328067251250092e-05,
      "loss": 0.0102,
      "step": 8744
    },
    {
      "epoch": 0.6337645396238721,
      "grad_norm": 0.832311749458313,
      "learning_rate": 7.326617870860207e-05,
      "loss": 0.031,
      "step": 8745
    },
    {
      "epoch": 0.6338370112693409,
      "grad_norm": 3.745809555053711,
      "learning_rate": 7.325168490470324e-05,
      "loss": 0.0453,
      "step": 8746
    },
    {
      "epoch": 0.6339094829148095,
      "grad_norm": 0.6935720443725586,
      "learning_rate": 7.323719110080441e-05,
      "loss": 0.0424,
      "step": 8747
    },
    {
      "epoch": 0.6339819545602783,
      "grad_norm": 1.9176541566848755,
      "learning_rate": 7.322269729690557e-05,
      "loss": 0.0968,
      "step": 8748
    },
    {
      "epoch": 0.634054426205747,
      "grad_norm": 7.6524224281311035,
      "learning_rate": 7.320820349300674e-05,
      "loss": 0.0421,
      "step": 8749
    },
    {
      "epoch": 0.6341268978512157,
      "grad_norm": 3.3640944957733154,
      "learning_rate": 7.319370968910791e-05,
      "loss": 0.2125,
      "step": 8750
    },
    {
      "epoch": 0.6341993694966844,
      "grad_norm": 5.35515832901001,
      "learning_rate": 7.317921588520907e-05,
      "loss": 0.1257,
      "step": 8751
    },
    {
      "epoch": 0.6342718411421532,
      "grad_norm": 0.6308778524398804,
      "learning_rate": 7.316472208131024e-05,
      "loss": 0.0337,
      "step": 8752
    },
    {
      "epoch": 0.6343443127876218,
      "grad_norm": 1.2697954177856445,
      "learning_rate": 7.315022827741141e-05,
      "loss": 0.0282,
      "step": 8753
    },
    {
      "epoch": 0.6344167844330906,
      "grad_norm": 0.6608088612556458,
      "learning_rate": 7.313573447351258e-05,
      "loss": 0.0329,
      "step": 8754
    },
    {
      "epoch": 0.6344892560785592,
      "grad_norm": 0.9218531847000122,
      "learning_rate": 7.312124066961375e-05,
      "loss": 0.0149,
      "step": 8755
    },
    {
      "epoch": 0.634561727724028,
      "grad_norm": 2.844383716583252,
      "learning_rate": 7.310674686571492e-05,
      "loss": 0.1714,
      "step": 8756
    },
    {
      "epoch": 0.6346341993694967,
      "grad_norm": 2.218817949295044,
      "learning_rate": 7.309225306181607e-05,
      "loss": 0.0599,
      "step": 8757
    },
    {
      "epoch": 0.6347066710149654,
      "grad_norm": 1.4190419912338257,
      "learning_rate": 7.307775925791724e-05,
      "loss": 0.0685,
      "step": 8758
    },
    {
      "epoch": 0.6347791426604341,
      "grad_norm": 1.6300767660140991,
      "learning_rate": 7.306326545401841e-05,
      "loss": 0.0231,
      "step": 8759
    },
    {
      "epoch": 0.6348516143059029,
      "grad_norm": 2.1625781059265137,
      "learning_rate": 7.304877165011957e-05,
      "loss": 0.0603,
      "step": 8760
    },
    {
      "epoch": 0.6349240859513715,
      "grad_norm": 1.974825143814087,
      "learning_rate": 7.303427784622074e-05,
      "loss": 0.0908,
      "step": 8761
    },
    {
      "epoch": 0.6349965575968403,
      "grad_norm": 1.134755253791809,
      "learning_rate": 7.301978404232191e-05,
      "loss": 0.0409,
      "step": 8762
    },
    {
      "epoch": 0.6350690292423089,
      "grad_norm": 2.4515655040740967,
      "learning_rate": 7.300529023842307e-05,
      "loss": 0.0753,
      "step": 8763
    },
    {
      "epoch": 0.6351415008877777,
      "grad_norm": 1.4735859632492065,
      "learning_rate": 7.299079643452425e-05,
      "loss": 0.0258,
      "step": 8764
    },
    {
      "epoch": 0.6352139725332464,
      "grad_norm": 1.2648288011550903,
      "learning_rate": 7.297630263062542e-05,
      "loss": 0.0467,
      "step": 8765
    },
    {
      "epoch": 0.635286444178715,
      "grad_norm": 1.6257027387619019,
      "learning_rate": 7.296180882672658e-05,
      "loss": 0.0626,
      "step": 8766
    },
    {
      "epoch": 0.6353589158241838,
      "grad_norm": 0.6367665529251099,
      "learning_rate": 7.294731502282775e-05,
      "loss": 0.0135,
      "step": 8767
    },
    {
      "epoch": 0.6354313874696526,
      "grad_norm": 1.5315653085708618,
      "learning_rate": 7.293282121892892e-05,
      "loss": 0.0513,
      "step": 8768
    },
    {
      "epoch": 0.6355038591151212,
      "grad_norm": 2.9846198558807373,
      "learning_rate": 7.291832741503007e-05,
      "loss": 0.1321,
      "step": 8769
    },
    {
      "epoch": 0.63557633076059,
      "grad_norm": 1.1265634298324585,
      "learning_rate": 7.290383361113124e-05,
      "loss": 0.0435,
      "step": 8770
    },
    {
      "epoch": 0.6356488024060586,
      "grad_norm": 2.915323257446289,
      "learning_rate": 7.288933980723241e-05,
      "loss": 0.0914,
      "step": 8771
    },
    {
      "epoch": 0.6357212740515273,
      "grad_norm": 0.7190527319908142,
      "learning_rate": 7.287484600333357e-05,
      "loss": 0.0193,
      "step": 8772
    },
    {
      "epoch": 0.6357937456969961,
      "grad_norm": 4.01520299911499,
      "learning_rate": 7.286035219943474e-05,
      "loss": 0.0837,
      "step": 8773
    },
    {
      "epoch": 0.6358662173424647,
      "grad_norm": 0.984358012676239,
      "learning_rate": 7.284585839553591e-05,
      "loss": 0.0311,
      "step": 8774
    },
    {
      "epoch": 0.6359386889879335,
      "grad_norm": 4.295718193054199,
      "learning_rate": 7.283136459163708e-05,
      "loss": 0.0652,
      "step": 8775
    },
    {
      "epoch": 0.6360111606334021,
      "grad_norm": 0.7388430833816528,
      "learning_rate": 7.281687078773825e-05,
      "loss": 0.0416,
      "step": 8776
    },
    {
      "epoch": 0.6360836322788709,
      "grad_norm": 1.4025628566741943,
      "learning_rate": 7.280237698383942e-05,
      "loss": 0.0158,
      "step": 8777
    },
    {
      "epoch": 0.6361561039243396,
      "grad_norm": 2.165172576904297,
      "learning_rate": 7.278788317994058e-05,
      "loss": 0.1095,
      "step": 8778
    },
    {
      "epoch": 0.6362285755698083,
      "grad_norm": 1.9729063510894775,
      "learning_rate": 7.277338937604175e-05,
      "loss": 0.0828,
      "step": 8779
    },
    {
      "epoch": 0.636301047215277,
      "grad_norm": 0.6495842337608337,
      "learning_rate": 7.275889557214292e-05,
      "loss": 0.0236,
      "step": 8780
    },
    {
      "epoch": 0.6363735188607458,
      "grad_norm": 0.6231552362442017,
      "learning_rate": 7.274440176824407e-05,
      "loss": 0.0408,
      "step": 8781
    },
    {
      "epoch": 0.6364459905062144,
      "grad_norm": 0.01576441340148449,
      "learning_rate": 7.272990796434524e-05,
      "loss": 0.0003,
      "step": 8782
    },
    {
      "epoch": 0.6365184621516832,
      "grad_norm": 3.824885368347168,
      "learning_rate": 7.271541416044641e-05,
      "loss": 0.1038,
      "step": 8783
    },
    {
      "epoch": 0.6365909337971518,
      "grad_norm": 5.975714683532715,
      "learning_rate": 7.270092035654757e-05,
      "loss": 0.1786,
      "step": 8784
    },
    {
      "epoch": 0.6366634054426206,
      "grad_norm": 2.083096742630005,
      "learning_rate": 7.268642655264874e-05,
      "loss": 0.0835,
      "step": 8785
    },
    {
      "epoch": 0.6367358770880893,
      "grad_norm": 1.4588406085968018,
      "learning_rate": 7.267193274874991e-05,
      "loss": 0.0566,
      "step": 8786
    },
    {
      "epoch": 0.636808348733558,
      "grad_norm": 2.3614706993103027,
      "learning_rate": 7.265743894485108e-05,
      "loss": 0.1217,
      "step": 8787
    },
    {
      "epoch": 0.6368808203790267,
      "grad_norm": 0.13671942055225372,
      "learning_rate": 7.264294514095225e-05,
      "loss": 0.0021,
      "step": 8788
    },
    {
      "epoch": 0.6369532920244955,
      "grad_norm": 4.496955394744873,
      "learning_rate": 7.262845133705342e-05,
      "loss": 0.1657,
      "step": 8789
    },
    {
      "epoch": 0.6370257636699641,
      "grad_norm": 3.4738357067108154,
      "learning_rate": 7.261395753315458e-05,
      "loss": 0.0842,
      "step": 8790
    },
    {
      "epoch": 0.6370982353154329,
      "grad_norm": 0.963463306427002,
      "learning_rate": 7.259946372925575e-05,
      "loss": 0.0432,
      "step": 8791
    },
    {
      "epoch": 0.6371707069609015,
      "grad_norm": 0.3001939654350281,
      "learning_rate": 7.258496992535692e-05,
      "loss": 0.0067,
      "step": 8792
    },
    {
      "epoch": 0.6372431786063703,
      "grad_norm": 2.1970701217651367,
      "learning_rate": 7.257047612145807e-05,
      "loss": 0.0628,
      "step": 8793
    },
    {
      "epoch": 0.637315650251839,
      "grad_norm": 0.04281292110681534,
      "learning_rate": 7.255598231755924e-05,
      "loss": 0.0008,
      "step": 8794
    },
    {
      "epoch": 0.6373881218973076,
      "grad_norm": 2.133960723876953,
      "learning_rate": 7.254148851366041e-05,
      "loss": 0.1546,
      "step": 8795
    },
    {
      "epoch": 0.6374605935427764,
      "grad_norm": 2.2706973552703857,
      "learning_rate": 7.252699470976157e-05,
      "loss": 0.0593,
      "step": 8796
    },
    {
      "epoch": 0.6375330651882452,
      "grad_norm": 0.9153186678886414,
      "learning_rate": 7.251250090586274e-05,
      "loss": 0.0409,
      "step": 8797
    },
    {
      "epoch": 0.6376055368337138,
      "grad_norm": 1.279096245765686,
      "learning_rate": 7.249800710196391e-05,
      "loss": 0.0771,
      "step": 8798
    },
    {
      "epoch": 0.6376780084791825,
      "grad_norm": 0.253528356552124,
      "learning_rate": 7.248351329806508e-05,
      "loss": 0.0049,
      "step": 8799
    },
    {
      "epoch": 0.6377504801246512,
      "grad_norm": 1.1536071300506592,
      "learning_rate": 7.246901949416625e-05,
      "loss": 0.0465,
      "step": 8800
    },
    {
      "epoch": 0.6378229517701199,
      "grad_norm": 0.8167569041252136,
      "learning_rate": 7.245452569026742e-05,
      "loss": 0.0271,
      "step": 8801
    },
    {
      "epoch": 0.6378954234155887,
      "grad_norm": 1.8317757844924927,
      "learning_rate": 7.244003188636858e-05,
      "loss": 0.0498,
      "step": 8802
    },
    {
      "epoch": 0.6379678950610573,
      "grad_norm": 0.634299635887146,
      "learning_rate": 7.242553808246975e-05,
      "loss": 0.0222,
      "step": 8803
    },
    {
      "epoch": 0.6380403667065261,
      "grad_norm": 0.569206178188324,
      "learning_rate": 7.241104427857092e-05,
      "loss": 0.0557,
      "step": 8804
    },
    {
      "epoch": 0.6381128383519947,
      "grad_norm": 2.154416561126709,
      "learning_rate": 7.239655047467207e-05,
      "loss": 0.0845,
      "step": 8805
    },
    {
      "epoch": 0.6381853099974635,
      "grad_norm": 3.016047477722168,
      "learning_rate": 7.238205667077324e-05,
      "loss": 0.0617,
      "step": 8806
    },
    {
      "epoch": 0.6382577816429322,
      "grad_norm": 0.253617525100708,
      "learning_rate": 7.236756286687441e-05,
      "loss": 0.006,
      "step": 8807
    },
    {
      "epoch": 0.6383302532884009,
      "grad_norm": 0.9990046620368958,
      "learning_rate": 7.235306906297557e-05,
      "loss": 0.0573,
      "step": 8808
    },
    {
      "epoch": 0.6384027249338696,
      "grad_norm": 1.104477047920227,
      "learning_rate": 7.233857525907674e-05,
      "loss": 0.035,
      "step": 8809
    },
    {
      "epoch": 0.6384751965793384,
      "grad_norm": 1.4549275636672974,
      "learning_rate": 7.232408145517791e-05,
      "loss": 0.0656,
      "step": 8810
    },
    {
      "epoch": 0.638547668224807,
      "grad_norm": 1.3651195764541626,
      "learning_rate": 7.23095876512791e-05,
      "loss": 0.0455,
      "step": 8811
    },
    {
      "epoch": 0.6386201398702758,
      "grad_norm": 2.413114309310913,
      "learning_rate": 7.229509384738025e-05,
      "loss": 0.1133,
      "step": 8812
    },
    {
      "epoch": 0.6386926115157444,
      "grad_norm": 1.7278610467910767,
      "learning_rate": 7.228060004348142e-05,
      "loss": 0.0498,
      "step": 8813
    },
    {
      "epoch": 0.6387650831612132,
      "grad_norm": 1.4681681394577026,
      "learning_rate": 7.226610623958259e-05,
      "loss": 0.0645,
      "step": 8814
    },
    {
      "epoch": 0.6388375548066819,
      "grad_norm": 0.35203173756599426,
      "learning_rate": 7.225161243568375e-05,
      "loss": 0.0082,
      "step": 8815
    },
    {
      "epoch": 0.6389100264521506,
      "grad_norm": 1.5942249298095703,
      "learning_rate": 7.223711863178492e-05,
      "loss": 0.0921,
      "step": 8816
    },
    {
      "epoch": 0.6389824980976193,
      "grad_norm": 2.310884952545166,
      "learning_rate": 7.222262482788609e-05,
      "loss": 0.0908,
      "step": 8817
    },
    {
      "epoch": 0.6390549697430881,
      "grad_norm": 0.41030600666999817,
      "learning_rate": 7.220813102398724e-05,
      "loss": 0.0197,
      "step": 8818
    },
    {
      "epoch": 0.6391274413885567,
      "grad_norm": 0.33629801869392395,
      "learning_rate": 7.219363722008841e-05,
      "loss": 0.0055,
      "step": 8819
    },
    {
      "epoch": 0.6391999130340255,
      "grad_norm": 1.7774525880813599,
      "learning_rate": 7.217914341618958e-05,
      "loss": 0.0505,
      "step": 8820
    },
    {
      "epoch": 0.6392723846794941,
      "grad_norm": 1.2735742330551147,
      "learning_rate": 7.216464961229074e-05,
      "loss": 0.0719,
      "step": 8821
    },
    {
      "epoch": 0.6393448563249629,
      "grad_norm": 1.0859346389770508,
      "learning_rate": 7.215015580839192e-05,
      "loss": 0.0828,
      "step": 8822
    },
    {
      "epoch": 0.6394173279704316,
      "grad_norm": 1.53341543674469,
      "learning_rate": 7.21356620044931e-05,
      "loss": 0.0758,
      "step": 8823
    },
    {
      "epoch": 0.6394897996159002,
      "grad_norm": 0.8716740012168884,
      "learning_rate": 7.212116820059425e-05,
      "loss": 0.0562,
      "step": 8824
    },
    {
      "epoch": 0.639562271261369,
      "grad_norm": 0.42247259616851807,
      "learning_rate": 7.210667439669542e-05,
      "loss": 0.0283,
      "step": 8825
    },
    {
      "epoch": 0.6396347429068377,
      "grad_norm": 1.5558834075927734,
      "learning_rate": 7.209218059279659e-05,
      "loss": 0.103,
      "step": 8826
    },
    {
      "epoch": 0.6397072145523064,
      "grad_norm": 1.1131125688552856,
      "learning_rate": 7.207768678889775e-05,
      "loss": 0.061,
      "step": 8827
    },
    {
      "epoch": 0.6397796861977751,
      "grad_norm": 2.130453109741211,
      "learning_rate": 7.206319298499892e-05,
      "loss": 0.0938,
      "step": 8828
    },
    {
      "epoch": 0.6398521578432438,
      "grad_norm": 0.4938526153564453,
      "learning_rate": 7.204869918110009e-05,
      "loss": 0.0055,
      "step": 8829
    },
    {
      "epoch": 0.6399246294887125,
      "grad_norm": 0.818317174911499,
      "learning_rate": 7.203420537720124e-05,
      "loss": 0.034,
      "step": 8830
    },
    {
      "epoch": 0.6399971011341813,
      "grad_norm": 1.3469840288162231,
      "learning_rate": 7.201971157330241e-05,
      "loss": 0.0869,
      "step": 8831
    },
    {
      "epoch": 0.6400695727796499,
      "grad_norm": 1.3601192235946655,
      "learning_rate": 7.200521776940358e-05,
      "loss": 0.0728,
      "step": 8832
    },
    {
      "epoch": 0.6401420444251187,
      "grad_norm": 0.03670617938041687,
      "learning_rate": 7.199072396550475e-05,
      "loss": 0.0011,
      "step": 8833
    },
    {
      "epoch": 0.6402145160705874,
      "grad_norm": 2.593088388442993,
      "learning_rate": 7.197623016160592e-05,
      "loss": 0.092,
      "step": 8834
    },
    {
      "epoch": 0.6402869877160561,
      "grad_norm": 1.1869360208511353,
      "learning_rate": 7.19617363577071e-05,
      "loss": 0.0298,
      "step": 8835
    },
    {
      "epoch": 0.6403594593615248,
      "grad_norm": 0.958001971244812,
      "learning_rate": 7.194724255380825e-05,
      "loss": 0.0433,
      "step": 8836
    },
    {
      "epoch": 0.6404319310069935,
      "grad_norm": 0.3086435794830322,
      "learning_rate": 7.193274874990942e-05,
      "loss": 0.0062,
      "step": 8837
    },
    {
      "epoch": 0.6405044026524622,
      "grad_norm": 0.5873464345932007,
      "learning_rate": 7.191825494601059e-05,
      "loss": 0.0065,
      "step": 8838
    },
    {
      "epoch": 0.640576874297931,
      "grad_norm": 0.6758513450622559,
      "learning_rate": 7.190376114211175e-05,
      "loss": 0.0378,
      "step": 8839
    },
    {
      "epoch": 0.6406493459433996,
      "grad_norm": 1.3298778533935547,
      "learning_rate": 7.188926733821292e-05,
      "loss": 0.0576,
      "step": 8840
    },
    {
      "epoch": 0.6407218175888684,
      "grad_norm": 0.5295823216438293,
      "learning_rate": 7.187477353431409e-05,
      "loss": 0.0464,
      "step": 8841
    },
    {
      "epoch": 0.640794289234337,
      "grad_norm": 1.1694068908691406,
      "learning_rate": 7.186027973041524e-05,
      "loss": 0.0249,
      "step": 8842
    },
    {
      "epoch": 0.6408667608798058,
      "grad_norm": 0.8069843053817749,
      "learning_rate": 7.184578592651641e-05,
      "loss": 0.0944,
      "step": 8843
    },
    {
      "epoch": 0.6409392325252745,
      "grad_norm": 1.036637544631958,
      "learning_rate": 7.183129212261758e-05,
      "loss": 0.0403,
      "step": 8844
    },
    {
      "epoch": 0.6410117041707432,
      "grad_norm": 0.8590859174728394,
      "learning_rate": 7.181679831871875e-05,
      "loss": 0.0569,
      "step": 8845
    },
    {
      "epoch": 0.6410841758162119,
      "grad_norm": 2.9327268600463867,
      "learning_rate": 7.180230451481992e-05,
      "loss": 0.0426,
      "step": 8846
    },
    {
      "epoch": 0.6411566474616807,
      "grad_norm": 0.865814745426178,
      "learning_rate": 7.17878107109211e-05,
      "loss": 0.0219,
      "step": 8847
    },
    {
      "epoch": 0.6412291191071493,
      "grad_norm": 3.3029189109802246,
      "learning_rate": 7.177331690702225e-05,
      "loss": 0.0934,
      "step": 8848
    },
    {
      "epoch": 0.6413015907526181,
      "grad_norm": 0.3427758812904358,
      "learning_rate": 7.175882310312342e-05,
      "loss": 0.0106,
      "step": 8849
    },
    {
      "epoch": 0.6413740623980867,
      "grad_norm": 0.4786706864833832,
      "learning_rate": 7.174432929922459e-05,
      "loss": 0.0196,
      "step": 8850
    },
    {
      "epoch": 0.6414465340435554,
      "grad_norm": 0.6932528614997864,
      "learning_rate": 7.172983549532575e-05,
      "loss": 0.0597,
      "step": 8851
    },
    {
      "epoch": 0.6415190056890242,
      "grad_norm": 1.4711017608642578,
      "learning_rate": 7.171534169142692e-05,
      "loss": 0.0427,
      "step": 8852
    },
    {
      "epoch": 0.6415914773344928,
      "grad_norm": 1.9815760850906372,
      "learning_rate": 7.170084788752809e-05,
      "loss": 0.1055,
      "step": 8853
    },
    {
      "epoch": 0.6416639489799616,
      "grad_norm": 0.5471175909042358,
      "learning_rate": 7.168635408362924e-05,
      "loss": 0.0118,
      "step": 8854
    },
    {
      "epoch": 0.6417364206254303,
      "grad_norm": 1.7815691232681274,
      "learning_rate": 7.167186027973041e-05,
      "loss": 0.0764,
      "step": 8855
    },
    {
      "epoch": 0.641808892270899,
      "grad_norm": 0.6041998863220215,
      "learning_rate": 7.165736647583158e-05,
      "loss": 0.0301,
      "step": 8856
    },
    {
      "epoch": 0.6418813639163677,
      "grad_norm": 1.2998981475830078,
      "learning_rate": 7.164287267193275e-05,
      "loss": 0.0659,
      "step": 8857
    },
    {
      "epoch": 0.6419538355618364,
      "grad_norm": 1.4541599750518799,
      "learning_rate": 7.162837886803392e-05,
      "loss": 0.0817,
      "step": 8858
    },
    {
      "epoch": 0.6420263072073051,
      "grad_norm": 2.4178154468536377,
      "learning_rate": 7.161388506413509e-05,
      "loss": 0.0563,
      "step": 8859
    },
    {
      "epoch": 0.6420987788527739,
      "grad_norm": 1.000775933265686,
      "learning_rate": 7.159939126023625e-05,
      "loss": 0.0177,
      "step": 8860
    },
    {
      "epoch": 0.6421712504982425,
      "grad_norm": 0.9980804324150085,
      "learning_rate": 7.158489745633742e-05,
      "loss": 0.0654,
      "step": 8861
    },
    {
      "epoch": 0.6422437221437113,
      "grad_norm": 0.7042743563652039,
      "learning_rate": 7.157040365243859e-05,
      "loss": 0.0207,
      "step": 8862
    },
    {
      "epoch": 0.64231619378918,
      "grad_norm": 1.8977612257003784,
      "learning_rate": 7.155590984853975e-05,
      "loss": 0.0983,
      "step": 8863
    },
    {
      "epoch": 0.6423886654346487,
      "grad_norm": 1.5700689554214478,
      "learning_rate": 7.154141604464092e-05,
      "loss": 0.0689,
      "step": 8864
    },
    {
      "epoch": 0.6424611370801174,
      "grad_norm": 1.279630184173584,
      "learning_rate": 7.152692224074209e-05,
      "loss": 0.0525,
      "step": 8865
    },
    {
      "epoch": 0.6425336087255861,
      "grad_norm": 2.2383487224578857,
      "learning_rate": 7.151242843684324e-05,
      "loss": 0.0763,
      "step": 8866
    },
    {
      "epoch": 0.6426060803710548,
      "grad_norm": 1.5124496221542358,
      "learning_rate": 7.149793463294441e-05,
      "loss": 0.0276,
      "step": 8867
    },
    {
      "epoch": 0.6426785520165236,
      "grad_norm": 1.2118616104125977,
      "learning_rate": 7.148344082904558e-05,
      "loss": 0.0348,
      "step": 8868
    },
    {
      "epoch": 0.6427510236619922,
      "grad_norm": 0.8378046154975891,
      "learning_rate": 7.146894702514675e-05,
      "loss": 0.0187,
      "step": 8869
    },
    {
      "epoch": 0.642823495307461,
      "grad_norm": 3.4962165355682373,
      "learning_rate": 7.145445322124792e-05,
      "loss": 0.0602,
      "step": 8870
    },
    {
      "epoch": 0.6428959669529297,
      "grad_norm": 0.47720637917518616,
      "learning_rate": 7.143995941734909e-05,
      "loss": 0.0112,
      "step": 8871
    },
    {
      "epoch": 0.6429684385983984,
      "grad_norm": 1.17954421043396,
      "learning_rate": 7.142546561345025e-05,
      "loss": 0.0892,
      "step": 8872
    },
    {
      "epoch": 0.6430409102438671,
      "grad_norm": 1.383090853691101,
      "learning_rate": 7.141097180955142e-05,
      "loss": 0.0194,
      "step": 8873
    },
    {
      "epoch": 0.6431133818893358,
      "grad_norm": 1.3268837928771973,
      "learning_rate": 7.139647800565259e-05,
      "loss": 0.0753,
      "step": 8874
    },
    {
      "epoch": 0.6431858535348045,
      "grad_norm": 0.30526483058929443,
      "learning_rate": 7.138198420175375e-05,
      "loss": 0.0171,
      "step": 8875
    },
    {
      "epoch": 0.6432583251802733,
      "grad_norm": 0.518419086933136,
      "learning_rate": 7.136749039785492e-05,
      "loss": 0.0125,
      "step": 8876
    },
    {
      "epoch": 0.6433307968257419,
      "grad_norm": 3.7734808921813965,
      "learning_rate": 7.135299659395609e-05,
      "loss": 0.0745,
      "step": 8877
    },
    {
      "epoch": 0.6434032684712107,
      "grad_norm": 3.403508424758911,
      "learning_rate": 7.133850279005724e-05,
      "loss": 0.1348,
      "step": 8878
    },
    {
      "epoch": 0.6434757401166793,
      "grad_norm": 1.1347771883010864,
      "learning_rate": 7.132400898615843e-05,
      "loss": 0.0272,
      "step": 8879
    },
    {
      "epoch": 0.643548211762148,
      "grad_norm": 1.572510004043579,
      "learning_rate": 7.13095151822596e-05,
      "loss": 0.0597,
      "step": 8880
    },
    {
      "epoch": 0.6436206834076168,
      "grad_norm": 2.2481839656829834,
      "learning_rate": 7.129502137836075e-05,
      "loss": 0.0738,
      "step": 8881
    },
    {
      "epoch": 0.6436931550530854,
      "grad_norm": 0.581820547580719,
      "learning_rate": 7.128052757446192e-05,
      "loss": 0.0243,
      "step": 8882
    },
    {
      "epoch": 0.6437656266985542,
      "grad_norm": 1.3235265016555786,
      "learning_rate": 7.126603377056309e-05,
      "loss": 0.0474,
      "step": 8883
    },
    {
      "epoch": 0.643838098344023,
      "grad_norm": 2.565704822540283,
      "learning_rate": 7.125153996666425e-05,
      "loss": 0.0664,
      "step": 8884
    },
    {
      "epoch": 0.6439105699894916,
      "grad_norm": 3.6252522468566895,
      "learning_rate": 7.123704616276542e-05,
      "loss": 0.0956,
      "step": 8885
    },
    {
      "epoch": 0.6439830416349603,
      "grad_norm": 0.9888908863067627,
      "learning_rate": 7.122255235886659e-05,
      "loss": 0.0352,
      "step": 8886
    },
    {
      "epoch": 0.644055513280429,
      "grad_norm": 1.3588027954101562,
      "learning_rate": 7.120805855496775e-05,
      "loss": 0.0548,
      "step": 8887
    },
    {
      "epoch": 0.6441279849258977,
      "grad_norm": 2.962332248687744,
      "learning_rate": 7.119356475106892e-05,
      "loss": 0.0742,
      "step": 8888
    },
    {
      "epoch": 0.6442004565713665,
      "grad_norm": 0.7380894422531128,
      "learning_rate": 7.117907094717009e-05,
      "loss": 0.0247,
      "step": 8889
    },
    {
      "epoch": 0.6442729282168351,
      "grad_norm": 0.6652267575263977,
      "learning_rate": 7.116457714327126e-05,
      "loss": 0.0308,
      "step": 8890
    },
    {
      "epoch": 0.6443453998623039,
      "grad_norm": 2.077845811843872,
      "learning_rate": 7.115008333937243e-05,
      "loss": 0.1287,
      "step": 8891
    },
    {
      "epoch": 0.6444178715077726,
      "grad_norm": 2.7147274017333984,
      "learning_rate": 7.11355895354736e-05,
      "loss": 0.0512,
      "step": 8892
    },
    {
      "epoch": 0.6444903431532413,
      "grad_norm": 1.9769949913024902,
      "learning_rate": 7.112109573157477e-05,
      "loss": 0.062,
      "step": 8893
    },
    {
      "epoch": 0.64456281479871,
      "grad_norm": 2.469242572784424,
      "learning_rate": 7.110660192767592e-05,
      "loss": 0.0193,
      "step": 8894
    },
    {
      "epoch": 0.6446352864441787,
      "grad_norm": 1.5006436109542847,
      "learning_rate": 7.109210812377709e-05,
      "loss": 0.0571,
      "step": 8895
    },
    {
      "epoch": 0.6447077580896474,
      "grad_norm": 3.0777766704559326,
      "learning_rate": 7.107761431987826e-05,
      "loss": 0.0474,
      "step": 8896
    },
    {
      "epoch": 0.6447802297351162,
      "grad_norm": 1.325810432434082,
      "learning_rate": 7.106312051597942e-05,
      "loss": 0.0707,
      "step": 8897
    },
    {
      "epoch": 0.6448527013805848,
      "grad_norm": 0.6103187799453735,
      "learning_rate": 7.104862671208059e-05,
      "loss": 0.0417,
      "step": 8898
    },
    {
      "epoch": 0.6449251730260536,
      "grad_norm": 0.5254618525505066,
      "learning_rate": 7.103413290818176e-05,
      "loss": 0.0203,
      "step": 8899
    },
    {
      "epoch": 0.6449976446715223,
      "grad_norm": 2.3967947959899902,
      "learning_rate": 7.101963910428292e-05,
      "loss": 0.0446,
      "step": 8900
    },
    {
      "epoch": 0.645070116316991,
      "grad_norm": 0.8302704095840454,
      "learning_rate": 7.100514530038409e-05,
      "loss": 0.0248,
      "step": 8901
    },
    {
      "epoch": 0.6451425879624597,
      "grad_norm": 1.4874602556228638,
      "learning_rate": 7.099065149648526e-05,
      "loss": 0.0611,
      "step": 8902
    },
    {
      "epoch": 0.6452150596079284,
      "grad_norm": 1.0390254259109497,
      "learning_rate": 7.097615769258643e-05,
      "loss": 0.0627,
      "step": 8903
    },
    {
      "epoch": 0.6452875312533971,
      "grad_norm": 1.414818525314331,
      "learning_rate": 7.09616638886876e-05,
      "loss": 0.0734,
      "step": 8904
    },
    {
      "epoch": 0.6453600028988659,
      "grad_norm": 2.698890209197998,
      "learning_rate": 7.094717008478877e-05,
      "loss": 0.1088,
      "step": 8905
    },
    {
      "epoch": 0.6454324745443345,
      "grad_norm": 3.6371841430664062,
      "learning_rate": 7.093267628088992e-05,
      "loss": 0.0731,
      "step": 8906
    },
    {
      "epoch": 0.6455049461898033,
      "grad_norm": 0.5165979266166687,
      "learning_rate": 7.091818247699109e-05,
      "loss": 0.0137,
      "step": 8907
    },
    {
      "epoch": 0.645577417835272,
      "grad_norm": 1.9486443996429443,
      "learning_rate": 7.090368867309226e-05,
      "loss": 0.0679,
      "step": 8908
    },
    {
      "epoch": 0.6456498894807406,
      "grad_norm": 8.599175453186035,
      "learning_rate": 7.088919486919342e-05,
      "loss": 0.0484,
      "step": 8909
    },
    {
      "epoch": 0.6457223611262094,
      "grad_norm": 2.532318353652954,
      "learning_rate": 7.087470106529459e-05,
      "loss": 0.1464,
      "step": 8910
    },
    {
      "epoch": 0.645794832771678,
      "grad_norm": 0.487419068813324,
      "learning_rate": 7.086020726139576e-05,
      "loss": 0.0183,
      "step": 8911
    },
    {
      "epoch": 0.6458673044171468,
      "grad_norm": 0.8656772971153259,
      "learning_rate": 7.084571345749692e-05,
      "loss": 0.0485,
      "step": 8912
    },
    {
      "epoch": 0.6459397760626155,
      "grad_norm": 8.936042785644531,
      "learning_rate": 7.083121965359809e-05,
      "loss": 0.1401,
      "step": 8913
    },
    {
      "epoch": 0.6460122477080842,
      "grad_norm": 2.875687837600708,
      "learning_rate": 7.081672584969926e-05,
      "loss": 0.1209,
      "step": 8914
    },
    {
      "epoch": 0.6460847193535529,
      "grad_norm": 1.6893298625946045,
      "learning_rate": 7.080223204580043e-05,
      "loss": 0.0494,
      "step": 8915
    },
    {
      "epoch": 0.6461571909990216,
      "grad_norm": 0.5323785543441772,
      "learning_rate": 7.07877382419016e-05,
      "loss": 0.0165,
      "step": 8916
    },
    {
      "epoch": 0.6462296626444903,
      "grad_norm": 1.39580500125885,
      "learning_rate": 7.077324443800277e-05,
      "loss": 0.0663,
      "step": 8917
    },
    {
      "epoch": 0.6463021342899591,
      "grad_norm": 2.0237672328948975,
      "learning_rate": 7.075875063410392e-05,
      "loss": 0.0878,
      "step": 8918
    },
    {
      "epoch": 0.6463746059354277,
      "grad_norm": 1.5932062864303589,
      "learning_rate": 7.074425683020509e-05,
      "loss": 0.057,
      "step": 8919
    },
    {
      "epoch": 0.6464470775808965,
      "grad_norm": 1.5086872577667236,
      "learning_rate": 7.072976302630626e-05,
      "loss": 0.056,
      "step": 8920
    },
    {
      "epoch": 0.6465195492263652,
      "grad_norm": 1.6112090349197388,
      "learning_rate": 7.071526922240742e-05,
      "loss": 0.0855,
      "step": 8921
    },
    {
      "epoch": 0.6465920208718339,
      "grad_norm": 0.30173856019973755,
      "learning_rate": 7.070077541850859e-05,
      "loss": 0.0052,
      "step": 8922
    },
    {
      "epoch": 0.6466644925173026,
      "grad_norm": 2.5014045238494873,
      "learning_rate": 7.068628161460976e-05,
      "loss": 0.0977,
      "step": 8923
    },
    {
      "epoch": 0.6467369641627713,
      "grad_norm": 0.9055681228637695,
      "learning_rate": 7.067178781071092e-05,
      "loss": 0.076,
      "step": 8924
    },
    {
      "epoch": 0.64680943580824,
      "grad_norm": 0.8345815539360046,
      "learning_rate": 7.065729400681209e-05,
      "loss": 0.0261,
      "step": 8925
    },
    {
      "epoch": 0.6468819074537088,
      "grad_norm": 0.627768874168396,
      "learning_rate": 7.064280020291326e-05,
      "loss": 0.0394,
      "step": 8926
    },
    {
      "epoch": 0.6469543790991774,
      "grad_norm": 2.871365785598755,
      "learning_rate": 7.062830639901443e-05,
      "loss": 0.0921,
      "step": 8927
    },
    {
      "epoch": 0.6470268507446462,
      "grad_norm": 1.186923623085022,
      "learning_rate": 7.06138125951156e-05,
      "loss": 0.0823,
      "step": 8928
    },
    {
      "epoch": 0.6470993223901149,
      "grad_norm": 0.7093499898910522,
      "learning_rate": 7.059931879121677e-05,
      "loss": 0.0131,
      "step": 8929
    },
    {
      "epoch": 0.6471717940355836,
      "grad_norm": 1.9515570402145386,
      "learning_rate": 7.058482498731792e-05,
      "loss": 0.0978,
      "step": 8930
    },
    {
      "epoch": 0.6472442656810523,
      "grad_norm": 1.0250964164733887,
      "learning_rate": 7.057033118341909e-05,
      "loss": 0.0772,
      "step": 8931
    },
    {
      "epoch": 0.647316737326521,
      "grad_norm": 2.758065700531006,
      "learning_rate": 7.055583737952026e-05,
      "loss": 0.1156,
      "step": 8932
    },
    {
      "epoch": 0.6473892089719897,
      "grad_norm": 0.4231809377670288,
      "learning_rate": 7.054134357562142e-05,
      "loss": 0.0281,
      "step": 8933
    },
    {
      "epoch": 0.6474616806174585,
      "grad_norm": 0.34418657422065735,
      "learning_rate": 7.052684977172259e-05,
      "loss": 0.0085,
      "step": 8934
    },
    {
      "epoch": 0.6475341522629271,
      "grad_norm": 1.5248384475708008,
      "learning_rate": 7.051235596782376e-05,
      "loss": 0.0169,
      "step": 8935
    },
    {
      "epoch": 0.6476066239083959,
      "grad_norm": 0.8537617325782776,
      "learning_rate": 7.049786216392491e-05,
      "loss": 0.0218,
      "step": 8936
    },
    {
      "epoch": 0.6476790955538646,
      "grad_norm": 1.2296816110610962,
      "learning_rate": 7.04833683600261e-05,
      "loss": 0.0401,
      "step": 8937
    },
    {
      "epoch": 0.6477515671993332,
      "grad_norm": 0.44102174043655396,
      "learning_rate": 7.046887455612727e-05,
      "loss": 0.0138,
      "step": 8938
    },
    {
      "epoch": 0.647824038844802,
      "grad_norm": 1.3027235269546509,
      "learning_rate": 7.045438075222842e-05,
      "loss": 0.0755,
      "step": 8939
    },
    {
      "epoch": 0.6478965104902706,
      "grad_norm": 0.33274999260902405,
      "learning_rate": 7.04398869483296e-05,
      "loss": 0.0046,
      "step": 8940
    },
    {
      "epoch": 0.6479689821357394,
      "grad_norm": 0.6346879005432129,
      "learning_rate": 7.042539314443077e-05,
      "loss": 0.0153,
      "step": 8941
    },
    {
      "epoch": 0.6480414537812081,
      "grad_norm": 0.9928535223007202,
      "learning_rate": 7.041089934053192e-05,
      "loss": 0.0288,
      "step": 8942
    },
    {
      "epoch": 0.6481139254266768,
      "grad_norm": 1.7522071599960327,
      "learning_rate": 7.039640553663309e-05,
      "loss": 0.1159,
      "step": 8943
    },
    {
      "epoch": 0.6481863970721455,
      "grad_norm": 1.0619299411773682,
      "learning_rate": 7.038191173273426e-05,
      "loss": 0.0386,
      "step": 8944
    },
    {
      "epoch": 0.6482588687176142,
      "grad_norm": 0.9991269707679749,
      "learning_rate": 7.036741792883542e-05,
      "loss": 0.0693,
      "step": 8945
    },
    {
      "epoch": 0.6483313403630829,
      "grad_norm": 0.6538941860198975,
      "learning_rate": 7.035292412493659e-05,
      "loss": 0.0272,
      "step": 8946
    },
    {
      "epoch": 0.6484038120085517,
      "grad_norm": 6.178625106811523,
      "learning_rate": 7.033843032103776e-05,
      "loss": 0.2477,
      "step": 8947
    },
    {
      "epoch": 0.6484762836540203,
      "grad_norm": 2.006442070007324,
      "learning_rate": 7.032393651713893e-05,
      "loss": 0.0519,
      "step": 8948
    },
    {
      "epoch": 0.6485487552994891,
      "grad_norm": 2.065366744995117,
      "learning_rate": 7.03094427132401e-05,
      "loss": 0.1481,
      "step": 8949
    },
    {
      "epoch": 0.6486212269449578,
      "grad_norm": 1.68089759349823,
      "learning_rate": 7.029494890934127e-05,
      "loss": 0.0645,
      "step": 8950
    },
    {
      "epoch": 0.6486936985904265,
      "grad_norm": 0.651926577091217,
      "learning_rate": 7.028045510544242e-05,
      "loss": 0.0135,
      "step": 8951
    },
    {
      "epoch": 0.6487661702358952,
      "grad_norm": 0.9193757772445679,
      "learning_rate": 7.02659613015436e-05,
      "loss": 0.0188,
      "step": 8952
    },
    {
      "epoch": 0.6488386418813639,
      "grad_norm": 0.7390238046646118,
      "learning_rate": 7.025146749764476e-05,
      "loss": 0.0268,
      "step": 8953
    },
    {
      "epoch": 0.6489111135268326,
      "grad_norm": 2.10384464263916,
      "learning_rate": 7.023697369374592e-05,
      "loss": 0.0637,
      "step": 8954
    },
    {
      "epoch": 0.6489835851723014,
      "grad_norm": 0.445857435464859,
      "learning_rate": 7.022247988984709e-05,
      "loss": 0.0241,
      "step": 8955
    },
    {
      "epoch": 0.64905605681777,
      "grad_norm": 1.7643380165100098,
      "learning_rate": 7.020798608594826e-05,
      "loss": 0.0622,
      "step": 8956
    },
    {
      "epoch": 0.6491285284632388,
      "grad_norm": 1.5636531114578247,
      "learning_rate": 7.019349228204942e-05,
      "loss": 0.0469,
      "step": 8957
    },
    {
      "epoch": 0.6492010001087075,
      "grad_norm": 1.7008721828460693,
      "learning_rate": 7.017899847815059e-05,
      "loss": 0.0163,
      "step": 8958
    },
    {
      "epoch": 0.6492734717541762,
      "grad_norm": 0.7759462594985962,
      "learning_rate": 7.016450467425176e-05,
      "loss": 0.0125,
      "step": 8959
    },
    {
      "epoch": 0.6493459433996449,
      "grad_norm": 0.07531223446130753,
      "learning_rate": 7.015001087035293e-05,
      "loss": 0.0017,
      "step": 8960
    },
    {
      "epoch": 0.6494184150451136,
      "grad_norm": 0.6397080421447754,
      "learning_rate": 7.01355170664541e-05,
      "loss": 0.0296,
      "step": 8961
    },
    {
      "epoch": 0.6494908866905823,
      "grad_norm": 0.6805391907691956,
      "learning_rate": 7.012102326255527e-05,
      "loss": 0.0126,
      "step": 8962
    },
    {
      "epoch": 0.649563358336051,
      "grad_norm": 0.6556404829025269,
      "learning_rate": 7.010652945865642e-05,
      "loss": 0.0473,
      "step": 8963
    },
    {
      "epoch": 0.6496358299815197,
      "grad_norm": 1.87224543094635,
      "learning_rate": 7.00920356547576e-05,
      "loss": 0.1199,
      "step": 8964
    },
    {
      "epoch": 0.6497083016269884,
      "grad_norm": 1.6402950286865234,
      "learning_rate": 7.007754185085876e-05,
      "loss": 0.0968,
      "step": 8965
    },
    {
      "epoch": 0.6497807732724572,
      "grad_norm": 1.9997540712356567,
      "learning_rate": 7.006304804695992e-05,
      "loss": 0.1679,
      "step": 8966
    },
    {
      "epoch": 0.6498532449179258,
      "grad_norm": 1.8833653926849365,
      "learning_rate": 7.004855424306109e-05,
      "loss": 0.0684,
      "step": 8967
    },
    {
      "epoch": 0.6499257165633946,
      "grad_norm": 1.2857457399368286,
      "learning_rate": 7.003406043916226e-05,
      "loss": 0.0299,
      "step": 8968
    },
    {
      "epoch": 0.6499981882088632,
      "grad_norm": 1.4907283782958984,
      "learning_rate": 7.001956663526342e-05,
      "loss": 0.0644,
      "step": 8969
    },
    {
      "epoch": 0.650070659854332,
      "grad_norm": 0.4229140877723694,
      "learning_rate": 7.000507283136459e-05,
      "loss": 0.0205,
      "step": 8970
    },
    {
      "epoch": 0.6501431314998007,
      "grad_norm": 2.2079057693481445,
      "learning_rate": 6.999057902746576e-05,
      "loss": 0.1213,
      "step": 8971
    },
    {
      "epoch": 0.6502156031452694,
      "grad_norm": 1.6158236265182495,
      "learning_rate": 6.997608522356693e-05,
      "loss": 0.0582,
      "step": 8972
    },
    {
      "epoch": 0.6502880747907381,
      "grad_norm": 1.2905523777008057,
      "learning_rate": 6.99615914196681e-05,
      "loss": 0.0581,
      "step": 8973
    },
    {
      "epoch": 0.6503605464362069,
      "grad_norm": 4.193971633911133,
      "learning_rate": 6.994709761576927e-05,
      "loss": 0.073,
      "step": 8974
    },
    {
      "epoch": 0.6504330180816755,
      "grad_norm": 4.701550483703613,
      "learning_rate": 6.993260381187044e-05,
      "loss": 0.1315,
      "step": 8975
    },
    {
      "epoch": 0.6505054897271443,
      "grad_norm": 2.251026153564453,
      "learning_rate": 6.99181100079716e-05,
      "loss": 0.1128,
      "step": 8976
    },
    {
      "epoch": 0.6505779613726129,
      "grad_norm": 0.6208699941635132,
      "learning_rate": 6.990361620407276e-05,
      "loss": 0.0142,
      "step": 8977
    },
    {
      "epoch": 0.6506504330180817,
      "grad_norm": 1.7375909090042114,
      "learning_rate": 6.988912240017393e-05,
      "loss": 0.0167,
      "step": 8978
    },
    {
      "epoch": 0.6507229046635504,
      "grad_norm": 0.30976468324661255,
      "learning_rate": 6.987462859627509e-05,
      "loss": 0.0147,
      "step": 8979
    },
    {
      "epoch": 0.6507953763090191,
      "grad_norm": 0.8157417178153992,
      "learning_rate": 6.986013479237626e-05,
      "loss": 0.039,
      "step": 8980
    },
    {
      "epoch": 0.6508678479544878,
      "grad_norm": 0.4378354251384735,
      "learning_rate": 6.984564098847743e-05,
      "loss": 0.0199,
      "step": 8981
    },
    {
      "epoch": 0.6509403195999565,
      "grad_norm": 2.4923698902130127,
      "learning_rate": 6.983114718457859e-05,
      "loss": 0.071,
      "step": 8982
    },
    {
      "epoch": 0.6510127912454252,
      "grad_norm": 2.801997423171997,
      "learning_rate": 6.981665338067976e-05,
      "loss": 0.0945,
      "step": 8983
    },
    {
      "epoch": 0.651085262890894,
      "grad_norm": 2.070352792739868,
      "learning_rate": 6.980215957678094e-05,
      "loss": 0.0637,
      "step": 8984
    },
    {
      "epoch": 0.6511577345363626,
      "grad_norm": 1.8726557493209839,
      "learning_rate": 6.97876657728821e-05,
      "loss": 0.0413,
      "step": 8985
    },
    {
      "epoch": 0.6512302061818314,
      "grad_norm": 1.2820059061050415,
      "learning_rate": 6.977317196898327e-05,
      "loss": 0.076,
      "step": 8986
    },
    {
      "epoch": 0.6513026778273001,
      "grad_norm": 0.9088284969329834,
      "learning_rate": 6.975867816508444e-05,
      "loss": 0.0259,
      "step": 8987
    },
    {
      "epoch": 0.6513751494727688,
      "grad_norm": 0.8197026252746582,
      "learning_rate": 6.97441843611856e-05,
      "loss": 0.0155,
      "step": 8988
    },
    {
      "epoch": 0.6514476211182375,
      "grad_norm": 0.8377233147621155,
      "learning_rate": 6.972969055728676e-05,
      "loss": 0.0525,
      "step": 8989
    },
    {
      "epoch": 0.6515200927637061,
      "grad_norm": 1.0992846488952637,
      "learning_rate": 6.971519675338793e-05,
      "loss": 0.025,
      "step": 8990
    },
    {
      "epoch": 0.6515925644091749,
      "grad_norm": 1.3392865657806396,
      "learning_rate": 6.970070294948909e-05,
      "loss": 0.0315,
      "step": 8991
    },
    {
      "epoch": 0.6516650360546437,
      "grad_norm": 0.8923776149749756,
      "learning_rate": 6.968620914559026e-05,
      "loss": 0.0538,
      "step": 8992
    },
    {
      "epoch": 0.6517375077001123,
      "grad_norm": 1.7640633583068848,
      "learning_rate": 6.967171534169143e-05,
      "loss": 0.0933,
      "step": 8993
    },
    {
      "epoch": 0.651809979345581,
      "grad_norm": 0.04475421458482742,
      "learning_rate": 6.965722153779259e-05,
      "loss": 0.0008,
      "step": 8994
    },
    {
      "epoch": 0.6518824509910498,
      "grad_norm": 2.1796717643737793,
      "learning_rate": 6.964272773389377e-05,
      "loss": 0.0797,
      "step": 8995
    },
    {
      "epoch": 0.6519549226365184,
      "grad_norm": 1.4086058139801025,
      "learning_rate": 6.962823392999494e-05,
      "loss": 0.0402,
      "step": 8996
    },
    {
      "epoch": 0.6520273942819872,
      "grad_norm": 0.24774841964244843,
      "learning_rate": 6.96137401260961e-05,
      "loss": 0.0049,
      "step": 8997
    },
    {
      "epoch": 0.6520998659274558,
      "grad_norm": 1.2685304880142212,
      "learning_rate": 6.959924632219727e-05,
      "loss": 0.0786,
      "step": 8998
    },
    {
      "epoch": 0.6521723375729246,
      "grad_norm": 0.7752339243888855,
      "learning_rate": 6.958475251829844e-05,
      "loss": 0.0398,
      "step": 8999
    },
    {
      "epoch": 0.6522448092183933,
      "grad_norm": 1.4690163135528564,
      "learning_rate": 6.95702587143996e-05,
      "loss": 0.0473,
      "step": 9000
    },
    {
      "epoch": 0.652317280863862,
      "grad_norm": 1.9029600620269775,
      "learning_rate": 6.955576491050076e-05,
      "loss": 0.0718,
      "step": 9001
    },
    {
      "epoch": 0.6523897525093307,
      "grad_norm": 1.5164873600006104,
      "learning_rate": 6.954127110660193e-05,
      "loss": 0.0399,
      "step": 9002
    },
    {
      "epoch": 0.6524622241547995,
      "grad_norm": 2.2115347385406494,
      "learning_rate": 6.952677730270309e-05,
      "loss": 0.0707,
      "step": 9003
    },
    {
      "epoch": 0.6525346958002681,
      "grad_norm": 2.1090362071990967,
      "learning_rate": 6.951228349880426e-05,
      "loss": 0.0545,
      "step": 9004
    },
    {
      "epoch": 0.6526071674457369,
      "grad_norm": 4.757358074188232,
      "learning_rate": 6.949778969490543e-05,
      "loss": 0.101,
      "step": 9005
    },
    {
      "epoch": 0.6526796390912055,
      "grad_norm": 0.6327043771743774,
      "learning_rate": 6.94832958910066e-05,
      "loss": 0.0135,
      "step": 9006
    },
    {
      "epoch": 0.6527521107366743,
      "grad_norm": 1.2552481889724731,
      "learning_rate": 6.946880208710777e-05,
      "loss": 0.044,
      "step": 9007
    },
    {
      "epoch": 0.652824582382143,
      "grad_norm": 1.973689317703247,
      "learning_rate": 6.945430828320894e-05,
      "loss": 0.1183,
      "step": 9008
    },
    {
      "epoch": 0.6528970540276117,
      "grad_norm": 1.3273292779922485,
      "learning_rate": 6.94398144793101e-05,
      "loss": 0.1018,
      "step": 9009
    },
    {
      "epoch": 0.6529695256730804,
      "grad_norm": 0.4578979015350342,
      "learning_rate": 6.942532067541127e-05,
      "loss": 0.011,
      "step": 9010
    },
    {
      "epoch": 0.6530419973185492,
      "grad_norm": 1.368347406387329,
      "learning_rate": 6.941082687151244e-05,
      "loss": 0.0254,
      "step": 9011
    },
    {
      "epoch": 0.6531144689640178,
      "grad_norm": 1.6617971658706665,
      "learning_rate": 6.93963330676136e-05,
      "loss": 0.0739,
      "step": 9012
    },
    {
      "epoch": 0.6531869406094866,
      "grad_norm": 0.9177846312522888,
      "learning_rate": 6.938183926371476e-05,
      "loss": 0.0322,
      "step": 9013
    },
    {
      "epoch": 0.6532594122549552,
      "grad_norm": 1.4780094623565674,
      "learning_rate": 6.936734545981593e-05,
      "loss": 0.0732,
      "step": 9014
    },
    {
      "epoch": 0.653331883900424,
      "grad_norm": 2.357478618621826,
      "learning_rate": 6.935285165591709e-05,
      "loss": 0.0902,
      "step": 9015
    },
    {
      "epoch": 0.6534043555458927,
      "grad_norm": 3.2351624965667725,
      "learning_rate": 6.933835785201826e-05,
      "loss": 0.0708,
      "step": 9016
    },
    {
      "epoch": 0.6534768271913614,
      "grad_norm": 1.5554028749465942,
      "learning_rate": 6.932386404811943e-05,
      "loss": 0.04,
      "step": 9017
    },
    {
      "epoch": 0.6535492988368301,
      "grad_norm": 1.9205355644226074,
      "learning_rate": 6.93093702442206e-05,
      "loss": 0.1181,
      "step": 9018
    },
    {
      "epoch": 0.6536217704822987,
      "grad_norm": 4.597006320953369,
      "learning_rate": 6.929487644032177e-05,
      "loss": 0.0692,
      "step": 9019
    },
    {
      "epoch": 0.6536942421277675,
      "grad_norm": 0.7476874589920044,
      "learning_rate": 6.928038263642294e-05,
      "loss": 0.028,
      "step": 9020
    },
    {
      "epoch": 0.6537667137732363,
      "grad_norm": 0.19922339916229248,
      "learning_rate": 6.92658888325241e-05,
      "loss": 0.0044,
      "step": 9021
    },
    {
      "epoch": 0.6538391854187049,
      "grad_norm": 5.414308547973633,
      "learning_rate": 6.925139502862527e-05,
      "loss": 0.087,
      "step": 9022
    },
    {
      "epoch": 0.6539116570641736,
      "grad_norm": 0.4274504482746124,
      "learning_rate": 6.923690122472644e-05,
      "loss": 0.0164,
      "step": 9023
    },
    {
      "epoch": 0.6539841287096424,
      "grad_norm": 1.65491783618927,
      "learning_rate": 6.92224074208276e-05,
      "loss": 0.0684,
      "step": 9024
    },
    {
      "epoch": 0.654056600355111,
      "grad_norm": 2.5445666313171387,
      "learning_rate": 6.920791361692876e-05,
      "loss": 0.0784,
      "step": 9025
    },
    {
      "epoch": 0.6541290720005798,
      "grad_norm": 0.5345587134361267,
      "learning_rate": 6.919341981302993e-05,
      "loss": 0.029,
      "step": 9026
    },
    {
      "epoch": 0.6542015436460484,
      "grad_norm": 2.0695719718933105,
      "learning_rate": 6.917892600913109e-05,
      "loss": 0.0656,
      "step": 9027
    },
    {
      "epoch": 0.6542740152915172,
      "grad_norm": 1.5684782266616821,
      "learning_rate": 6.916443220523226e-05,
      "loss": 0.0372,
      "step": 9028
    },
    {
      "epoch": 0.6543464869369859,
      "grad_norm": 0.47607168555259705,
      "learning_rate": 6.914993840133343e-05,
      "loss": 0.0194,
      "step": 9029
    },
    {
      "epoch": 0.6544189585824546,
      "grad_norm": 0.8727381825447083,
      "learning_rate": 6.91354445974346e-05,
      "loss": 0.0388,
      "step": 9030
    },
    {
      "epoch": 0.6544914302279233,
      "grad_norm": 1.0974760055541992,
      "learning_rate": 6.912095079353577e-05,
      "loss": 0.0707,
      "step": 9031
    },
    {
      "epoch": 0.6545639018733921,
      "grad_norm": 1.507030963897705,
      "learning_rate": 6.910645698963694e-05,
      "loss": 0.0715,
      "step": 9032
    },
    {
      "epoch": 0.6546363735188607,
      "grad_norm": 0.46238741278648376,
      "learning_rate": 6.90919631857381e-05,
      "loss": 0.0186,
      "step": 9033
    },
    {
      "epoch": 0.6547088451643295,
      "grad_norm": 0.8346683382987976,
      "learning_rate": 6.907746938183927e-05,
      "loss": 0.0472,
      "step": 9034
    },
    {
      "epoch": 0.6547813168097981,
      "grad_norm": 1.1160523891448975,
      "learning_rate": 6.906297557794044e-05,
      "loss": 0.0335,
      "step": 9035
    },
    {
      "epoch": 0.6548537884552669,
      "grad_norm": 1.8928020000457764,
      "learning_rate": 6.90484817740416e-05,
      "loss": 0.0461,
      "step": 9036
    },
    {
      "epoch": 0.6549262601007356,
      "grad_norm": 0.7111009359359741,
      "learning_rate": 6.903398797014276e-05,
      "loss": 0.0415,
      "step": 9037
    },
    {
      "epoch": 0.6549987317462043,
      "grad_norm": 3.3994948863983154,
      "learning_rate": 6.901949416624393e-05,
      "loss": 0.0571,
      "step": 9038
    },
    {
      "epoch": 0.655071203391673,
      "grad_norm": 1.2540171146392822,
      "learning_rate": 6.900500036234509e-05,
      "loss": 0.0444,
      "step": 9039
    },
    {
      "epoch": 0.6551436750371418,
      "grad_norm": 0.8276132345199585,
      "learning_rate": 6.899050655844626e-05,
      "loss": 0.0255,
      "step": 9040
    },
    {
      "epoch": 0.6552161466826104,
      "grad_norm": 2.760957717895508,
      "learning_rate": 6.897601275454743e-05,
      "loss": 0.0391,
      "step": 9041
    },
    {
      "epoch": 0.6552886183280792,
      "grad_norm": 2.6833112239837646,
      "learning_rate": 6.89615189506486e-05,
      "loss": 0.0885,
      "step": 9042
    },
    {
      "epoch": 0.6553610899735478,
      "grad_norm": 1.1435483694076538,
      "learning_rate": 6.894702514674977e-05,
      "loss": 0.051,
      "step": 9043
    },
    {
      "epoch": 0.6554335616190166,
      "grad_norm": 1.5657374858856201,
      "learning_rate": 6.893253134285094e-05,
      "loss": 0.0421,
      "step": 9044
    },
    {
      "epoch": 0.6555060332644853,
      "grad_norm": 0.8400461077690125,
      "learning_rate": 6.89180375389521e-05,
      "loss": 0.0508,
      "step": 9045
    },
    {
      "epoch": 0.655578504909954,
      "grad_norm": 0.45282742381095886,
      "learning_rate": 6.890354373505327e-05,
      "loss": 0.0251,
      "step": 9046
    },
    {
      "epoch": 0.6556509765554227,
      "grad_norm": 0.5890634059906006,
      "learning_rate": 6.888904993115444e-05,
      "loss": 0.0309,
      "step": 9047
    },
    {
      "epoch": 0.6557234482008915,
      "grad_norm": 2.1467387676239014,
      "learning_rate": 6.887455612725559e-05,
      "loss": 0.0921,
      "step": 9048
    },
    {
      "epoch": 0.6557959198463601,
      "grad_norm": 1.8215659856796265,
      "learning_rate": 6.886006232335676e-05,
      "loss": 0.0614,
      "step": 9049
    },
    {
      "epoch": 0.6558683914918289,
      "grad_norm": 1.2900390625,
      "learning_rate": 6.884556851945793e-05,
      "loss": 0.0493,
      "step": 9050
    },
    {
      "epoch": 0.6559408631372975,
      "grad_norm": 2.2399542331695557,
      "learning_rate": 6.883107471555909e-05,
      "loss": 0.1064,
      "step": 9051
    },
    {
      "epoch": 0.6560133347827662,
      "grad_norm": 2.402351140975952,
      "learning_rate": 6.881658091166027e-05,
      "loss": 0.0631,
      "step": 9052
    },
    {
      "epoch": 0.656085806428235,
      "grad_norm": 0.6146105527877808,
      "learning_rate": 6.880208710776144e-05,
      "loss": 0.0171,
      "step": 9053
    },
    {
      "epoch": 0.6561582780737036,
      "grad_norm": 3.7491068840026855,
      "learning_rate": 6.878759330386261e-05,
      "loss": 0.0591,
      "step": 9054
    },
    {
      "epoch": 0.6562307497191724,
      "grad_norm": 1.9895813465118408,
      "learning_rate": 6.877309949996377e-05,
      "loss": 0.1092,
      "step": 9055
    },
    {
      "epoch": 0.656303221364641,
      "grad_norm": 1.9087352752685547,
      "learning_rate": 6.875860569606494e-05,
      "loss": 0.1209,
      "step": 9056
    },
    {
      "epoch": 0.6563756930101098,
      "grad_norm": 0.7189581990242004,
      "learning_rate": 6.874411189216611e-05,
      "loss": 0.022,
      "step": 9057
    },
    {
      "epoch": 0.6564481646555785,
      "grad_norm": 1.2605352401733398,
      "learning_rate": 6.872961808826727e-05,
      "loss": 0.0413,
      "step": 9058
    },
    {
      "epoch": 0.6565206363010472,
      "grad_norm": 0.2724979817867279,
      "learning_rate": 6.871512428436844e-05,
      "loss": 0.0159,
      "step": 9059
    },
    {
      "epoch": 0.6565931079465159,
      "grad_norm": 0.9118690490722656,
      "learning_rate": 6.87006304804696e-05,
      "loss": 0.0309,
      "step": 9060
    },
    {
      "epoch": 0.6566655795919847,
      "grad_norm": 1.4820361137390137,
      "learning_rate": 6.868613667657076e-05,
      "loss": 0.0164,
      "step": 9061
    },
    {
      "epoch": 0.6567380512374533,
      "grad_norm": 3.370913505554199,
      "learning_rate": 6.867164287267193e-05,
      "loss": 0.1235,
      "step": 9062
    },
    {
      "epoch": 0.6568105228829221,
      "grad_norm": 0.13794425129890442,
      "learning_rate": 6.86571490687731e-05,
      "loss": 0.0053,
      "step": 9063
    },
    {
      "epoch": 0.6568829945283907,
      "grad_norm": 2.3493618965148926,
      "learning_rate": 6.864265526487427e-05,
      "loss": 0.0517,
      "step": 9064
    },
    {
      "epoch": 0.6569554661738595,
      "grad_norm": 0.19646945595741272,
      "learning_rate": 6.862816146097544e-05,
      "loss": 0.0036,
      "step": 9065
    },
    {
      "epoch": 0.6570279378193282,
      "grad_norm": 1.6518892049789429,
      "learning_rate": 6.861366765707661e-05,
      "loss": 0.0788,
      "step": 9066
    },
    {
      "epoch": 0.6571004094647969,
      "grad_norm": 1.890601396560669,
      "learning_rate": 6.859917385317777e-05,
      "loss": 0.0622,
      "step": 9067
    },
    {
      "epoch": 0.6571728811102656,
      "grad_norm": 1.7801744937896729,
      "learning_rate": 6.858468004927894e-05,
      "loss": 0.0688,
      "step": 9068
    },
    {
      "epoch": 0.6572453527557344,
      "grad_norm": 2.339228630065918,
      "learning_rate": 6.857018624538011e-05,
      "loss": 0.1461,
      "step": 9069
    },
    {
      "epoch": 0.657317824401203,
      "grad_norm": 3.031120538711548,
      "learning_rate": 6.855569244148127e-05,
      "loss": 0.0795,
      "step": 9070
    },
    {
      "epoch": 0.6573902960466718,
      "grad_norm": 1.101684808731079,
      "learning_rate": 6.854119863758244e-05,
      "loss": 0.0416,
      "step": 9071
    },
    {
      "epoch": 0.6574627676921404,
      "grad_norm": 0.9771392941474915,
      "learning_rate": 6.85267048336836e-05,
      "loss": 0.0116,
      "step": 9072
    },
    {
      "epoch": 0.6575352393376092,
      "grad_norm": 0.2437383383512497,
      "learning_rate": 6.851221102978476e-05,
      "loss": 0.0082,
      "step": 9073
    },
    {
      "epoch": 0.6576077109830779,
      "grad_norm": 0.7313566207885742,
      "learning_rate": 6.849771722588593e-05,
      "loss": 0.0232,
      "step": 9074
    },
    {
      "epoch": 0.6576801826285466,
      "grad_norm": 2.9488658905029297,
      "learning_rate": 6.84832234219871e-05,
      "loss": 0.0674,
      "step": 9075
    },
    {
      "epoch": 0.6577526542740153,
      "grad_norm": 0.9674209952354431,
      "learning_rate": 6.846872961808827e-05,
      "loss": 0.0575,
      "step": 9076
    },
    {
      "epoch": 0.657825125919484,
      "grad_norm": 1.872653603553772,
      "learning_rate": 6.845423581418944e-05,
      "loss": 0.0259,
      "step": 9077
    },
    {
      "epoch": 0.6578975975649527,
      "grad_norm": 1.1658358573913574,
      "learning_rate": 6.843974201029061e-05,
      "loss": 0.0513,
      "step": 9078
    },
    {
      "epoch": 0.6579700692104214,
      "grad_norm": 1.5374045372009277,
      "learning_rate": 6.842524820639177e-05,
      "loss": 0.0954,
      "step": 9079
    },
    {
      "epoch": 0.6580425408558901,
      "grad_norm": 3.5219664573669434,
      "learning_rate": 6.841075440249294e-05,
      "loss": 0.1055,
      "step": 9080
    },
    {
      "epoch": 0.6581150125013588,
      "grad_norm": 1.7697423696517944,
      "learning_rate": 6.839626059859411e-05,
      "loss": 0.0353,
      "step": 9081
    },
    {
      "epoch": 0.6581874841468276,
      "grad_norm": 3.641897439956665,
      "learning_rate": 6.838176679469527e-05,
      "loss": 0.2046,
      "step": 9082
    },
    {
      "epoch": 0.6582599557922962,
      "grad_norm": 0.5258480310440063,
      "learning_rate": 6.836727299079644e-05,
      "loss": 0.0238,
      "step": 9083
    },
    {
      "epoch": 0.658332427437765,
      "grad_norm": 0.8596758842468262,
      "learning_rate": 6.83527791868976e-05,
      "loss": 0.0511,
      "step": 9084
    },
    {
      "epoch": 0.6584048990832336,
      "grad_norm": 2.2638070583343506,
      "learning_rate": 6.833828538299876e-05,
      "loss": 0.0696,
      "step": 9085
    },
    {
      "epoch": 0.6584773707287024,
      "grad_norm": 3.177797317504883,
      "learning_rate": 6.832379157909993e-05,
      "loss": 0.0588,
      "step": 9086
    },
    {
      "epoch": 0.6585498423741711,
      "grad_norm": 1.436022162437439,
      "learning_rate": 6.83092977752011e-05,
      "loss": 0.0484,
      "step": 9087
    },
    {
      "epoch": 0.6586223140196398,
      "grad_norm": 1.0813387632369995,
      "learning_rate": 6.829480397130227e-05,
      "loss": 0.0456,
      "step": 9088
    },
    {
      "epoch": 0.6586947856651085,
      "grad_norm": 1.665287733078003,
      "learning_rate": 6.828031016740344e-05,
      "loss": 0.064,
      "step": 9089
    },
    {
      "epoch": 0.6587672573105773,
      "grad_norm": 1.1362829208374023,
      "learning_rate": 6.826581636350461e-05,
      "loss": 0.0373,
      "step": 9090
    },
    {
      "epoch": 0.6588397289560459,
      "grad_norm": 2.178659439086914,
      "learning_rate": 6.825132255960577e-05,
      "loss": 0.1098,
      "step": 9091
    },
    {
      "epoch": 0.6589122006015147,
      "grad_norm": 1.0805994272232056,
      "learning_rate": 6.823682875570694e-05,
      "loss": 0.0188,
      "step": 9092
    },
    {
      "epoch": 0.6589846722469833,
      "grad_norm": 0.544802188873291,
      "learning_rate": 6.822233495180811e-05,
      "loss": 0.0099,
      "step": 9093
    },
    {
      "epoch": 0.6590571438924521,
      "grad_norm": 1.5382040739059448,
      "learning_rate": 6.820784114790927e-05,
      "loss": 0.0734,
      "step": 9094
    },
    {
      "epoch": 0.6591296155379208,
      "grad_norm": 1.4005506038665771,
      "learning_rate": 6.819334734401044e-05,
      "loss": 0.0914,
      "step": 9095
    },
    {
      "epoch": 0.6592020871833895,
      "grad_norm": 2.228233814239502,
      "learning_rate": 6.81788535401116e-05,
      "loss": 0.0957,
      "step": 9096
    },
    {
      "epoch": 0.6592745588288582,
      "grad_norm": 2.6130902767181396,
      "learning_rate": 6.816435973621276e-05,
      "loss": 0.0226,
      "step": 9097
    },
    {
      "epoch": 0.659347030474327,
      "grad_norm": 1.675645112991333,
      "learning_rate": 6.814986593231393e-05,
      "loss": 0.1042,
      "step": 9098
    },
    {
      "epoch": 0.6594195021197956,
      "grad_norm": 0.7640977501869202,
      "learning_rate": 6.81353721284151e-05,
      "loss": 0.0142,
      "step": 9099
    },
    {
      "epoch": 0.6594919737652644,
      "grad_norm": 0.231978178024292,
      "learning_rate": 6.812087832451627e-05,
      "loss": 0.0127,
      "step": 9100
    },
    {
      "epoch": 0.659564445410733,
      "grad_norm": 2.1343278884887695,
      "learning_rate": 6.810638452061744e-05,
      "loss": 0.0637,
      "step": 9101
    },
    {
      "epoch": 0.6596369170562018,
      "grad_norm": 3.8578882217407227,
      "learning_rate": 6.809189071671861e-05,
      "loss": 0.0558,
      "step": 9102
    },
    {
      "epoch": 0.6597093887016705,
      "grad_norm": 1.7182763814926147,
      "learning_rate": 6.807739691281977e-05,
      "loss": 0.0304,
      "step": 9103
    },
    {
      "epoch": 0.6597818603471391,
      "grad_norm": 0.4370923936367035,
      "learning_rate": 6.806290310892094e-05,
      "loss": 0.0065,
      "step": 9104
    },
    {
      "epoch": 0.6598543319926079,
      "grad_norm": 2.0017497539520264,
      "learning_rate": 6.804840930502211e-05,
      "loss": 0.1005,
      "step": 9105
    },
    {
      "epoch": 0.6599268036380767,
      "grad_norm": 1.420493721961975,
      "learning_rate": 6.803391550112327e-05,
      "loss": 0.0428,
      "step": 9106
    },
    {
      "epoch": 0.6599992752835453,
      "grad_norm": 1.6987855434417725,
      "learning_rate": 6.801942169722444e-05,
      "loss": 0.0811,
      "step": 9107
    },
    {
      "epoch": 0.660071746929014,
      "grad_norm": 2.1878607273101807,
      "learning_rate": 6.80049278933256e-05,
      "loss": 0.0692,
      "step": 9108
    },
    {
      "epoch": 0.6601442185744827,
      "grad_norm": 1.6902354955673218,
      "learning_rate": 6.799043408942676e-05,
      "loss": 0.0509,
      "step": 9109
    },
    {
      "epoch": 0.6602166902199514,
      "grad_norm": 2.8246757984161377,
      "learning_rate": 6.797594028552795e-05,
      "loss": 0.0846,
      "step": 9110
    },
    {
      "epoch": 0.6602891618654202,
      "grad_norm": 0.11815903335809708,
      "learning_rate": 6.796144648162912e-05,
      "loss": 0.002,
      "step": 9111
    },
    {
      "epoch": 0.6603616335108888,
      "grad_norm": 1.1113617420196533,
      "learning_rate": 6.794695267773027e-05,
      "loss": 0.046,
      "step": 9112
    },
    {
      "epoch": 0.6604341051563576,
      "grad_norm": 0.29690414667129517,
      "learning_rate": 6.793245887383144e-05,
      "loss": 0.0113,
      "step": 9113
    },
    {
      "epoch": 0.6605065768018263,
      "grad_norm": 1.2733348608016968,
      "learning_rate": 6.791796506993261e-05,
      "loss": 0.0655,
      "step": 9114
    },
    {
      "epoch": 0.660579048447295,
      "grad_norm": 0.6904186606407166,
      "learning_rate": 6.790347126603377e-05,
      "loss": 0.0323,
      "step": 9115
    },
    {
      "epoch": 0.6606515200927637,
      "grad_norm": 1.1310175657272339,
      "learning_rate": 6.788897746213494e-05,
      "loss": 0.0427,
      "step": 9116
    },
    {
      "epoch": 0.6607239917382324,
      "grad_norm": 1.6423134803771973,
      "learning_rate": 6.787448365823611e-05,
      "loss": 0.0411,
      "step": 9117
    },
    {
      "epoch": 0.6607964633837011,
      "grad_norm": 2.582841396331787,
      "learning_rate": 6.785998985433727e-05,
      "loss": 0.1041,
      "step": 9118
    },
    {
      "epoch": 0.6608689350291699,
      "grad_norm": 0.8011845946311951,
      "learning_rate": 6.784549605043844e-05,
      "loss": 0.0148,
      "step": 9119
    },
    {
      "epoch": 0.6609414066746385,
      "grad_norm": 0.8639059662818909,
      "learning_rate": 6.78310022465396e-05,
      "loss": 0.0374,
      "step": 9120
    },
    {
      "epoch": 0.6610138783201073,
      "grad_norm": 1.219192624092102,
      "learning_rate": 6.781650844264078e-05,
      "loss": 0.024,
      "step": 9121
    },
    {
      "epoch": 0.6610863499655759,
      "grad_norm": 1.0403932332992554,
      "learning_rate": 6.780201463874195e-05,
      "loss": 0.0232,
      "step": 9122
    },
    {
      "epoch": 0.6611588216110447,
      "grad_norm": 9.14940071105957,
      "learning_rate": 6.778752083484312e-05,
      "loss": 0.0768,
      "step": 9123
    },
    {
      "epoch": 0.6612312932565134,
      "grad_norm": 1.429185152053833,
      "learning_rate": 6.777302703094427e-05,
      "loss": 0.0771,
      "step": 9124
    },
    {
      "epoch": 0.6613037649019821,
      "grad_norm": 0.517769455909729,
      "learning_rate": 6.775853322704544e-05,
      "loss": 0.0031,
      "step": 9125
    },
    {
      "epoch": 0.6613762365474508,
      "grad_norm": 1.291268229484558,
      "learning_rate": 6.774403942314661e-05,
      "loss": 0.0878,
      "step": 9126
    },
    {
      "epoch": 0.6614487081929196,
      "grad_norm": 1.6889384984970093,
      "learning_rate": 6.772954561924777e-05,
      "loss": 0.0523,
      "step": 9127
    },
    {
      "epoch": 0.6615211798383882,
      "grad_norm": 0.3461255729198456,
      "learning_rate": 6.771505181534894e-05,
      "loss": 0.0083,
      "step": 9128
    },
    {
      "epoch": 0.661593651483857,
      "grad_norm": 4.054506778717041,
      "learning_rate": 6.770055801145011e-05,
      "loss": 0.0716,
      "step": 9129
    },
    {
      "epoch": 0.6616661231293256,
      "grad_norm": 1.2757556438446045,
      "learning_rate": 6.768606420755127e-05,
      "loss": 0.0447,
      "step": 9130
    },
    {
      "epoch": 0.6617385947747944,
      "grad_norm": 0.737851083278656,
      "learning_rate": 6.767157040365244e-05,
      "loss": 0.0329,
      "step": 9131
    },
    {
      "epoch": 0.6618110664202631,
      "grad_norm": 3.3262228965759277,
      "learning_rate": 6.76570765997536e-05,
      "loss": 0.125,
      "step": 9132
    },
    {
      "epoch": 0.6618835380657317,
      "grad_norm": 0.5797545909881592,
      "learning_rate": 6.764258279585478e-05,
      "loss": 0.0152,
      "step": 9133
    },
    {
      "epoch": 0.6619560097112005,
      "grad_norm": 0.9149790406227112,
      "learning_rate": 6.762808899195595e-05,
      "loss": 0.0314,
      "step": 9134
    },
    {
      "epoch": 0.6620284813566693,
      "grad_norm": 4.004139423370361,
      "learning_rate": 6.761359518805712e-05,
      "loss": 0.09,
      "step": 9135
    },
    {
      "epoch": 0.6621009530021379,
      "grad_norm": 0.8081129193305969,
      "learning_rate": 6.759910138415829e-05,
      "loss": 0.0091,
      "step": 9136
    },
    {
      "epoch": 0.6621734246476066,
      "grad_norm": 2.2913460731506348,
      "learning_rate": 6.758460758025944e-05,
      "loss": 0.0984,
      "step": 9137
    },
    {
      "epoch": 0.6622458962930753,
      "grad_norm": 1.0567647218704224,
      "learning_rate": 6.757011377636061e-05,
      "loss": 0.0348,
      "step": 9138
    },
    {
      "epoch": 0.662318367938544,
      "grad_norm": 2.1394946575164795,
      "learning_rate": 6.755561997246178e-05,
      "loss": 0.1424,
      "step": 9139
    },
    {
      "epoch": 0.6623908395840128,
      "grad_norm": 1.6435458660125732,
      "learning_rate": 6.754112616856294e-05,
      "loss": 0.0741,
      "step": 9140
    },
    {
      "epoch": 0.6624633112294814,
      "grad_norm": 1.4026726484298706,
      "learning_rate": 6.752663236466411e-05,
      "loss": 0.0695,
      "step": 9141
    },
    {
      "epoch": 0.6625357828749502,
      "grad_norm": 3.65047287940979,
      "learning_rate": 6.751213856076528e-05,
      "loss": 0.1406,
      "step": 9142
    },
    {
      "epoch": 0.6626082545204189,
      "grad_norm": 0.48984792828559875,
      "learning_rate": 6.749764475686644e-05,
      "loss": 0.0128,
      "step": 9143
    },
    {
      "epoch": 0.6626807261658876,
      "grad_norm": 0.6635177135467529,
      "learning_rate": 6.74831509529676e-05,
      "loss": 0.0134,
      "step": 9144
    },
    {
      "epoch": 0.6627531978113563,
      "grad_norm": 1.3884799480438232,
      "learning_rate": 6.746865714906878e-05,
      "loss": 0.0566,
      "step": 9145
    },
    {
      "epoch": 0.662825669456825,
      "grad_norm": 0.8660954833030701,
      "learning_rate": 6.745416334516995e-05,
      "loss": 0.06,
      "step": 9146
    },
    {
      "epoch": 0.6628981411022937,
      "grad_norm": 1.7863309383392334,
      "learning_rate": 6.743966954127112e-05,
      "loss": 0.0728,
      "step": 9147
    },
    {
      "epoch": 0.6629706127477625,
      "grad_norm": 1.5803296566009521,
      "learning_rate": 6.742517573737229e-05,
      "loss": 0.0668,
      "step": 9148
    },
    {
      "epoch": 0.6630430843932311,
      "grad_norm": 1.5606118440628052,
      "learning_rate": 6.741068193347344e-05,
      "loss": 0.1044,
      "step": 9149
    },
    {
      "epoch": 0.6631155560386999,
      "grad_norm": 1.1429486274719238,
      "learning_rate": 6.739618812957461e-05,
      "loss": 0.034,
      "step": 9150
    },
    {
      "epoch": 0.6631880276841686,
      "grad_norm": 1.3141396045684814,
      "learning_rate": 6.738169432567578e-05,
      "loss": 0.0396,
      "step": 9151
    },
    {
      "epoch": 0.6632604993296373,
      "grad_norm": 1.9747798442840576,
      "learning_rate": 6.736720052177694e-05,
      "loss": 0.1203,
      "step": 9152
    },
    {
      "epoch": 0.663332970975106,
      "grad_norm": 4.166389465332031,
      "learning_rate": 6.735270671787811e-05,
      "loss": 0.1287,
      "step": 9153
    },
    {
      "epoch": 0.6634054426205747,
      "grad_norm": 2.2900748252868652,
      "learning_rate": 6.733821291397928e-05,
      "loss": 0.0653,
      "step": 9154
    },
    {
      "epoch": 0.6634779142660434,
      "grad_norm": 1.9523141384124756,
      "learning_rate": 6.732371911008043e-05,
      "loss": 0.043,
      "step": 9155
    },
    {
      "epoch": 0.6635503859115122,
      "grad_norm": 1.5245124101638794,
      "learning_rate": 6.73092253061816e-05,
      "loss": 0.0645,
      "step": 9156
    },
    {
      "epoch": 0.6636228575569808,
      "grad_norm": 0.30488836765289307,
      "learning_rate": 6.729473150228279e-05,
      "loss": 0.0042,
      "step": 9157
    },
    {
      "epoch": 0.6636953292024496,
      "grad_norm": 0.43403923511505127,
      "learning_rate": 6.728023769838394e-05,
      "loss": 0.01,
      "step": 9158
    },
    {
      "epoch": 0.6637678008479182,
      "grad_norm": 1.9032503366470337,
      "learning_rate": 6.726574389448512e-05,
      "loss": 0.0827,
      "step": 9159
    },
    {
      "epoch": 0.663840272493387,
      "grad_norm": 0.9619352221488953,
      "learning_rate": 6.725125009058629e-05,
      "loss": 0.0184,
      "step": 9160
    },
    {
      "epoch": 0.6639127441388557,
      "grad_norm": 1.0721209049224854,
      "learning_rate": 6.723675628668744e-05,
      "loss": 0.0721,
      "step": 9161
    },
    {
      "epoch": 0.6639852157843243,
      "grad_norm": 0.709411084651947,
      "learning_rate": 6.722226248278861e-05,
      "loss": 0.0208,
      "step": 9162
    },
    {
      "epoch": 0.6640576874297931,
      "grad_norm": 1.9267911911010742,
      "learning_rate": 6.720776867888978e-05,
      "loss": 0.0956,
      "step": 9163
    },
    {
      "epoch": 0.6641301590752618,
      "grad_norm": 2.811875104904175,
      "learning_rate": 6.719327487499094e-05,
      "loss": 0.1324,
      "step": 9164
    },
    {
      "epoch": 0.6642026307207305,
      "grad_norm": 0.13247069716453552,
      "learning_rate": 6.717878107109211e-05,
      "loss": 0.0094,
      "step": 9165
    },
    {
      "epoch": 0.6642751023661992,
      "grad_norm": 0.589784562587738,
      "learning_rate": 6.716428726719328e-05,
      "loss": 0.0243,
      "step": 9166
    },
    {
      "epoch": 0.6643475740116679,
      "grad_norm": 0.06798200309276581,
      "learning_rate": 6.714979346329443e-05,
      "loss": 0.0014,
      "step": 9167
    },
    {
      "epoch": 0.6644200456571366,
      "grad_norm": 1.1025317907333374,
      "learning_rate": 6.713529965939562e-05,
      "loss": 0.0556,
      "step": 9168
    },
    {
      "epoch": 0.6644925173026054,
      "grad_norm": 2.1861772537231445,
      "learning_rate": 6.712080585549679e-05,
      "loss": 0.0891,
      "step": 9169
    },
    {
      "epoch": 0.664564988948074,
      "grad_norm": 0.32022616267204285,
      "learning_rate": 6.710631205159794e-05,
      "loss": 0.019,
      "step": 9170
    },
    {
      "epoch": 0.6646374605935428,
      "grad_norm": 0.925266444683075,
      "learning_rate": 6.709181824769911e-05,
      "loss": 0.0302,
      "step": 9171
    },
    {
      "epoch": 0.6647099322390115,
      "grad_norm": 1.2181519269943237,
      "learning_rate": 6.707732444380028e-05,
      "loss": 0.0288,
      "step": 9172
    },
    {
      "epoch": 0.6647824038844802,
      "grad_norm": 0.9017288684844971,
      "learning_rate": 6.706283063990144e-05,
      "loss": 0.0168,
      "step": 9173
    },
    {
      "epoch": 0.6648548755299489,
      "grad_norm": 0.5822490453720093,
      "learning_rate": 6.704833683600261e-05,
      "loss": 0.0196,
      "step": 9174
    },
    {
      "epoch": 0.6649273471754176,
      "grad_norm": 8.067809104919434,
      "learning_rate": 6.703384303210378e-05,
      "loss": 0.02,
      "step": 9175
    },
    {
      "epoch": 0.6649998188208863,
      "grad_norm": 0.827764630317688,
      "learning_rate": 6.701934922820494e-05,
      "loss": 0.0258,
      "step": 9176
    },
    {
      "epoch": 0.6650722904663551,
      "grad_norm": 1.1961055994033813,
      "learning_rate": 6.700485542430611e-05,
      "loss": 0.0712,
      "step": 9177
    },
    {
      "epoch": 0.6651447621118237,
      "grad_norm": 0.2520330250263214,
      "learning_rate": 6.699036162040728e-05,
      "loss": 0.0259,
      "step": 9178
    },
    {
      "epoch": 0.6652172337572925,
      "grad_norm": 1.078925371170044,
      "learning_rate": 6.697586781650845e-05,
      "loss": 0.0292,
      "step": 9179
    },
    {
      "epoch": 0.6652897054027612,
      "grad_norm": 1.7803767919540405,
      "learning_rate": 6.696137401260962e-05,
      "loss": 0.0308,
      "step": 9180
    },
    {
      "epoch": 0.6653621770482299,
      "grad_norm": 2.6988139152526855,
      "learning_rate": 6.694688020871079e-05,
      "loss": 0.0506,
      "step": 9181
    },
    {
      "epoch": 0.6654346486936986,
      "grad_norm": 1.8426384925842285,
      "learning_rate": 6.693238640481194e-05,
      "loss": 0.1084,
      "step": 9182
    },
    {
      "epoch": 0.6655071203391673,
      "grad_norm": 1.0858973264694214,
      "learning_rate": 6.691789260091311e-05,
      "loss": 0.0279,
      "step": 9183
    },
    {
      "epoch": 0.665579591984636,
      "grad_norm": 1.6145179271697998,
      "learning_rate": 6.690339879701428e-05,
      "loss": 0.0217,
      "step": 9184
    },
    {
      "epoch": 0.6656520636301048,
      "grad_norm": 1.3013956546783447,
      "learning_rate": 6.688890499311544e-05,
      "loss": 0.0183,
      "step": 9185
    },
    {
      "epoch": 0.6657245352755734,
      "grad_norm": 0.9579058885574341,
      "learning_rate": 6.687441118921661e-05,
      "loss": 0.0414,
      "step": 9186
    },
    {
      "epoch": 0.6657970069210422,
      "grad_norm": 3.567457914352417,
      "learning_rate": 6.685991738531778e-05,
      "loss": 0.1328,
      "step": 9187
    },
    {
      "epoch": 0.6658694785665108,
      "grad_norm": 1.5586533546447754,
      "learning_rate": 6.684542358141894e-05,
      "loss": 0.1067,
      "step": 9188
    },
    {
      "epoch": 0.6659419502119795,
      "grad_norm": 1.4802467823028564,
      "learning_rate": 6.683092977752011e-05,
      "loss": 0.0542,
      "step": 9189
    },
    {
      "epoch": 0.6660144218574483,
      "grad_norm": 1.7424991130828857,
      "learning_rate": 6.681643597362128e-05,
      "loss": 0.0762,
      "step": 9190
    },
    {
      "epoch": 0.6660868935029169,
      "grad_norm": 0.6699798107147217,
      "learning_rate": 6.680194216972245e-05,
      "loss": 0.0078,
      "step": 9191
    },
    {
      "epoch": 0.6661593651483857,
      "grad_norm": 2.0333774089813232,
      "learning_rate": 6.678744836582362e-05,
      "loss": 0.0581,
      "step": 9192
    },
    {
      "epoch": 0.6662318367938544,
      "grad_norm": 2.0138237476348877,
      "learning_rate": 6.677295456192479e-05,
      "loss": 0.0439,
      "step": 9193
    },
    {
      "epoch": 0.6663043084393231,
      "grad_norm": 2.36063289642334,
      "learning_rate": 6.675846075802594e-05,
      "loss": 0.0383,
      "step": 9194
    },
    {
      "epoch": 0.6663767800847918,
      "grad_norm": 1.1404742002487183,
      "learning_rate": 6.674396695412711e-05,
      "loss": 0.0651,
      "step": 9195
    },
    {
      "epoch": 0.6664492517302605,
      "grad_norm": 1.9977697134017944,
      "learning_rate": 6.672947315022828e-05,
      "loss": 0.0454,
      "step": 9196
    },
    {
      "epoch": 0.6665217233757292,
      "grad_norm": 0.5479637980461121,
      "learning_rate": 6.671497934632944e-05,
      "loss": 0.029,
      "step": 9197
    },
    {
      "epoch": 0.666594195021198,
      "grad_norm": 0.9116500020027161,
      "learning_rate": 6.670048554243061e-05,
      "loss": 0.0204,
      "step": 9198
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 2.4367103576660156,
      "learning_rate": 6.668599173853178e-05,
      "loss": 0.0969,
      "step": 9199
    },
    {
      "epoch": 0.6667391383121354,
      "grad_norm": 1.3503363132476807,
      "learning_rate": 6.667149793463294e-05,
      "loss": 0.1018,
      "step": 9200
    },
    {
      "epoch": 0.6668116099576041,
      "grad_norm": 6.089087009429932,
      "learning_rate": 6.665700413073411e-05,
      "loss": 0.1133,
      "step": 9201
    },
    {
      "epoch": 0.6668840816030728,
      "grad_norm": 0.8714764714241028,
      "learning_rate": 6.664251032683528e-05,
      "loss": 0.0406,
      "step": 9202
    },
    {
      "epoch": 0.6669565532485415,
      "grad_norm": 1.1886533498764038,
      "learning_rate": 6.662801652293645e-05,
      "loss": 0.0328,
      "step": 9203
    },
    {
      "epoch": 0.6670290248940102,
      "grad_norm": 0.7914983630180359,
      "learning_rate": 6.661352271903762e-05,
      "loss": 0.0144,
      "step": 9204
    },
    {
      "epoch": 0.6671014965394789,
      "grad_norm": 3.3885555267333984,
      "learning_rate": 6.659902891513879e-05,
      "loss": 0.0741,
      "step": 9205
    },
    {
      "epoch": 0.6671739681849477,
      "grad_norm": 0.35210680961608887,
      "learning_rate": 6.658453511123994e-05,
      "loss": 0.0199,
      "step": 9206
    },
    {
      "epoch": 0.6672464398304163,
      "grad_norm": 1.2011138200759888,
      "learning_rate": 6.657004130734111e-05,
      "loss": 0.0575,
      "step": 9207
    },
    {
      "epoch": 0.6673189114758851,
      "grad_norm": 0.4282776713371277,
      "learning_rate": 6.655554750344228e-05,
      "loss": 0.0225,
      "step": 9208
    },
    {
      "epoch": 0.6673913831213538,
      "grad_norm": 0.7999053001403809,
      "learning_rate": 6.654105369954344e-05,
      "loss": 0.0502,
      "step": 9209
    },
    {
      "epoch": 0.6674638547668225,
      "grad_norm": 0.9090418219566345,
      "learning_rate": 6.652655989564461e-05,
      "loss": 0.0073,
      "step": 9210
    },
    {
      "epoch": 0.6675363264122912,
      "grad_norm": 1.2783232927322388,
      "learning_rate": 6.651206609174578e-05,
      "loss": 0.051,
      "step": 9211
    },
    {
      "epoch": 0.6676087980577599,
      "grad_norm": 1.2921369075775146,
      "learning_rate": 6.649757228784694e-05,
      "loss": 0.01,
      "step": 9212
    },
    {
      "epoch": 0.6676812697032286,
      "grad_norm": 0.8494499921798706,
      "learning_rate": 6.648307848394811e-05,
      "loss": 0.045,
      "step": 9213
    },
    {
      "epoch": 0.6677537413486974,
      "grad_norm": 0.6121731400489807,
      "learning_rate": 6.646858468004928e-05,
      "loss": 0.0199,
      "step": 9214
    },
    {
      "epoch": 0.667826212994166,
      "grad_norm": 1.5628547668457031,
      "learning_rate": 6.645409087615046e-05,
      "loss": 0.041,
      "step": 9215
    },
    {
      "epoch": 0.6678986846396348,
      "grad_norm": 1.0364569425582886,
      "learning_rate": 6.643959707225162e-05,
      "loss": 0.0453,
      "step": 9216
    },
    {
      "epoch": 0.6679711562851035,
      "grad_norm": 1.5887197256088257,
      "learning_rate": 6.642510326835279e-05,
      "loss": 0.0343,
      "step": 9217
    },
    {
      "epoch": 0.6680436279305721,
      "grad_norm": 3.835322380065918,
      "learning_rate": 6.641060946445396e-05,
      "loss": 0.0851,
      "step": 9218
    },
    {
      "epoch": 0.6681160995760409,
      "grad_norm": 1.9873347282409668,
      "learning_rate": 6.639611566055511e-05,
      "loss": 0.0545,
      "step": 9219
    },
    {
      "epoch": 0.6681885712215095,
      "grad_norm": 2.017550230026245,
      "learning_rate": 6.638162185665628e-05,
      "loss": 0.0709,
      "step": 9220
    },
    {
      "epoch": 0.6682610428669783,
      "grad_norm": 1.0505698919296265,
      "learning_rate": 6.636712805275745e-05,
      "loss": 0.0377,
      "step": 9221
    },
    {
      "epoch": 0.668333514512447,
      "grad_norm": 0.07909410446882248,
      "learning_rate": 6.635263424885861e-05,
      "loss": 0.0009,
      "step": 9222
    },
    {
      "epoch": 0.6684059861579157,
      "grad_norm": 4.0306477546691895,
      "learning_rate": 6.633814044495978e-05,
      "loss": 0.0995,
      "step": 9223
    },
    {
      "epoch": 0.6684784578033844,
      "grad_norm": 2.4704527854919434,
      "learning_rate": 6.632364664106095e-05,
      "loss": 0.0646,
      "step": 9224
    },
    {
      "epoch": 0.6685509294488531,
      "grad_norm": 0.43194273114204407,
      "learning_rate": 6.630915283716212e-05,
      "loss": 0.0187,
      "step": 9225
    },
    {
      "epoch": 0.6686234010943218,
      "grad_norm": 1.6994951963424683,
      "learning_rate": 6.629465903326329e-05,
      "loss": 0.0767,
      "step": 9226
    },
    {
      "epoch": 0.6686958727397906,
      "grad_norm": 2.0098655223846436,
      "learning_rate": 6.628016522936446e-05,
      "loss": 0.0215,
      "step": 9227
    },
    {
      "epoch": 0.6687683443852592,
      "grad_norm": 1.7201879024505615,
      "learning_rate": 6.626567142546562e-05,
      "loss": 0.1291,
      "step": 9228
    },
    {
      "epoch": 0.668840816030728,
      "grad_norm": 0.30990251898765564,
      "learning_rate": 6.625117762156679e-05,
      "loss": 0.0027,
      "step": 9229
    },
    {
      "epoch": 0.6689132876761967,
      "grad_norm": 3.5232434272766113,
      "learning_rate": 6.623668381766796e-05,
      "loss": 0.2264,
      "step": 9230
    },
    {
      "epoch": 0.6689857593216654,
      "grad_norm": 1.8546667098999023,
      "learning_rate": 6.622219001376911e-05,
      "loss": 0.1102,
      "step": 9231
    },
    {
      "epoch": 0.6690582309671341,
      "grad_norm": 4.993468761444092,
      "learning_rate": 6.620769620987028e-05,
      "loss": 0.0995,
      "step": 9232
    },
    {
      "epoch": 0.6691307026126028,
      "grad_norm": 0.8526115417480469,
      "learning_rate": 6.619320240597145e-05,
      "loss": 0.0342,
      "step": 9233
    },
    {
      "epoch": 0.6692031742580715,
      "grad_norm": 2.3168087005615234,
      "learning_rate": 6.617870860207261e-05,
      "loss": 0.0966,
      "step": 9234
    },
    {
      "epoch": 0.6692756459035403,
      "grad_norm": 0.7330572009086609,
      "learning_rate": 6.616421479817378e-05,
      "loss": 0.0154,
      "step": 9235
    },
    {
      "epoch": 0.6693481175490089,
      "grad_norm": 1.0892255306243896,
      "learning_rate": 6.614972099427495e-05,
      "loss": 0.0444,
      "step": 9236
    },
    {
      "epoch": 0.6694205891944777,
      "grad_norm": 2.212418556213379,
      "learning_rate": 6.613522719037612e-05,
      "loss": 0.0462,
      "step": 9237
    },
    {
      "epoch": 0.6694930608399464,
      "grad_norm": 1.050743818283081,
      "learning_rate": 6.612073338647729e-05,
      "loss": 0.0444,
      "step": 9238
    },
    {
      "epoch": 0.6695655324854151,
      "grad_norm": 1.931061029434204,
      "learning_rate": 6.610623958257846e-05,
      "loss": 0.0351,
      "step": 9239
    },
    {
      "epoch": 0.6696380041308838,
      "grad_norm": 2.245694160461426,
      "learning_rate": 6.609174577867962e-05,
      "loss": 0.0506,
      "step": 9240
    },
    {
      "epoch": 0.6697104757763525,
      "grad_norm": 1.6965326070785522,
      "learning_rate": 6.607725197478079e-05,
      "loss": 0.0658,
      "step": 9241
    },
    {
      "epoch": 0.6697829474218212,
      "grad_norm": 1.366641640663147,
      "learning_rate": 6.606275817088196e-05,
      "loss": 0.0548,
      "step": 9242
    },
    {
      "epoch": 0.66985541906729,
      "grad_norm": 2.744417905807495,
      "learning_rate": 6.604826436698311e-05,
      "loss": 0.1601,
      "step": 9243
    },
    {
      "epoch": 0.6699278907127586,
      "grad_norm": 2.279951810836792,
      "learning_rate": 6.603377056308428e-05,
      "loss": 0.0603,
      "step": 9244
    },
    {
      "epoch": 0.6700003623582274,
      "grad_norm": 2.1731605529785156,
      "learning_rate": 6.601927675918545e-05,
      "loss": 0.0567,
      "step": 9245
    },
    {
      "epoch": 0.6700728340036961,
      "grad_norm": 1.7191733121871948,
      "learning_rate": 6.600478295528661e-05,
      "loss": 0.0853,
      "step": 9246
    },
    {
      "epoch": 0.6701453056491647,
      "grad_norm": 1.3724322319030762,
      "learning_rate": 6.599028915138778e-05,
      "loss": 0.0642,
      "step": 9247
    },
    {
      "epoch": 0.6702177772946335,
      "grad_norm": 1.2163975238800049,
      "learning_rate": 6.597579534748895e-05,
      "loss": 0.0478,
      "step": 9248
    },
    {
      "epoch": 0.6702902489401021,
      "grad_norm": 0.3556620180606842,
      "learning_rate": 6.596130154359012e-05,
      "loss": 0.0115,
      "step": 9249
    },
    {
      "epoch": 0.6703627205855709,
      "grad_norm": 1.3131139278411865,
      "learning_rate": 6.594680773969129e-05,
      "loss": 0.0738,
      "step": 9250
    },
    {
      "epoch": 0.6704351922310396,
      "grad_norm": 1.3024296760559082,
      "learning_rate": 6.593231393579246e-05,
      "loss": 0.0316,
      "step": 9251
    },
    {
      "epoch": 0.6705076638765083,
      "grad_norm": 2.5891005992889404,
      "learning_rate": 6.591782013189362e-05,
      "loss": 0.1169,
      "step": 9252
    },
    {
      "epoch": 0.670580135521977,
      "grad_norm": 0.8143800497055054,
      "learning_rate": 6.590332632799479e-05,
      "loss": 0.0299,
      "step": 9253
    },
    {
      "epoch": 0.6706526071674458,
      "grad_norm": 0.3096280097961426,
      "learning_rate": 6.588883252409596e-05,
      "loss": 0.0034,
      "step": 9254
    },
    {
      "epoch": 0.6707250788129144,
      "grad_norm": 0.3986160457134247,
      "learning_rate": 6.587433872019711e-05,
      "loss": 0.0106,
      "step": 9255
    },
    {
      "epoch": 0.6707975504583832,
      "grad_norm": 1.853132724761963,
      "learning_rate": 6.585984491629828e-05,
      "loss": 0.0939,
      "step": 9256
    },
    {
      "epoch": 0.6708700221038518,
      "grad_norm": 2.079773426055908,
      "learning_rate": 6.584535111239945e-05,
      "loss": 0.058,
      "step": 9257
    },
    {
      "epoch": 0.6709424937493206,
      "grad_norm": 1.0373646020889282,
      "learning_rate": 6.583085730850061e-05,
      "loss": 0.0412,
      "step": 9258
    },
    {
      "epoch": 0.6710149653947893,
      "grad_norm": 0.505841851234436,
      "learning_rate": 6.581636350460178e-05,
      "loss": 0.0154,
      "step": 9259
    },
    {
      "epoch": 0.671087437040258,
      "grad_norm": 0.6939623951911926,
      "learning_rate": 6.580186970070295e-05,
      "loss": 0.0172,
      "step": 9260
    },
    {
      "epoch": 0.6711599086857267,
      "grad_norm": 0.6462224721908569,
      "learning_rate": 6.578737589680412e-05,
      "loss": 0.0375,
      "step": 9261
    },
    {
      "epoch": 0.6712323803311954,
      "grad_norm": 1.0258811712265015,
      "learning_rate": 6.577288209290529e-05,
      "loss": 0.0335,
      "step": 9262
    },
    {
      "epoch": 0.6713048519766641,
      "grad_norm": 1.1726478338241577,
      "learning_rate": 6.575838828900646e-05,
      "loss": 0.082,
      "step": 9263
    },
    {
      "epoch": 0.6713773236221329,
      "grad_norm": 3.137706995010376,
      "learning_rate": 6.574389448510762e-05,
      "loss": 0.1539,
      "step": 9264
    },
    {
      "epoch": 0.6714497952676015,
      "grad_norm": 1.9161092042922974,
      "learning_rate": 6.572940068120879e-05,
      "loss": 0.0844,
      "step": 9265
    },
    {
      "epoch": 0.6715222669130703,
      "grad_norm": 1.2309987545013428,
      "learning_rate": 6.571490687730996e-05,
      "loss": 0.0443,
      "step": 9266
    },
    {
      "epoch": 0.671594738558539,
      "grad_norm": 0.7167524695396423,
      "learning_rate": 6.570041307341111e-05,
      "loss": 0.0185,
      "step": 9267
    },
    {
      "epoch": 0.6716672102040077,
      "grad_norm": 1.537352204322815,
      "learning_rate": 6.568591926951228e-05,
      "loss": 0.0802,
      "step": 9268
    },
    {
      "epoch": 0.6717396818494764,
      "grad_norm": 1.0385359525680542,
      "learning_rate": 6.567142546561345e-05,
      "loss": 0.0321,
      "step": 9269
    },
    {
      "epoch": 0.671812153494945,
      "grad_norm": 2.3542592525482178,
      "learning_rate": 6.565693166171461e-05,
      "loss": 0.0967,
      "step": 9270
    },
    {
      "epoch": 0.6718846251404138,
      "grad_norm": 0.8416262865066528,
      "learning_rate": 6.564243785781578e-05,
      "loss": 0.0227,
      "step": 9271
    },
    {
      "epoch": 0.6719570967858826,
      "grad_norm": 0.6308873295783997,
      "learning_rate": 6.562794405391695e-05,
      "loss": 0.0059,
      "step": 9272
    },
    {
      "epoch": 0.6720295684313512,
      "grad_norm": 1.522304654121399,
      "learning_rate": 6.561345025001812e-05,
      "loss": 0.0805,
      "step": 9273
    },
    {
      "epoch": 0.67210204007682,
      "grad_norm": 1.0008219480514526,
      "learning_rate": 6.559895644611929e-05,
      "loss": 0.0323,
      "step": 9274
    },
    {
      "epoch": 0.6721745117222887,
      "grad_norm": 2.4730846881866455,
      "learning_rate": 6.558446264222046e-05,
      "loss": 0.0888,
      "step": 9275
    },
    {
      "epoch": 0.6722469833677573,
      "grad_norm": 0.3686511516571045,
      "learning_rate": 6.556996883832162e-05,
      "loss": 0.0255,
      "step": 9276
    },
    {
      "epoch": 0.6723194550132261,
      "grad_norm": 0.3415822386741638,
      "learning_rate": 6.555547503442279e-05,
      "loss": 0.0055,
      "step": 9277
    },
    {
      "epoch": 0.6723919266586947,
      "grad_norm": 1.0949543714523315,
      "learning_rate": 6.554098123052396e-05,
      "loss": 0.036,
      "step": 9278
    },
    {
      "epoch": 0.6724643983041635,
      "grad_norm": 1.3937122821807861,
      "learning_rate": 6.552648742662511e-05,
      "loss": 0.0913,
      "step": 9279
    },
    {
      "epoch": 0.6725368699496322,
      "grad_norm": 2.31024432182312,
      "learning_rate": 6.551199362272628e-05,
      "loss": 0.0677,
      "step": 9280
    },
    {
      "epoch": 0.6726093415951009,
      "grad_norm": 1.105439305305481,
      "learning_rate": 6.549749981882745e-05,
      "loss": 0.0262,
      "step": 9281
    },
    {
      "epoch": 0.6726818132405696,
      "grad_norm": 1.4636436700820923,
      "learning_rate": 6.548300601492861e-05,
      "loss": 0.0557,
      "step": 9282
    },
    {
      "epoch": 0.6727542848860384,
      "grad_norm": 0.6341388821601868,
      "learning_rate": 6.546851221102979e-05,
      "loss": 0.0257,
      "step": 9283
    },
    {
      "epoch": 0.672826756531507,
      "grad_norm": 0.08273741602897644,
      "learning_rate": 6.545401840713096e-05,
      "loss": 0.0008,
      "step": 9284
    },
    {
      "epoch": 0.6728992281769758,
      "grad_norm": 2.2722434997558594,
      "learning_rate": 6.543952460323212e-05,
      "loss": 0.047,
      "step": 9285
    },
    {
      "epoch": 0.6729716998224444,
      "grad_norm": 1.3538566827774048,
      "learning_rate": 6.542503079933329e-05,
      "loss": 0.0657,
      "step": 9286
    },
    {
      "epoch": 0.6730441714679132,
      "grad_norm": 1.8736344575881958,
      "learning_rate": 6.541053699543446e-05,
      "loss": 0.0689,
      "step": 9287
    },
    {
      "epoch": 0.6731166431133819,
      "grad_norm": 1.2404199838638306,
      "learning_rate": 6.539604319153562e-05,
      "loss": 0.0419,
      "step": 9288
    },
    {
      "epoch": 0.6731891147588506,
      "grad_norm": 1.3150594234466553,
      "learning_rate": 6.538154938763679e-05,
      "loss": 0.0284,
      "step": 9289
    },
    {
      "epoch": 0.6732615864043193,
      "grad_norm": 1.4149898290634155,
      "learning_rate": 6.536705558373796e-05,
      "loss": 0.0968,
      "step": 9290
    },
    {
      "epoch": 0.6733340580497881,
      "grad_norm": 0.053429048508405685,
      "learning_rate": 6.535256177983911e-05,
      "loss": 0.0007,
      "step": 9291
    },
    {
      "epoch": 0.6734065296952567,
      "grad_norm": 0.7572848796844482,
      "learning_rate": 6.533806797594028e-05,
      "loss": 0.0148,
      "step": 9292
    },
    {
      "epoch": 0.6734790013407255,
      "grad_norm": 3.1288249492645264,
      "learning_rate": 6.532357417204145e-05,
      "loss": 0.0756,
      "step": 9293
    },
    {
      "epoch": 0.6735514729861941,
      "grad_norm": 1.7151474952697754,
      "learning_rate": 6.530908036814262e-05,
      "loss": 0.1098,
      "step": 9294
    },
    {
      "epoch": 0.6736239446316629,
      "grad_norm": 0.844429075717926,
      "learning_rate": 6.529458656424379e-05,
      "loss": 0.0391,
      "step": 9295
    },
    {
      "epoch": 0.6736964162771316,
      "grad_norm": 1.7006689310073853,
      "learning_rate": 6.528009276034496e-05,
      "loss": 0.0539,
      "step": 9296
    },
    {
      "epoch": 0.6737688879226003,
      "grad_norm": 2.0675978660583496,
      "learning_rate": 6.526559895644613e-05,
      "loss": 0.0275,
      "step": 9297
    },
    {
      "epoch": 0.673841359568069,
      "grad_norm": 4.491079330444336,
      "learning_rate": 6.525110515254729e-05,
      "loss": 0.0273,
      "step": 9298
    },
    {
      "epoch": 0.6739138312135377,
      "grad_norm": 1.0293996334075928,
      "learning_rate": 6.523661134864846e-05,
      "loss": 0.0452,
      "step": 9299
    },
    {
      "epoch": 0.6739863028590064,
      "grad_norm": 0.9252052903175354,
      "learning_rate": 6.522211754474963e-05,
      "loss": 0.0308,
      "step": 9300
    },
    {
      "epoch": 0.6740587745044752,
      "grad_norm": 1.029793620109558,
      "learning_rate": 6.520762374085079e-05,
      "loss": 0.0877,
      "step": 9301
    },
    {
      "epoch": 0.6741312461499438,
      "grad_norm": 1.3056113719940186,
      "learning_rate": 6.519312993695196e-05,
      "loss": 0.0027,
      "step": 9302
    },
    {
      "epoch": 0.6742037177954125,
      "grad_norm": 3.072183609008789,
      "learning_rate": 6.517863613305313e-05,
      "loss": 0.0899,
      "step": 9303
    },
    {
      "epoch": 0.6742761894408813,
      "grad_norm": 0.07991167902946472,
      "learning_rate": 6.516414232915428e-05,
      "loss": 0.0016,
      "step": 9304
    },
    {
      "epoch": 0.6743486610863499,
      "grad_norm": 0.928885281085968,
      "learning_rate": 6.514964852525545e-05,
      "loss": 0.0393,
      "step": 9305
    },
    {
      "epoch": 0.6744211327318187,
      "grad_norm": 0.6599005460739136,
      "learning_rate": 6.513515472135662e-05,
      "loss": 0.0183,
      "step": 9306
    },
    {
      "epoch": 0.6744936043772873,
      "grad_norm": 0.6840566396713257,
      "learning_rate": 6.512066091745779e-05,
      "loss": 0.0085,
      "step": 9307
    },
    {
      "epoch": 0.6745660760227561,
      "grad_norm": 2.3574390411376953,
      "learning_rate": 6.510616711355896e-05,
      "loss": 0.1699,
      "step": 9308
    },
    {
      "epoch": 0.6746385476682248,
      "grad_norm": 0.7202348113059998,
      "learning_rate": 6.509167330966013e-05,
      "loss": 0.0549,
      "step": 9309
    },
    {
      "epoch": 0.6747110193136935,
      "grad_norm": 0.2807731032371521,
      "learning_rate": 6.507717950576129e-05,
      "loss": 0.0102,
      "step": 9310
    },
    {
      "epoch": 0.6747834909591622,
      "grad_norm": 1.800241470336914,
      "learning_rate": 6.506268570186246e-05,
      "loss": 0.0235,
      "step": 9311
    },
    {
      "epoch": 0.674855962604631,
      "grad_norm": 0.06357256323099136,
      "learning_rate": 6.504819189796363e-05,
      "loss": 0.0016,
      "step": 9312
    },
    {
      "epoch": 0.6749284342500996,
      "grad_norm": 1.8641537427902222,
      "learning_rate": 6.503369809406479e-05,
      "loss": 0.0149,
      "step": 9313
    },
    {
      "epoch": 0.6750009058955684,
      "grad_norm": 0.9930700063705444,
      "learning_rate": 6.501920429016596e-05,
      "loss": 0.0216,
      "step": 9314
    },
    {
      "epoch": 0.675073377541037,
      "grad_norm": 0.5816619992256165,
      "learning_rate": 6.500471048626713e-05,
      "loss": 0.0352,
      "step": 9315
    },
    {
      "epoch": 0.6751458491865058,
      "grad_norm": 0.8518078923225403,
      "learning_rate": 6.499021668236828e-05,
      "loss": 0.0245,
      "step": 9316
    },
    {
      "epoch": 0.6752183208319745,
      "grad_norm": 1.6440677642822266,
      "learning_rate": 6.497572287846945e-05,
      "loss": 0.048,
      "step": 9317
    },
    {
      "epoch": 0.6752907924774432,
      "grad_norm": 2.9373679161071777,
      "learning_rate": 6.496122907457062e-05,
      "loss": 0.0621,
      "step": 9318
    },
    {
      "epoch": 0.6753632641229119,
      "grad_norm": 0.18968640267848969,
      "learning_rate": 6.494673527067179e-05,
      "loss": 0.0089,
      "step": 9319
    },
    {
      "epoch": 0.6754357357683807,
      "grad_norm": 1.5874985456466675,
      "learning_rate": 6.493224146677296e-05,
      "loss": 0.0278,
      "step": 9320
    },
    {
      "epoch": 0.6755082074138493,
      "grad_norm": 1.2481460571289062,
      "learning_rate": 6.491774766287413e-05,
      "loss": 0.0536,
      "step": 9321
    },
    {
      "epoch": 0.6755806790593181,
      "grad_norm": 1.7582976818084717,
      "learning_rate": 6.490325385897529e-05,
      "loss": 0.1222,
      "step": 9322
    },
    {
      "epoch": 0.6756531507047867,
      "grad_norm": 0.7948431372642517,
      "learning_rate": 6.488876005507646e-05,
      "loss": 0.0247,
      "step": 9323
    },
    {
      "epoch": 0.6757256223502555,
      "grad_norm": 0.10580920428037643,
      "learning_rate": 6.487426625117763e-05,
      "loss": 0.0019,
      "step": 9324
    },
    {
      "epoch": 0.6757980939957242,
      "grad_norm": 1.378598928451538,
      "learning_rate": 6.485977244727879e-05,
      "loss": 0.045,
      "step": 9325
    },
    {
      "epoch": 0.6758705656411929,
      "grad_norm": 2.869624614715576,
      "learning_rate": 6.484527864337996e-05,
      "loss": 0.0561,
      "step": 9326
    },
    {
      "epoch": 0.6759430372866616,
      "grad_norm": 7.044346332550049,
      "learning_rate": 6.483078483948113e-05,
      "loss": 0.0673,
      "step": 9327
    },
    {
      "epoch": 0.6760155089321302,
      "grad_norm": 0.9916974306106567,
      "learning_rate": 6.481629103558228e-05,
      "loss": 0.0318,
      "step": 9328
    },
    {
      "epoch": 0.676087980577599,
      "grad_norm": 0.6592278480529785,
      "learning_rate": 6.480179723168345e-05,
      "loss": 0.01,
      "step": 9329
    },
    {
      "epoch": 0.6761604522230678,
      "grad_norm": 0.47242090106010437,
      "learning_rate": 6.478730342778464e-05,
      "loss": 0.0071,
      "step": 9330
    },
    {
      "epoch": 0.6762329238685364,
      "grad_norm": 0.3448185324668884,
      "learning_rate": 6.477280962388579e-05,
      "loss": 0.0097,
      "step": 9331
    },
    {
      "epoch": 0.6763053955140051,
      "grad_norm": 3.8316495418548584,
      "learning_rate": 6.475831581998696e-05,
      "loss": 0.0717,
      "step": 9332
    },
    {
      "epoch": 0.6763778671594739,
      "grad_norm": 0.6396363973617554,
      "learning_rate": 6.474382201608813e-05,
      "loss": 0.0316,
      "step": 9333
    },
    {
      "epoch": 0.6764503388049425,
      "grad_norm": 2.456374406814575,
      "learning_rate": 6.472932821218929e-05,
      "loss": 0.105,
      "step": 9334
    },
    {
      "epoch": 0.6765228104504113,
      "grad_norm": 1.612652063369751,
      "learning_rate": 6.471483440829046e-05,
      "loss": 0.0334,
      "step": 9335
    },
    {
      "epoch": 0.6765952820958799,
      "grad_norm": 0.4373684525489807,
      "learning_rate": 6.470034060439163e-05,
      "loss": 0.0088,
      "step": 9336
    },
    {
      "epoch": 0.6766677537413487,
      "grad_norm": 1.5494807958602905,
      "learning_rate": 6.468584680049279e-05,
      "loss": 0.0858,
      "step": 9337
    },
    {
      "epoch": 0.6767402253868174,
      "grad_norm": 0.46742525696754456,
      "learning_rate": 6.467135299659396e-05,
      "loss": 0.008,
      "step": 9338
    },
    {
      "epoch": 0.6768126970322861,
      "grad_norm": 1.4115513563156128,
      "learning_rate": 6.465685919269513e-05,
      "loss": 0.0372,
      "step": 9339
    },
    {
      "epoch": 0.6768851686777548,
      "grad_norm": 0.9938063621520996,
      "learning_rate": 6.46423653887963e-05,
      "loss": 0.0396,
      "step": 9340
    },
    {
      "epoch": 0.6769576403232236,
      "grad_norm": 0.4466671049594879,
      "learning_rate": 6.462787158489747e-05,
      "loss": 0.0063,
      "step": 9341
    },
    {
      "epoch": 0.6770301119686922,
      "grad_norm": 1.0154714584350586,
      "learning_rate": 6.461337778099864e-05,
      "loss": 0.0134,
      "step": 9342
    },
    {
      "epoch": 0.677102583614161,
      "grad_norm": 1.3135782480239868,
      "learning_rate": 6.459888397709979e-05,
      "loss": 0.0261,
      "step": 9343
    },
    {
      "epoch": 0.6771750552596296,
      "grad_norm": 0.29649898409843445,
      "learning_rate": 6.458439017320096e-05,
      "loss": 0.0057,
      "step": 9344
    },
    {
      "epoch": 0.6772475269050984,
      "grad_norm": 2.3604907989501953,
      "learning_rate": 6.456989636930213e-05,
      "loss": 0.0429,
      "step": 9345
    },
    {
      "epoch": 0.6773199985505671,
      "grad_norm": 1.5663940906524658,
      "learning_rate": 6.455540256540329e-05,
      "loss": 0.0417,
      "step": 9346
    },
    {
      "epoch": 0.6773924701960358,
      "grad_norm": 0.49743297696113586,
      "learning_rate": 6.454090876150446e-05,
      "loss": 0.0044,
      "step": 9347
    },
    {
      "epoch": 0.6774649418415045,
      "grad_norm": 0.49433207511901855,
      "learning_rate": 6.452641495760563e-05,
      "loss": 0.0151,
      "step": 9348
    },
    {
      "epoch": 0.6775374134869733,
      "grad_norm": 2.6150033473968506,
      "learning_rate": 6.451192115370679e-05,
      "loss": 0.075,
      "step": 9349
    },
    {
      "epoch": 0.6776098851324419,
      "grad_norm": 1.7765969038009644,
      "learning_rate": 6.449742734980796e-05,
      "loss": 0.0486,
      "step": 9350
    },
    {
      "epoch": 0.6776823567779107,
      "grad_norm": 5.6293416023254395,
      "learning_rate": 6.448293354590913e-05,
      "loss": 0.1088,
      "step": 9351
    },
    {
      "epoch": 0.6777548284233793,
      "grad_norm": 1.1726694107055664,
      "learning_rate": 6.44684397420103e-05,
      "loss": 0.0366,
      "step": 9352
    },
    {
      "epoch": 0.6778273000688481,
      "grad_norm": 1.5588912963867188,
      "learning_rate": 6.445394593811147e-05,
      "loss": 0.0984,
      "step": 9353
    },
    {
      "epoch": 0.6778997717143168,
      "grad_norm": 1.6174763441085815,
      "learning_rate": 6.443945213421264e-05,
      "loss": 0.0264,
      "step": 9354
    },
    {
      "epoch": 0.6779722433597855,
      "grad_norm": 1.0333077907562256,
      "learning_rate": 6.442495833031379e-05,
      "loss": 0.0276,
      "step": 9355
    },
    {
      "epoch": 0.6780447150052542,
      "grad_norm": 3.7889907360076904,
      "learning_rate": 6.441046452641496e-05,
      "loss": 0.1296,
      "step": 9356
    },
    {
      "epoch": 0.678117186650723,
      "grad_norm": 2.1390137672424316,
      "learning_rate": 6.439597072251613e-05,
      "loss": 0.112,
      "step": 9357
    },
    {
      "epoch": 0.6781896582961916,
      "grad_norm": 1.5965828895568848,
      "learning_rate": 6.438147691861729e-05,
      "loss": 0.0478,
      "step": 9358
    },
    {
      "epoch": 0.6782621299416604,
      "grad_norm": 1.398094892501831,
      "learning_rate": 6.436698311471846e-05,
      "loss": 0.0428,
      "step": 9359
    },
    {
      "epoch": 0.678334601587129,
      "grad_norm": 1.3066920042037964,
      "learning_rate": 6.435248931081963e-05,
      "loss": 0.0429,
      "step": 9360
    },
    {
      "epoch": 0.6784070732325977,
      "grad_norm": 0.602389395236969,
      "learning_rate": 6.433799550692079e-05,
      "loss": 0.0048,
      "step": 9361
    },
    {
      "epoch": 0.6784795448780665,
      "grad_norm": 0.9071775674819946,
      "learning_rate": 6.432350170302196e-05,
      "loss": 0.0497,
      "step": 9362
    },
    {
      "epoch": 0.6785520165235351,
      "grad_norm": 7.52434778213501,
      "learning_rate": 6.430900789912313e-05,
      "loss": 0.066,
      "step": 9363
    },
    {
      "epoch": 0.6786244881690039,
      "grad_norm": 1.1810041666030884,
      "learning_rate": 6.42945140952243e-05,
      "loss": 0.0372,
      "step": 9364
    },
    {
      "epoch": 0.6786969598144725,
      "grad_norm": 3.6770870685577393,
      "learning_rate": 6.428002029132547e-05,
      "loss": 0.0982,
      "step": 9365
    },
    {
      "epoch": 0.6787694314599413,
      "grad_norm": 0.3811511695384979,
      "learning_rate": 6.426552648742664e-05,
      "loss": 0.0082,
      "step": 9366
    },
    {
      "epoch": 0.67884190310541,
      "grad_norm": 2.0955123901367188,
      "learning_rate": 6.425103268352779e-05,
      "loss": 0.0562,
      "step": 9367
    },
    {
      "epoch": 0.6789143747508787,
      "grad_norm": 1.2420529127120972,
      "learning_rate": 6.423653887962896e-05,
      "loss": 0.0138,
      "step": 9368
    },
    {
      "epoch": 0.6789868463963474,
      "grad_norm": 0.7902721166610718,
      "learning_rate": 6.422204507573013e-05,
      "loss": 0.0225,
      "step": 9369
    },
    {
      "epoch": 0.6790593180418162,
      "grad_norm": 0.8964207172393799,
      "learning_rate": 6.420755127183129e-05,
      "loss": 0.0202,
      "step": 9370
    },
    {
      "epoch": 0.6791317896872848,
      "grad_norm": 1.2849745750427246,
      "learning_rate": 6.419305746793246e-05,
      "loss": 0.0551,
      "step": 9371
    },
    {
      "epoch": 0.6792042613327536,
      "grad_norm": 2.405874252319336,
      "learning_rate": 6.417856366403363e-05,
      "loss": 0.0791,
      "step": 9372
    },
    {
      "epoch": 0.6792767329782222,
      "grad_norm": 0.813023567199707,
      "learning_rate": 6.416406986013478e-05,
      "loss": 0.0457,
      "step": 9373
    },
    {
      "epoch": 0.679349204623691,
      "grad_norm": 0.9382805824279785,
      "learning_rate": 6.414957605623595e-05,
      "loss": 0.0258,
      "step": 9374
    },
    {
      "epoch": 0.6794216762691597,
      "grad_norm": 0.8988068699836731,
      "learning_rate": 6.413508225233712e-05,
      "loss": 0.0256,
      "step": 9375
    },
    {
      "epoch": 0.6794941479146284,
      "grad_norm": 5.731899261474609,
      "learning_rate": 6.41205884484383e-05,
      "loss": 0.1378,
      "step": 9376
    },
    {
      "epoch": 0.6795666195600971,
      "grad_norm": 2.758647918701172,
      "learning_rate": 6.410609464453946e-05,
      "loss": 0.061,
      "step": 9377
    },
    {
      "epoch": 0.6796390912055659,
      "grad_norm": 1.173035740852356,
      "learning_rate": 6.409160084064063e-05,
      "loss": 0.0457,
      "step": 9378
    },
    {
      "epoch": 0.6797115628510345,
      "grad_norm": 0.4243888556957245,
      "learning_rate": 6.40771070367418e-05,
      "loss": 0.0073,
      "step": 9379
    },
    {
      "epoch": 0.6797840344965033,
      "grad_norm": 1.2050565481185913,
      "learning_rate": 6.406261323284296e-05,
      "loss": 0.0449,
      "step": 9380
    },
    {
      "epoch": 0.6798565061419719,
      "grad_norm": 0.8879191875457764,
      "learning_rate": 6.404811942894413e-05,
      "loss": 0.0223,
      "step": 9381
    },
    {
      "epoch": 0.6799289777874407,
      "grad_norm": 1.470603585243225,
      "learning_rate": 6.40336256250453e-05,
      "loss": 0.0179,
      "step": 9382
    },
    {
      "epoch": 0.6800014494329094,
      "grad_norm": 1.659946322441101,
      "learning_rate": 6.401913182114646e-05,
      "loss": 0.0285,
      "step": 9383
    },
    {
      "epoch": 0.680073921078378,
      "grad_norm": 0.4227689802646637,
      "learning_rate": 6.400463801724763e-05,
      "loss": 0.0112,
      "step": 9384
    },
    {
      "epoch": 0.6801463927238468,
      "grad_norm": 1.1500451564788818,
      "learning_rate": 6.39901442133488e-05,
      "loss": 0.0765,
      "step": 9385
    },
    {
      "epoch": 0.6802188643693156,
      "grad_norm": 0.0445474237203598,
      "learning_rate": 6.397565040944995e-05,
      "loss": 0.0002,
      "step": 9386
    },
    {
      "epoch": 0.6802913360147842,
      "grad_norm": 0.1990276277065277,
      "learning_rate": 6.396115660555112e-05,
      "loss": 0.0017,
      "step": 9387
    },
    {
      "epoch": 0.680363807660253,
      "grad_norm": 2.9569733142852783,
      "learning_rate": 6.394666280165231e-05,
      "loss": 0.0809,
      "step": 9388
    },
    {
      "epoch": 0.6804362793057216,
      "grad_norm": 0.7882640957832336,
      "learning_rate": 6.393216899775346e-05,
      "loss": 0.0202,
      "step": 9389
    },
    {
      "epoch": 0.6805087509511903,
      "grad_norm": 4.533348083496094,
      "learning_rate": 6.391767519385463e-05,
      "loss": 0.0269,
      "step": 9390
    },
    {
      "epoch": 0.6805812225966591,
      "grad_norm": 2.1361262798309326,
      "learning_rate": 6.39031813899558e-05,
      "loss": 0.1312,
      "step": 9391
    },
    {
      "epoch": 0.6806536942421277,
      "grad_norm": 0.5472638010978699,
      "learning_rate": 6.388868758605696e-05,
      "loss": 0.0091,
      "step": 9392
    },
    {
      "epoch": 0.6807261658875965,
      "grad_norm": 3.409444808959961,
      "learning_rate": 6.387419378215813e-05,
      "loss": 0.076,
      "step": 9393
    },
    {
      "epoch": 0.6807986375330652,
      "grad_norm": 1.5257668495178223,
      "learning_rate": 6.38596999782593e-05,
      "loss": 0.0276,
      "step": 9394
    },
    {
      "epoch": 0.6808711091785339,
      "grad_norm": 0.24177509546279907,
      "learning_rate": 6.384520617436046e-05,
      "loss": 0.0082,
      "step": 9395
    },
    {
      "epoch": 0.6809435808240026,
      "grad_norm": 2.776951551437378,
      "learning_rate": 6.383071237046163e-05,
      "loss": 0.0874,
      "step": 9396
    },
    {
      "epoch": 0.6810160524694713,
      "grad_norm": 3.0478014945983887,
      "learning_rate": 6.38162185665628e-05,
      "loss": 0.0794,
      "step": 9397
    },
    {
      "epoch": 0.68108852411494,
      "grad_norm": 0.9490275979042053,
      "learning_rate": 6.380172476266397e-05,
      "loss": 0.0447,
      "step": 9398
    },
    {
      "epoch": 0.6811609957604088,
      "grad_norm": 1.4088772535324097,
      "learning_rate": 6.378723095876514e-05,
      "loss": 0.1544,
      "step": 9399
    },
    {
      "epoch": 0.6812334674058774,
      "grad_norm": 2.061342477798462,
      "learning_rate": 6.377273715486631e-05,
      "loss": 0.1284,
      "step": 9400
    },
    {
      "epoch": 0.6813059390513462,
      "grad_norm": 0.16475923359394073,
      "learning_rate": 6.375824335096746e-05,
      "loss": 0.0041,
      "step": 9401
    },
    {
      "epoch": 0.6813784106968148,
      "grad_norm": 0.4284669756889343,
      "learning_rate": 6.374374954706863e-05,
      "loss": 0.0116,
      "step": 9402
    },
    {
      "epoch": 0.6814508823422836,
      "grad_norm": 1.2741942405700684,
      "learning_rate": 6.37292557431698e-05,
      "loss": 0.0749,
      "step": 9403
    },
    {
      "epoch": 0.6815233539877523,
      "grad_norm": 1.1432207822799683,
      "learning_rate": 6.371476193927096e-05,
      "loss": 0.0586,
      "step": 9404
    },
    {
      "epoch": 0.681595825633221,
      "grad_norm": 2.178725481033325,
      "learning_rate": 6.370026813537213e-05,
      "loss": 0.0574,
      "step": 9405
    },
    {
      "epoch": 0.6816682972786897,
      "grad_norm": 3.0195016860961914,
      "learning_rate": 6.36857743314733e-05,
      "loss": 0.0994,
      "step": 9406
    },
    {
      "epoch": 0.6817407689241585,
      "grad_norm": 1.3035210371017456,
      "learning_rate": 6.367128052757446e-05,
      "loss": 0.0534,
      "step": 9407
    },
    {
      "epoch": 0.6818132405696271,
      "grad_norm": 6.398419380187988,
      "learning_rate": 6.365678672367563e-05,
      "loss": 0.0507,
      "step": 9408
    },
    {
      "epoch": 0.6818857122150959,
      "grad_norm": 1.8836097717285156,
      "learning_rate": 6.36422929197768e-05,
      "loss": 0.0862,
      "step": 9409
    },
    {
      "epoch": 0.6819581838605645,
      "grad_norm": 0.9304128885269165,
      "learning_rate": 6.362779911587797e-05,
      "loss": 0.0356,
      "step": 9410
    },
    {
      "epoch": 0.6820306555060333,
      "grad_norm": 6.382404804229736,
      "learning_rate": 6.361330531197914e-05,
      "loss": 0.1378,
      "step": 9411
    },
    {
      "epoch": 0.682103127151502,
      "grad_norm": 2.26064395904541,
      "learning_rate": 6.359881150808031e-05,
      "loss": 0.0883,
      "step": 9412
    },
    {
      "epoch": 0.6821755987969707,
      "grad_norm": 1.1156752109527588,
      "learning_rate": 6.358431770418146e-05,
      "loss": 0.0529,
      "step": 9413
    },
    {
      "epoch": 0.6822480704424394,
      "grad_norm": 7.736636161804199,
      "learning_rate": 6.356982390028263e-05,
      "loss": 0.0359,
      "step": 9414
    },
    {
      "epoch": 0.6823205420879082,
      "grad_norm": 0.4059616029262543,
      "learning_rate": 6.35553300963838e-05,
      "loss": 0.0108,
      "step": 9415
    },
    {
      "epoch": 0.6823930137333768,
      "grad_norm": 1.4119826555252075,
      "learning_rate": 6.354083629248496e-05,
      "loss": 0.0546,
      "step": 9416
    },
    {
      "epoch": 0.6824654853788455,
      "grad_norm": 1.6301608085632324,
      "learning_rate": 6.352634248858613e-05,
      "loss": 0.0702,
      "step": 9417
    },
    {
      "epoch": 0.6825379570243142,
      "grad_norm": 3.574941635131836,
      "learning_rate": 6.35118486846873e-05,
      "loss": 0.0975,
      "step": 9418
    },
    {
      "epoch": 0.6826104286697829,
      "grad_norm": 2.4798390865325928,
      "learning_rate": 6.349735488078846e-05,
      "loss": 0.1099,
      "step": 9419
    },
    {
      "epoch": 0.6826829003152517,
      "grad_norm": 1.8772735595703125,
      "learning_rate": 6.348286107688963e-05,
      "loss": 0.0477,
      "step": 9420
    },
    {
      "epoch": 0.6827553719607203,
      "grad_norm": 1.3896538019180298,
      "learning_rate": 6.34683672729908e-05,
      "loss": 0.028,
      "step": 9421
    },
    {
      "epoch": 0.6828278436061891,
      "grad_norm": 1.242630958557129,
      "learning_rate": 6.345387346909197e-05,
      "loss": 0.081,
      "step": 9422
    },
    {
      "epoch": 0.6829003152516578,
      "grad_norm": 1.1526187658309937,
      "learning_rate": 6.343937966519314e-05,
      "loss": 0.0842,
      "step": 9423
    },
    {
      "epoch": 0.6829727868971265,
      "grad_norm": 1.7294301986694336,
      "learning_rate": 6.342488586129431e-05,
      "loss": 0.0468,
      "step": 9424
    },
    {
      "epoch": 0.6830452585425952,
      "grad_norm": 1.4403831958770752,
      "learning_rate": 6.341039205739546e-05,
      "loss": 0.0767,
      "step": 9425
    },
    {
      "epoch": 0.6831177301880639,
      "grad_norm": 2.332843780517578,
      "learning_rate": 6.339589825349663e-05,
      "loss": 0.0263,
      "step": 9426
    },
    {
      "epoch": 0.6831902018335326,
      "grad_norm": 0.48945972323417664,
      "learning_rate": 6.33814044495978e-05,
      "loss": 0.0164,
      "step": 9427
    },
    {
      "epoch": 0.6832626734790014,
      "grad_norm": 2.24316143989563,
      "learning_rate": 6.336691064569896e-05,
      "loss": 0.0749,
      "step": 9428
    },
    {
      "epoch": 0.68333514512447,
      "grad_norm": 2.5775115489959717,
      "learning_rate": 6.335241684180013e-05,
      "loss": 0.104,
      "step": 9429
    },
    {
      "epoch": 0.6834076167699388,
      "grad_norm": 0.1294686645269394,
      "learning_rate": 6.33379230379013e-05,
      "loss": 0.0106,
      "step": 9430
    },
    {
      "epoch": 0.6834800884154075,
      "grad_norm": 1.0494630336761475,
      "learning_rate": 6.332342923400246e-05,
      "loss": 0.0206,
      "step": 9431
    },
    {
      "epoch": 0.6835525600608762,
      "grad_norm": 0.3553417921066284,
      "learning_rate": 6.330893543010363e-05,
      "loss": 0.0093,
      "step": 9432
    },
    {
      "epoch": 0.6836250317063449,
      "grad_norm": 2.5124568939208984,
      "learning_rate": 6.32944416262048e-05,
      "loss": 0.1233,
      "step": 9433
    },
    {
      "epoch": 0.6836975033518136,
      "grad_norm": 3.2589380741119385,
      "learning_rate": 6.327994782230597e-05,
      "loss": 0.1052,
      "step": 9434
    },
    {
      "epoch": 0.6837699749972823,
      "grad_norm": 0.7987371683120728,
      "learning_rate": 6.326545401840714e-05,
      "loss": 0.0182,
      "step": 9435
    },
    {
      "epoch": 0.6838424466427511,
      "grad_norm": 0.5809184312820435,
      "learning_rate": 6.325096021450831e-05,
      "loss": 0.0228,
      "step": 9436
    },
    {
      "epoch": 0.6839149182882197,
      "grad_norm": 1.9081525802612305,
      "learning_rate": 6.323646641060946e-05,
      "loss": 0.0446,
      "step": 9437
    },
    {
      "epoch": 0.6839873899336885,
      "grad_norm": 0.8811498284339905,
      "learning_rate": 6.322197260671063e-05,
      "loss": 0.0109,
      "step": 9438
    },
    {
      "epoch": 0.6840598615791571,
      "grad_norm": 2.0688929557800293,
      "learning_rate": 6.32074788028118e-05,
      "loss": 0.0097,
      "step": 9439
    },
    {
      "epoch": 0.6841323332246259,
      "grad_norm": 0.5622225999832153,
      "learning_rate": 6.319298499891296e-05,
      "loss": 0.0171,
      "step": 9440
    },
    {
      "epoch": 0.6842048048700946,
      "grad_norm": 0.07632198184728622,
      "learning_rate": 6.317849119501413e-05,
      "loss": 0.0013,
      "step": 9441
    },
    {
      "epoch": 0.6842772765155632,
      "grad_norm": 0.5745964646339417,
      "learning_rate": 6.31639973911153e-05,
      "loss": 0.0226,
      "step": 9442
    },
    {
      "epoch": 0.684349748161032,
      "grad_norm": 1.271803379058838,
      "learning_rate": 6.314950358721646e-05,
      "loss": 0.0338,
      "step": 9443
    },
    {
      "epoch": 0.6844222198065008,
      "grad_norm": 1.6566821336746216,
      "learning_rate": 6.313500978331763e-05,
      "loss": 0.0451,
      "step": 9444
    },
    {
      "epoch": 0.6844946914519694,
      "grad_norm": 4.350915431976318,
      "learning_rate": 6.31205159794188e-05,
      "loss": 0.0881,
      "step": 9445
    },
    {
      "epoch": 0.6845671630974381,
      "grad_norm": 1.3473259210586548,
      "learning_rate": 6.310602217551997e-05,
      "loss": 0.0535,
      "step": 9446
    },
    {
      "epoch": 0.6846396347429068,
      "grad_norm": 1.9288854598999023,
      "learning_rate": 6.309152837162114e-05,
      "loss": 0.059,
      "step": 9447
    },
    {
      "epoch": 0.6847121063883755,
      "grad_norm": 1.6473535299301147,
      "learning_rate": 6.307703456772231e-05,
      "loss": 0.1114,
      "step": 9448
    },
    {
      "epoch": 0.6847845780338443,
      "grad_norm": 0.8051962852478027,
      "learning_rate": 6.306254076382346e-05,
      "loss": 0.0349,
      "step": 9449
    },
    {
      "epoch": 0.6848570496793129,
      "grad_norm": 0.21592755615711212,
      "learning_rate": 6.304804695992463e-05,
      "loss": 0.0074,
      "step": 9450
    },
    {
      "epoch": 0.6849295213247817,
      "grad_norm": 1.9049162864685059,
      "learning_rate": 6.30335531560258e-05,
      "loss": 0.0477,
      "step": 9451
    },
    {
      "epoch": 0.6850019929702504,
      "grad_norm": 2.62557315826416,
      "learning_rate": 6.301905935212696e-05,
      "loss": 0.0615,
      "step": 9452
    },
    {
      "epoch": 0.6850744646157191,
      "grad_norm": 1.7055209875106812,
      "learning_rate": 6.300456554822813e-05,
      "loss": 0.0248,
      "step": 9453
    },
    {
      "epoch": 0.6851469362611878,
      "grad_norm": 6.372060775756836,
      "learning_rate": 6.29900717443293e-05,
      "loss": 0.0728,
      "step": 9454
    },
    {
      "epoch": 0.6852194079066565,
      "grad_norm": 0.47946271300315857,
      "learning_rate": 6.297557794043046e-05,
      "loss": 0.0061,
      "step": 9455
    },
    {
      "epoch": 0.6852918795521252,
      "grad_norm": 2.4969546794891357,
      "learning_rate": 6.296108413653164e-05,
      "loss": 0.0864,
      "step": 9456
    },
    {
      "epoch": 0.685364351197594,
      "grad_norm": 1.473862886428833,
      "learning_rate": 6.294659033263281e-05,
      "loss": 0.035,
      "step": 9457
    },
    {
      "epoch": 0.6854368228430626,
      "grad_norm": 1.188027262687683,
      "learning_rate": 6.293209652873398e-05,
      "loss": 0.0782,
      "step": 9458
    },
    {
      "epoch": 0.6855092944885314,
      "grad_norm": 2.094102621078491,
      "learning_rate": 6.291760272483514e-05,
      "loss": 0.103,
      "step": 9459
    },
    {
      "epoch": 0.6855817661340001,
      "grad_norm": 0.2068656086921692,
      "learning_rate": 6.290310892093631e-05,
      "loss": 0.0057,
      "step": 9460
    },
    {
      "epoch": 0.6856542377794688,
      "grad_norm": 1.2213166952133179,
      "learning_rate": 6.288861511703748e-05,
      "loss": 0.0453,
      "step": 9461
    },
    {
      "epoch": 0.6857267094249375,
      "grad_norm": 1.4061647653579712,
      "learning_rate": 6.287412131313863e-05,
      "loss": 0.048,
      "step": 9462
    },
    {
      "epoch": 0.6857991810704062,
      "grad_norm": 0.1263582855463028,
      "learning_rate": 6.28596275092398e-05,
      "loss": 0.0016,
      "step": 9463
    },
    {
      "epoch": 0.6858716527158749,
      "grad_norm": 0.05761757120490074,
      "learning_rate": 6.284513370534097e-05,
      "loss": 0.001,
      "step": 9464
    },
    {
      "epoch": 0.6859441243613437,
      "grad_norm": 1.5354851484298706,
      "learning_rate": 6.283063990144213e-05,
      "loss": 0.047,
      "step": 9465
    },
    {
      "epoch": 0.6860165960068123,
      "grad_norm": 1.5734119415283203,
      "learning_rate": 6.28161460975433e-05,
      "loss": 0.0321,
      "step": 9466
    },
    {
      "epoch": 0.6860890676522811,
      "grad_norm": 0.669785737991333,
      "learning_rate": 6.280165229364447e-05,
      "loss": 0.0225,
      "step": 9467
    },
    {
      "epoch": 0.6861615392977497,
      "grad_norm": 2.719688892364502,
      "learning_rate": 6.278715848974564e-05,
      "loss": 0.0714,
      "step": 9468
    },
    {
      "epoch": 0.6862340109432185,
      "grad_norm": 0.276951402425766,
      "learning_rate": 6.277266468584681e-05,
      "loss": 0.0034,
      "step": 9469
    },
    {
      "epoch": 0.6863064825886872,
      "grad_norm": 1.530983567237854,
      "learning_rate": 6.275817088194798e-05,
      "loss": 0.0643,
      "step": 9470
    },
    {
      "epoch": 0.6863789542341558,
      "grad_norm": 1.2434864044189453,
      "learning_rate": 6.274367707804914e-05,
      "loss": 0.0395,
      "step": 9471
    },
    {
      "epoch": 0.6864514258796246,
      "grad_norm": 1.181075096130371,
      "learning_rate": 6.272918327415031e-05,
      "loss": 0.0631,
      "step": 9472
    },
    {
      "epoch": 0.6865238975250934,
      "grad_norm": 0.27747511863708496,
      "learning_rate": 6.271468947025148e-05,
      "loss": 0.0051,
      "step": 9473
    },
    {
      "epoch": 0.686596369170562,
      "grad_norm": 0.8800508975982666,
      "learning_rate": 6.270019566635263e-05,
      "loss": 0.0428,
      "step": 9474
    },
    {
      "epoch": 0.6866688408160307,
      "grad_norm": 4.976923942565918,
      "learning_rate": 6.26857018624538e-05,
      "loss": 0.0854,
      "step": 9475
    },
    {
      "epoch": 0.6867413124614994,
      "grad_norm": 0.4871882498264313,
      "learning_rate": 6.267120805855497e-05,
      "loss": 0.0295,
      "step": 9476
    },
    {
      "epoch": 0.6868137841069681,
      "grad_norm": 3.149550199508667,
      "learning_rate": 6.265671425465613e-05,
      "loss": 0.1432,
      "step": 9477
    },
    {
      "epoch": 0.6868862557524369,
      "grad_norm": 3.7746481895446777,
      "learning_rate": 6.26422204507573e-05,
      "loss": 0.0945,
      "step": 9478
    },
    {
      "epoch": 0.6869587273979055,
      "grad_norm": 0.9949992895126343,
      "learning_rate": 6.262772664685847e-05,
      "loss": 0.0328,
      "step": 9479
    },
    {
      "epoch": 0.6870311990433743,
      "grad_norm": 0.8714317679405212,
      "learning_rate": 6.261323284295964e-05,
      "loss": 0.0192,
      "step": 9480
    },
    {
      "epoch": 0.687103670688843,
      "grad_norm": 3.275054931640625,
      "learning_rate": 6.259873903906081e-05,
      "loss": 0.0895,
      "step": 9481
    },
    {
      "epoch": 0.6871761423343117,
      "grad_norm": 0.3752672076225281,
      "learning_rate": 6.258424523516198e-05,
      "loss": 0.0071,
      "step": 9482
    },
    {
      "epoch": 0.6872486139797804,
      "grad_norm": 0.12213627994060516,
      "learning_rate": 6.256975143126314e-05,
      "loss": 0.0027,
      "step": 9483
    },
    {
      "epoch": 0.6873210856252491,
      "grad_norm": 4.054811954498291,
      "learning_rate": 6.25552576273643e-05,
      "loss": 0.1823,
      "step": 9484
    },
    {
      "epoch": 0.6873935572707178,
      "grad_norm": 1.0398045778274536,
      "learning_rate": 6.254076382346548e-05,
      "loss": 0.0541,
      "step": 9485
    },
    {
      "epoch": 0.6874660289161866,
      "grad_norm": 0.7939443588256836,
      "learning_rate": 6.252627001956663e-05,
      "loss": 0.0296,
      "step": 9486
    },
    {
      "epoch": 0.6875385005616552,
      "grad_norm": 3.5627946853637695,
      "learning_rate": 6.25117762156678e-05,
      "loss": 0.0739,
      "step": 9487
    },
    {
      "epoch": 0.687610972207124,
      "grad_norm": 1.7582244873046875,
      "learning_rate": 6.249728241176897e-05,
      "loss": 0.093,
      "step": 9488
    },
    {
      "epoch": 0.6876834438525927,
      "grad_norm": 1.8550223112106323,
      "learning_rate": 6.248278860787013e-05,
      "loss": 0.0631,
      "step": 9489
    },
    {
      "epoch": 0.6877559154980614,
      "grad_norm": 1.9069817066192627,
      "learning_rate": 6.24682948039713e-05,
      "loss": 0.0322,
      "step": 9490
    },
    {
      "epoch": 0.6878283871435301,
      "grad_norm": 0.2267046570777893,
      "learning_rate": 6.245380100007247e-05,
      "loss": 0.0028,
      "step": 9491
    },
    {
      "epoch": 0.6879008587889988,
      "grad_norm": 1.7557423114776611,
      "learning_rate": 6.243930719617364e-05,
      "loss": 0.0504,
      "step": 9492
    },
    {
      "epoch": 0.6879733304344675,
      "grad_norm": 0.03597388416528702,
      "learning_rate": 6.242481339227481e-05,
      "loss": 0.0008,
      "step": 9493
    },
    {
      "epoch": 0.6880458020799363,
      "grad_norm": 1.3588069677352905,
      "learning_rate": 6.241031958837598e-05,
      "loss": 0.0484,
      "step": 9494
    },
    {
      "epoch": 0.6881182737254049,
      "grad_norm": 1.1674455404281616,
      "learning_rate": 6.239582578447714e-05,
      "loss": 0.0334,
      "step": 9495
    },
    {
      "epoch": 0.6881907453708737,
      "grad_norm": 3.9483449459075928,
      "learning_rate": 6.23813319805783e-05,
      "loss": 0.1065,
      "step": 9496
    },
    {
      "epoch": 0.6882632170163424,
      "grad_norm": 0.8794748187065125,
      "learning_rate": 6.236683817667948e-05,
      "loss": 0.0276,
      "step": 9497
    },
    {
      "epoch": 0.688335688661811,
      "grad_norm": 2.2097504138946533,
      "learning_rate": 6.235234437278063e-05,
      "loss": 0.0391,
      "step": 9498
    },
    {
      "epoch": 0.6884081603072798,
      "grad_norm": 0.07628825306892395,
      "learning_rate": 6.23378505688818e-05,
      "loss": 0.0015,
      "step": 9499
    },
    {
      "epoch": 0.6884806319527484,
      "grad_norm": 0.4763091802597046,
      "learning_rate": 6.232335676498297e-05,
      "loss": 0.0278,
      "step": 9500
    },
    {
      "epoch": 0.6885531035982172,
      "grad_norm": 2.6879706382751465,
      "learning_rate": 6.230886296108413e-05,
      "loss": 0.1259,
      "step": 9501
    },
    {
      "epoch": 0.688625575243686,
      "grad_norm": 1.6002651453018188,
      "learning_rate": 6.22943691571853e-05,
      "loss": 0.0215,
      "step": 9502
    },
    {
      "epoch": 0.6886980468891546,
      "grad_norm": 3.3649098873138428,
      "learning_rate": 6.227987535328648e-05,
      "loss": 0.153,
      "step": 9503
    },
    {
      "epoch": 0.6887705185346233,
      "grad_norm": 2.7700934410095215,
      "learning_rate": 6.226538154938764e-05,
      "loss": 0.1048,
      "step": 9504
    },
    {
      "epoch": 0.688842990180092,
      "grad_norm": 1.866719365119934,
      "learning_rate": 6.225088774548881e-05,
      "loss": 0.0642,
      "step": 9505
    },
    {
      "epoch": 0.6889154618255607,
      "grad_norm": 6.220841884613037,
      "learning_rate": 6.223639394158998e-05,
      "loss": 0.2244,
      "step": 9506
    },
    {
      "epoch": 0.6889879334710295,
      "grad_norm": 2.7912185192108154,
      "learning_rate": 6.222190013769114e-05,
      "loss": 0.1111,
      "step": 9507
    },
    {
      "epoch": 0.6890604051164981,
      "grad_norm": 1.2546252012252808,
      "learning_rate": 6.22074063337923e-05,
      "loss": 0.0224,
      "step": 9508
    },
    {
      "epoch": 0.6891328767619669,
      "grad_norm": 1.0032374858856201,
      "learning_rate": 6.219291252989348e-05,
      "loss": 0.038,
      "step": 9509
    },
    {
      "epoch": 0.6892053484074356,
      "grad_norm": 3.1251468658447266,
      "learning_rate": 6.217841872599463e-05,
      "loss": 0.0873,
      "step": 9510
    },
    {
      "epoch": 0.6892778200529043,
      "grad_norm": 1.4978622198104858,
      "learning_rate": 6.21639249220958e-05,
      "loss": 0.0697,
      "step": 9511
    },
    {
      "epoch": 0.689350291698373,
      "grad_norm": 1.4893162250518799,
      "learning_rate": 6.214943111819697e-05,
      "loss": 0.0651,
      "step": 9512
    },
    {
      "epoch": 0.6894227633438417,
      "grad_norm": 1.0575621128082275,
      "learning_rate": 6.213493731429814e-05,
      "loss": 0.0228,
      "step": 9513
    },
    {
      "epoch": 0.6894952349893104,
      "grad_norm": 1.357246994972229,
      "learning_rate": 6.212044351039931e-05,
      "loss": 0.0359,
      "step": 9514
    },
    {
      "epoch": 0.6895677066347792,
      "grad_norm": 1.7301297187805176,
      "learning_rate": 6.210594970650048e-05,
      "loss": 0.0923,
      "step": 9515
    },
    {
      "epoch": 0.6896401782802478,
      "grad_norm": 0.8327244520187378,
      "learning_rate": 6.209145590260164e-05,
      "loss": 0.0313,
      "step": 9516
    },
    {
      "epoch": 0.6897126499257166,
      "grad_norm": 0.7203262448310852,
      "learning_rate": 6.207696209870281e-05,
      "loss": 0.0226,
      "step": 9517
    },
    {
      "epoch": 0.6897851215711853,
      "grad_norm": 0.6422759890556335,
      "learning_rate": 6.206246829480398e-05,
      "loss": 0.023,
      "step": 9518
    },
    {
      "epoch": 0.689857593216654,
      "grad_norm": 2.47298526763916,
      "learning_rate": 6.204797449090514e-05,
      "loss": 0.0953,
      "step": 9519
    },
    {
      "epoch": 0.6899300648621227,
      "grad_norm": 1.6647528409957886,
      "learning_rate": 6.20334806870063e-05,
      "loss": 0.0281,
      "step": 9520
    },
    {
      "epoch": 0.6900025365075914,
      "grad_norm": 0.6038795709609985,
      "learning_rate": 6.201898688310748e-05,
      "loss": 0.0221,
      "step": 9521
    },
    {
      "epoch": 0.6900750081530601,
      "grad_norm": 1.7856848239898682,
      "learning_rate": 6.200449307920863e-05,
      "loss": 0.1133,
      "step": 9522
    },
    {
      "epoch": 0.6901474797985289,
      "grad_norm": 1.4414379596710205,
      "learning_rate": 6.19899992753098e-05,
      "loss": 0.0371,
      "step": 9523
    },
    {
      "epoch": 0.6902199514439975,
      "grad_norm": 1.0530437231063843,
      "learning_rate": 6.197550547141097e-05,
      "loss": 0.0438,
      "step": 9524
    },
    {
      "epoch": 0.6902924230894663,
      "grad_norm": 1.8910983800888062,
      "learning_rate": 6.196101166751214e-05,
      "loss": 0.0537,
      "step": 9525
    },
    {
      "epoch": 0.690364894734935,
      "grad_norm": 0.8515897989273071,
      "learning_rate": 6.194651786361331e-05,
      "loss": 0.0346,
      "step": 9526
    },
    {
      "epoch": 0.6904373663804036,
      "grad_norm": 2.0102291107177734,
      "learning_rate": 6.193202405971448e-05,
      "loss": 0.0584,
      "step": 9527
    },
    {
      "epoch": 0.6905098380258724,
      "grad_norm": 0.9747049808502197,
      "learning_rate": 6.191753025581564e-05,
      "loss": 0.0208,
      "step": 9528
    },
    {
      "epoch": 0.690582309671341,
      "grad_norm": 1.2524387836456299,
      "learning_rate": 6.190303645191681e-05,
      "loss": 0.0559,
      "step": 9529
    },
    {
      "epoch": 0.6906547813168098,
      "grad_norm": 1.3046599626541138,
      "learning_rate": 6.188854264801798e-05,
      "loss": 0.0775,
      "step": 9530
    },
    {
      "epoch": 0.6907272529622785,
      "grad_norm": 1.2994166612625122,
      "learning_rate": 6.187404884411914e-05,
      "loss": 0.0409,
      "step": 9531
    },
    {
      "epoch": 0.6907997246077472,
      "grad_norm": 1.2317404747009277,
      "learning_rate": 6.18595550402203e-05,
      "loss": 0.037,
      "step": 9532
    },
    {
      "epoch": 0.6908721962532159,
      "grad_norm": 0.8202106356620789,
      "learning_rate": 6.184506123632148e-05,
      "loss": 0.0263,
      "step": 9533
    },
    {
      "epoch": 0.6909446678986847,
      "grad_norm": 0.44394779205322266,
      "learning_rate": 6.183056743242263e-05,
      "loss": 0.0124,
      "step": 9534
    },
    {
      "epoch": 0.6910171395441533,
      "grad_norm": 1.1770929098129272,
      "learning_rate": 6.18160736285238e-05,
      "loss": 0.0264,
      "step": 9535
    },
    {
      "epoch": 0.6910896111896221,
      "grad_norm": 3.1770074367523193,
      "learning_rate": 6.180157982462497e-05,
      "loss": 0.1036,
      "step": 9536
    },
    {
      "epoch": 0.6911620828350907,
      "grad_norm": 0.15757933259010315,
      "learning_rate": 6.178708602072614e-05,
      "loss": 0.0117,
      "step": 9537
    },
    {
      "epoch": 0.6912345544805595,
      "grad_norm": 1.8109235763549805,
      "learning_rate": 6.177259221682731e-05,
      "loss": 0.0483,
      "step": 9538
    },
    {
      "epoch": 0.6913070261260282,
      "grad_norm": 2.1125898361206055,
      "learning_rate": 6.175809841292848e-05,
      "loss": 0.1098,
      "step": 9539
    },
    {
      "epoch": 0.6913794977714969,
      "grad_norm": 1.9650211334228516,
      "learning_rate": 6.174360460902965e-05,
      "loss": 0.0696,
      "step": 9540
    },
    {
      "epoch": 0.6914519694169656,
      "grad_norm": 2.957792282104492,
      "learning_rate": 6.172911080513081e-05,
      "loss": 0.1327,
      "step": 9541
    },
    {
      "epoch": 0.6915244410624343,
      "grad_norm": 2.1469597816467285,
      "learning_rate": 6.171461700123198e-05,
      "loss": 0.0506,
      "step": 9542
    },
    {
      "epoch": 0.691596912707903,
      "grad_norm": 0.6093264818191528,
      "learning_rate": 6.170012319733315e-05,
      "loss": 0.0337,
      "step": 9543
    },
    {
      "epoch": 0.6916693843533718,
      "grad_norm": 0.4751523733139038,
      "learning_rate": 6.16856293934343e-05,
      "loss": 0.0193,
      "step": 9544
    },
    {
      "epoch": 0.6917418559988404,
      "grad_norm": 0.3715288043022156,
      "learning_rate": 6.167113558953548e-05,
      "loss": 0.0197,
      "step": 9545
    },
    {
      "epoch": 0.6918143276443092,
      "grad_norm": 0.3511042594909668,
      "learning_rate": 6.165664178563665e-05,
      "loss": 0.0062,
      "step": 9546
    },
    {
      "epoch": 0.6918867992897779,
      "grad_norm": 1.3315677642822266,
      "learning_rate": 6.16421479817378e-05,
      "loss": 0.0268,
      "step": 9547
    },
    {
      "epoch": 0.6919592709352466,
      "grad_norm": 1.8824360370635986,
      "learning_rate": 6.162765417783897e-05,
      "loss": 0.1,
      "step": 9548
    },
    {
      "epoch": 0.6920317425807153,
      "grad_norm": 0.696764349937439,
      "learning_rate": 6.161316037394014e-05,
      "loss": 0.0231,
      "step": 9549
    },
    {
      "epoch": 0.692104214226184,
      "grad_norm": 0.12498056143522263,
      "learning_rate": 6.159866657004131e-05,
      "loss": 0.0032,
      "step": 9550
    },
    {
      "epoch": 0.6921766858716527,
      "grad_norm": 2.1071906089782715,
      "learning_rate": 6.158417276614248e-05,
      "loss": 0.072,
      "step": 9551
    },
    {
      "epoch": 0.6922491575171215,
      "grad_norm": 0.982380747795105,
      "learning_rate": 6.156967896224365e-05,
      "loss": 0.0191,
      "step": 9552
    },
    {
      "epoch": 0.6923216291625901,
      "grad_norm": 1.8216686248779297,
      "learning_rate": 6.155518515834481e-05,
      "loss": 0.1463,
      "step": 9553
    },
    {
      "epoch": 0.6923941008080589,
      "grad_norm": 3.13460111618042,
      "learning_rate": 6.154069135444598e-05,
      "loss": 0.0893,
      "step": 9554
    },
    {
      "epoch": 0.6924665724535276,
      "grad_norm": 2.0542609691619873,
      "learning_rate": 6.152619755054715e-05,
      "loss": 0.0401,
      "step": 9555
    },
    {
      "epoch": 0.6925390440989962,
      "grad_norm": 2.5675580501556396,
      "learning_rate": 6.15117037466483e-05,
      "loss": 0.0547,
      "step": 9556
    },
    {
      "epoch": 0.692611515744465,
      "grad_norm": 2.4254279136657715,
      "learning_rate": 6.149720994274948e-05,
      "loss": 0.0507,
      "step": 9557
    },
    {
      "epoch": 0.6926839873899336,
      "grad_norm": 1.2322468757629395,
      "learning_rate": 6.148271613885065e-05,
      "loss": 0.0489,
      "step": 9558
    },
    {
      "epoch": 0.6927564590354024,
      "grad_norm": 5.257791042327881,
      "learning_rate": 6.14682223349518e-05,
      "loss": 0.1291,
      "step": 9559
    },
    {
      "epoch": 0.6928289306808711,
      "grad_norm": 2.2921078205108643,
      "learning_rate": 6.145372853105297e-05,
      "loss": 0.0995,
      "step": 9560
    },
    {
      "epoch": 0.6929014023263398,
      "grad_norm": 1.8274661302566528,
      "learning_rate": 6.143923472715416e-05,
      "loss": 0.0478,
      "step": 9561
    },
    {
      "epoch": 0.6929738739718085,
      "grad_norm": 1.5270793437957764,
      "learning_rate": 6.142474092325531e-05,
      "loss": 0.0336,
      "step": 9562
    },
    {
      "epoch": 0.6930463456172773,
      "grad_norm": 1.7644233703613281,
      "learning_rate": 6.141024711935648e-05,
      "loss": 0.0477,
      "step": 9563
    },
    {
      "epoch": 0.6931188172627459,
      "grad_norm": 3.734640121459961,
      "learning_rate": 6.139575331545765e-05,
      "loss": 0.0866,
      "step": 9564
    },
    {
      "epoch": 0.6931912889082147,
      "grad_norm": 4.57108736038208,
      "learning_rate": 6.138125951155881e-05,
      "loss": 0.0776,
      "step": 9565
    },
    {
      "epoch": 0.6932637605536833,
      "grad_norm": 0.36008813977241516,
      "learning_rate": 6.136676570765998e-05,
      "loss": 0.011,
      "step": 9566
    },
    {
      "epoch": 0.6933362321991521,
      "grad_norm": 0.2519836723804474,
      "learning_rate": 6.135227190376115e-05,
      "loss": 0.0116,
      "step": 9567
    },
    {
      "epoch": 0.6934087038446208,
      "grad_norm": 1.6258569955825806,
      "learning_rate": 6.13377780998623e-05,
      "loss": 0.1195,
      "step": 9568
    },
    {
      "epoch": 0.6934811754900895,
      "grad_norm": 0.0832836925983429,
      "learning_rate": 6.132328429596348e-05,
      "loss": 0.0009,
      "step": 9569
    },
    {
      "epoch": 0.6935536471355582,
      "grad_norm": 0.2993548512458801,
      "learning_rate": 6.130879049206465e-05,
      "loss": 0.0022,
      "step": 9570
    },
    {
      "epoch": 0.6936261187810269,
      "grad_norm": 0.8370712399482727,
      "learning_rate": 6.129429668816582e-05,
      "loss": 0.028,
      "step": 9571
    },
    {
      "epoch": 0.6936985904264956,
      "grad_norm": 1.3485347032546997,
      "learning_rate": 6.127980288426699e-05,
      "loss": 0.0474,
      "step": 9572
    },
    {
      "epoch": 0.6937710620719644,
      "grad_norm": 2.089724540710449,
      "learning_rate": 6.126530908036816e-05,
      "loss": 0.053,
      "step": 9573
    },
    {
      "epoch": 0.693843533717433,
      "grad_norm": 1.0037932395935059,
      "learning_rate": 6.125081527646931e-05,
      "loss": 0.0396,
      "step": 9574
    },
    {
      "epoch": 0.6939160053629018,
      "grad_norm": 0.8072032928466797,
      "learning_rate": 6.123632147257048e-05,
      "loss": 0.0295,
      "step": 9575
    },
    {
      "epoch": 0.6939884770083705,
      "grad_norm": 0.0533221997320652,
      "learning_rate": 6.122182766867165e-05,
      "loss": 0.001,
      "step": 9576
    },
    {
      "epoch": 0.6940609486538392,
      "grad_norm": 1.5368326902389526,
      "learning_rate": 6.120733386477281e-05,
      "loss": 0.0202,
      "step": 9577
    },
    {
      "epoch": 0.6941334202993079,
      "grad_norm": 3.2383952140808105,
      "learning_rate": 6.119284006087398e-05,
      "loss": 0.0769,
      "step": 9578
    },
    {
      "epoch": 0.6942058919447766,
      "grad_norm": 2.9260075092315674,
      "learning_rate": 6.117834625697515e-05,
      "loss": 0.1599,
      "step": 9579
    },
    {
      "epoch": 0.6942783635902453,
      "grad_norm": 1.5775443315505981,
      "learning_rate": 6.11638524530763e-05,
      "loss": 0.0584,
      "step": 9580
    },
    {
      "epoch": 0.6943508352357141,
      "grad_norm": 1.841647744178772,
      "learning_rate": 6.114935864917748e-05,
      "loss": 0.0692,
      "step": 9581
    },
    {
      "epoch": 0.6944233068811827,
      "grad_norm": 2.0948641300201416,
      "learning_rate": 6.113486484527865e-05,
      "loss": 0.0463,
      "step": 9582
    },
    {
      "epoch": 0.6944957785266515,
      "grad_norm": 1.1014891862869263,
      "learning_rate": 6.112037104137982e-05,
      "loss": 0.1012,
      "step": 9583
    },
    {
      "epoch": 0.6945682501721202,
      "grad_norm": 0.09417731314897537,
      "learning_rate": 6.110587723748099e-05,
      "loss": 0.0015,
      "step": 9584
    },
    {
      "epoch": 0.6946407218175888,
      "grad_norm": 1.7859946489334106,
      "learning_rate": 6.109138343358216e-05,
      "loss": 0.0374,
      "step": 9585
    },
    {
      "epoch": 0.6947131934630576,
      "grad_norm": 4.496376037597656,
      "learning_rate": 6.107688962968331e-05,
      "loss": 0.0772,
      "step": 9586
    },
    {
      "epoch": 0.6947856651085262,
      "grad_norm": 0.4571313261985779,
      "learning_rate": 6.106239582578448e-05,
      "loss": 0.0107,
      "step": 9587
    },
    {
      "epoch": 0.694858136753995,
      "grad_norm": 2.1797986030578613,
      "learning_rate": 6.104790202188565e-05,
      "loss": 0.0626,
      "step": 9588
    },
    {
      "epoch": 0.6949306083994637,
      "grad_norm": 0.8149721026420593,
      "learning_rate": 6.103340821798681e-05,
      "loss": 0.02,
      "step": 9589
    },
    {
      "epoch": 0.6950030800449324,
      "grad_norm": 0.9612059593200684,
      "learning_rate": 6.101891441408798e-05,
      "loss": 0.0345,
      "step": 9590
    },
    {
      "epoch": 0.6950755516904011,
      "grad_norm": 0.34622520208358765,
      "learning_rate": 6.100442061018915e-05,
      "loss": 0.0081,
      "step": 9591
    },
    {
      "epoch": 0.6951480233358699,
      "grad_norm": 1.0161274671554565,
      "learning_rate": 6.098992680629031e-05,
      "loss": 0.0417,
      "step": 9592
    },
    {
      "epoch": 0.6952204949813385,
      "grad_norm": 1.2879481315612793,
      "learning_rate": 6.097543300239148e-05,
      "loss": 0.0473,
      "step": 9593
    },
    {
      "epoch": 0.6952929666268073,
      "grad_norm": 0.6600268483161926,
      "learning_rate": 6.096093919849265e-05,
      "loss": 0.0102,
      "step": 9594
    },
    {
      "epoch": 0.6953654382722759,
      "grad_norm": 0.2995138466358185,
      "learning_rate": 6.094644539459381e-05,
      "loss": 0.0164,
      "step": 9595
    },
    {
      "epoch": 0.6954379099177447,
      "grad_norm": 0.9134699106216431,
      "learning_rate": 6.093195159069498e-05,
      "loss": 0.043,
      "step": 9596
    },
    {
      "epoch": 0.6955103815632134,
      "grad_norm": 1.296675443649292,
      "learning_rate": 6.091745778679615e-05,
      "loss": 0.0253,
      "step": 9597
    },
    {
      "epoch": 0.6955828532086821,
      "grad_norm": 1.110883355140686,
      "learning_rate": 6.090296398289731e-05,
      "loss": 0.034,
      "step": 9598
    },
    {
      "epoch": 0.6956553248541508,
      "grad_norm": 5.232511520385742,
      "learning_rate": 6.088847017899848e-05,
      "loss": 0.0506,
      "step": 9599
    },
    {
      "epoch": 0.6957277964996196,
      "grad_norm": 2.255507230758667,
      "learning_rate": 6.087397637509965e-05,
      "loss": 0.0752,
      "step": 9600
    },
    {
      "epoch": 0.6958002681450882,
      "grad_norm": 3.1769113540649414,
      "learning_rate": 6.085948257120081e-05,
      "loss": 0.0444,
      "step": 9601
    },
    {
      "epoch": 0.695872739790557,
      "grad_norm": 2.6659162044525146,
      "learning_rate": 6.084498876730198e-05,
      "loss": 0.1015,
      "step": 9602
    },
    {
      "epoch": 0.6959452114360256,
      "grad_norm": 2.8941402435302734,
      "learning_rate": 6.083049496340315e-05,
      "loss": 0.048,
      "step": 9603
    },
    {
      "epoch": 0.6960176830814944,
      "grad_norm": 1.2390192747116089,
      "learning_rate": 6.081600115950431e-05,
      "loss": 0.0573,
      "step": 9604
    },
    {
      "epoch": 0.6960901547269631,
      "grad_norm": 2.978550910949707,
      "learning_rate": 6.080150735560548e-05,
      "loss": 0.0943,
      "step": 9605
    },
    {
      "epoch": 0.6961626263724318,
      "grad_norm": 1.7933486700057983,
      "learning_rate": 6.078701355170665e-05,
      "loss": 0.0538,
      "step": 9606
    },
    {
      "epoch": 0.6962350980179005,
      "grad_norm": 1.5137465000152588,
      "learning_rate": 6.077251974780781e-05,
      "loss": 0.0562,
      "step": 9607
    },
    {
      "epoch": 0.6963075696633692,
      "grad_norm": 3.0564088821411133,
      "learning_rate": 6.075802594390898e-05,
      "loss": 0.1551,
      "step": 9608
    },
    {
      "epoch": 0.6963800413088379,
      "grad_norm": 0.9650001525878906,
      "learning_rate": 6.074353214001015e-05,
      "loss": 0.0216,
      "step": 9609
    },
    {
      "epoch": 0.6964525129543067,
      "grad_norm": 1.9870615005493164,
      "learning_rate": 6.072903833611131e-05,
      "loss": 0.0719,
      "step": 9610
    },
    {
      "epoch": 0.6965249845997753,
      "grad_norm": 1.6468851566314697,
      "learning_rate": 6.071454453221248e-05,
      "loss": 0.0441,
      "step": 9611
    },
    {
      "epoch": 0.696597456245244,
      "grad_norm": 0.1988818347454071,
      "learning_rate": 6.070005072831365e-05,
      "loss": 0.0073,
      "step": 9612
    },
    {
      "epoch": 0.6966699278907128,
      "grad_norm": 0.922529399394989,
      "learning_rate": 6.068555692441481e-05,
      "loss": 0.0535,
      "step": 9613
    },
    {
      "epoch": 0.6967423995361814,
      "grad_norm": 0.5198454856872559,
      "learning_rate": 6.067106312051598e-05,
      "loss": 0.0217,
      "step": 9614
    },
    {
      "epoch": 0.6968148711816502,
      "grad_norm": 2.0504701137542725,
      "learning_rate": 6.065656931661715e-05,
      "loss": 0.0595,
      "step": 9615
    },
    {
      "epoch": 0.6968873428271188,
      "grad_norm": 1.8390089273452759,
      "learning_rate": 6.064207551271831e-05,
      "loss": 0.0807,
      "step": 9616
    },
    {
      "epoch": 0.6969598144725876,
      "grad_norm": 2.752549648284912,
      "learning_rate": 6.062758170881948e-05,
      "loss": 0.1256,
      "step": 9617
    },
    {
      "epoch": 0.6970322861180563,
      "grad_norm": 0.869595468044281,
      "learning_rate": 6.061308790492065e-05,
      "loss": 0.0318,
      "step": 9618
    },
    {
      "epoch": 0.697104757763525,
      "grad_norm": 0.33062201738357544,
      "learning_rate": 6.059859410102181e-05,
      "loss": 0.0057,
      "step": 9619
    },
    {
      "epoch": 0.6971772294089937,
      "grad_norm": 0.9859969615936279,
      "learning_rate": 6.058410029712298e-05,
      "loss": 0.0281,
      "step": 9620
    },
    {
      "epoch": 0.6972497010544625,
      "grad_norm": 2.3514909744262695,
      "learning_rate": 6.0569606493224155e-05,
      "loss": 0.0567,
      "step": 9621
    },
    {
      "epoch": 0.6973221726999311,
      "grad_norm": 1.055886149406433,
      "learning_rate": 6.0555112689325325e-05,
      "loss": 0.0509,
      "step": 9622
    },
    {
      "epoch": 0.6973946443453999,
      "grad_norm": 0.8142964839935303,
      "learning_rate": 6.054061888542648e-05,
      "loss": 0.0625,
      "step": 9623
    },
    {
      "epoch": 0.6974671159908685,
      "grad_norm": 1.0078963041305542,
      "learning_rate": 6.052612508152765e-05,
      "loss": 0.0531,
      "step": 9624
    },
    {
      "epoch": 0.6975395876363373,
      "grad_norm": 1.930896282196045,
      "learning_rate": 6.051163127762882e-05,
      "loss": 0.0604,
      "step": 9625
    },
    {
      "epoch": 0.697612059281806,
      "grad_norm": 2.149657964706421,
      "learning_rate": 6.0497137473729984e-05,
      "loss": 0.141,
      "step": 9626
    },
    {
      "epoch": 0.6976845309272747,
      "grad_norm": 1.8055340051651,
      "learning_rate": 6.0482643669831154e-05,
      "loss": 0.0578,
      "step": 9627
    },
    {
      "epoch": 0.6977570025727434,
      "grad_norm": 1.6967124938964844,
      "learning_rate": 6.0468149865932324e-05,
      "loss": 0.1175,
      "step": 9628
    },
    {
      "epoch": 0.6978294742182122,
      "grad_norm": 3.017449140548706,
      "learning_rate": 6.045365606203348e-05,
      "loss": 0.0925,
      "step": 9629
    },
    {
      "epoch": 0.6979019458636808,
      "grad_norm": 1.3297616243362427,
      "learning_rate": 6.043916225813465e-05,
      "loss": 0.0177,
      "step": 9630
    },
    {
      "epoch": 0.6979744175091496,
      "grad_norm": 2.2080960273742676,
      "learning_rate": 6.042466845423582e-05,
      "loss": 0.0907,
      "step": 9631
    },
    {
      "epoch": 0.6980468891546182,
      "grad_norm": 0.26898545026779175,
      "learning_rate": 6.0410174650336984e-05,
      "loss": 0.0034,
      "step": 9632
    },
    {
      "epoch": 0.698119360800087,
      "grad_norm": 0.8114532828330994,
      "learning_rate": 6.0395680846438154e-05,
      "loss": 0.0261,
      "step": 9633
    },
    {
      "epoch": 0.6981918324455557,
      "grad_norm": 1.7750054597854614,
      "learning_rate": 6.0381187042539324e-05,
      "loss": 0.0682,
      "step": 9634
    },
    {
      "epoch": 0.6982643040910244,
      "grad_norm": 3.8231923580169678,
      "learning_rate": 6.036669323864048e-05,
      "loss": 0.1171,
      "step": 9635
    },
    {
      "epoch": 0.6983367757364931,
      "grad_norm": 1.766703724861145,
      "learning_rate": 6.035219943474165e-05,
      "loss": 0.0905,
      "step": 9636
    },
    {
      "epoch": 0.6984092473819619,
      "grad_norm": 1.6075795888900757,
      "learning_rate": 6.033770563084282e-05,
      "loss": 0.0699,
      "step": 9637
    },
    {
      "epoch": 0.6984817190274305,
      "grad_norm": 2.2108888626098633,
      "learning_rate": 6.0323211826943984e-05,
      "loss": 0.146,
      "step": 9638
    },
    {
      "epoch": 0.6985541906728993,
      "grad_norm": 0.300656259059906,
      "learning_rate": 6.0308718023045154e-05,
      "loss": 0.0096,
      "step": 9639
    },
    {
      "epoch": 0.6986266623183679,
      "grad_norm": 0.45931515097618103,
      "learning_rate": 6.0294224219146324e-05,
      "loss": 0.024,
      "step": 9640
    },
    {
      "epoch": 0.6986991339638366,
      "grad_norm": 3.5929031372070312,
      "learning_rate": 6.027973041524748e-05,
      "loss": 0.1047,
      "step": 9641
    },
    {
      "epoch": 0.6987716056093054,
      "grad_norm": 0.5145033001899719,
      "learning_rate": 6.026523661134865e-05,
      "loss": 0.0312,
      "step": 9642
    },
    {
      "epoch": 0.698844077254774,
      "grad_norm": 3.3996083736419678,
      "learning_rate": 6.025074280744982e-05,
      "loss": 0.181,
      "step": 9643
    },
    {
      "epoch": 0.6989165489002428,
      "grad_norm": 1.093446969985962,
      "learning_rate": 6.0236249003550984e-05,
      "loss": 0.0481,
      "step": 9644
    },
    {
      "epoch": 0.6989890205457114,
      "grad_norm": 2.684136152267456,
      "learning_rate": 6.0221755199652154e-05,
      "loss": 0.1191,
      "step": 9645
    },
    {
      "epoch": 0.6990614921911802,
      "grad_norm": 0.9258183836936951,
      "learning_rate": 6.0207261395753324e-05,
      "loss": 0.044,
      "step": 9646
    },
    {
      "epoch": 0.6991339638366489,
      "grad_norm": 1.0507210493087769,
      "learning_rate": 6.019276759185448e-05,
      "loss": 0.0796,
      "step": 9647
    },
    {
      "epoch": 0.6992064354821176,
      "grad_norm": 1.5349370241165161,
      "learning_rate": 6.017827378795565e-05,
      "loss": 0.0673,
      "step": 9648
    },
    {
      "epoch": 0.6992789071275863,
      "grad_norm": 0.8920416235923767,
      "learning_rate": 6.016377998405682e-05,
      "loss": 0.0678,
      "step": 9649
    },
    {
      "epoch": 0.6993513787730551,
      "grad_norm": 0.4227164685726166,
      "learning_rate": 6.0149286180157984e-05,
      "loss": 0.007,
      "step": 9650
    },
    {
      "epoch": 0.6994238504185237,
      "grad_norm": 3.013122081756592,
      "learning_rate": 6.0134792376259154e-05,
      "loss": 0.1147,
      "step": 9651
    },
    {
      "epoch": 0.6994963220639925,
      "grad_norm": 0.29782289266586304,
      "learning_rate": 6.0120298572360324e-05,
      "loss": 0.0113,
      "step": 9652
    },
    {
      "epoch": 0.6995687937094611,
      "grad_norm": 0.22901500761508942,
      "learning_rate": 6.010580476846148e-05,
      "loss": 0.0053,
      "step": 9653
    },
    {
      "epoch": 0.6996412653549299,
      "grad_norm": 0.6571559309959412,
      "learning_rate": 6.009131096456265e-05,
      "loss": 0.0367,
      "step": 9654
    },
    {
      "epoch": 0.6997137370003986,
      "grad_norm": 1.2532329559326172,
      "learning_rate": 6.007681716066382e-05,
      "loss": 0.0498,
      "step": 9655
    },
    {
      "epoch": 0.6997862086458673,
      "grad_norm": 0.8585573434829712,
      "learning_rate": 6.0062323356764984e-05,
      "loss": 0.0222,
      "step": 9656
    },
    {
      "epoch": 0.699858680291336,
      "grad_norm": 0.726158618927002,
      "learning_rate": 6.0047829552866154e-05,
      "loss": 0.0422,
      "step": 9657
    },
    {
      "epoch": 0.6999311519368048,
      "grad_norm": 0.1965237408876419,
      "learning_rate": 6.0033335748967324e-05,
      "loss": 0.006,
      "step": 9658
    },
    {
      "epoch": 0.7000036235822734,
      "grad_norm": 1.1623607873916626,
      "learning_rate": 6.001884194506848e-05,
      "loss": 0.0446,
      "step": 9659
    },
    {
      "epoch": 0.7000760952277422,
      "grad_norm": 0.7321026921272278,
      "learning_rate": 6.000434814116965e-05,
      "loss": 0.015,
      "step": 9660
    },
    {
      "epoch": 0.7001485668732108,
      "grad_norm": 1.1375890970230103,
      "learning_rate": 5.998985433727082e-05,
      "loss": 0.0528,
      "step": 9661
    },
    {
      "epoch": 0.7002210385186796,
      "grad_norm": 2.618163824081421,
      "learning_rate": 5.9975360533371984e-05,
      "loss": 0.2262,
      "step": 9662
    },
    {
      "epoch": 0.7002935101641483,
      "grad_norm": 2.648820638656616,
      "learning_rate": 5.9960866729473154e-05,
      "loss": 0.0409,
      "step": 9663
    },
    {
      "epoch": 0.700365981809617,
      "grad_norm": 1.5864137411117554,
      "learning_rate": 5.9946372925574324e-05,
      "loss": 0.0502,
      "step": 9664
    },
    {
      "epoch": 0.7004384534550857,
      "grad_norm": 1.0951265096664429,
      "learning_rate": 5.993187912167548e-05,
      "loss": 0.0068,
      "step": 9665
    },
    {
      "epoch": 0.7005109251005545,
      "grad_norm": 3.7517566680908203,
      "learning_rate": 5.991738531777665e-05,
      "loss": 0.0964,
      "step": 9666
    },
    {
      "epoch": 0.7005833967460231,
      "grad_norm": 0.43777623772621155,
      "learning_rate": 5.990289151387782e-05,
      "loss": 0.0162,
      "step": 9667
    },
    {
      "epoch": 0.7006558683914919,
      "grad_norm": 1.900073766708374,
      "learning_rate": 5.9888397709978984e-05,
      "loss": 0.0939,
      "step": 9668
    },
    {
      "epoch": 0.7007283400369605,
      "grad_norm": 2.063652276992798,
      "learning_rate": 5.9873903906080154e-05,
      "loss": 0.0867,
      "step": 9669
    },
    {
      "epoch": 0.7008008116824292,
      "grad_norm": 1.7175664901733398,
      "learning_rate": 5.9859410102181324e-05,
      "loss": 0.0693,
      "step": 9670
    },
    {
      "epoch": 0.700873283327898,
      "grad_norm": 1.6493785381317139,
      "learning_rate": 5.984491629828248e-05,
      "loss": 0.0759,
      "step": 9671
    },
    {
      "epoch": 0.7009457549733666,
      "grad_norm": 0.3464225232601166,
      "learning_rate": 5.983042249438365e-05,
      "loss": 0.0192,
      "step": 9672
    },
    {
      "epoch": 0.7010182266188354,
      "grad_norm": 1.292759895324707,
      "learning_rate": 5.981592869048482e-05,
      "loss": 0.0407,
      "step": 9673
    },
    {
      "epoch": 0.7010906982643041,
      "grad_norm": 0.465945303440094,
      "learning_rate": 5.9801434886585984e-05,
      "loss": 0.0156,
      "step": 9674
    },
    {
      "epoch": 0.7011631699097728,
      "grad_norm": 3.7937800884246826,
      "learning_rate": 5.9786941082687154e-05,
      "loss": 0.0737,
      "step": 9675
    },
    {
      "epoch": 0.7012356415552415,
      "grad_norm": 0.06070369854569435,
      "learning_rate": 5.9772447278788324e-05,
      "loss": 0.0015,
      "step": 9676
    },
    {
      "epoch": 0.7013081132007102,
      "grad_norm": 2.2181191444396973,
      "learning_rate": 5.975795347488948e-05,
      "loss": 0.1061,
      "step": 9677
    },
    {
      "epoch": 0.7013805848461789,
      "grad_norm": 2.4726216793060303,
      "learning_rate": 5.974345967099065e-05,
      "loss": 0.0297,
      "step": 9678
    },
    {
      "epoch": 0.7014530564916477,
      "grad_norm": 1.2345097064971924,
      "learning_rate": 5.972896586709183e-05,
      "loss": 0.0431,
      "step": 9679
    },
    {
      "epoch": 0.7015255281371163,
      "grad_norm": 0.8272472023963928,
      "learning_rate": 5.9714472063192984e-05,
      "loss": 0.0545,
      "step": 9680
    },
    {
      "epoch": 0.7015979997825851,
      "grad_norm": 0.7561001777648926,
      "learning_rate": 5.9699978259294154e-05,
      "loss": 0.0049,
      "step": 9681
    },
    {
      "epoch": 0.7016704714280537,
      "grad_norm": 1.0531044006347656,
      "learning_rate": 5.9685484455395324e-05,
      "loss": 0.0294,
      "step": 9682
    },
    {
      "epoch": 0.7017429430735225,
      "grad_norm": 0.5878399014472961,
      "learning_rate": 5.967099065149648e-05,
      "loss": 0.0268,
      "step": 9683
    },
    {
      "epoch": 0.7018154147189912,
      "grad_norm": 0.7815462946891785,
      "learning_rate": 5.965649684759766e-05,
      "loss": 0.0279,
      "step": 9684
    },
    {
      "epoch": 0.7018878863644599,
      "grad_norm": 2.7141079902648926,
      "learning_rate": 5.964200304369883e-05,
      "loss": 0.1488,
      "step": 9685
    },
    {
      "epoch": 0.7019603580099286,
      "grad_norm": 1.173587679862976,
      "learning_rate": 5.9627509239799983e-05,
      "loss": 0.0422,
      "step": 9686
    },
    {
      "epoch": 0.7020328296553974,
      "grad_norm": 2.444387912750244,
      "learning_rate": 5.9613015435901153e-05,
      "loss": 0.1133,
      "step": 9687
    },
    {
      "epoch": 0.702105301300866,
      "grad_norm": 0.6961274743080139,
      "learning_rate": 5.9598521632002323e-05,
      "loss": 0.0329,
      "step": 9688
    },
    {
      "epoch": 0.7021777729463348,
      "grad_norm": 1.5146172046661377,
      "learning_rate": 5.958402782810349e-05,
      "loss": 0.0373,
      "step": 9689
    },
    {
      "epoch": 0.7022502445918034,
      "grad_norm": 1.5192118883132935,
      "learning_rate": 5.956953402420466e-05,
      "loss": 0.1007,
      "step": 9690
    },
    {
      "epoch": 0.7023227162372722,
      "grad_norm": 0.8047327399253845,
      "learning_rate": 5.955504022030583e-05,
      "loss": 0.0124,
      "step": 9691
    },
    {
      "epoch": 0.7023951878827409,
      "grad_norm": 1.391486644744873,
      "learning_rate": 5.954054641640698e-05,
      "loss": 0.0342,
      "step": 9692
    },
    {
      "epoch": 0.7024676595282096,
      "grad_norm": 1.1758638620376587,
      "learning_rate": 5.952605261250815e-05,
      "loss": 0.0596,
      "step": 9693
    },
    {
      "epoch": 0.7025401311736783,
      "grad_norm": 0.8050851821899414,
      "learning_rate": 5.951155880860932e-05,
      "loss": 0.0219,
      "step": 9694
    },
    {
      "epoch": 0.7026126028191471,
      "grad_norm": 5.949068069458008,
      "learning_rate": 5.949706500471049e-05,
      "loss": 0.0517,
      "step": 9695
    },
    {
      "epoch": 0.7026850744646157,
      "grad_norm": 1.7971177101135254,
      "learning_rate": 5.948257120081166e-05,
      "loss": 0.083,
      "step": 9696
    },
    {
      "epoch": 0.7027575461100845,
      "grad_norm": 0.08065801858901978,
      "learning_rate": 5.946807739691283e-05,
      "loss": 0.0009,
      "step": 9697
    },
    {
      "epoch": 0.7028300177555531,
      "grad_norm": 2.516566514968872,
      "learning_rate": 5.945358359301398e-05,
      "loss": 0.0952,
      "step": 9698
    },
    {
      "epoch": 0.7029024894010218,
      "grad_norm": 1.6093367338180542,
      "learning_rate": 5.943908978911515e-05,
      "loss": 0.0822,
      "step": 9699
    },
    {
      "epoch": 0.7029749610464906,
      "grad_norm": 0.5968093276023865,
      "learning_rate": 5.942459598521632e-05,
      "loss": 0.0202,
      "step": 9700
    },
    {
      "epoch": 0.7030474326919592,
      "grad_norm": 1.014108419418335,
      "learning_rate": 5.941010218131749e-05,
      "loss": 0.0277,
      "step": 9701
    },
    {
      "epoch": 0.703119904337428,
      "grad_norm": 1.9324418306350708,
      "learning_rate": 5.9395608377418657e-05,
      "loss": 0.0744,
      "step": 9702
    },
    {
      "epoch": 0.7031923759828967,
      "grad_norm": 2.675691604614258,
      "learning_rate": 5.9381114573519827e-05,
      "loss": 0.0513,
      "step": 9703
    },
    {
      "epoch": 0.7032648476283654,
      "grad_norm": 1.2211856842041016,
      "learning_rate": 5.9366620769621e-05,
      "loss": 0.0402,
      "step": 9704
    },
    {
      "epoch": 0.7033373192738341,
      "grad_norm": 1.4641449451446533,
      "learning_rate": 5.935212696572215e-05,
      "loss": 0.082,
      "step": 9705
    },
    {
      "epoch": 0.7034097909193028,
      "grad_norm": 2.3638358116149902,
      "learning_rate": 5.933763316182332e-05,
      "loss": 0.0532,
      "step": 9706
    },
    {
      "epoch": 0.7034822625647715,
      "grad_norm": 3.4437198638916016,
      "learning_rate": 5.932313935792449e-05,
      "loss": 0.0397,
      "step": 9707
    },
    {
      "epoch": 0.7035547342102403,
      "grad_norm": 1.7495380640029907,
      "learning_rate": 5.9308645554025656e-05,
      "loss": 0.0288,
      "step": 9708
    },
    {
      "epoch": 0.7036272058557089,
      "grad_norm": 1.2396620512008667,
      "learning_rate": 5.9294151750126827e-05,
      "loss": 0.0225,
      "step": 9709
    },
    {
      "epoch": 0.7036996775011777,
      "grad_norm": 0.12526151537895203,
      "learning_rate": 5.9279657946227997e-05,
      "loss": 0.0025,
      "step": 9710
    },
    {
      "epoch": 0.7037721491466463,
      "grad_norm": 0.26203668117523193,
      "learning_rate": 5.926516414232915e-05,
      "loss": 0.0139,
      "step": 9711
    },
    {
      "epoch": 0.7038446207921151,
      "grad_norm": 1.2195338010787964,
      "learning_rate": 5.925067033843032e-05,
      "loss": 0.0625,
      "step": 9712
    },
    {
      "epoch": 0.7039170924375838,
      "grad_norm": 1.4825046062469482,
      "learning_rate": 5.923617653453149e-05,
      "loss": 0.0509,
      "step": 9713
    },
    {
      "epoch": 0.7039895640830525,
      "grad_norm": 0.7788606286048889,
      "learning_rate": 5.9221682730632656e-05,
      "loss": 0.0456,
      "step": 9714
    },
    {
      "epoch": 0.7040620357285212,
      "grad_norm": 1.911014437675476,
      "learning_rate": 5.9207188926733826e-05,
      "loss": 0.0418,
      "step": 9715
    },
    {
      "epoch": 0.70413450737399,
      "grad_norm": 2.4502387046813965,
      "learning_rate": 5.9192695122834996e-05,
      "loss": 0.1177,
      "step": 9716
    },
    {
      "epoch": 0.7042069790194586,
      "grad_norm": 3.1871328353881836,
      "learning_rate": 5.917820131893615e-05,
      "loss": 0.1692,
      "step": 9717
    },
    {
      "epoch": 0.7042794506649274,
      "grad_norm": 2.536581039428711,
      "learning_rate": 5.916370751503732e-05,
      "loss": 0.0703,
      "step": 9718
    },
    {
      "epoch": 0.704351922310396,
      "grad_norm": 0.6638222932815552,
      "learning_rate": 5.914921371113849e-05,
      "loss": 0.0266,
      "step": 9719
    },
    {
      "epoch": 0.7044243939558648,
      "grad_norm": 0.4536203145980835,
      "learning_rate": 5.9134719907239656e-05,
      "loss": 0.018,
      "step": 9720
    },
    {
      "epoch": 0.7044968656013335,
      "grad_norm": 1.2497742176055908,
      "learning_rate": 5.9120226103340826e-05,
      "loss": 0.0447,
      "step": 9721
    },
    {
      "epoch": 0.7045693372468022,
      "grad_norm": 0.8881485462188721,
      "learning_rate": 5.9105732299441996e-05,
      "loss": 0.0558,
      "step": 9722
    },
    {
      "epoch": 0.7046418088922709,
      "grad_norm": 1.2324057817459106,
      "learning_rate": 5.909123849554315e-05,
      "loss": 0.0639,
      "step": 9723
    },
    {
      "epoch": 0.7047142805377397,
      "grad_norm": 1.5730952024459839,
      "learning_rate": 5.907674469164432e-05,
      "loss": 0.0728,
      "step": 9724
    },
    {
      "epoch": 0.7047867521832083,
      "grad_norm": 1.4145630598068237,
      "learning_rate": 5.906225088774549e-05,
      "loss": 0.0788,
      "step": 9725
    },
    {
      "epoch": 0.704859223828677,
      "grad_norm": 1.474779486656189,
      "learning_rate": 5.9047757083846656e-05,
      "loss": 0.0471,
      "step": 9726
    },
    {
      "epoch": 0.7049316954741457,
      "grad_norm": 1.788572072982788,
      "learning_rate": 5.9033263279947826e-05,
      "loss": 0.0771,
      "step": 9727
    },
    {
      "epoch": 0.7050041671196144,
      "grad_norm": 0.3085845708847046,
      "learning_rate": 5.9018769476048996e-05,
      "loss": 0.0099,
      "step": 9728
    },
    {
      "epoch": 0.7050766387650832,
      "grad_norm": 0.8905460238456726,
      "learning_rate": 5.900427567215015e-05,
      "loss": 0.041,
      "step": 9729
    },
    {
      "epoch": 0.7051491104105518,
      "grad_norm": 0.3309190273284912,
      "learning_rate": 5.898978186825132e-05,
      "loss": 0.0136,
      "step": 9730
    },
    {
      "epoch": 0.7052215820560206,
      "grad_norm": 1.7516425848007202,
      "learning_rate": 5.89752880643525e-05,
      "loss": 0.0746,
      "step": 9731
    },
    {
      "epoch": 0.7052940537014893,
      "grad_norm": 2.194793939590454,
      "learning_rate": 5.8960794260453656e-05,
      "loss": 0.0942,
      "step": 9732
    },
    {
      "epoch": 0.705366525346958,
      "grad_norm": 0.7973214983940125,
      "learning_rate": 5.8946300456554826e-05,
      "loss": 0.0268,
      "step": 9733
    },
    {
      "epoch": 0.7054389969924267,
      "grad_norm": 0.8107184171676636,
      "learning_rate": 5.8931806652655996e-05,
      "loss": 0.0566,
      "step": 9734
    },
    {
      "epoch": 0.7055114686378954,
      "grad_norm": 1.4868701696395874,
      "learning_rate": 5.891731284875715e-05,
      "loss": 0.0533,
      "step": 9735
    },
    {
      "epoch": 0.7055839402833641,
      "grad_norm": 0.7927929162979126,
      "learning_rate": 5.890281904485833e-05,
      "loss": 0.0243,
      "step": 9736
    },
    {
      "epoch": 0.7056564119288329,
      "grad_norm": 0.6511560678482056,
      "learning_rate": 5.88883252409595e-05,
      "loss": 0.0117,
      "step": 9737
    },
    {
      "epoch": 0.7057288835743015,
      "grad_norm": 1.0134190320968628,
      "learning_rate": 5.8873831437060656e-05,
      "loss": 0.0658,
      "step": 9738
    },
    {
      "epoch": 0.7058013552197703,
      "grad_norm": 0.2383250743150711,
      "learning_rate": 5.8859337633161826e-05,
      "loss": 0.0132,
      "step": 9739
    },
    {
      "epoch": 0.705873826865239,
      "grad_norm": 0.22895066440105438,
      "learning_rate": 5.8844843829262996e-05,
      "loss": 0.012,
      "step": 9740
    },
    {
      "epoch": 0.7059462985107077,
      "grad_norm": 6.198612213134766,
      "learning_rate": 5.883035002536416e-05,
      "loss": 0.0785,
      "step": 9741
    },
    {
      "epoch": 0.7060187701561764,
      "grad_norm": 1.3040540218353271,
      "learning_rate": 5.881585622146533e-05,
      "loss": 0.0808,
      "step": 9742
    },
    {
      "epoch": 0.7060912418016451,
      "grad_norm": 3.063324451446533,
      "learning_rate": 5.88013624175665e-05,
      "loss": 0.0406,
      "step": 9743
    },
    {
      "epoch": 0.7061637134471138,
      "grad_norm": 1.5798771381378174,
      "learning_rate": 5.8786868613667656e-05,
      "loss": 0.0507,
      "step": 9744
    },
    {
      "epoch": 0.7062361850925826,
      "grad_norm": 0.3998848795890808,
      "learning_rate": 5.8772374809768826e-05,
      "loss": 0.0074,
      "step": 9745
    },
    {
      "epoch": 0.7063086567380512,
      "grad_norm": 1.0189274549484253,
      "learning_rate": 5.8757881005869996e-05,
      "loss": 0.0156,
      "step": 9746
    },
    {
      "epoch": 0.70638112838352,
      "grad_norm": 1.010813593864441,
      "learning_rate": 5.874338720197116e-05,
      "loss": 0.0373,
      "step": 9747
    },
    {
      "epoch": 0.7064536000289886,
      "grad_norm": 2.2114291191101074,
      "learning_rate": 5.872889339807233e-05,
      "loss": 0.0998,
      "step": 9748
    },
    {
      "epoch": 0.7065260716744574,
      "grad_norm": 1.226270318031311,
      "learning_rate": 5.87143995941735e-05,
      "loss": 0.0267,
      "step": 9749
    },
    {
      "epoch": 0.7065985433199261,
      "grad_norm": 0.7057319283485413,
      "learning_rate": 5.8699905790274656e-05,
      "loss": 0.0433,
      "step": 9750
    },
    {
      "epoch": 0.7066710149653948,
      "grad_norm": 0.023789778351783752,
      "learning_rate": 5.8685411986375826e-05,
      "loss": 0.0005,
      "step": 9751
    },
    {
      "epoch": 0.7067434866108635,
      "grad_norm": 1.7732834815979004,
      "learning_rate": 5.8670918182476996e-05,
      "loss": 0.0434,
      "step": 9752
    },
    {
      "epoch": 0.7068159582563323,
      "grad_norm": 1.0198426246643066,
      "learning_rate": 5.865642437857816e-05,
      "loss": 0.051,
      "step": 9753
    },
    {
      "epoch": 0.7068884299018009,
      "grad_norm": 0.5162261128425598,
      "learning_rate": 5.864193057467933e-05,
      "loss": 0.0214,
      "step": 9754
    },
    {
      "epoch": 0.7069609015472696,
      "grad_norm": 0.33576130867004395,
      "learning_rate": 5.86274367707805e-05,
      "loss": 0.0159,
      "step": 9755
    },
    {
      "epoch": 0.7070333731927383,
      "grad_norm": 1.2275413274765015,
      "learning_rate": 5.8612942966881656e-05,
      "loss": 0.0498,
      "step": 9756
    },
    {
      "epoch": 0.707105844838207,
      "grad_norm": 1.3529103994369507,
      "learning_rate": 5.8598449162982826e-05,
      "loss": 0.0757,
      "step": 9757
    },
    {
      "epoch": 0.7071783164836758,
      "grad_norm": 1.5932923555374146,
      "learning_rate": 5.8583955359083996e-05,
      "loss": 0.0627,
      "step": 9758
    },
    {
      "epoch": 0.7072507881291444,
      "grad_norm": 2.667468309402466,
      "learning_rate": 5.856946155518516e-05,
      "loss": 0.151,
      "step": 9759
    },
    {
      "epoch": 0.7073232597746132,
      "grad_norm": 1.3716474771499634,
      "learning_rate": 5.855496775128633e-05,
      "loss": 0.0737,
      "step": 9760
    },
    {
      "epoch": 0.7073957314200819,
      "grad_norm": 2.25026798248291,
      "learning_rate": 5.85404739473875e-05,
      "loss": 0.0796,
      "step": 9761
    },
    {
      "epoch": 0.7074682030655506,
      "grad_norm": 1.6475967168807983,
      "learning_rate": 5.8525980143488656e-05,
      "loss": 0.0556,
      "step": 9762
    },
    {
      "epoch": 0.7075406747110193,
      "grad_norm": 1.2985440492630005,
      "learning_rate": 5.8511486339589826e-05,
      "loss": 0.032,
      "step": 9763
    },
    {
      "epoch": 0.707613146356488,
      "grad_norm": 2.654035806655884,
      "learning_rate": 5.8496992535690996e-05,
      "loss": 0.1186,
      "step": 9764
    },
    {
      "epoch": 0.7076856180019567,
      "grad_norm": 3.225637435913086,
      "learning_rate": 5.848249873179216e-05,
      "loss": 0.0867,
      "step": 9765
    },
    {
      "epoch": 0.7077580896474255,
      "grad_norm": 1.5221569538116455,
      "learning_rate": 5.846800492789333e-05,
      "loss": 0.0297,
      "step": 9766
    },
    {
      "epoch": 0.7078305612928941,
      "grad_norm": 0.6635845303535461,
      "learning_rate": 5.84535111239945e-05,
      "loss": 0.0187,
      "step": 9767
    },
    {
      "epoch": 0.7079030329383629,
      "grad_norm": 2.54832124710083,
      "learning_rate": 5.8439017320095655e-05,
      "loss": 0.0664,
      "step": 9768
    },
    {
      "epoch": 0.7079755045838316,
      "grad_norm": 0.9912289381027222,
      "learning_rate": 5.8424523516196825e-05,
      "loss": 0.0255,
      "step": 9769
    },
    {
      "epoch": 0.7080479762293003,
      "grad_norm": 0.9446470737457275,
      "learning_rate": 5.8410029712297996e-05,
      "loss": 0.0348,
      "step": 9770
    },
    {
      "epoch": 0.708120447874769,
      "grad_norm": 2.376171827316284,
      "learning_rate": 5.839553590839916e-05,
      "loss": 0.0283,
      "step": 9771
    },
    {
      "epoch": 0.7081929195202377,
      "grad_norm": 1.0706905126571655,
      "learning_rate": 5.838104210450033e-05,
      "loss": 0.0194,
      "step": 9772
    },
    {
      "epoch": 0.7082653911657064,
      "grad_norm": 1.401985764503479,
      "learning_rate": 5.83665483006015e-05,
      "loss": 0.1025,
      "step": 9773
    },
    {
      "epoch": 0.7083378628111752,
      "grad_norm": 1.6095080375671387,
      "learning_rate": 5.8352054496702655e-05,
      "loss": 0.0671,
      "step": 9774
    },
    {
      "epoch": 0.7084103344566438,
      "grad_norm": 1.531099796295166,
      "learning_rate": 5.8337560692803825e-05,
      "loss": 0.1152,
      "step": 9775
    },
    {
      "epoch": 0.7084828061021126,
      "grad_norm": 0.547434389591217,
      "learning_rate": 5.8323066888904995e-05,
      "loss": 0.0117,
      "step": 9776
    },
    {
      "epoch": 0.7085552777475813,
      "grad_norm": 5.039543628692627,
      "learning_rate": 5.830857308500616e-05,
      "loss": 0.1985,
      "step": 9777
    },
    {
      "epoch": 0.70862774939305,
      "grad_norm": 0.7679221630096436,
      "learning_rate": 5.829407928110733e-05,
      "loss": 0.0157,
      "step": 9778
    },
    {
      "epoch": 0.7087002210385187,
      "grad_norm": 1.0451229810714722,
      "learning_rate": 5.82795854772085e-05,
      "loss": 0.0205,
      "step": 9779
    },
    {
      "epoch": 0.7087726926839873,
      "grad_norm": 1.9279546737670898,
      "learning_rate": 5.8265091673309655e-05,
      "loss": 0.0699,
      "step": 9780
    },
    {
      "epoch": 0.7088451643294561,
      "grad_norm": 1.6367590427398682,
      "learning_rate": 5.8250597869410825e-05,
      "loss": 0.0729,
      "step": 9781
    },
    {
      "epoch": 0.7089176359749249,
      "grad_norm": 2.199554920196533,
      "learning_rate": 5.8236104065511995e-05,
      "loss": 0.0684,
      "step": 9782
    },
    {
      "epoch": 0.7089901076203935,
      "grad_norm": 6.534700870513916,
      "learning_rate": 5.8221610261613165e-05,
      "loss": 0.1261,
      "step": 9783
    },
    {
      "epoch": 0.7090625792658622,
      "grad_norm": 2.5987696647644043,
      "learning_rate": 5.820711645771433e-05,
      "loss": 0.0817,
      "step": 9784
    },
    {
      "epoch": 0.7091350509113309,
      "grad_norm": 1.541029691696167,
      "learning_rate": 5.81926226538155e-05,
      "loss": 0.0414,
      "step": 9785
    },
    {
      "epoch": 0.7092075225567996,
      "grad_norm": 1.1749893426895142,
      "learning_rate": 5.817812884991667e-05,
      "loss": 0.0259,
      "step": 9786
    },
    {
      "epoch": 0.7092799942022684,
      "grad_norm": 0.606254518032074,
      "learning_rate": 5.8163635046017825e-05,
      "loss": 0.0173,
      "step": 9787
    },
    {
      "epoch": 0.709352465847737,
      "grad_norm": 0.4481233060359955,
      "learning_rate": 5.8149141242118995e-05,
      "loss": 0.0187,
      "step": 9788
    },
    {
      "epoch": 0.7094249374932058,
      "grad_norm": 1.2931344509124756,
      "learning_rate": 5.813464743822017e-05,
      "loss": 0.0177,
      "step": 9789
    },
    {
      "epoch": 0.7094974091386745,
      "grad_norm": 1.3980385065078735,
      "learning_rate": 5.812015363432133e-05,
      "loss": 0.0844,
      "step": 9790
    },
    {
      "epoch": 0.7095698807841432,
      "grad_norm": 0.9800703525543213,
      "learning_rate": 5.81056598304225e-05,
      "loss": 0.0126,
      "step": 9791
    },
    {
      "epoch": 0.7096423524296119,
      "grad_norm": 2.306396961212158,
      "learning_rate": 5.809116602652367e-05,
      "loss": 0.0664,
      "step": 9792
    },
    {
      "epoch": 0.7097148240750806,
      "grad_norm": 1.6059166193008423,
      "learning_rate": 5.8076672222624825e-05,
      "loss": 0.0754,
      "step": 9793
    },
    {
      "epoch": 0.7097872957205493,
      "grad_norm": 0.37734028697013855,
      "learning_rate": 5.8062178418726e-05,
      "loss": 0.0181,
      "step": 9794
    },
    {
      "epoch": 0.7098597673660181,
      "grad_norm": 1.230804204940796,
      "learning_rate": 5.804768461482717e-05,
      "loss": 0.0571,
      "step": 9795
    },
    {
      "epoch": 0.7099322390114867,
      "grad_norm": 1.9609352350234985,
      "learning_rate": 5.803319081092833e-05,
      "loss": 0.0343,
      "step": 9796
    },
    {
      "epoch": 0.7100047106569555,
      "grad_norm": 1.4150974750518799,
      "learning_rate": 5.80186970070295e-05,
      "loss": 0.0744,
      "step": 9797
    },
    {
      "epoch": 0.7100771823024242,
      "grad_norm": 1.5140299797058105,
      "learning_rate": 5.800420320313067e-05,
      "loss": 0.0648,
      "step": 9798
    },
    {
      "epoch": 0.7101496539478929,
      "grad_norm": 1.2073352336883545,
      "learning_rate": 5.798970939923183e-05,
      "loss": 0.042,
      "step": 9799
    },
    {
      "epoch": 0.7102221255933616,
      "grad_norm": 2.3474550247192383,
      "learning_rate": 5.7975215595333e-05,
      "loss": 0.0515,
      "step": 9800
    },
    {
      "epoch": 0.7102945972388303,
      "grad_norm": 0.42600175738334656,
      "learning_rate": 5.796072179143417e-05,
      "loss": 0.0219,
      "step": 9801
    },
    {
      "epoch": 0.710367068884299,
      "grad_norm": 1.1685667037963867,
      "learning_rate": 5.794622798753533e-05,
      "loss": 0.0279,
      "step": 9802
    },
    {
      "epoch": 0.7104395405297678,
      "grad_norm": 2.546809434890747,
      "learning_rate": 5.79317341836365e-05,
      "loss": 0.049,
      "step": 9803
    },
    {
      "epoch": 0.7105120121752364,
      "grad_norm": 0.16202588379383087,
      "learning_rate": 5.791724037973767e-05,
      "loss": 0.004,
      "step": 9804
    },
    {
      "epoch": 0.7105844838207052,
      "grad_norm": 1.3680185079574585,
      "learning_rate": 5.790274657583883e-05,
      "loss": 0.0517,
      "step": 9805
    },
    {
      "epoch": 0.7106569554661739,
      "grad_norm": 2.4460089206695557,
      "learning_rate": 5.788825277194e-05,
      "loss": 0.0585,
      "step": 9806
    },
    {
      "epoch": 0.7107294271116426,
      "grad_norm": 3.5937044620513916,
      "learning_rate": 5.787375896804117e-05,
      "loss": 0.0995,
      "step": 9807
    },
    {
      "epoch": 0.7108018987571113,
      "grad_norm": 2.440375328063965,
      "learning_rate": 5.785926516414233e-05,
      "loss": 0.0591,
      "step": 9808
    },
    {
      "epoch": 0.71087437040258,
      "grad_norm": 1.8885033130645752,
      "learning_rate": 5.78447713602435e-05,
      "loss": 0.1005,
      "step": 9809
    },
    {
      "epoch": 0.7109468420480487,
      "grad_norm": 3.5908796787261963,
      "learning_rate": 5.783027755634467e-05,
      "loss": 0.1441,
      "step": 9810
    },
    {
      "epoch": 0.7110193136935175,
      "grad_norm": 1.0233603715896606,
      "learning_rate": 5.781578375244583e-05,
      "loss": 0.0242,
      "step": 9811
    },
    {
      "epoch": 0.7110917853389861,
      "grad_norm": 2.230109453201294,
      "learning_rate": 5.7801289948547e-05,
      "loss": 0.0584,
      "step": 9812
    },
    {
      "epoch": 0.7111642569844548,
      "grad_norm": 0.06268717348575592,
      "learning_rate": 5.778679614464817e-05,
      "loss": 0.0012,
      "step": 9813
    },
    {
      "epoch": 0.7112367286299235,
      "grad_norm": 1.9037104845046997,
      "learning_rate": 5.777230234074933e-05,
      "loss": 0.0479,
      "step": 9814
    },
    {
      "epoch": 0.7113092002753922,
      "grad_norm": 2.4163198471069336,
      "learning_rate": 5.77578085368505e-05,
      "loss": 0.0332,
      "step": 9815
    },
    {
      "epoch": 0.711381671920861,
      "grad_norm": 1.4843531847000122,
      "learning_rate": 5.774331473295167e-05,
      "loss": 0.0196,
      "step": 9816
    },
    {
      "epoch": 0.7114541435663296,
      "grad_norm": 1.1719695329666138,
      "learning_rate": 5.772882092905283e-05,
      "loss": 0.0171,
      "step": 9817
    },
    {
      "epoch": 0.7115266152117984,
      "grad_norm": 1.3686120510101318,
      "learning_rate": 5.7714327125154e-05,
      "loss": 0.0722,
      "step": 9818
    },
    {
      "epoch": 0.7115990868572671,
      "grad_norm": 1.2741775512695312,
      "learning_rate": 5.769983332125517e-05,
      "loss": 0.0268,
      "step": 9819
    },
    {
      "epoch": 0.7116715585027358,
      "grad_norm": 1.1217836141586304,
      "learning_rate": 5.768533951735633e-05,
      "loss": 0.0162,
      "step": 9820
    },
    {
      "epoch": 0.7117440301482045,
      "grad_norm": 0.9464262127876282,
      "learning_rate": 5.76708457134575e-05,
      "loss": 0.0634,
      "step": 9821
    },
    {
      "epoch": 0.7118165017936732,
      "grad_norm": 0.37576931715011597,
      "learning_rate": 5.765635190955867e-05,
      "loss": 0.005,
      "step": 9822
    },
    {
      "epoch": 0.7118889734391419,
      "grad_norm": 1.4278746843338013,
      "learning_rate": 5.764185810565983e-05,
      "loss": 0.0596,
      "step": 9823
    },
    {
      "epoch": 0.7119614450846107,
      "grad_norm": 3.8282713890075684,
      "learning_rate": 5.7627364301761e-05,
      "loss": 0.0888,
      "step": 9824
    },
    {
      "epoch": 0.7120339167300793,
      "grad_norm": 0.5816289782524109,
      "learning_rate": 5.761287049786217e-05,
      "loss": 0.011,
      "step": 9825
    },
    {
      "epoch": 0.7121063883755481,
      "grad_norm": 1.4570890665054321,
      "learning_rate": 5.759837669396333e-05,
      "loss": 0.0664,
      "step": 9826
    },
    {
      "epoch": 0.7121788600210168,
      "grad_norm": 0.8837308287620544,
      "learning_rate": 5.75838828900645e-05,
      "loss": 0.0404,
      "step": 9827
    },
    {
      "epoch": 0.7122513316664855,
      "grad_norm": 2.264260768890381,
      "learning_rate": 5.756938908616567e-05,
      "loss": 0.0231,
      "step": 9828
    },
    {
      "epoch": 0.7123238033119542,
      "grad_norm": 2.1234898567199707,
      "learning_rate": 5.755489528226683e-05,
      "loss": 0.0698,
      "step": 9829
    },
    {
      "epoch": 0.7123962749574229,
      "grad_norm": 1.4211680889129639,
      "learning_rate": 5.7540401478368e-05,
      "loss": 0.066,
      "step": 9830
    },
    {
      "epoch": 0.7124687466028916,
      "grad_norm": 0.24095243215560913,
      "learning_rate": 5.752590767446917e-05,
      "loss": 0.0144,
      "step": 9831
    },
    {
      "epoch": 0.7125412182483604,
      "grad_norm": 0.9043025970458984,
      "learning_rate": 5.751141387057033e-05,
      "loss": 0.0408,
      "step": 9832
    },
    {
      "epoch": 0.712613689893829,
      "grad_norm": 1.7422035932540894,
      "learning_rate": 5.74969200666715e-05,
      "loss": 0.0838,
      "step": 9833
    },
    {
      "epoch": 0.7126861615392978,
      "grad_norm": 0.7123635411262512,
      "learning_rate": 5.748242626277267e-05,
      "loss": 0.0306,
      "step": 9834
    },
    {
      "epoch": 0.7127586331847665,
      "grad_norm": 0.7450507879257202,
      "learning_rate": 5.746793245887383e-05,
      "loss": 0.0232,
      "step": 9835
    },
    {
      "epoch": 0.7128311048302352,
      "grad_norm": 2.550837516784668,
      "learning_rate": 5.7453438654975e-05,
      "loss": 0.1514,
      "step": 9836
    },
    {
      "epoch": 0.7129035764757039,
      "grad_norm": 0.7646411657333374,
      "learning_rate": 5.743894485107617e-05,
      "loss": 0.0155,
      "step": 9837
    },
    {
      "epoch": 0.7129760481211725,
      "grad_norm": 1.0312085151672363,
      "learning_rate": 5.742445104717733e-05,
      "loss": 0.0291,
      "step": 9838
    },
    {
      "epoch": 0.7130485197666413,
      "grad_norm": 2.133291244506836,
      "learning_rate": 5.74099572432785e-05,
      "loss": 0.1141,
      "step": 9839
    },
    {
      "epoch": 0.71312099141211,
      "grad_norm": 0.6098321080207825,
      "learning_rate": 5.739546343937967e-05,
      "loss": 0.0168,
      "step": 9840
    },
    {
      "epoch": 0.7131934630575787,
      "grad_norm": 0.20363527536392212,
      "learning_rate": 5.738096963548083e-05,
      "loss": 0.004,
      "step": 9841
    },
    {
      "epoch": 0.7132659347030474,
      "grad_norm": 6.625663757324219,
      "learning_rate": 5.7366475831582e-05,
      "loss": 0.1263,
      "step": 9842
    },
    {
      "epoch": 0.7133384063485162,
      "grad_norm": 0.4384477734565735,
      "learning_rate": 5.735198202768317e-05,
      "loss": 0.0138,
      "step": 9843
    },
    {
      "epoch": 0.7134108779939848,
      "grad_norm": 2.4452145099639893,
      "learning_rate": 5.733748822378433e-05,
      "loss": 0.1467,
      "step": 9844
    },
    {
      "epoch": 0.7134833496394536,
      "grad_norm": 0.421777606010437,
      "learning_rate": 5.73229944198855e-05,
      "loss": 0.0189,
      "step": 9845
    },
    {
      "epoch": 0.7135558212849222,
      "grad_norm": 1.7348535060882568,
      "learning_rate": 5.7308500615986674e-05,
      "loss": 0.0616,
      "step": 9846
    },
    {
      "epoch": 0.713628292930391,
      "grad_norm": 2.6181371212005615,
      "learning_rate": 5.729400681208783e-05,
      "loss": 0.2217,
      "step": 9847
    },
    {
      "epoch": 0.7137007645758597,
      "grad_norm": 1.500943660736084,
      "learning_rate": 5.7279513008189e-05,
      "loss": 0.1067,
      "step": 9848
    },
    {
      "epoch": 0.7137732362213284,
      "grad_norm": 0.7401875853538513,
      "learning_rate": 5.726501920429017e-05,
      "loss": 0.0347,
      "step": 9849
    },
    {
      "epoch": 0.7138457078667971,
      "grad_norm": 0.9490007758140564,
      "learning_rate": 5.725052540039133e-05,
      "loss": 0.0259,
      "step": 9850
    },
    {
      "epoch": 0.7139181795122658,
      "grad_norm": 1.7877131700515747,
      "learning_rate": 5.72360315964925e-05,
      "loss": 0.0307,
      "step": 9851
    },
    {
      "epoch": 0.7139906511577345,
      "grad_norm": 1.4664939641952515,
      "learning_rate": 5.7221537792593674e-05,
      "loss": 0.0257,
      "step": 9852
    },
    {
      "epoch": 0.7140631228032033,
      "grad_norm": 1.7038085460662842,
      "learning_rate": 5.720704398869483e-05,
      "loss": 0.064,
      "step": 9853
    },
    {
      "epoch": 0.7141355944486719,
      "grad_norm": 1.6068775653839111,
      "learning_rate": 5.7192550184796e-05,
      "loss": 0.0472,
      "step": 9854
    },
    {
      "epoch": 0.7142080660941407,
      "grad_norm": 0.974479615688324,
      "learning_rate": 5.717805638089717e-05,
      "loss": 0.0437,
      "step": 9855
    },
    {
      "epoch": 0.7142805377396094,
      "grad_norm": 0.32891348004341125,
      "learning_rate": 5.716356257699833e-05,
      "loss": 0.015,
      "step": 9856
    },
    {
      "epoch": 0.7143530093850781,
      "grad_norm": 1.4066352844238281,
      "learning_rate": 5.7149068773099504e-05,
      "loss": 0.0658,
      "step": 9857
    },
    {
      "epoch": 0.7144254810305468,
      "grad_norm": 1.4494048357009888,
      "learning_rate": 5.7134574969200674e-05,
      "loss": 0.1118,
      "step": 9858
    },
    {
      "epoch": 0.7144979526760155,
      "grad_norm": 2.8246402740478516,
      "learning_rate": 5.712008116530183e-05,
      "loss": 0.0732,
      "step": 9859
    },
    {
      "epoch": 0.7145704243214842,
      "grad_norm": 1.250598430633545,
      "learning_rate": 5.7105587361403e-05,
      "loss": 0.0883,
      "step": 9860
    },
    {
      "epoch": 0.714642895966953,
      "grad_norm": 2.234912633895874,
      "learning_rate": 5.709109355750417e-05,
      "loss": 0.0853,
      "step": 9861
    },
    {
      "epoch": 0.7147153676124216,
      "grad_norm": 3.5273139476776123,
      "learning_rate": 5.7076599753605334e-05,
      "loss": 0.0479,
      "step": 9862
    },
    {
      "epoch": 0.7147878392578904,
      "grad_norm": 0.7157668471336365,
      "learning_rate": 5.7062105949706504e-05,
      "loss": 0.0139,
      "step": 9863
    },
    {
      "epoch": 0.7148603109033591,
      "grad_norm": 1.7687369585037231,
      "learning_rate": 5.7047612145807674e-05,
      "loss": 0.0317,
      "step": 9864
    },
    {
      "epoch": 0.7149327825488277,
      "grad_norm": 0.2001316398382187,
      "learning_rate": 5.7033118341908844e-05,
      "loss": 0.0029,
      "step": 9865
    },
    {
      "epoch": 0.7150052541942965,
      "grad_norm": 2.144977569580078,
      "learning_rate": 5.701862453801e-05,
      "loss": 0.0847,
      "step": 9866
    },
    {
      "epoch": 0.7150777258397651,
      "grad_norm": 1.4908896684646606,
      "learning_rate": 5.700413073411117e-05,
      "loss": 0.0746,
      "step": 9867
    },
    {
      "epoch": 0.7151501974852339,
      "grad_norm": 2.4867136478424072,
      "learning_rate": 5.698963693021234e-05,
      "loss": 0.0753,
      "step": 9868
    },
    {
      "epoch": 0.7152226691307026,
      "grad_norm": 1.1399521827697754,
      "learning_rate": 5.6975143126313504e-05,
      "loss": 0.0443,
      "step": 9869
    },
    {
      "epoch": 0.7152951407761713,
      "grad_norm": 0.5477652549743652,
      "learning_rate": 5.6960649322414674e-05,
      "loss": 0.0317,
      "step": 9870
    },
    {
      "epoch": 0.71536761242164,
      "grad_norm": 1.1562368869781494,
      "learning_rate": 5.6946155518515844e-05,
      "loss": 0.0657,
      "step": 9871
    },
    {
      "epoch": 0.7154400840671088,
      "grad_norm": 0.9040394425392151,
      "learning_rate": 5.6931661714617e-05,
      "loss": 0.0375,
      "step": 9872
    },
    {
      "epoch": 0.7155125557125774,
      "grad_norm": 0.8176087141036987,
      "learning_rate": 5.691716791071817e-05,
      "loss": 0.0457,
      "step": 9873
    },
    {
      "epoch": 0.7155850273580462,
      "grad_norm": 1.4703259468078613,
      "learning_rate": 5.690267410681934e-05,
      "loss": 0.0602,
      "step": 9874
    },
    {
      "epoch": 0.7156574990035148,
      "grad_norm": 1.2134623527526855,
      "learning_rate": 5.6888180302920504e-05,
      "loss": 0.0425,
      "step": 9875
    },
    {
      "epoch": 0.7157299706489836,
      "grad_norm": 2.741581916809082,
      "learning_rate": 5.6873686499021674e-05,
      "loss": 0.1514,
      "step": 9876
    },
    {
      "epoch": 0.7158024422944523,
      "grad_norm": 0.9652805924415588,
      "learning_rate": 5.6859192695122844e-05,
      "loss": 0.0291,
      "step": 9877
    },
    {
      "epoch": 0.715874913939921,
      "grad_norm": 2.101283073425293,
      "learning_rate": 5.6844698891224e-05,
      "loss": 0.1329,
      "step": 9878
    },
    {
      "epoch": 0.7159473855853897,
      "grad_norm": 2.574254035949707,
      "learning_rate": 5.683020508732517e-05,
      "loss": 0.106,
      "step": 9879
    },
    {
      "epoch": 0.7160198572308585,
      "grad_norm": 0.4364015460014343,
      "learning_rate": 5.681571128342634e-05,
      "loss": 0.0228,
      "step": 9880
    },
    {
      "epoch": 0.7160923288763271,
      "grad_norm": 0.8047988414764404,
      "learning_rate": 5.6801217479527504e-05,
      "loss": 0.0274,
      "step": 9881
    },
    {
      "epoch": 0.7161648005217959,
      "grad_norm": 1.3774019479751587,
      "learning_rate": 5.6786723675628674e-05,
      "loss": 0.0596,
      "step": 9882
    },
    {
      "epoch": 0.7162372721672645,
      "grad_norm": 0.8462109565734863,
      "learning_rate": 5.6772229871729844e-05,
      "loss": 0.0389,
      "step": 9883
    },
    {
      "epoch": 0.7163097438127333,
      "grad_norm": 1.1091715097427368,
      "learning_rate": 5.6757736067831e-05,
      "loss": 0.053,
      "step": 9884
    },
    {
      "epoch": 0.716382215458202,
      "grad_norm": 1.119644284248352,
      "learning_rate": 5.674324226393217e-05,
      "loss": 0.1207,
      "step": 9885
    },
    {
      "epoch": 0.7164546871036707,
      "grad_norm": 1.9028716087341309,
      "learning_rate": 5.672874846003334e-05,
      "loss": 0.0616,
      "step": 9886
    },
    {
      "epoch": 0.7165271587491394,
      "grad_norm": 0.9448625445365906,
      "learning_rate": 5.6714254656134504e-05,
      "loss": 0.0238,
      "step": 9887
    },
    {
      "epoch": 0.7165996303946081,
      "grad_norm": 1.1950284242630005,
      "learning_rate": 5.6699760852235674e-05,
      "loss": 0.0766,
      "step": 9888
    },
    {
      "epoch": 0.7166721020400768,
      "grad_norm": 0.6055464148521423,
      "learning_rate": 5.6685267048336844e-05,
      "loss": 0.0246,
      "step": 9889
    },
    {
      "epoch": 0.7167445736855456,
      "grad_norm": 0.19471794366836548,
      "learning_rate": 5.6670773244438e-05,
      "loss": 0.0062,
      "step": 9890
    },
    {
      "epoch": 0.7168170453310142,
      "grad_norm": 2.803438186645508,
      "learning_rate": 5.665627944053917e-05,
      "loss": 0.1003,
      "step": 9891
    },
    {
      "epoch": 0.716889516976483,
      "grad_norm": 0.9075749516487122,
      "learning_rate": 5.664178563664034e-05,
      "loss": 0.0421,
      "step": 9892
    },
    {
      "epoch": 0.7169619886219517,
      "grad_norm": 1.2817964553833008,
      "learning_rate": 5.6627291832741504e-05,
      "loss": 0.0951,
      "step": 9893
    },
    {
      "epoch": 0.7170344602674203,
      "grad_norm": 1.0941096544265747,
      "learning_rate": 5.6612798028842674e-05,
      "loss": 0.098,
      "step": 9894
    },
    {
      "epoch": 0.7171069319128891,
      "grad_norm": 2.8211965560913086,
      "learning_rate": 5.6598304224943844e-05,
      "loss": 0.0421,
      "step": 9895
    },
    {
      "epoch": 0.7171794035583577,
      "grad_norm": 0.8782821297645569,
      "learning_rate": 5.6583810421045e-05,
      "loss": 0.0377,
      "step": 9896
    },
    {
      "epoch": 0.7172518752038265,
      "grad_norm": 1.4175305366516113,
      "learning_rate": 5.656931661714617e-05,
      "loss": 0.0476,
      "step": 9897
    },
    {
      "epoch": 0.7173243468492952,
      "grad_norm": 1.4494054317474365,
      "learning_rate": 5.655482281324734e-05,
      "loss": 0.0387,
      "step": 9898
    },
    {
      "epoch": 0.7173968184947639,
      "grad_norm": 0.26717573404312134,
      "learning_rate": 5.6540329009348503e-05,
      "loss": 0.0101,
      "step": 9899
    },
    {
      "epoch": 0.7174692901402326,
      "grad_norm": 0.8995519280433655,
      "learning_rate": 5.6525835205449674e-05,
      "loss": 0.0219,
      "step": 9900
    },
    {
      "epoch": 0.7175417617857014,
      "grad_norm": 1.1866968870162964,
      "learning_rate": 5.6511341401550844e-05,
      "loss": 0.0744,
      "step": 9901
    },
    {
      "epoch": 0.71761423343117,
      "grad_norm": 0.8407491445541382,
      "learning_rate": 5.6496847597652e-05,
      "loss": 0.0324,
      "step": 9902
    },
    {
      "epoch": 0.7176867050766388,
      "grad_norm": 0.8867236375808716,
      "learning_rate": 5.648235379375317e-05,
      "loss": 0.0468,
      "step": 9903
    },
    {
      "epoch": 0.7177591767221074,
      "grad_norm": 1.5768247842788696,
      "learning_rate": 5.646785998985435e-05,
      "loss": 0.088,
      "step": 9904
    },
    {
      "epoch": 0.7178316483675762,
      "grad_norm": 1.449125051498413,
      "learning_rate": 5.64533661859555e-05,
      "loss": 0.0501,
      "step": 9905
    },
    {
      "epoch": 0.7179041200130449,
      "grad_norm": 1.9060611724853516,
      "learning_rate": 5.6438872382056673e-05,
      "loss": 0.1334,
      "step": 9906
    },
    {
      "epoch": 0.7179765916585136,
      "grad_norm": 1.5712378025054932,
      "learning_rate": 5.6424378578157843e-05,
      "loss": 0.0607,
      "step": 9907
    },
    {
      "epoch": 0.7180490633039823,
      "grad_norm": 1.7305042743682861,
      "learning_rate": 5.6409884774259e-05,
      "loss": 0.0469,
      "step": 9908
    },
    {
      "epoch": 0.7181215349494511,
      "grad_norm": 1.7052055597305298,
      "learning_rate": 5.639539097036018e-05,
      "loss": 0.1062,
      "step": 9909
    },
    {
      "epoch": 0.7181940065949197,
      "grad_norm": 1.2969722747802734,
      "learning_rate": 5.638089716646135e-05,
      "loss": 0.0552,
      "step": 9910
    },
    {
      "epoch": 0.7182664782403885,
      "grad_norm": 0.10399220883846283,
      "learning_rate": 5.63664033625625e-05,
      "loss": 0.0032,
      "step": 9911
    },
    {
      "epoch": 0.7183389498858571,
      "grad_norm": 1.187586784362793,
      "learning_rate": 5.635190955866367e-05,
      "loss": 0.035,
      "step": 9912
    },
    {
      "epoch": 0.7184114215313259,
      "grad_norm": 1.2660115957260132,
      "learning_rate": 5.633741575476484e-05,
      "loss": 0.0352,
      "step": 9913
    },
    {
      "epoch": 0.7184838931767946,
      "grad_norm": 0.5754127502441406,
      "learning_rate": 5.632292195086601e-05,
      "loss": 0.0165,
      "step": 9914
    },
    {
      "epoch": 0.7185563648222633,
      "grad_norm": 0.700485110282898,
      "learning_rate": 5.630842814696718e-05,
      "loss": 0.0628,
      "step": 9915
    },
    {
      "epoch": 0.718628836467732,
      "grad_norm": 0.5707727074623108,
      "learning_rate": 5.629393434306835e-05,
      "loss": 0.019,
      "step": 9916
    },
    {
      "epoch": 0.7187013081132008,
      "grad_norm": 1.275057077407837,
      "learning_rate": 5.62794405391695e-05,
      "loss": 0.0785,
      "step": 9917
    },
    {
      "epoch": 0.7187737797586694,
      "grad_norm": 1.1868863105773926,
      "learning_rate": 5.626494673527067e-05,
      "loss": 0.0713,
      "step": 9918
    },
    {
      "epoch": 0.7188462514041382,
      "grad_norm": 1.848459243774414,
      "learning_rate": 5.625045293137184e-05,
      "loss": 0.0622,
      "step": 9919
    },
    {
      "epoch": 0.7189187230496068,
      "grad_norm": 1.505975604057312,
      "learning_rate": 5.6235959127473007e-05,
      "loss": 0.0417,
      "step": 9920
    },
    {
      "epoch": 0.7189911946950756,
      "grad_norm": 0.637548565864563,
      "learning_rate": 5.6221465323574177e-05,
      "loss": 0.0247,
      "step": 9921
    },
    {
      "epoch": 0.7190636663405443,
      "grad_norm": 2.3458638191223145,
      "learning_rate": 5.6206971519675347e-05,
      "loss": 0.0855,
      "step": 9922
    },
    {
      "epoch": 0.719136137986013,
      "grad_norm": 1.150136113166809,
      "learning_rate": 5.61924777157765e-05,
      "loss": 0.0558,
      "step": 9923
    },
    {
      "epoch": 0.7192086096314817,
      "grad_norm": 0.9646680951118469,
      "learning_rate": 5.617798391187767e-05,
      "loss": 0.0538,
      "step": 9924
    },
    {
      "epoch": 0.7192810812769503,
      "grad_norm": 2.686047315597534,
      "learning_rate": 5.616349010797884e-05,
      "loss": 0.0832,
      "step": 9925
    },
    {
      "epoch": 0.7193535529224191,
      "grad_norm": 0.6282468438148499,
      "learning_rate": 5.6148996304080006e-05,
      "loss": 0.0485,
      "step": 9926
    },
    {
      "epoch": 0.7194260245678878,
      "grad_norm": 0.48015767335891724,
      "learning_rate": 5.6134502500181176e-05,
      "loss": 0.0092,
      "step": 9927
    },
    {
      "epoch": 0.7194984962133565,
      "grad_norm": 1.162724494934082,
      "learning_rate": 5.6120008696282346e-05,
      "loss": 0.0175,
      "step": 9928
    },
    {
      "epoch": 0.7195709678588252,
      "grad_norm": 2.6668264865875244,
      "learning_rate": 5.61055148923835e-05,
      "loss": 0.033,
      "step": 9929
    },
    {
      "epoch": 0.719643439504294,
      "grad_norm": 0.3514498174190521,
      "learning_rate": 5.609102108848467e-05,
      "loss": 0.0114,
      "step": 9930
    },
    {
      "epoch": 0.7197159111497626,
      "grad_norm": 0.7821198105812073,
      "learning_rate": 5.607652728458584e-05,
      "loss": 0.0267,
      "step": 9931
    },
    {
      "epoch": 0.7197883827952314,
      "grad_norm": 2.8180885314941406,
      "learning_rate": 5.6062033480687006e-05,
      "loss": 0.072,
      "step": 9932
    },
    {
      "epoch": 0.7198608544407,
      "grad_norm": 0.4480423331260681,
      "learning_rate": 5.6047539676788176e-05,
      "loss": 0.0272,
      "step": 9933
    },
    {
      "epoch": 0.7199333260861688,
      "grad_norm": 1.873093605041504,
      "learning_rate": 5.6033045872889346e-05,
      "loss": 0.0682,
      "step": 9934
    },
    {
      "epoch": 0.7200057977316375,
      "grad_norm": 0.22366046905517578,
      "learning_rate": 5.60185520689905e-05,
      "loss": 0.0069,
      "step": 9935
    },
    {
      "epoch": 0.7200782693771062,
      "grad_norm": 0.754574179649353,
      "learning_rate": 5.600405826509167e-05,
      "loss": 0.0361,
      "step": 9936
    },
    {
      "epoch": 0.7201507410225749,
      "grad_norm": 4.250607967376709,
      "learning_rate": 5.598956446119284e-05,
      "loss": 0.084,
      "step": 9937
    },
    {
      "epoch": 0.7202232126680437,
      "grad_norm": 1.5907450914382935,
      "learning_rate": 5.5975070657294006e-05,
      "loss": 0.0616,
      "step": 9938
    },
    {
      "epoch": 0.7202956843135123,
      "grad_norm": 1.8454056978225708,
      "learning_rate": 5.5960576853395176e-05,
      "loss": 0.038,
      "step": 9939
    },
    {
      "epoch": 0.7203681559589811,
      "grad_norm": 0.2250676453113556,
      "learning_rate": 5.5946083049496346e-05,
      "loss": 0.0089,
      "step": 9940
    },
    {
      "epoch": 0.7204406276044497,
      "grad_norm": 2.800895929336548,
      "learning_rate": 5.59315892455975e-05,
      "loss": 0.0543,
      "step": 9941
    },
    {
      "epoch": 0.7205130992499185,
      "grad_norm": 0.9335989952087402,
      "learning_rate": 5.591709544169867e-05,
      "loss": 0.0353,
      "step": 9942
    },
    {
      "epoch": 0.7205855708953872,
      "grad_norm": 1.3610961437225342,
      "learning_rate": 5.590260163779984e-05,
      "loss": 0.055,
      "step": 9943
    },
    {
      "epoch": 0.7206580425408559,
      "grad_norm": 0.6608692407608032,
      "learning_rate": 5.5888107833901006e-05,
      "loss": 0.024,
      "step": 9944
    },
    {
      "epoch": 0.7207305141863246,
      "grad_norm": 1.339950442314148,
      "learning_rate": 5.5873614030002176e-05,
      "loss": 0.0363,
      "step": 9945
    },
    {
      "epoch": 0.7208029858317934,
      "grad_norm": 1.2252675294876099,
      "learning_rate": 5.5859120226103346e-05,
      "loss": 0.036,
      "step": 9946
    },
    {
      "epoch": 0.720875457477262,
      "grad_norm": 0.8443348407745361,
      "learning_rate": 5.5844626422204516e-05,
      "loss": 0.0297,
      "step": 9947
    },
    {
      "epoch": 0.7209479291227308,
      "grad_norm": 1.2638881206512451,
      "learning_rate": 5.583013261830567e-05,
      "loss": 0.0407,
      "step": 9948
    },
    {
      "epoch": 0.7210204007681994,
      "grad_norm": 1.056365966796875,
      "learning_rate": 5.581563881440684e-05,
      "loss": 0.0544,
      "step": 9949
    },
    {
      "epoch": 0.7210928724136682,
      "grad_norm": 1.374211311340332,
      "learning_rate": 5.580114501050801e-05,
      "loss": 0.0819,
      "step": 9950
    },
    {
      "epoch": 0.7211653440591369,
      "grad_norm": 3.734769821166992,
      "learning_rate": 5.5786651206609176e-05,
      "loss": 0.0656,
      "step": 9951
    },
    {
      "epoch": 0.7212378157046055,
      "grad_norm": 1.2903735637664795,
      "learning_rate": 5.5772157402710346e-05,
      "loss": 0.0819,
      "step": 9952
    },
    {
      "epoch": 0.7213102873500743,
      "grad_norm": 2.870321035385132,
      "learning_rate": 5.5757663598811516e-05,
      "loss": 0.1003,
      "step": 9953
    },
    {
      "epoch": 0.7213827589955429,
      "grad_norm": 0.6760267019271851,
      "learning_rate": 5.574316979491267e-05,
      "loss": 0.0356,
      "step": 9954
    },
    {
      "epoch": 0.7214552306410117,
      "grad_norm": 3.155597686767578,
      "learning_rate": 5.572867599101384e-05,
      "loss": 0.113,
      "step": 9955
    },
    {
      "epoch": 0.7215277022864804,
      "grad_norm": 0.6410878300666809,
      "learning_rate": 5.571418218711501e-05,
      "loss": 0.0121,
      "step": 9956
    },
    {
      "epoch": 0.7216001739319491,
      "grad_norm": 4.997089862823486,
      "learning_rate": 5.5699688383216176e-05,
      "loss": 0.0279,
      "step": 9957
    },
    {
      "epoch": 0.7216726455774178,
      "grad_norm": 0.4641726016998291,
      "learning_rate": 5.5685194579317346e-05,
      "loss": 0.0068,
      "step": 9958
    },
    {
      "epoch": 0.7217451172228866,
      "grad_norm": 2.4568512439727783,
      "learning_rate": 5.5670700775418516e-05,
      "loss": 0.0461,
      "step": 9959
    },
    {
      "epoch": 0.7218175888683552,
      "grad_norm": 0.8517777919769287,
      "learning_rate": 5.565620697151967e-05,
      "loss": 0.0544,
      "step": 9960
    },
    {
      "epoch": 0.721890060513824,
      "grad_norm": 0.27971476316452026,
      "learning_rate": 5.564171316762084e-05,
      "loss": 0.0048,
      "step": 9961
    },
    {
      "epoch": 0.7219625321592926,
      "grad_norm": 0.7400618195533752,
      "learning_rate": 5.562721936372202e-05,
      "loss": 0.0305,
      "step": 9962
    },
    {
      "epoch": 0.7220350038047614,
      "grad_norm": 0.5901859998703003,
      "learning_rate": 5.5612725559823176e-05,
      "loss": 0.0223,
      "step": 9963
    },
    {
      "epoch": 0.7221074754502301,
      "grad_norm": 1.7797952890396118,
      "learning_rate": 5.5598231755924346e-05,
      "loss": 0.0935,
      "step": 9964
    },
    {
      "epoch": 0.7221799470956988,
      "grad_norm": 2.2211685180664062,
      "learning_rate": 5.5583737952025516e-05,
      "loss": 0.0533,
      "step": 9965
    },
    {
      "epoch": 0.7222524187411675,
      "grad_norm": 0.9438599348068237,
      "learning_rate": 5.556924414812667e-05,
      "loss": 0.0079,
      "step": 9966
    },
    {
      "epoch": 0.7223248903866363,
      "grad_norm": 1.80818772315979,
      "learning_rate": 5.555475034422785e-05,
      "loss": 0.0691,
      "step": 9967
    },
    {
      "epoch": 0.7223973620321049,
      "grad_norm": 0.8600148558616638,
      "learning_rate": 5.554025654032902e-05,
      "loss": 0.0237,
      "step": 9968
    },
    {
      "epoch": 0.7224698336775737,
      "grad_norm": 2.291851758956909,
      "learning_rate": 5.5525762736430176e-05,
      "loss": 0.0408,
      "step": 9969
    },
    {
      "epoch": 0.7225423053230423,
      "grad_norm": 2.0202760696411133,
      "learning_rate": 5.5511268932531346e-05,
      "loss": 0.0735,
      "step": 9970
    },
    {
      "epoch": 0.7226147769685111,
      "grad_norm": 0.41060981154441833,
      "learning_rate": 5.5496775128632516e-05,
      "loss": 0.0089,
      "step": 9971
    },
    {
      "epoch": 0.7226872486139798,
      "grad_norm": 0.866136372089386,
      "learning_rate": 5.548228132473368e-05,
      "loss": 0.0096,
      "step": 9972
    },
    {
      "epoch": 0.7227597202594485,
      "grad_norm": 1.4244781732559204,
      "learning_rate": 5.546778752083485e-05,
      "loss": 0.0313,
      "step": 9973
    },
    {
      "epoch": 0.7228321919049172,
      "grad_norm": 0.9873323440551758,
      "learning_rate": 5.545329371693602e-05,
      "loss": 0.0391,
      "step": 9974
    },
    {
      "epoch": 0.722904663550386,
      "grad_norm": 0.19826984405517578,
      "learning_rate": 5.5438799913037176e-05,
      "loss": 0.004,
      "step": 9975
    },
    {
      "epoch": 0.7229771351958546,
      "grad_norm": 0.5739062428474426,
      "learning_rate": 5.5424306109138346e-05,
      "loss": 0.0412,
      "step": 9976
    },
    {
      "epoch": 0.7230496068413234,
      "grad_norm": 0.9848126769065857,
      "learning_rate": 5.5409812305239516e-05,
      "loss": 0.0557,
      "step": 9977
    },
    {
      "epoch": 0.723122078486792,
      "grad_norm": 1.6824679374694824,
      "learning_rate": 5.539531850134068e-05,
      "loss": 0.029,
      "step": 9978
    },
    {
      "epoch": 0.7231945501322607,
      "grad_norm": 2.345402717590332,
      "learning_rate": 5.538082469744185e-05,
      "loss": 0.0432,
      "step": 9979
    },
    {
      "epoch": 0.7232670217777295,
      "grad_norm": 1.0812242031097412,
      "learning_rate": 5.536633089354302e-05,
      "loss": 0.0442,
      "step": 9980
    },
    {
      "epoch": 0.7233394934231981,
      "grad_norm": 1.2571020126342773,
      "learning_rate": 5.5351837089644176e-05,
      "loss": 0.0754,
      "step": 9981
    },
    {
      "epoch": 0.7234119650686669,
      "grad_norm": 1.8359875679016113,
      "learning_rate": 5.5337343285745346e-05,
      "loss": 0.0614,
      "step": 9982
    },
    {
      "epoch": 0.7234844367141356,
      "grad_norm": 1.1732579469680786,
      "learning_rate": 5.5322849481846516e-05,
      "loss": 0.0257,
      "step": 9983
    },
    {
      "epoch": 0.7235569083596043,
      "grad_norm": 1.2706794738769531,
      "learning_rate": 5.530835567794768e-05,
      "loss": 0.0445,
      "step": 9984
    },
    {
      "epoch": 0.723629380005073,
      "grad_norm": 0.9628943204879761,
      "learning_rate": 5.529386187404885e-05,
      "loss": 0.0355,
      "step": 9985
    },
    {
      "epoch": 0.7237018516505417,
      "grad_norm": 1.1802372932434082,
      "learning_rate": 5.527936807015002e-05,
      "loss": 0.0147,
      "step": 9986
    },
    {
      "epoch": 0.7237743232960104,
      "grad_norm": 1.970274567604065,
      "learning_rate": 5.5264874266251175e-05,
      "loss": 0.0936,
      "step": 9987
    },
    {
      "epoch": 0.7238467949414792,
      "grad_norm": 0.8041926026344299,
      "learning_rate": 5.5250380462352345e-05,
      "loss": 0.0082,
      "step": 9988
    },
    {
      "epoch": 0.7239192665869478,
      "grad_norm": 1.1568092107772827,
      "learning_rate": 5.5235886658453515e-05,
      "loss": 0.0454,
      "step": 9989
    },
    {
      "epoch": 0.7239917382324166,
      "grad_norm": 2.216829776763916,
      "learning_rate": 5.522139285455468e-05,
      "loss": 0.0954,
      "step": 9990
    },
    {
      "epoch": 0.7240642098778852,
      "grad_norm": 1.1174558401107788,
      "learning_rate": 5.520689905065585e-05,
      "loss": 0.0985,
      "step": 9991
    },
    {
      "epoch": 0.724136681523354,
      "grad_norm": 0.26945751905441284,
      "learning_rate": 5.519240524675702e-05,
      "loss": 0.0088,
      "step": 9992
    },
    {
      "epoch": 0.7242091531688227,
      "grad_norm": 1.065000295639038,
      "learning_rate": 5.5177911442858175e-05,
      "loss": 0.0617,
      "step": 9993
    },
    {
      "epoch": 0.7242816248142914,
      "grad_norm": 0.25121647119522095,
      "learning_rate": 5.5163417638959345e-05,
      "loss": 0.005,
      "step": 9994
    },
    {
      "epoch": 0.7243540964597601,
      "grad_norm": 2.710174083709717,
      "learning_rate": 5.5148923835060515e-05,
      "loss": 0.15,
      "step": 9995
    },
    {
      "epoch": 0.7244265681052289,
      "grad_norm": 0.8628157377243042,
      "learning_rate": 5.513443003116168e-05,
      "loss": 0.0258,
      "step": 9996
    },
    {
      "epoch": 0.7244990397506975,
      "grad_norm": 1.134652853012085,
      "learning_rate": 5.511993622726285e-05,
      "loss": 0.0129,
      "step": 9997
    },
    {
      "epoch": 0.7245715113961663,
      "grad_norm": 0.9667015075683594,
      "learning_rate": 5.510544242336402e-05,
      "loss": 0.0095,
      "step": 9998
    },
    {
      "epoch": 0.7246439830416349,
      "grad_norm": 1.572779893875122,
      "learning_rate": 5.5090948619465175e-05,
      "loss": 0.0783,
      "step": 9999
    },
    {
      "epoch": 0.7247164546871037,
      "grad_norm": 1.926226019859314,
      "learning_rate": 5.5076454815566345e-05,
      "loss": 0.0246,
      "step": 10000
    },
    {
      "epoch": 0.7247889263325724,
      "grad_norm": 1.5091966390609741,
      "learning_rate": 5.5061961011667515e-05,
      "loss": 0.058,
      "step": 10001
    },
    {
      "epoch": 0.724861397978041,
      "grad_norm": 2.5494017601013184,
      "learning_rate": 5.504746720776868e-05,
      "loss": 0.0902,
      "step": 10002
    },
    {
      "epoch": 0.7249338696235098,
      "grad_norm": 0.19559502601623535,
      "learning_rate": 5.503297340386985e-05,
      "loss": 0.0036,
      "step": 10003
    },
    {
      "epoch": 0.7250063412689786,
      "grad_norm": 1.3224263191223145,
      "learning_rate": 5.501847959997102e-05,
      "loss": 0.0519,
      "step": 10004
    },
    {
      "epoch": 0.7250788129144472,
      "grad_norm": 0.7923078536987305,
      "learning_rate": 5.5003985796072175e-05,
      "loss": 0.0204,
      "step": 10005
    },
    {
      "epoch": 0.725151284559916,
      "grad_norm": 2.419682264328003,
      "learning_rate": 5.4989491992173345e-05,
      "loss": 0.1139,
      "step": 10006
    },
    {
      "epoch": 0.7252237562053846,
      "grad_norm": 0.9474354982376099,
      "learning_rate": 5.4974998188274515e-05,
      "loss": 0.0509,
      "step": 10007
    },
    {
      "epoch": 0.7252962278508533,
      "grad_norm": 1.0510848760604858,
      "learning_rate": 5.496050438437568e-05,
      "loss": 0.0554,
      "step": 10008
    },
    {
      "epoch": 0.7253686994963221,
      "grad_norm": 2.4791858196258545,
      "learning_rate": 5.494601058047685e-05,
      "loss": 0.0634,
      "step": 10009
    },
    {
      "epoch": 0.7254411711417907,
      "grad_norm": 0.7575910687446594,
      "learning_rate": 5.493151677657802e-05,
      "loss": 0.0176,
      "step": 10010
    },
    {
      "epoch": 0.7255136427872595,
      "grad_norm": 0.8817568421363831,
      "learning_rate": 5.4917022972679175e-05,
      "loss": 0.0135,
      "step": 10011
    },
    {
      "epoch": 0.7255861144327282,
      "grad_norm": 1.0393314361572266,
      "learning_rate": 5.4902529168780345e-05,
      "loss": 0.0419,
      "step": 10012
    },
    {
      "epoch": 0.7256585860781969,
      "grad_norm": 0.3244028091430664,
      "learning_rate": 5.4888035364881515e-05,
      "loss": 0.0145,
      "step": 10013
    },
    {
      "epoch": 0.7257310577236656,
      "grad_norm": 0.6749831438064575,
      "learning_rate": 5.487354156098268e-05,
      "loss": 0.0435,
      "step": 10014
    },
    {
      "epoch": 0.7258035293691343,
      "grad_norm": 3.7473840713500977,
      "learning_rate": 5.485904775708385e-05,
      "loss": 0.0973,
      "step": 10015
    },
    {
      "epoch": 0.725876001014603,
      "grad_norm": 3.4487671852111816,
      "learning_rate": 5.484455395318502e-05,
      "loss": 0.1039,
      "step": 10016
    },
    {
      "epoch": 0.7259484726600718,
      "grad_norm": 0.4141180217266083,
      "learning_rate": 5.4830060149286175e-05,
      "loss": 0.0135,
      "step": 10017
    },
    {
      "epoch": 0.7260209443055404,
      "grad_norm": 1.1112165451049805,
      "learning_rate": 5.4815566345387345e-05,
      "loss": 0.0217,
      "step": 10018
    },
    {
      "epoch": 0.7260934159510092,
      "grad_norm": 0.5126709938049316,
      "learning_rate": 5.480107254148852e-05,
      "loss": 0.0332,
      "step": 10019
    },
    {
      "epoch": 0.7261658875964779,
      "grad_norm": 1.004849910736084,
      "learning_rate": 5.478657873758968e-05,
      "loss": 0.0169,
      "step": 10020
    },
    {
      "epoch": 0.7262383592419466,
      "grad_norm": 0.19693180918693542,
      "learning_rate": 5.477208493369085e-05,
      "loss": 0.0043,
      "step": 10021
    },
    {
      "epoch": 0.7263108308874153,
      "grad_norm": 0.3178727328777313,
      "learning_rate": 5.475759112979202e-05,
      "loss": 0.0088,
      "step": 10022
    },
    {
      "epoch": 0.726383302532884,
      "grad_norm": 1.3676427602767944,
      "learning_rate": 5.4743097325893175e-05,
      "loss": 0.0379,
      "step": 10023
    },
    {
      "epoch": 0.7264557741783527,
      "grad_norm": 1.2300416231155396,
      "learning_rate": 5.472860352199435e-05,
      "loss": 0.056,
      "step": 10024
    },
    {
      "epoch": 0.7265282458238215,
      "grad_norm": 0.5098249316215515,
      "learning_rate": 5.471410971809552e-05,
      "loss": 0.0183,
      "step": 10025
    },
    {
      "epoch": 0.7266007174692901,
      "grad_norm": 0.9626944661140442,
      "learning_rate": 5.469961591419669e-05,
      "loss": 0.0311,
      "step": 10026
    },
    {
      "epoch": 0.7266731891147589,
      "grad_norm": 0.35643789172172546,
      "learning_rate": 5.468512211029785e-05,
      "loss": 0.0149,
      "step": 10027
    },
    {
      "epoch": 0.7267456607602275,
      "grad_norm": 0.9645525813102722,
      "learning_rate": 5.467062830639902e-05,
      "loss": 0.0356,
      "step": 10028
    },
    {
      "epoch": 0.7268181324056963,
      "grad_norm": 0.6927396059036255,
      "learning_rate": 5.465613450250019e-05,
      "loss": 0.0408,
      "step": 10029
    },
    {
      "epoch": 0.726890604051165,
      "grad_norm": 0.8784387111663818,
      "learning_rate": 5.464164069860135e-05,
      "loss": 0.0225,
      "step": 10030
    },
    {
      "epoch": 0.7269630756966337,
      "grad_norm": 1.0037099123001099,
      "learning_rate": 5.462714689470252e-05,
      "loss": 0.0456,
      "step": 10031
    },
    {
      "epoch": 0.7270355473421024,
      "grad_norm": 2.239422082901001,
      "learning_rate": 5.461265309080369e-05,
      "loss": 0.1037,
      "step": 10032
    },
    {
      "epoch": 0.7271080189875712,
      "grad_norm": 0.14368103444576263,
      "learning_rate": 5.459815928690485e-05,
      "loss": 0.0027,
      "step": 10033
    },
    {
      "epoch": 0.7271804906330398,
      "grad_norm": 1.4584431648254395,
      "learning_rate": 5.458366548300602e-05,
      "loss": 0.0402,
      "step": 10034
    },
    {
      "epoch": 0.7272529622785086,
      "grad_norm": 4.925788402557373,
      "learning_rate": 5.456917167910719e-05,
      "loss": 0.1079,
      "step": 10035
    },
    {
      "epoch": 0.7273254339239772,
      "grad_norm": 0.8425577878952026,
      "learning_rate": 5.455467787520835e-05,
      "loss": 0.0327,
      "step": 10036
    },
    {
      "epoch": 0.727397905569446,
      "grad_norm": 1.2543843984603882,
      "learning_rate": 5.454018407130952e-05,
      "loss": 0.016,
      "step": 10037
    },
    {
      "epoch": 0.7274703772149147,
      "grad_norm": 0.2901010811328888,
      "learning_rate": 5.452569026741069e-05,
      "loss": 0.0057,
      "step": 10038
    },
    {
      "epoch": 0.7275428488603833,
      "grad_norm": 1.4051604270935059,
      "learning_rate": 5.451119646351185e-05,
      "loss": 0.0817,
      "step": 10039
    },
    {
      "epoch": 0.7276153205058521,
      "grad_norm": 0.2509652376174927,
      "learning_rate": 5.449670265961302e-05,
      "loss": 0.0058,
      "step": 10040
    },
    {
      "epoch": 0.7276877921513208,
      "grad_norm": 0.6277639269828796,
      "learning_rate": 5.448220885571419e-05,
      "loss": 0.0113,
      "step": 10041
    },
    {
      "epoch": 0.7277602637967895,
      "grad_norm": 1.1179312467575073,
      "learning_rate": 5.446771505181535e-05,
      "loss": 0.0075,
      "step": 10042
    },
    {
      "epoch": 0.7278327354422582,
      "grad_norm": 2.6729536056518555,
      "learning_rate": 5.445322124791652e-05,
      "loss": 0.0663,
      "step": 10043
    },
    {
      "epoch": 0.7279052070877269,
      "grad_norm": 1.3113877773284912,
      "learning_rate": 5.443872744401769e-05,
      "loss": 0.0337,
      "step": 10044
    },
    {
      "epoch": 0.7279776787331956,
      "grad_norm": 0.15635688602924347,
      "learning_rate": 5.442423364011885e-05,
      "loss": 0.0072,
      "step": 10045
    },
    {
      "epoch": 0.7280501503786644,
      "grad_norm": 3.474982261657715,
      "learning_rate": 5.440973983622002e-05,
      "loss": 0.0539,
      "step": 10046
    },
    {
      "epoch": 0.728122622024133,
      "grad_norm": 3.166334390640259,
      "learning_rate": 5.439524603232119e-05,
      "loss": 0.0599,
      "step": 10047
    },
    {
      "epoch": 0.7281950936696018,
      "grad_norm": 2.0143027305603027,
      "learning_rate": 5.438075222842235e-05,
      "loss": 0.0726,
      "step": 10048
    },
    {
      "epoch": 0.7282675653150705,
      "grad_norm": 2.966721773147583,
      "learning_rate": 5.436625842452352e-05,
      "loss": 0.1038,
      "step": 10049
    },
    {
      "epoch": 0.7283400369605392,
      "grad_norm": 1.6743919849395752,
      "learning_rate": 5.435176462062469e-05,
      "loss": 0.0901,
      "step": 10050
    },
    {
      "epoch": 0.7284125086060079,
      "grad_norm": 3.6681060791015625,
      "learning_rate": 5.433727081672585e-05,
      "loss": 0.1186,
      "step": 10051
    },
    {
      "epoch": 0.7284849802514766,
      "grad_norm": 1.468004584312439,
      "learning_rate": 5.432277701282702e-05,
      "loss": 0.0279,
      "step": 10052
    },
    {
      "epoch": 0.7285574518969453,
      "grad_norm": 2.2296648025512695,
      "learning_rate": 5.430828320892819e-05,
      "loss": 0.0787,
      "step": 10053
    },
    {
      "epoch": 0.7286299235424141,
      "grad_norm": 2.8800435066223145,
      "learning_rate": 5.429378940502935e-05,
      "loss": 0.1663,
      "step": 10054
    },
    {
      "epoch": 0.7287023951878827,
      "grad_norm": 0.532153844833374,
      "learning_rate": 5.427929560113052e-05,
      "loss": 0.0076,
      "step": 10055
    },
    {
      "epoch": 0.7287748668333515,
      "grad_norm": 2.7174160480499268,
      "learning_rate": 5.426480179723169e-05,
      "loss": 0.0383,
      "step": 10056
    },
    {
      "epoch": 0.7288473384788202,
      "grad_norm": 1.5749080181121826,
      "learning_rate": 5.425030799333285e-05,
      "loss": 0.0327,
      "step": 10057
    },
    {
      "epoch": 0.7289198101242889,
      "grad_norm": 3.2436399459838867,
      "learning_rate": 5.423581418943402e-05,
      "loss": 0.0966,
      "step": 10058
    },
    {
      "epoch": 0.7289922817697576,
      "grad_norm": 1.6043184995651245,
      "learning_rate": 5.422132038553519e-05,
      "loss": 0.0252,
      "step": 10059
    },
    {
      "epoch": 0.7290647534152263,
      "grad_norm": 0.9145424365997314,
      "learning_rate": 5.420682658163635e-05,
      "loss": 0.0088,
      "step": 10060
    },
    {
      "epoch": 0.729137225060695,
      "grad_norm": 3.1764488220214844,
      "learning_rate": 5.419233277773752e-05,
      "loss": 0.1425,
      "step": 10061
    },
    {
      "epoch": 0.7292096967061638,
      "grad_norm": 0.6196242570877075,
      "learning_rate": 5.417783897383869e-05,
      "loss": 0.0247,
      "step": 10062
    },
    {
      "epoch": 0.7292821683516324,
      "grad_norm": 2.893655776977539,
      "learning_rate": 5.416334516993985e-05,
      "loss": 0.0836,
      "step": 10063
    },
    {
      "epoch": 0.7293546399971012,
      "grad_norm": 1.4264309406280518,
      "learning_rate": 5.414885136604102e-05,
      "loss": 0.0256,
      "step": 10064
    },
    {
      "epoch": 0.7294271116425698,
      "grad_norm": 0.5672501921653748,
      "learning_rate": 5.413435756214219e-05,
      "loss": 0.0082,
      "step": 10065
    },
    {
      "epoch": 0.7294995832880385,
      "grad_norm": 1.3090636730194092,
      "learning_rate": 5.411986375824335e-05,
      "loss": 0.0438,
      "step": 10066
    },
    {
      "epoch": 0.7295720549335073,
      "grad_norm": 0.5005289912223816,
      "learning_rate": 5.410536995434452e-05,
      "loss": 0.0076,
      "step": 10067
    },
    {
      "epoch": 0.7296445265789759,
      "grad_norm": 0.3989338278770447,
      "learning_rate": 5.409087615044569e-05,
      "loss": 0.0094,
      "step": 10068
    },
    {
      "epoch": 0.7297169982244447,
      "grad_norm": 0.45568516850471497,
      "learning_rate": 5.407638234654685e-05,
      "loss": 0.0049,
      "step": 10069
    },
    {
      "epoch": 0.7297894698699134,
      "grad_norm": 1.8086446523666382,
      "learning_rate": 5.406188854264802e-05,
      "loss": 0.0709,
      "step": 10070
    },
    {
      "epoch": 0.7298619415153821,
      "grad_norm": 1.927565574645996,
      "learning_rate": 5.404739473874919e-05,
      "loss": 0.0383,
      "step": 10071
    },
    {
      "epoch": 0.7299344131608508,
      "grad_norm": 1.4076207876205444,
      "learning_rate": 5.403290093485035e-05,
      "loss": 0.03,
      "step": 10072
    },
    {
      "epoch": 0.7300068848063195,
      "grad_norm": 0.47523173689842224,
      "learning_rate": 5.401840713095152e-05,
      "loss": 0.006,
      "step": 10073
    },
    {
      "epoch": 0.7300793564517882,
      "grad_norm": 1.135911226272583,
      "learning_rate": 5.400391332705269e-05,
      "loss": 0.0326,
      "step": 10074
    },
    {
      "epoch": 0.730151828097257,
      "grad_norm": 2.6395833492279053,
      "learning_rate": 5.398941952315385e-05,
      "loss": 0.1047,
      "step": 10075
    },
    {
      "epoch": 0.7302242997427256,
      "grad_norm": 2.172955274581909,
      "learning_rate": 5.397492571925502e-05,
      "loss": 0.069,
      "step": 10076
    },
    {
      "epoch": 0.7302967713881944,
      "grad_norm": 0.6456172466278076,
      "learning_rate": 5.3960431915356194e-05,
      "loss": 0.0154,
      "step": 10077
    },
    {
      "epoch": 0.7303692430336631,
      "grad_norm": 1.392662525177002,
      "learning_rate": 5.394593811145735e-05,
      "loss": 0.0338,
      "step": 10078
    },
    {
      "epoch": 0.7304417146791318,
      "grad_norm": 0.7243893146514893,
      "learning_rate": 5.393144430755852e-05,
      "loss": 0.0265,
      "step": 10079
    },
    {
      "epoch": 0.7305141863246005,
      "grad_norm": 5.38932466506958,
      "learning_rate": 5.391695050365969e-05,
      "loss": 0.0948,
      "step": 10080
    },
    {
      "epoch": 0.7305866579700692,
      "grad_norm": 2.092531204223633,
      "learning_rate": 5.390245669976085e-05,
      "loss": 0.0389,
      "step": 10081
    },
    {
      "epoch": 0.7306591296155379,
      "grad_norm": 1.6248961687088013,
      "learning_rate": 5.3887962895862024e-05,
      "loss": 0.0393,
      "step": 10082
    },
    {
      "epoch": 0.7307316012610067,
      "grad_norm": 3.291895627975464,
      "learning_rate": 5.3873469091963194e-05,
      "loss": 0.0908,
      "step": 10083
    },
    {
      "epoch": 0.7308040729064753,
      "grad_norm": 1.228177785873413,
      "learning_rate": 5.385897528806435e-05,
      "loss": 0.0341,
      "step": 10084
    },
    {
      "epoch": 0.7308765445519441,
      "grad_norm": 3.4403741359710693,
      "learning_rate": 5.384448148416552e-05,
      "loss": 0.0992,
      "step": 10085
    },
    {
      "epoch": 0.7309490161974128,
      "grad_norm": 1.7083100080490112,
      "learning_rate": 5.382998768026669e-05,
      "loss": 0.0869,
      "step": 10086
    },
    {
      "epoch": 0.7310214878428815,
      "grad_norm": 1.177277684211731,
      "learning_rate": 5.3815493876367854e-05,
      "loss": 0.0799,
      "step": 10087
    },
    {
      "epoch": 0.7310939594883502,
      "grad_norm": 1.4135468006134033,
      "learning_rate": 5.3801000072469024e-05,
      "loss": 0.0266,
      "step": 10088
    },
    {
      "epoch": 0.7311664311338189,
      "grad_norm": 3.5692977905273438,
      "learning_rate": 5.3786506268570194e-05,
      "loss": 0.1957,
      "step": 10089
    },
    {
      "epoch": 0.7312389027792876,
      "grad_norm": 0.7006113529205322,
      "learning_rate": 5.377201246467135e-05,
      "loss": 0.0198,
      "step": 10090
    },
    {
      "epoch": 0.7313113744247564,
      "grad_norm": 0.8109986782073975,
      "learning_rate": 5.375751866077252e-05,
      "loss": 0.0092,
      "step": 10091
    },
    {
      "epoch": 0.731383846070225,
      "grad_norm": 2.33121395111084,
      "learning_rate": 5.374302485687369e-05,
      "loss": 0.0584,
      "step": 10092
    },
    {
      "epoch": 0.7314563177156937,
      "grad_norm": 1.1500442028045654,
      "learning_rate": 5.3728531052974854e-05,
      "loss": 0.0481,
      "step": 10093
    },
    {
      "epoch": 0.7315287893611624,
      "grad_norm": 3.374009132385254,
      "learning_rate": 5.3714037249076024e-05,
      "loss": 0.1372,
      "step": 10094
    },
    {
      "epoch": 0.7316012610066311,
      "grad_norm": 0.7137840986251831,
      "learning_rate": 5.3699543445177194e-05,
      "loss": 0.0103,
      "step": 10095
    },
    {
      "epoch": 0.7316737326520999,
      "grad_norm": 1.565885305404663,
      "learning_rate": 5.368504964127835e-05,
      "loss": 0.061,
      "step": 10096
    },
    {
      "epoch": 0.7317462042975685,
      "grad_norm": 1.6746487617492676,
      "learning_rate": 5.367055583737952e-05,
      "loss": 0.0213,
      "step": 10097
    },
    {
      "epoch": 0.7318186759430373,
      "grad_norm": 1.0078128576278687,
      "learning_rate": 5.365606203348069e-05,
      "loss": 0.0555,
      "step": 10098
    },
    {
      "epoch": 0.731891147588506,
      "grad_norm": 0.7077714800834656,
      "learning_rate": 5.3641568229581854e-05,
      "loss": 0.0166,
      "step": 10099
    },
    {
      "epoch": 0.7319636192339747,
      "grad_norm": 4.661062717437744,
      "learning_rate": 5.3627074425683024e-05,
      "loss": 0.2758,
      "step": 10100
    },
    {
      "epoch": 0.7320360908794434,
      "grad_norm": 2.3673648834228516,
      "learning_rate": 5.3612580621784194e-05,
      "loss": 0.071,
      "step": 10101
    },
    {
      "epoch": 0.7321085625249121,
      "grad_norm": 1.7340887784957886,
      "learning_rate": 5.359808681788535e-05,
      "loss": 0.0441,
      "step": 10102
    },
    {
      "epoch": 0.7321810341703808,
      "grad_norm": 0.07058749347925186,
      "learning_rate": 5.358359301398652e-05,
      "loss": 0.0011,
      "step": 10103
    },
    {
      "epoch": 0.7322535058158496,
      "grad_norm": 1.4296185970306396,
      "learning_rate": 5.356909921008769e-05,
      "loss": 0.0682,
      "step": 10104
    },
    {
      "epoch": 0.7323259774613182,
      "grad_norm": 1.0456619262695312,
      "learning_rate": 5.3554605406188854e-05,
      "loss": 0.0128,
      "step": 10105
    },
    {
      "epoch": 0.732398449106787,
      "grad_norm": 1.001247763633728,
      "learning_rate": 5.3540111602290024e-05,
      "loss": 0.0358,
      "step": 10106
    },
    {
      "epoch": 0.7324709207522557,
      "grad_norm": 0.059748806059360504,
      "learning_rate": 5.3525617798391194e-05,
      "loss": 0.0016,
      "step": 10107
    },
    {
      "epoch": 0.7325433923977244,
      "grad_norm": 3.6434524059295654,
      "learning_rate": 5.3511123994492364e-05,
      "loss": 0.066,
      "step": 10108
    },
    {
      "epoch": 0.7326158640431931,
      "grad_norm": 1.4385029077529907,
      "learning_rate": 5.349663019059352e-05,
      "loss": 0.0515,
      "step": 10109
    },
    {
      "epoch": 0.7326883356886618,
      "grad_norm": 0.29456204175949097,
      "learning_rate": 5.348213638669469e-05,
      "loss": 0.0135,
      "step": 10110
    },
    {
      "epoch": 0.7327608073341305,
      "grad_norm": 2.497012138366699,
      "learning_rate": 5.346764258279586e-05,
      "loss": 0.0235,
      "step": 10111
    },
    {
      "epoch": 0.7328332789795993,
      "grad_norm": 2.5672576427459717,
      "learning_rate": 5.3453148778897024e-05,
      "loss": 0.0927,
      "step": 10112
    },
    {
      "epoch": 0.7329057506250679,
      "grad_norm": 2.027409791946411,
      "learning_rate": 5.3438654974998194e-05,
      "loss": 0.0271,
      "step": 10113
    },
    {
      "epoch": 0.7329782222705367,
      "grad_norm": 2.745908737182617,
      "learning_rate": 5.3424161171099364e-05,
      "loss": 0.1821,
      "step": 10114
    },
    {
      "epoch": 0.7330506939160054,
      "grad_norm": 0.6082513928413391,
      "learning_rate": 5.340966736720052e-05,
      "loss": 0.0274,
      "step": 10115
    },
    {
      "epoch": 0.733123165561474,
      "grad_norm": 0.916942834854126,
      "learning_rate": 5.339517356330169e-05,
      "loss": 0.0359,
      "step": 10116
    },
    {
      "epoch": 0.7331956372069428,
      "grad_norm": 1.9532157182693481,
      "learning_rate": 5.338067975940286e-05,
      "loss": 0.0728,
      "step": 10117
    },
    {
      "epoch": 0.7332681088524114,
      "grad_norm": 0.23420950770378113,
      "learning_rate": 5.3366185955504023e-05,
      "loss": 0.0074,
      "step": 10118
    },
    {
      "epoch": 0.7333405804978802,
      "grad_norm": 2.9419257640838623,
      "learning_rate": 5.3351692151605193e-05,
      "loss": 0.0715,
      "step": 10119
    },
    {
      "epoch": 0.733413052143349,
      "grad_norm": 1.3925319910049438,
      "learning_rate": 5.3337198347706364e-05,
      "loss": 0.0418,
      "step": 10120
    },
    {
      "epoch": 0.7334855237888176,
      "grad_norm": 1.0045530796051025,
      "learning_rate": 5.332270454380752e-05,
      "loss": 0.0345,
      "step": 10121
    },
    {
      "epoch": 0.7335579954342863,
      "grad_norm": 0.1559242308139801,
      "learning_rate": 5.330821073990869e-05,
      "loss": 0.0037,
      "step": 10122
    },
    {
      "epoch": 0.7336304670797551,
      "grad_norm": 0.45296213030815125,
      "learning_rate": 5.329371693600986e-05,
      "loss": 0.0124,
      "step": 10123
    },
    {
      "epoch": 0.7337029387252237,
      "grad_norm": 2.5922157764434814,
      "learning_rate": 5.327922313211102e-05,
      "loss": 0.0418,
      "step": 10124
    },
    {
      "epoch": 0.7337754103706925,
      "grad_norm": 0.7313434481620789,
      "learning_rate": 5.3264729328212193e-05,
      "loss": 0.026,
      "step": 10125
    },
    {
      "epoch": 0.7338478820161611,
      "grad_norm": 2.259061098098755,
      "learning_rate": 5.3250235524313363e-05,
      "loss": 0.0687,
      "step": 10126
    },
    {
      "epoch": 0.7339203536616299,
      "grad_norm": 0.4791658818721771,
      "learning_rate": 5.323574172041452e-05,
      "loss": 0.0289,
      "step": 10127
    },
    {
      "epoch": 0.7339928253070986,
      "grad_norm": 1.499530553817749,
      "learning_rate": 5.322124791651569e-05,
      "loss": 0.0587,
      "step": 10128
    },
    {
      "epoch": 0.7340652969525673,
      "grad_norm": 1.3325704336166382,
      "learning_rate": 5.320675411261686e-05,
      "loss": 0.1149,
      "step": 10129
    },
    {
      "epoch": 0.734137768598036,
      "grad_norm": 1.5995148420333862,
      "learning_rate": 5.319226030871802e-05,
      "loss": 0.0505,
      "step": 10130
    },
    {
      "epoch": 0.7342102402435047,
      "grad_norm": 0.9634920954704285,
      "learning_rate": 5.317776650481919e-05,
      "loss": 0.0343,
      "step": 10131
    },
    {
      "epoch": 0.7342827118889734,
      "grad_norm": 1.0227265357971191,
      "learning_rate": 5.316327270092036e-05,
      "loss": 0.0281,
      "step": 10132
    },
    {
      "epoch": 0.7343551835344422,
      "grad_norm": 2.0002453327178955,
      "learning_rate": 5.314877889702152e-05,
      "loss": 0.1238,
      "step": 10133
    },
    {
      "epoch": 0.7344276551799108,
      "grad_norm": 0.23278579115867615,
      "learning_rate": 5.313428509312269e-05,
      "loss": 0.0039,
      "step": 10134
    },
    {
      "epoch": 0.7345001268253796,
      "grad_norm": 3.4489705562591553,
      "learning_rate": 5.311979128922387e-05,
      "loss": 0.102,
      "step": 10135
    },
    {
      "epoch": 0.7345725984708483,
      "grad_norm": 1.4384804964065552,
      "learning_rate": 5.310529748532502e-05,
      "loss": 0.0511,
      "step": 10136
    },
    {
      "epoch": 0.734645070116317,
      "grad_norm": 1.4805262088775635,
      "learning_rate": 5.309080368142619e-05,
      "loss": 0.0487,
      "step": 10137
    },
    {
      "epoch": 0.7347175417617857,
      "grad_norm": 1.0076240301132202,
      "learning_rate": 5.307630987752736e-05,
      "loss": 0.0326,
      "step": 10138
    },
    {
      "epoch": 0.7347900134072544,
      "grad_norm": 1.5375418663024902,
      "learning_rate": 5.306181607362852e-05,
      "loss": 0.0345,
      "step": 10139
    },
    {
      "epoch": 0.7348624850527231,
      "grad_norm": 1.9832777976989746,
      "learning_rate": 5.3047322269729697e-05,
      "loss": 0.0744,
      "step": 10140
    },
    {
      "epoch": 0.7349349566981919,
      "grad_norm": 0.7240375280380249,
      "learning_rate": 5.3032828465830867e-05,
      "loss": 0.0057,
      "step": 10141
    },
    {
      "epoch": 0.7350074283436605,
      "grad_norm": 1.851065754890442,
      "learning_rate": 5.301833466193202e-05,
      "loss": 0.0803,
      "step": 10142
    },
    {
      "epoch": 0.7350798999891293,
      "grad_norm": 0.09615618735551834,
      "learning_rate": 5.300384085803319e-05,
      "loss": 0.0016,
      "step": 10143
    },
    {
      "epoch": 0.735152371634598,
      "grad_norm": 0.1636013388633728,
      "learning_rate": 5.298934705413436e-05,
      "loss": 0.006,
      "step": 10144
    },
    {
      "epoch": 0.7352248432800667,
      "grad_norm": 2.191969156265259,
      "learning_rate": 5.2974853250235526e-05,
      "loss": 0.0728,
      "step": 10145
    },
    {
      "epoch": 0.7352973149255354,
      "grad_norm": 1.339181900024414,
      "learning_rate": 5.2960359446336696e-05,
      "loss": 0.0347,
      "step": 10146
    },
    {
      "epoch": 0.735369786571004,
      "grad_norm": 3.180198907852173,
      "learning_rate": 5.2945865642437866e-05,
      "loss": 0.1103,
      "step": 10147
    },
    {
      "epoch": 0.7354422582164728,
      "grad_norm": 1.72208571434021,
      "learning_rate": 5.293137183853902e-05,
      "loss": 0.0954,
      "step": 10148
    },
    {
      "epoch": 0.7355147298619416,
      "grad_norm": 3.742762804031372,
      "learning_rate": 5.291687803464019e-05,
      "loss": 0.0428,
      "step": 10149
    },
    {
      "epoch": 0.7355872015074102,
      "grad_norm": 3.1853513717651367,
      "learning_rate": 5.290238423074136e-05,
      "loss": 0.0935,
      "step": 10150
    },
    {
      "epoch": 0.735659673152879,
      "grad_norm": 2.7691385746002197,
      "learning_rate": 5.2887890426842526e-05,
      "loss": 0.1334,
      "step": 10151
    },
    {
      "epoch": 0.7357321447983477,
      "grad_norm": 1.6781773567199707,
      "learning_rate": 5.2873396622943696e-05,
      "loss": 0.0261,
      "step": 10152
    },
    {
      "epoch": 0.7358046164438163,
      "grad_norm": 0.2900216579437256,
      "learning_rate": 5.2858902819044866e-05,
      "loss": 0.005,
      "step": 10153
    },
    {
      "epoch": 0.7358770880892851,
      "grad_norm": 0.8746040463447571,
      "learning_rate": 5.284440901514602e-05,
      "loss": 0.0634,
      "step": 10154
    },
    {
      "epoch": 0.7359495597347537,
      "grad_norm": 0.3242766857147217,
      "learning_rate": 5.282991521124719e-05,
      "loss": 0.0057,
      "step": 10155
    },
    {
      "epoch": 0.7360220313802225,
      "grad_norm": 0.9069350957870483,
      "learning_rate": 5.281542140734836e-05,
      "loss": 0.0527,
      "step": 10156
    },
    {
      "epoch": 0.7360945030256912,
      "grad_norm": 1.2221685647964478,
      "learning_rate": 5.2800927603449526e-05,
      "loss": 0.0397,
      "step": 10157
    },
    {
      "epoch": 0.7361669746711599,
      "grad_norm": 1.1181261539459229,
      "learning_rate": 5.2786433799550696e-05,
      "loss": 0.0292,
      "step": 10158
    },
    {
      "epoch": 0.7362394463166286,
      "grad_norm": 2.263347625732422,
      "learning_rate": 5.2771939995651866e-05,
      "loss": 0.0575,
      "step": 10159
    },
    {
      "epoch": 0.7363119179620974,
      "grad_norm": 1.0637428760528564,
      "learning_rate": 5.275744619175302e-05,
      "loss": 0.0302,
      "step": 10160
    },
    {
      "epoch": 0.736384389607566,
      "grad_norm": 0.9933646321296692,
      "learning_rate": 5.274295238785419e-05,
      "loss": 0.0293,
      "step": 10161
    },
    {
      "epoch": 0.7364568612530348,
      "grad_norm": 1.9288287162780762,
      "learning_rate": 5.272845858395536e-05,
      "loss": 0.0277,
      "step": 10162
    },
    {
      "epoch": 0.7365293328985034,
      "grad_norm": 0.7196411490440369,
      "learning_rate": 5.2713964780056526e-05,
      "loss": 0.0163,
      "step": 10163
    },
    {
      "epoch": 0.7366018045439722,
      "grad_norm": 1.5661343336105347,
      "learning_rate": 5.2699470976157696e-05,
      "loss": 0.0517,
      "step": 10164
    },
    {
      "epoch": 0.7366742761894409,
      "grad_norm": 1.1184929609298706,
      "learning_rate": 5.2684977172258866e-05,
      "loss": 0.0875,
      "step": 10165
    },
    {
      "epoch": 0.7367467478349096,
      "grad_norm": 0.8598572611808777,
      "learning_rate": 5.267048336836002e-05,
      "loss": 0.0203,
      "step": 10166
    },
    {
      "epoch": 0.7368192194803783,
      "grad_norm": 1.262000322341919,
      "learning_rate": 5.265598956446119e-05,
      "loss": 0.0302,
      "step": 10167
    },
    {
      "epoch": 0.736891691125847,
      "grad_norm": 0.10384552925825119,
      "learning_rate": 5.264149576056236e-05,
      "loss": 0.0026,
      "step": 10168
    },
    {
      "epoch": 0.7369641627713157,
      "grad_norm": 1.639888048171997,
      "learning_rate": 5.2627001956663526e-05,
      "loss": 0.0229,
      "step": 10169
    },
    {
      "epoch": 0.7370366344167845,
      "grad_norm": 0.8559227585792542,
      "learning_rate": 5.2612508152764696e-05,
      "loss": 0.0088,
      "step": 10170
    },
    {
      "epoch": 0.7371091060622531,
      "grad_norm": 2.839259386062622,
      "learning_rate": 5.2598014348865866e-05,
      "loss": 0.1576,
      "step": 10171
    },
    {
      "epoch": 0.7371815777077219,
      "grad_norm": 0.340366393327713,
      "learning_rate": 5.258352054496702e-05,
      "loss": 0.0098,
      "step": 10172
    },
    {
      "epoch": 0.7372540493531906,
      "grad_norm": 1.3356225490570068,
      "learning_rate": 5.256902674106819e-05,
      "loss": 0.0826,
      "step": 10173
    },
    {
      "epoch": 0.7373265209986593,
      "grad_norm": 3.3073484897613525,
      "learning_rate": 5.255453293716936e-05,
      "loss": 0.1797,
      "step": 10174
    },
    {
      "epoch": 0.737398992644128,
      "grad_norm": 1.1671096086502075,
      "learning_rate": 5.2540039133270526e-05,
      "loss": 0.0135,
      "step": 10175
    },
    {
      "epoch": 0.7374714642895966,
      "grad_norm": 1.8082551956176758,
      "learning_rate": 5.2525545329371696e-05,
      "loss": 0.0905,
      "step": 10176
    },
    {
      "epoch": 0.7375439359350654,
      "grad_norm": 2.6479432582855225,
      "learning_rate": 5.2511051525472866e-05,
      "loss": 0.1433,
      "step": 10177
    },
    {
      "epoch": 0.7376164075805342,
      "grad_norm": 2.2222111225128174,
      "learning_rate": 5.249655772157402e-05,
      "loss": 0.0349,
      "step": 10178
    },
    {
      "epoch": 0.7376888792260028,
      "grad_norm": 2.181368112564087,
      "learning_rate": 5.248206391767519e-05,
      "loss": 0.0356,
      "step": 10179
    },
    {
      "epoch": 0.7377613508714715,
      "grad_norm": 0.735419750213623,
      "learning_rate": 5.246757011377636e-05,
      "loss": 0.0144,
      "step": 10180
    },
    {
      "epoch": 0.7378338225169403,
      "grad_norm": 0.2465585470199585,
      "learning_rate": 5.2453076309877526e-05,
      "loss": 0.005,
      "step": 10181
    },
    {
      "epoch": 0.7379062941624089,
      "grad_norm": 1.9145926237106323,
      "learning_rate": 5.2438582505978696e-05,
      "loss": 0.0501,
      "step": 10182
    },
    {
      "epoch": 0.7379787658078777,
      "grad_norm": 0.5072066187858582,
      "learning_rate": 5.2424088702079866e-05,
      "loss": 0.0126,
      "step": 10183
    },
    {
      "epoch": 0.7380512374533463,
      "grad_norm": 3.9704084396362305,
      "learning_rate": 5.240959489818102e-05,
      "loss": 0.0952,
      "step": 10184
    },
    {
      "epoch": 0.7381237090988151,
      "grad_norm": 2.2852063179016113,
      "learning_rate": 5.239510109428219e-05,
      "loss": 0.0555,
      "step": 10185
    },
    {
      "epoch": 0.7381961807442838,
      "grad_norm": 0.6703447699546814,
      "learning_rate": 5.238060729038336e-05,
      "loss": 0.0183,
      "step": 10186
    },
    {
      "epoch": 0.7382686523897525,
      "grad_norm": 2.387089490890503,
      "learning_rate": 5.2366113486484526e-05,
      "loss": 0.0578,
      "step": 10187
    },
    {
      "epoch": 0.7383411240352212,
      "grad_norm": 0.7602289915084839,
      "learning_rate": 5.2351619682585696e-05,
      "loss": 0.0874,
      "step": 10188
    },
    {
      "epoch": 0.73841359568069,
      "grad_norm": 1.709817886352539,
      "learning_rate": 5.2337125878686866e-05,
      "loss": 0.0883,
      "step": 10189
    },
    {
      "epoch": 0.7384860673261586,
      "grad_norm": 0.8062180876731873,
      "learning_rate": 5.2322632074788036e-05,
      "loss": 0.0334,
      "step": 10190
    },
    {
      "epoch": 0.7385585389716274,
      "grad_norm": 1.2031136751174927,
      "learning_rate": 5.230813827088919e-05,
      "loss": 0.0398,
      "step": 10191
    },
    {
      "epoch": 0.738631010617096,
      "grad_norm": 0.9309561252593994,
      "learning_rate": 5.229364446699037e-05,
      "loss": 0.0442,
      "step": 10192
    },
    {
      "epoch": 0.7387034822625648,
      "grad_norm": 5.388271331787109,
      "learning_rate": 5.227915066309154e-05,
      "loss": 0.1513,
      "step": 10193
    },
    {
      "epoch": 0.7387759539080335,
      "grad_norm": 1.8585140705108643,
      "learning_rate": 5.2264656859192696e-05,
      "loss": 0.0791,
      "step": 10194
    },
    {
      "epoch": 0.7388484255535022,
      "grad_norm": 1.5046788454055786,
      "learning_rate": 5.2250163055293866e-05,
      "loss": 0.0581,
      "step": 10195
    },
    {
      "epoch": 0.7389208971989709,
      "grad_norm": 0.30147114396095276,
      "learning_rate": 5.2235669251395036e-05,
      "loss": 0.0073,
      "step": 10196
    },
    {
      "epoch": 0.7389933688444396,
      "grad_norm": 2.133958578109741,
      "learning_rate": 5.22211754474962e-05,
      "loss": 0.0906,
      "step": 10197
    },
    {
      "epoch": 0.7390658404899083,
      "grad_norm": 1.0443588495254517,
      "learning_rate": 5.220668164359737e-05,
      "loss": 0.0835,
      "step": 10198
    },
    {
      "epoch": 0.7391383121353771,
      "grad_norm": 0.7523451447486877,
      "learning_rate": 5.219218783969854e-05,
      "loss": 0.0224,
      "step": 10199
    },
    {
      "epoch": 0.7392107837808457,
      "grad_norm": 0.21667051315307617,
      "learning_rate": 5.2177694035799696e-05,
      "loss": 0.0105,
      "step": 10200
    },
    {
      "epoch": 0.7392832554263145,
      "grad_norm": 3.648052930831909,
      "learning_rate": 5.2163200231900866e-05,
      "loss": 0.0858,
      "step": 10201
    },
    {
      "epoch": 0.7393557270717832,
      "grad_norm": 2.4369404315948486,
      "learning_rate": 5.2148706428002036e-05,
      "loss": 0.0365,
      "step": 10202
    },
    {
      "epoch": 0.7394281987172518,
      "grad_norm": 0.5466694831848145,
      "learning_rate": 5.21342126241032e-05,
      "loss": 0.0306,
      "step": 10203
    },
    {
      "epoch": 0.7395006703627206,
      "grad_norm": 0.16989323496818542,
      "learning_rate": 5.211971882020437e-05,
      "loss": 0.0031,
      "step": 10204
    },
    {
      "epoch": 0.7395731420081892,
      "grad_norm": 0.9631338715553284,
      "learning_rate": 5.210522501630554e-05,
      "loss": 0.0368,
      "step": 10205
    },
    {
      "epoch": 0.739645613653658,
      "grad_norm": 0.794640064239502,
      "learning_rate": 5.2090731212406695e-05,
      "loss": 0.0368,
      "step": 10206
    },
    {
      "epoch": 0.7397180852991267,
      "grad_norm": 0.6052107214927673,
      "learning_rate": 5.2076237408507865e-05,
      "loss": 0.0522,
      "step": 10207
    },
    {
      "epoch": 0.7397905569445954,
      "grad_norm": 1.0129021406173706,
      "learning_rate": 5.2061743604609035e-05,
      "loss": 0.0241,
      "step": 10208
    },
    {
      "epoch": 0.7398630285900641,
      "grad_norm": 1.3496379852294922,
      "learning_rate": 5.20472498007102e-05,
      "loss": 0.0479,
      "step": 10209
    },
    {
      "epoch": 0.7399355002355329,
      "grad_norm": 1.0126913785934448,
      "learning_rate": 5.203275599681137e-05,
      "loss": 0.048,
      "step": 10210
    },
    {
      "epoch": 0.7400079718810015,
      "grad_norm": 0.7410886883735657,
      "learning_rate": 5.201826219291254e-05,
      "loss": 0.0357,
      "step": 10211
    },
    {
      "epoch": 0.7400804435264703,
      "grad_norm": 0.8003770112991333,
      "learning_rate": 5.2003768389013695e-05,
      "loss": 0.0236,
      "step": 10212
    },
    {
      "epoch": 0.7401529151719389,
      "grad_norm": 0.8849192261695862,
      "learning_rate": 5.1989274585114865e-05,
      "loss": 0.0125,
      "step": 10213
    },
    {
      "epoch": 0.7402253868174077,
      "grad_norm": 0.9348212480545044,
      "learning_rate": 5.1974780781216035e-05,
      "loss": 0.0332,
      "step": 10214
    },
    {
      "epoch": 0.7402978584628764,
      "grad_norm": 0.01606450229883194,
      "learning_rate": 5.19602869773172e-05,
      "loss": 0.0004,
      "step": 10215
    },
    {
      "epoch": 0.7403703301083451,
      "grad_norm": 0.4943199157714844,
      "learning_rate": 5.194579317341837e-05,
      "loss": 0.0107,
      "step": 10216
    },
    {
      "epoch": 0.7404428017538138,
      "grad_norm": 2.156242847442627,
      "learning_rate": 5.193129936951954e-05,
      "loss": 0.145,
      "step": 10217
    },
    {
      "epoch": 0.7405152733992826,
      "grad_norm": 0.911307156085968,
      "learning_rate": 5.1916805565620695e-05,
      "loss": 0.0507,
      "step": 10218
    },
    {
      "epoch": 0.7405877450447512,
      "grad_norm": 1.061320424079895,
      "learning_rate": 5.1902311761721865e-05,
      "loss": 0.0274,
      "step": 10219
    },
    {
      "epoch": 0.74066021669022,
      "grad_norm": 2.0935561656951904,
      "learning_rate": 5.1887817957823035e-05,
      "loss": 0.0464,
      "step": 10220
    },
    {
      "epoch": 0.7407326883356886,
      "grad_norm": 0.23972836136817932,
      "learning_rate": 5.18733241539242e-05,
      "loss": 0.0057,
      "step": 10221
    },
    {
      "epoch": 0.7408051599811574,
      "grad_norm": 2.1191141605377197,
      "learning_rate": 5.185883035002537e-05,
      "loss": 0.0984,
      "step": 10222
    },
    {
      "epoch": 0.7408776316266261,
      "grad_norm": 1.6111853122711182,
      "learning_rate": 5.184433654612654e-05,
      "loss": 0.0584,
      "step": 10223
    },
    {
      "epoch": 0.7409501032720948,
      "grad_norm": 4.432945251464844,
      "learning_rate": 5.1829842742227695e-05,
      "loss": 0.0452,
      "step": 10224
    },
    {
      "epoch": 0.7410225749175635,
      "grad_norm": 8.687182426452637,
      "learning_rate": 5.1815348938328865e-05,
      "loss": 0.1261,
      "step": 10225
    },
    {
      "epoch": 0.7410950465630323,
      "grad_norm": 1.085888147354126,
      "learning_rate": 5.1800855134430035e-05,
      "loss": 0.0173,
      "step": 10226
    },
    {
      "epoch": 0.7411675182085009,
      "grad_norm": 0.5603145956993103,
      "learning_rate": 5.17863613305312e-05,
      "loss": 0.0103,
      "step": 10227
    },
    {
      "epoch": 0.7412399898539697,
      "grad_norm": 1.0778579711914062,
      "learning_rate": 5.177186752663237e-05,
      "loss": 0.0586,
      "step": 10228
    },
    {
      "epoch": 0.7413124614994383,
      "grad_norm": 0.2862944006919861,
      "learning_rate": 5.175737372273354e-05,
      "loss": 0.0041,
      "step": 10229
    },
    {
      "epoch": 0.741384933144907,
      "grad_norm": 0.556627631187439,
      "learning_rate": 5.1742879918834695e-05,
      "loss": 0.0098,
      "step": 10230
    },
    {
      "epoch": 0.7414574047903758,
      "grad_norm": 1.0342551469802856,
      "learning_rate": 5.1728386114935865e-05,
      "loss": 0.0431,
      "step": 10231
    },
    {
      "epoch": 0.7415298764358444,
      "grad_norm": 1.1607123613357544,
      "learning_rate": 5.1713892311037035e-05,
      "loss": 0.031,
      "step": 10232
    },
    {
      "epoch": 0.7416023480813132,
      "grad_norm": 1.9686702489852905,
      "learning_rate": 5.16993985071382e-05,
      "loss": 0.0683,
      "step": 10233
    },
    {
      "epoch": 0.7416748197267818,
      "grad_norm": 0.5824950337409973,
      "learning_rate": 5.168490470323937e-05,
      "loss": 0.01,
      "step": 10234
    },
    {
      "epoch": 0.7417472913722506,
      "grad_norm": 1.6135236024856567,
      "learning_rate": 5.167041089934054e-05,
      "loss": 0.0499,
      "step": 10235
    },
    {
      "epoch": 0.7418197630177193,
      "grad_norm": 1.7357761859893799,
      "learning_rate": 5.1655917095441695e-05,
      "loss": 0.0733,
      "step": 10236
    },
    {
      "epoch": 0.741892234663188,
      "grad_norm": 3.260131359100342,
      "learning_rate": 5.1641423291542865e-05,
      "loss": 0.071,
      "step": 10237
    },
    {
      "epoch": 0.7419647063086567,
      "grad_norm": 1.2435072660446167,
      "learning_rate": 5.1626929487644035e-05,
      "loss": 0.0851,
      "step": 10238
    },
    {
      "epoch": 0.7420371779541255,
      "grad_norm": 1.5265740156173706,
      "learning_rate": 5.16124356837452e-05,
      "loss": 0.0702,
      "step": 10239
    },
    {
      "epoch": 0.7421096495995941,
      "grad_norm": 0.07915894687175751,
      "learning_rate": 5.159794187984637e-05,
      "loss": 0.001,
      "step": 10240
    },
    {
      "epoch": 0.7421821212450629,
      "grad_norm": 2.854358434677124,
      "learning_rate": 5.158344807594754e-05,
      "loss": 0.0757,
      "step": 10241
    },
    {
      "epoch": 0.7422545928905315,
      "grad_norm": 0.24252542853355408,
      "learning_rate": 5.1568954272048695e-05,
      "loss": 0.0076,
      "step": 10242
    },
    {
      "epoch": 0.7423270645360003,
      "grad_norm": 2.7373156547546387,
      "learning_rate": 5.1554460468149865e-05,
      "loss": 0.0897,
      "step": 10243
    },
    {
      "epoch": 0.742399536181469,
      "grad_norm": 1.1754852533340454,
      "learning_rate": 5.1539966664251035e-05,
      "loss": 0.0665,
      "step": 10244
    },
    {
      "epoch": 0.7424720078269377,
      "grad_norm": 0.6661415696144104,
      "learning_rate": 5.15254728603522e-05,
      "loss": 0.0205,
      "step": 10245
    },
    {
      "epoch": 0.7425444794724064,
      "grad_norm": 0.8101395964622498,
      "learning_rate": 5.151097905645337e-05,
      "loss": 0.0152,
      "step": 10246
    },
    {
      "epoch": 0.7426169511178752,
      "grad_norm": 1.1145274639129639,
      "learning_rate": 5.149648525255454e-05,
      "loss": 0.0472,
      "step": 10247
    },
    {
      "epoch": 0.7426894227633438,
      "grad_norm": 2.045043706893921,
      "learning_rate": 5.1481991448655695e-05,
      "loss": 0.0509,
      "step": 10248
    },
    {
      "epoch": 0.7427618944088126,
      "grad_norm": 1.5711637735366821,
      "learning_rate": 5.1467497644756865e-05,
      "loss": 0.0162,
      "step": 10249
    },
    {
      "epoch": 0.7428343660542812,
      "grad_norm": 0.5201337337493896,
      "learning_rate": 5.145300384085804e-05,
      "loss": 0.0244,
      "step": 10250
    },
    {
      "epoch": 0.74290683769975,
      "grad_norm": 0.14630821347236633,
      "learning_rate": 5.14385100369592e-05,
      "loss": 0.0036,
      "step": 10251
    },
    {
      "epoch": 0.7429793093452187,
      "grad_norm": 1.713083267211914,
      "learning_rate": 5.142401623306037e-05,
      "loss": 0.0298,
      "step": 10252
    },
    {
      "epoch": 0.7430517809906874,
      "grad_norm": 0.3383371829986572,
      "learning_rate": 5.140952242916154e-05,
      "loss": 0.0063,
      "step": 10253
    },
    {
      "epoch": 0.7431242526361561,
      "grad_norm": 0.8188722729682922,
      "learning_rate": 5.1395028625262695e-05,
      "loss": 0.0594,
      "step": 10254
    },
    {
      "epoch": 0.7431967242816249,
      "grad_norm": 1.1049928665161133,
      "learning_rate": 5.138053482136387e-05,
      "loss": 0.0175,
      "step": 10255
    },
    {
      "epoch": 0.7432691959270935,
      "grad_norm": 0.6957095861434937,
      "learning_rate": 5.136604101746504e-05,
      "loss": 0.0093,
      "step": 10256
    },
    {
      "epoch": 0.7433416675725623,
      "grad_norm": 1.8601912260055542,
      "learning_rate": 5.13515472135662e-05,
      "loss": 0.0993,
      "step": 10257
    },
    {
      "epoch": 0.7434141392180309,
      "grad_norm": 2.1029419898986816,
      "learning_rate": 5.133705340966737e-05,
      "loss": 0.1032,
      "step": 10258
    },
    {
      "epoch": 0.7434866108634997,
      "grad_norm": 2.0976920127868652,
      "learning_rate": 5.132255960576854e-05,
      "loss": 0.0386,
      "step": 10259
    },
    {
      "epoch": 0.7435590825089684,
      "grad_norm": 1.6318306922912598,
      "learning_rate": 5.13080658018697e-05,
      "loss": 0.0738,
      "step": 10260
    },
    {
      "epoch": 0.743631554154437,
      "grad_norm": 3.2846574783325195,
      "learning_rate": 5.129357199797087e-05,
      "loss": 0.0442,
      "step": 10261
    },
    {
      "epoch": 0.7437040257999058,
      "grad_norm": 2.1213977336883545,
      "learning_rate": 5.127907819407204e-05,
      "loss": 0.0146,
      "step": 10262
    },
    {
      "epoch": 0.7437764974453746,
      "grad_norm": 1.1771095991134644,
      "learning_rate": 5.12645843901732e-05,
      "loss": 0.0537,
      "step": 10263
    },
    {
      "epoch": 0.7438489690908432,
      "grad_norm": 2.6141445636749268,
      "learning_rate": 5.125009058627437e-05,
      "loss": 0.0561,
      "step": 10264
    },
    {
      "epoch": 0.743921440736312,
      "grad_norm": 0.3655948340892792,
      "learning_rate": 5.123559678237554e-05,
      "loss": 0.018,
      "step": 10265
    },
    {
      "epoch": 0.7439939123817806,
      "grad_norm": 2.3232200145721436,
      "learning_rate": 5.12211029784767e-05,
      "loss": 0.0757,
      "step": 10266
    },
    {
      "epoch": 0.7440663840272493,
      "grad_norm": 0.7533716559410095,
      "learning_rate": 5.120660917457787e-05,
      "loss": 0.028,
      "step": 10267
    },
    {
      "epoch": 0.7441388556727181,
      "grad_norm": 0.47630995512008667,
      "learning_rate": 5.119211537067904e-05,
      "loss": 0.011,
      "step": 10268
    },
    {
      "epoch": 0.7442113273181867,
      "grad_norm": 2.712306022644043,
      "learning_rate": 5.11776215667802e-05,
      "loss": 0.0583,
      "step": 10269
    },
    {
      "epoch": 0.7442837989636555,
      "grad_norm": 3.2475333213806152,
      "learning_rate": 5.116312776288137e-05,
      "loss": 0.0726,
      "step": 10270
    },
    {
      "epoch": 0.7443562706091241,
      "grad_norm": 0.8694556951522827,
      "learning_rate": 5.114863395898254e-05,
      "loss": 0.034,
      "step": 10271
    },
    {
      "epoch": 0.7444287422545929,
      "grad_norm": 1.2350295782089233,
      "learning_rate": 5.113414015508371e-05,
      "loss": 0.0331,
      "step": 10272
    },
    {
      "epoch": 0.7445012139000616,
      "grad_norm": 2.0485024452209473,
      "learning_rate": 5.111964635118487e-05,
      "loss": 0.0469,
      "step": 10273
    },
    {
      "epoch": 0.7445736855455303,
      "grad_norm": 0.4131890535354614,
      "learning_rate": 5.110515254728604e-05,
      "loss": 0.0159,
      "step": 10274
    },
    {
      "epoch": 0.744646157190999,
      "grad_norm": 1.0684378147125244,
      "learning_rate": 5.109065874338721e-05,
      "loss": 0.0236,
      "step": 10275
    },
    {
      "epoch": 0.7447186288364678,
      "grad_norm": 1.7072529792785645,
      "learning_rate": 5.107616493948837e-05,
      "loss": 0.0624,
      "step": 10276
    },
    {
      "epoch": 0.7447911004819364,
      "grad_norm": 0.08247825503349304,
      "learning_rate": 5.106167113558954e-05,
      "loss": 0.0012,
      "step": 10277
    },
    {
      "epoch": 0.7448635721274052,
      "grad_norm": 3.2798829078674316,
      "learning_rate": 5.104717733169071e-05,
      "loss": 0.0482,
      "step": 10278
    },
    {
      "epoch": 0.7449360437728738,
      "grad_norm": 0.9221967458724976,
      "learning_rate": 5.103268352779187e-05,
      "loss": 0.026,
      "step": 10279
    },
    {
      "epoch": 0.7450085154183426,
      "grad_norm": 1.1026668548583984,
      "learning_rate": 5.101818972389304e-05,
      "loss": 0.0424,
      "step": 10280
    },
    {
      "epoch": 0.7450809870638113,
      "grad_norm": 0.6910700798034668,
      "learning_rate": 5.100369591999421e-05,
      "loss": 0.015,
      "step": 10281
    },
    {
      "epoch": 0.74515345870928,
      "grad_norm": 0.9663248062133789,
      "learning_rate": 5.098920211609537e-05,
      "loss": 0.0204,
      "step": 10282
    },
    {
      "epoch": 0.7452259303547487,
      "grad_norm": 0.18618546426296234,
      "learning_rate": 5.097470831219654e-05,
      "loss": 0.0017,
      "step": 10283
    },
    {
      "epoch": 0.7452984020002175,
      "grad_norm": 0.22955788671970367,
      "learning_rate": 5.096021450829771e-05,
      "loss": 0.0062,
      "step": 10284
    },
    {
      "epoch": 0.7453708736456861,
      "grad_norm": 0.9348807334899902,
      "learning_rate": 5.094572070439887e-05,
      "loss": 0.015,
      "step": 10285
    },
    {
      "epoch": 0.7454433452911549,
      "grad_norm": 0.9899611473083496,
      "learning_rate": 5.093122690050004e-05,
      "loss": 0.039,
      "step": 10286
    },
    {
      "epoch": 0.7455158169366235,
      "grad_norm": 2.4279356002807617,
      "learning_rate": 5.091673309660121e-05,
      "loss": 0.0274,
      "step": 10287
    },
    {
      "epoch": 0.7455882885820923,
      "grad_norm": 1.284926414489746,
      "learning_rate": 5.090223929270237e-05,
      "loss": 0.0114,
      "step": 10288
    },
    {
      "epoch": 0.745660760227561,
      "grad_norm": 1.3952171802520752,
      "learning_rate": 5.088774548880354e-05,
      "loss": 0.0466,
      "step": 10289
    },
    {
      "epoch": 0.7457332318730296,
      "grad_norm": 2.1739609241485596,
      "learning_rate": 5.087325168490471e-05,
      "loss": 0.0536,
      "step": 10290
    },
    {
      "epoch": 0.7458057035184984,
      "grad_norm": 1.3765547275543213,
      "learning_rate": 5.085875788100587e-05,
      "loss": 0.0702,
      "step": 10291
    },
    {
      "epoch": 0.7458781751639671,
      "grad_norm": 3.244779109954834,
      "learning_rate": 5.084426407710704e-05,
      "loss": 0.154,
      "step": 10292
    },
    {
      "epoch": 0.7459506468094358,
      "grad_norm": 2.2840869426727295,
      "learning_rate": 5.082977027320821e-05,
      "loss": 0.0475,
      "step": 10293
    },
    {
      "epoch": 0.7460231184549045,
      "grad_norm": 3.5465352535247803,
      "learning_rate": 5.081527646930937e-05,
      "loss": 0.0747,
      "step": 10294
    },
    {
      "epoch": 0.7460955901003732,
      "grad_norm": 0.5856052041053772,
      "learning_rate": 5.080078266541054e-05,
      "loss": 0.0067,
      "step": 10295
    },
    {
      "epoch": 0.7461680617458419,
      "grad_norm": 0.31989893317222595,
      "learning_rate": 5.078628886151171e-05,
      "loss": 0.0014,
      "step": 10296
    },
    {
      "epoch": 0.7462405333913107,
      "grad_norm": 2.191943645477295,
      "learning_rate": 5.077179505761287e-05,
      "loss": 0.0916,
      "step": 10297
    },
    {
      "epoch": 0.7463130050367793,
      "grad_norm": 1.4212371110916138,
      "learning_rate": 5.075730125371404e-05,
      "loss": 0.0384,
      "step": 10298
    },
    {
      "epoch": 0.7463854766822481,
      "grad_norm": 1.3073508739471436,
      "learning_rate": 5.074280744981521e-05,
      "loss": 0.0508,
      "step": 10299
    },
    {
      "epoch": 0.7464579483277168,
      "grad_norm": 0.2984457314014435,
      "learning_rate": 5.072831364591637e-05,
      "loss": 0.0052,
      "step": 10300
    },
    {
      "epoch": 0.7465304199731855,
      "grad_norm": 0.8917143940925598,
      "learning_rate": 5.071381984201754e-05,
      "loss": 0.0254,
      "step": 10301
    },
    {
      "epoch": 0.7466028916186542,
      "grad_norm": 1.320308804512024,
      "learning_rate": 5.0699326038118714e-05,
      "loss": 0.0459,
      "step": 10302
    },
    {
      "epoch": 0.7466753632641229,
      "grad_norm": 1.0674794912338257,
      "learning_rate": 5.068483223421987e-05,
      "loss": 0.0403,
      "step": 10303
    },
    {
      "epoch": 0.7467478349095916,
      "grad_norm": 3.2097134590148926,
      "learning_rate": 5.067033843032104e-05,
      "loss": 0.1031,
      "step": 10304
    },
    {
      "epoch": 0.7468203065550604,
      "grad_norm": 1.6729499101638794,
      "learning_rate": 5.065584462642221e-05,
      "loss": 0.0616,
      "step": 10305
    },
    {
      "epoch": 0.746892778200529,
      "grad_norm": 1.6702769994735718,
      "learning_rate": 5.064135082252337e-05,
      "loss": 0.0473,
      "step": 10306
    },
    {
      "epoch": 0.7469652498459978,
      "grad_norm": 1.0025745630264282,
      "learning_rate": 5.062685701862454e-05,
      "loss": 0.0362,
      "step": 10307
    },
    {
      "epoch": 0.7470377214914664,
      "grad_norm": 1.6010774374008179,
      "learning_rate": 5.0612363214725714e-05,
      "loss": 0.0497,
      "step": 10308
    },
    {
      "epoch": 0.7471101931369352,
      "grad_norm": 8.417057991027832,
      "learning_rate": 5.059786941082687e-05,
      "loss": 0.2234,
      "step": 10309
    },
    {
      "epoch": 0.7471826647824039,
      "grad_norm": 3.1306838989257812,
      "learning_rate": 5.058337560692804e-05,
      "loss": 0.0403,
      "step": 10310
    },
    {
      "epoch": 0.7472551364278726,
      "grad_norm": 1.414455771446228,
      "learning_rate": 5.056888180302921e-05,
      "loss": 0.0447,
      "step": 10311
    },
    {
      "epoch": 0.7473276080733413,
      "grad_norm": 4.767064094543457,
      "learning_rate": 5.055438799913037e-05,
      "loss": 0.0253,
      "step": 10312
    },
    {
      "epoch": 0.7474000797188101,
      "grad_norm": 2.27799654006958,
      "learning_rate": 5.0539894195231544e-05,
      "loss": 0.0758,
      "step": 10313
    },
    {
      "epoch": 0.7474725513642787,
      "grad_norm": 1.5681108236312866,
      "learning_rate": 5.0525400391332714e-05,
      "loss": 0.0488,
      "step": 10314
    },
    {
      "epoch": 0.7475450230097475,
      "grad_norm": 0.2959820628166199,
      "learning_rate": 5.051090658743387e-05,
      "loss": 0.0105,
      "step": 10315
    },
    {
      "epoch": 0.7476174946552161,
      "grad_norm": 1.289355993270874,
      "learning_rate": 5.049641278353504e-05,
      "loss": 0.0486,
      "step": 10316
    },
    {
      "epoch": 0.7476899663006848,
      "grad_norm": 0.9855127334594727,
      "learning_rate": 5.048191897963621e-05,
      "loss": 0.0467,
      "step": 10317
    },
    {
      "epoch": 0.7477624379461536,
      "grad_norm": 0.7274397015571594,
      "learning_rate": 5.0467425175737374e-05,
      "loss": 0.0153,
      "step": 10318
    },
    {
      "epoch": 0.7478349095916222,
      "grad_norm": 0.7967629432678223,
      "learning_rate": 5.0452931371838544e-05,
      "loss": 0.013,
      "step": 10319
    },
    {
      "epoch": 0.747907381237091,
      "grad_norm": 0.1536947637796402,
      "learning_rate": 5.0438437567939714e-05,
      "loss": 0.0021,
      "step": 10320
    },
    {
      "epoch": 0.7479798528825597,
      "grad_norm": 0.49161723256111145,
      "learning_rate": 5.042394376404087e-05,
      "loss": 0.0198,
      "step": 10321
    },
    {
      "epoch": 0.7480523245280284,
      "grad_norm": 3.1219000816345215,
      "learning_rate": 5.040944996014204e-05,
      "loss": 0.117,
      "step": 10322
    },
    {
      "epoch": 0.7481247961734971,
      "grad_norm": 0.687642514705658,
      "learning_rate": 5.039495615624321e-05,
      "loss": 0.0039,
      "step": 10323
    },
    {
      "epoch": 0.7481972678189658,
      "grad_norm": 0.4245167672634125,
      "learning_rate": 5.0380462352344374e-05,
      "loss": 0.008,
      "step": 10324
    },
    {
      "epoch": 0.7482697394644345,
      "grad_norm": 0.335120290517807,
      "learning_rate": 5.0365968548445544e-05,
      "loss": 0.0183,
      "step": 10325
    },
    {
      "epoch": 0.7483422111099033,
      "grad_norm": 1.038281798362732,
      "learning_rate": 5.0351474744546714e-05,
      "loss": 0.0641,
      "step": 10326
    },
    {
      "epoch": 0.7484146827553719,
      "grad_norm": 1.5247812271118164,
      "learning_rate": 5.033698094064787e-05,
      "loss": 0.1067,
      "step": 10327
    },
    {
      "epoch": 0.7484871544008407,
      "grad_norm": 0.7197807431221008,
      "learning_rate": 5.032248713674904e-05,
      "loss": 0.0175,
      "step": 10328
    },
    {
      "epoch": 0.7485596260463094,
      "grad_norm": 0.735524594783783,
      "learning_rate": 5.030799333285021e-05,
      "loss": 0.0226,
      "step": 10329
    },
    {
      "epoch": 0.7486320976917781,
      "grad_norm": 1.4700653553009033,
      "learning_rate": 5.0293499528951374e-05,
      "loss": 0.057,
      "step": 10330
    },
    {
      "epoch": 0.7487045693372468,
      "grad_norm": 1.6401095390319824,
      "learning_rate": 5.0279005725052544e-05,
      "loss": 0.063,
      "step": 10331
    },
    {
      "epoch": 0.7487770409827155,
      "grad_norm": 1.4752756357192993,
      "learning_rate": 5.0264511921153714e-05,
      "loss": 0.057,
      "step": 10332
    },
    {
      "epoch": 0.7488495126281842,
      "grad_norm": 0.14722977578639984,
      "learning_rate": 5.025001811725487e-05,
      "loss": 0.0025,
      "step": 10333
    },
    {
      "epoch": 0.748921984273653,
      "grad_norm": 1.5501435995101929,
      "learning_rate": 5.023552431335604e-05,
      "loss": 0.0364,
      "step": 10334
    },
    {
      "epoch": 0.7489944559191216,
      "grad_norm": 1.9361257553100586,
      "learning_rate": 5.022103050945721e-05,
      "loss": 0.081,
      "step": 10335
    },
    {
      "epoch": 0.7490669275645904,
      "grad_norm": 4.845163345336914,
      "learning_rate": 5.0206536705558373e-05,
      "loss": 0.1304,
      "step": 10336
    },
    {
      "epoch": 0.749139399210059,
      "grad_norm": 8.595717430114746,
      "learning_rate": 5.0192042901659543e-05,
      "loss": 0.1063,
      "step": 10337
    },
    {
      "epoch": 0.7492118708555278,
      "grad_norm": 1.3165849447250366,
      "learning_rate": 5.0177549097760713e-05,
      "loss": 0.0502,
      "step": 10338
    },
    {
      "epoch": 0.7492843425009965,
      "grad_norm": 1.3921656608581543,
      "learning_rate": 5.016305529386187e-05,
      "loss": 0.0213,
      "step": 10339
    },
    {
      "epoch": 0.7493568141464652,
      "grad_norm": 0.4335969388484955,
      "learning_rate": 5.014856148996304e-05,
      "loss": 0.0179,
      "step": 10340
    },
    {
      "epoch": 0.7494292857919339,
      "grad_norm": 3.657217025756836,
      "learning_rate": 5.013406768606421e-05,
      "loss": 0.0601,
      "step": 10341
    },
    {
      "epoch": 0.7495017574374027,
      "grad_norm": 0.9203073382377625,
      "learning_rate": 5.011957388216537e-05,
      "loss": 0.0123,
      "step": 10342
    },
    {
      "epoch": 0.7495742290828713,
      "grad_norm": 1.3883668184280396,
      "learning_rate": 5.010508007826654e-05,
      "loss": 0.0242,
      "step": 10343
    },
    {
      "epoch": 0.74964670072834,
      "grad_norm": 1.1129649877548218,
      "learning_rate": 5.009058627436771e-05,
      "loss": 0.0361,
      "step": 10344
    },
    {
      "epoch": 0.7497191723738087,
      "grad_norm": 1.8541203737258911,
      "learning_rate": 5.007609247046887e-05,
      "loss": 0.04,
      "step": 10345
    },
    {
      "epoch": 0.7497916440192774,
      "grad_norm": 0.19171017408370972,
      "learning_rate": 5.006159866657004e-05,
      "loss": 0.0054,
      "step": 10346
    },
    {
      "epoch": 0.7498641156647462,
      "grad_norm": 2.08909010887146,
      "learning_rate": 5.004710486267121e-05,
      "loss": 0.1028,
      "step": 10347
    },
    {
      "epoch": 0.7499365873102148,
      "grad_norm": 1.3911361694335938,
      "learning_rate": 5.003261105877237e-05,
      "loss": 0.0913,
      "step": 10348
    },
    {
      "epoch": 0.7500090589556836,
      "grad_norm": 3.2943503856658936,
      "learning_rate": 5.001811725487354e-05,
      "loss": 0.0852,
      "step": 10349
    },
    {
      "epoch": 0.7500815306011523,
      "grad_norm": 1.7251830101013184,
      "learning_rate": 5.000362345097471e-05,
      "loss": 0.0512,
      "step": 10350
    },
    {
      "epoch": 0.750154002246621,
      "grad_norm": 1.5541130304336548,
      "learning_rate": 4.9989129647075877e-05,
      "loss": 0.0527,
      "step": 10351
    },
    {
      "epoch": 0.7502264738920897,
      "grad_norm": 0.8951008915901184,
      "learning_rate": 4.997463584317704e-05,
      "loss": 0.0127,
      "step": 10352
    },
    {
      "epoch": 0.7502989455375584,
      "grad_norm": 1.1552178859710693,
      "learning_rate": 4.996014203927821e-05,
      "loss": 0.0411,
      "step": 10353
    },
    {
      "epoch": 0.7503714171830271,
      "grad_norm": 1.0633918046951294,
      "learning_rate": 4.994564823537938e-05,
      "loss": 0.0352,
      "step": 10354
    },
    {
      "epoch": 0.7504438888284959,
      "grad_norm": 2.625102996826172,
      "learning_rate": 4.993115443148054e-05,
      "loss": 0.0542,
      "step": 10355
    },
    {
      "epoch": 0.7505163604739645,
      "grad_norm": 0.7436859011650085,
      "learning_rate": 4.991666062758171e-05,
      "loss": 0.0376,
      "step": 10356
    },
    {
      "epoch": 0.7505888321194333,
      "grad_norm": 0.5088507533073425,
      "learning_rate": 4.9902166823682876e-05,
      "loss": 0.0095,
      "step": 10357
    },
    {
      "epoch": 0.750661303764902,
      "grad_norm": 2.1348750591278076,
      "learning_rate": 4.988767301978404e-05,
      "loss": 0.0991,
      "step": 10358
    },
    {
      "epoch": 0.7507337754103707,
      "grad_norm": 0.11310821026563644,
      "learning_rate": 4.987317921588521e-05,
      "loss": 0.0011,
      "step": 10359
    },
    {
      "epoch": 0.7508062470558394,
      "grad_norm": 1.5998319387435913,
      "learning_rate": 4.985868541198638e-05,
      "loss": 0.0129,
      "step": 10360
    },
    {
      "epoch": 0.7508787187013081,
      "grad_norm": 0.5709646940231323,
      "learning_rate": 4.984419160808754e-05,
      "loss": 0.0209,
      "step": 10361
    },
    {
      "epoch": 0.7509511903467768,
      "grad_norm": 0.23582817614078522,
      "learning_rate": 4.982969780418871e-05,
      "loss": 0.0055,
      "step": 10362
    },
    {
      "epoch": 0.7510236619922456,
      "grad_norm": 1.0902113914489746,
      "learning_rate": 4.9815204000289876e-05,
      "loss": 0.0127,
      "step": 10363
    },
    {
      "epoch": 0.7510961336377142,
      "grad_norm": 1.0899426937103271,
      "learning_rate": 4.980071019639104e-05,
      "loss": 0.0215,
      "step": 10364
    },
    {
      "epoch": 0.751168605283183,
      "grad_norm": 1.3588802814483643,
      "learning_rate": 4.9786216392492216e-05,
      "loss": 0.0413,
      "step": 10365
    },
    {
      "epoch": 0.7512410769286517,
      "grad_norm": 0.9521171450614929,
      "learning_rate": 4.977172258859338e-05,
      "loss": 0.0413,
      "step": 10366
    },
    {
      "epoch": 0.7513135485741204,
      "grad_norm": 0.63027024269104,
      "learning_rate": 4.975722878469454e-05,
      "loss": 0.0127,
      "step": 10367
    },
    {
      "epoch": 0.7513860202195891,
      "grad_norm": 1.8913333415985107,
      "learning_rate": 4.974273498079571e-05,
      "loss": 0.1042,
      "step": 10368
    },
    {
      "epoch": 0.7514584918650578,
      "grad_norm": 2.3236615657806396,
      "learning_rate": 4.9728241176896876e-05,
      "loss": 0.0853,
      "step": 10369
    },
    {
      "epoch": 0.7515309635105265,
      "grad_norm": 1.063118815422058,
      "learning_rate": 4.9713747372998046e-05,
      "loss": 0.0617,
      "step": 10370
    },
    {
      "epoch": 0.7516034351559953,
      "grad_norm": 0.3464130163192749,
      "learning_rate": 4.9699253569099216e-05,
      "loss": 0.0045,
      "step": 10371
    },
    {
      "epoch": 0.7516759068014639,
      "grad_norm": 1.8053193092346191,
      "learning_rate": 4.968475976520038e-05,
      "loss": 0.0423,
      "step": 10372
    },
    {
      "epoch": 0.7517483784469327,
      "grad_norm": 1.6666057109832764,
      "learning_rate": 4.967026596130155e-05,
      "loss": 0.0422,
      "step": 10373
    },
    {
      "epoch": 0.7518208500924013,
      "grad_norm": 1.0071134567260742,
      "learning_rate": 4.965577215740271e-05,
      "loss": 0.0202,
      "step": 10374
    },
    {
      "epoch": 0.75189332173787,
      "grad_norm": 1.9875071048736572,
      "learning_rate": 4.9641278353503876e-05,
      "loss": 0.0571,
      "step": 10375
    },
    {
      "epoch": 0.7519657933833388,
      "grad_norm": 0.6257795691490173,
      "learning_rate": 4.9626784549605046e-05,
      "loss": 0.0263,
      "step": 10376
    },
    {
      "epoch": 0.7520382650288074,
      "grad_norm": 0.6189426779747009,
      "learning_rate": 4.9612290745706216e-05,
      "loss": 0.0113,
      "step": 10377
    },
    {
      "epoch": 0.7521107366742762,
      "grad_norm": 0.6525663137435913,
      "learning_rate": 4.959779694180738e-05,
      "loss": 0.023,
      "step": 10378
    },
    {
      "epoch": 0.752183208319745,
      "grad_norm": 1.3641304969787598,
      "learning_rate": 4.958330313790855e-05,
      "loss": 0.0622,
      "step": 10379
    },
    {
      "epoch": 0.7522556799652136,
      "grad_norm": 0.5953621864318848,
      "learning_rate": 4.956880933400971e-05,
      "loss": 0.0111,
      "step": 10380
    },
    {
      "epoch": 0.7523281516106823,
      "grad_norm": 2.210286855697632,
      "learning_rate": 4.9554315530110876e-05,
      "loss": 0.0891,
      "step": 10381
    },
    {
      "epoch": 0.752400623256151,
      "grad_norm": 1.8018897771835327,
      "learning_rate": 4.9539821726212046e-05,
      "loss": 0.0522,
      "step": 10382
    },
    {
      "epoch": 0.7524730949016197,
      "grad_norm": 1.5807479619979858,
      "learning_rate": 4.9525327922313216e-05,
      "loss": 0.0339,
      "step": 10383
    },
    {
      "epoch": 0.7525455665470885,
      "grad_norm": 4.231289386749268,
      "learning_rate": 4.951083411841438e-05,
      "loss": 0.1232,
      "step": 10384
    },
    {
      "epoch": 0.7526180381925571,
      "grad_norm": 2.584108352661133,
      "learning_rate": 4.949634031451555e-05,
      "loss": 0.0257,
      "step": 10385
    },
    {
      "epoch": 0.7526905098380259,
      "grad_norm": 1.6617695093154907,
      "learning_rate": 4.948184651061671e-05,
      "loss": 0.0259,
      "step": 10386
    },
    {
      "epoch": 0.7527629814834946,
      "grad_norm": 1.904295563697815,
      "learning_rate": 4.9467352706717876e-05,
      "loss": 0.0615,
      "step": 10387
    },
    {
      "epoch": 0.7528354531289633,
      "grad_norm": 1.5453543663024902,
      "learning_rate": 4.9452858902819046e-05,
      "loss": 0.0535,
      "step": 10388
    },
    {
      "epoch": 0.752907924774432,
      "grad_norm": 3.784196138381958,
      "learning_rate": 4.9438365098920216e-05,
      "loss": 0.0506,
      "step": 10389
    },
    {
      "epoch": 0.7529803964199007,
      "grad_norm": 0.5778054594993591,
      "learning_rate": 4.942387129502138e-05,
      "loss": 0.021,
      "step": 10390
    },
    {
      "epoch": 0.7530528680653694,
      "grad_norm": 0.4820273816585541,
      "learning_rate": 4.940937749112255e-05,
      "loss": 0.0124,
      "step": 10391
    },
    {
      "epoch": 0.7531253397108382,
      "grad_norm": 1.0075383186340332,
      "learning_rate": 4.939488368722371e-05,
      "loss": 0.0349,
      "step": 10392
    },
    {
      "epoch": 0.7531978113563068,
      "grad_norm": 1.101314902305603,
      "learning_rate": 4.9380389883324876e-05,
      "loss": 0.0138,
      "step": 10393
    },
    {
      "epoch": 0.7532702830017756,
      "grad_norm": 2.5740108489990234,
      "learning_rate": 4.936589607942605e-05,
      "loss": 0.06,
      "step": 10394
    },
    {
      "epoch": 0.7533427546472443,
      "grad_norm": 0.9043796062469482,
      "learning_rate": 4.9351402275527216e-05,
      "loss": 0.0184,
      "step": 10395
    },
    {
      "epoch": 0.753415226292713,
      "grad_norm": 0.7473829388618469,
      "learning_rate": 4.933690847162838e-05,
      "loss": 0.0167,
      "step": 10396
    },
    {
      "epoch": 0.7534876979381817,
      "grad_norm": 2.4277920722961426,
      "learning_rate": 4.932241466772955e-05,
      "loss": 0.0775,
      "step": 10397
    },
    {
      "epoch": 0.7535601695836504,
      "grad_norm": 0.8833837509155273,
      "learning_rate": 4.930792086383071e-05,
      "loss": 0.0221,
      "step": 10398
    },
    {
      "epoch": 0.7536326412291191,
      "grad_norm": 0.12276767939329147,
      "learning_rate": 4.929342705993188e-05,
      "loss": 0.0034,
      "step": 10399
    },
    {
      "epoch": 0.7537051128745879,
      "grad_norm": 0.6347082853317261,
      "learning_rate": 4.927893325603305e-05,
      "loss": 0.0153,
      "step": 10400
    },
    {
      "epoch": 0.7537775845200565,
      "grad_norm": 0.3017982840538025,
      "learning_rate": 4.9264439452134216e-05,
      "loss": 0.0051,
      "step": 10401
    },
    {
      "epoch": 0.7538500561655253,
      "grad_norm": 1.5414232015609741,
      "learning_rate": 4.924994564823538e-05,
      "loss": 0.0576,
      "step": 10402
    },
    {
      "epoch": 0.753922527810994,
      "grad_norm": 2.711404323577881,
      "learning_rate": 4.923545184433655e-05,
      "loss": 0.1227,
      "step": 10403
    },
    {
      "epoch": 0.7539949994564626,
      "grad_norm": 2.6521811485290527,
      "learning_rate": 4.922095804043771e-05,
      "loss": 0.0825,
      "step": 10404
    },
    {
      "epoch": 0.7540674711019314,
      "grad_norm": 4.557318687438965,
      "learning_rate": 4.920646423653888e-05,
      "loss": 0.0358,
      "step": 10405
    },
    {
      "epoch": 0.7541399427474,
      "grad_norm": 1.061029314994812,
      "learning_rate": 4.919197043264005e-05,
      "loss": 0.0313,
      "step": 10406
    },
    {
      "epoch": 0.7542124143928688,
      "grad_norm": 0.4102010130882263,
      "learning_rate": 4.9177476628741216e-05,
      "loss": 0.0111,
      "step": 10407
    },
    {
      "epoch": 0.7542848860383375,
      "grad_norm": 0.4975413680076599,
      "learning_rate": 4.916298282484238e-05,
      "loss": 0.0116,
      "step": 10408
    },
    {
      "epoch": 0.7543573576838062,
      "grad_norm": 0.8458265662193298,
      "learning_rate": 4.914848902094355e-05,
      "loss": 0.0327,
      "step": 10409
    },
    {
      "epoch": 0.7544298293292749,
      "grad_norm": 1.5277971029281616,
      "learning_rate": 4.913399521704471e-05,
      "loss": 0.045,
      "step": 10410
    },
    {
      "epoch": 0.7545023009747436,
      "grad_norm": 0.15640823543071747,
      "learning_rate": 4.911950141314588e-05,
      "loss": 0.0029,
      "step": 10411
    },
    {
      "epoch": 0.7545747726202123,
      "grad_norm": 0.18966108560562134,
      "learning_rate": 4.910500760924705e-05,
      "loss": 0.008,
      "step": 10412
    },
    {
      "epoch": 0.7546472442656811,
      "grad_norm": 0.5677139163017273,
      "learning_rate": 4.9090513805348216e-05,
      "loss": 0.0154,
      "step": 10413
    },
    {
      "epoch": 0.7547197159111497,
      "grad_norm": 0.03807932883501053,
      "learning_rate": 4.9076020001449386e-05,
      "loss": 0.0007,
      "step": 10414
    },
    {
      "epoch": 0.7547921875566185,
      "grad_norm": 1.799410343170166,
      "learning_rate": 4.906152619755055e-05,
      "loss": 0.0475,
      "step": 10415
    },
    {
      "epoch": 0.7548646592020872,
      "grad_norm": 1.3605276346206665,
      "learning_rate": 4.904703239365171e-05,
      "loss": 0.0323,
      "step": 10416
    },
    {
      "epoch": 0.7549371308475559,
      "grad_norm": 2.6172597408294678,
      "learning_rate": 4.903253858975288e-05,
      "loss": 0.0892,
      "step": 10417
    },
    {
      "epoch": 0.7550096024930246,
      "grad_norm": 0.44145476818084717,
      "learning_rate": 4.901804478585405e-05,
      "loss": 0.0077,
      "step": 10418
    },
    {
      "epoch": 0.7550820741384933,
      "grad_norm": 0.09463591873645782,
      "learning_rate": 4.9003550981955215e-05,
      "loss": 0.0014,
      "step": 10419
    },
    {
      "epoch": 0.755154545783962,
      "grad_norm": 1.6409199237823486,
      "learning_rate": 4.8989057178056386e-05,
      "loss": 0.024,
      "step": 10420
    },
    {
      "epoch": 0.7552270174294308,
      "grad_norm": 1.9591529369354248,
      "learning_rate": 4.897456337415755e-05,
      "loss": 0.0435,
      "step": 10421
    },
    {
      "epoch": 0.7552994890748994,
      "grad_norm": 1.9736665487289429,
      "learning_rate": 4.896006957025871e-05,
      "loss": 0.0744,
      "step": 10422
    },
    {
      "epoch": 0.7553719607203682,
      "grad_norm": 1.528650164604187,
      "learning_rate": 4.894557576635989e-05,
      "loss": 0.1092,
      "step": 10423
    },
    {
      "epoch": 0.7554444323658369,
      "grad_norm": 1.6626766920089722,
      "learning_rate": 4.893108196246105e-05,
      "loss": 0.053,
      "step": 10424
    },
    {
      "epoch": 0.7555169040113056,
      "grad_norm": 2.057577610015869,
      "learning_rate": 4.8916588158562215e-05,
      "loss": 0.1255,
      "step": 10425
    },
    {
      "epoch": 0.7555893756567743,
      "grad_norm": 1.7403850555419922,
      "learning_rate": 4.8902094354663385e-05,
      "loss": 0.0349,
      "step": 10426
    },
    {
      "epoch": 0.755661847302243,
      "grad_norm": 0.5219221115112305,
      "learning_rate": 4.888760055076455e-05,
      "loss": 0.0196,
      "step": 10427
    },
    {
      "epoch": 0.7557343189477117,
      "grad_norm": 0.9296720623970032,
      "learning_rate": 4.887310674686572e-05,
      "loss": 0.0229,
      "step": 10428
    },
    {
      "epoch": 0.7558067905931805,
      "grad_norm": 3.0852296352386475,
      "learning_rate": 4.885861294296689e-05,
      "loss": 0.0347,
      "step": 10429
    },
    {
      "epoch": 0.7558792622386491,
      "grad_norm": 0.6422743797302246,
      "learning_rate": 4.884411913906805e-05,
      "loss": 0.0234,
      "step": 10430
    },
    {
      "epoch": 0.7559517338841178,
      "grad_norm": 3.832064390182495,
      "learning_rate": 4.8829625335169215e-05,
      "loss": 0.057,
      "step": 10431
    },
    {
      "epoch": 0.7560242055295866,
      "grad_norm": 1.7325202226638794,
      "learning_rate": 4.8815131531270385e-05,
      "loss": 0.0624,
      "step": 10432
    },
    {
      "epoch": 0.7560966771750552,
      "grad_norm": 1.1156855821609497,
      "learning_rate": 4.880063772737155e-05,
      "loss": 0.0735,
      "step": 10433
    },
    {
      "epoch": 0.756169148820524,
      "grad_norm": 1.4264971017837524,
      "learning_rate": 4.878614392347272e-05,
      "loss": 0.0882,
      "step": 10434
    },
    {
      "epoch": 0.7562416204659926,
      "grad_norm": 0.22989651560783386,
      "learning_rate": 4.877165011957389e-05,
      "loss": 0.0063,
      "step": 10435
    },
    {
      "epoch": 0.7563140921114614,
      "grad_norm": 0.29153090715408325,
      "learning_rate": 4.875715631567505e-05,
      "loss": 0.0058,
      "step": 10436
    },
    {
      "epoch": 0.7563865637569301,
      "grad_norm": 3.52122163772583,
      "learning_rate": 4.8742662511776215e-05,
      "loss": 0.0686,
      "step": 10437
    },
    {
      "epoch": 0.7564590354023988,
      "grad_norm": 0.9434138536453247,
      "learning_rate": 4.8728168707877385e-05,
      "loss": 0.0266,
      "step": 10438
    },
    {
      "epoch": 0.7565315070478675,
      "grad_norm": 5.211435794830322,
      "learning_rate": 4.871367490397855e-05,
      "loss": 0.0329,
      "step": 10439
    },
    {
      "epoch": 0.7566039786933363,
      "grad_norm": 4.662255764007568,
      "learning_rate": 4.869918110007972e-05,
      "loss": 0.0597,
      "step": 10440
    },
    {
      "epoch": 0.7566764503388049,
      "grad_norm": 1.7405115365982056,
      "learning_rate": 4.868468729618089e-05,
      "loss": 0.0437,
      "step": 10441
    },
    {
      "epoch": 0.7567489219842737,
      "grad_norm": 1.8122057914733887,
      "learning_rate": 4.867019349228205e-05,
      "loss": 0.0864,
      "step": 10442
    },
    {
      "epoch": 0.7568213936297423,
      "grad_norm": 2.0888779163360596,
      "learning_rate": 4.8655699688383215e-05,
      "loss": 0.0916,
      "step": 10443
    },
    {
      "epoch": 0.7568938652752111,
      "grad_norm": 2.228132963180542,
      "learning_rate": 4.8641205884484385e-05,
      "loss": 0.0838,
      "step": 10444
    },
    {
      "epoch": 0.7569663369206798,
      "grad_norm": 2.1899781227111816,
      "learning_rate": 4.862671208058555e-05,
      "loss": 0.0573,
      "step": 10445
    },
    {
      "epoch": 0.7570388085661485,
      "grad_norm": 1.2770859003067017,
      "learning_rate": 4.861221827668672e-05,
      "loss": 0.0937,
      "step": 10446
    },
    {
      "epoch": 0.7571112802116172,
      "grad_norm": 0.26197001338005066,
      "learning_rate": 4.859772447278789e-05,
      "loss": 0.0047,
      "step": 10447
    },
    {
      "epoch": 0.7571837518570859,
      "grad_norm": 2.3556578159332275,
      "learning_rate": 4.858323066888905e-05,
      "loss": 0.0499,
      "step": 10448
    },
    {
      "epoch": 0.7572562235025546,
      "grad_norm": 0.6601155400276184,
      "learning_rate": 4.8568736864990215e-05,
      "loss": 0.0282,
      "step": 10449
    },
    {
      "epoch": 0.7573286951480234,
      "grad_norm": 1.415055751800537,
      "learning_rate": 4.8554243061091385e-05,
      "loss": 0.0985,
      "step": 10450
    },
    {
      "epoch": 0.757401166793492,
      "grad_norm": 2.979903221130371,
      "learning_rate": 4.853974925719255e-05,
      "loss": 0.1222,
      "step": 10451
    },
    {
      "epoch": 0.7574736384389608,
      "grad_norm": 1.0555217266082764,
      "learning_rate": 4.8525255453293725e-05,
      "loss": 0.0535,
      "step": 10452
    },
    {
      "epoch": 0.7575461100844295,
      "grad_norm": 1.1317625045776367,
      "learning_rate": 4.851076164939489e-05,
      "loss": 0.0519,
      "step": 10453
    },
    {
      "epoch": 0.7576185817298982,
      "grad_norm": 1.2921086549758911,
      "learning_rate": 4.849626784549605e-05,
      "loss": 0.0474,
      "step": 10454
    },
    {
      "epoch": 0.7576910533753669,
      "grad_norm": 0.9344328045845032,
      "learning_rate": 4.848177404159722e-05,
      "loss": 0.0355,
      "step": 10455
    },
    {
      "epoch": 0.7577635250208355,
      "grad_norm": 1.3309801816940308,
      "learning_rate": 4.8467280237698385e-05,
      "loss": 0.0358,
      "step": 10456
    },
    {
      "epoch": 0.7578359966663043,
      "grad_norm": 1.754916787147522,
      "learning_rate": 4.8452786433799555e-05,
      "loss": 0.0317,
      "step": 10457
    },
    {
      "epoch": 0.757908468311773,
      "grad_norm": 1.8412559032440186,
      "learning_rate": 4.8438292629900725e-05,
      "loss": 0.1184,
      "step": 10458
    },
    {
      "epoch": 0.7579809399572417,
      "grad_norm": 1.9127342700958252,
      "learning_rate": 4.842379882600189e-05,
      "loss": 0.1271,
      "step": 10459
    },
    {
      "epoch": 0.7580534116027104,
      "grad_norm": 1.8302154541015625,
      "learning_rate": 4.840930502210305e-05,
      "loss": 0.0407,
      "step": 10460
    },
    {
      "epoch": 0.7581258832481792,
      "grad_norm": 1.5320279598236084,
      "learning_rate": 4.839481121820422e-05,
      "loss": 0.0791,
      "step": 10461
    },
    {
      "epoch": 0.7581983548936478,
      "grad_norm": 2.0877456665039062,
      "learning_rate": 4.8380317414305385e-05,
      "loss": 0.0527,
      "step": 10462
    },
    {
      "epoch": 0.7582708265391166,
      "grad_norm": 2.4440078735351562,
      "learning_rate": 4.8365823610406555e-05,
      "loss": 0.0395,
      "step": 10463
    },
    {
      "epoch": 0.7583432981845852,
      "grad_norm": 1.7763736248016357,
      "learning_rate": 4.8351329806507725e-05,
      "loss": 0.0558,
      "step": 10464
    },
    {
      "epoch": 0.758415769830054,
      "grad_norm": 0.43593117594718933,
      "learning_rate": 4.833683600260889e-05,
      "loss": 0.021,
      "step": 10465
    },
    {
      "epoch": 0.7584882414755227,
      "grad_norm": 1.7880303859710693,
      "learning_rate": 4.832234219871005e-05,
      "loss": 0.0775,
      "step": 10466
    },
    {
      "epoch": 0.7585607131209914,
      "grad_norm": 0.5494965314865112,
      "learning_rate": 4.830784839481122e-05,
      "loss": 0.0216,
      "step": 10467
    },
    {
      "epoch": 0.7586331847664601,
      "grad_norm": 0.7200981378555298,
      "learning_rate": 4.8293354590912385e-05,
      "loss": 0.0512,
      "step": 10468
    },
    {
      "epoch": 0.7587056564119289,
      "grad_norm": 1.2904348373413086,
      "learning_rate": 4.8278860787013555e-05,
      "loss": 0.0575,
      "step": 10469
    },
    {
      "epoch": 0.7587781280573975,
      "grad_norm": 0.5841423273086548,
      "learning_rate": 4.8264366983114725e-05,
      "loss": 0.0147,
      "step": 10470
    },
    {
      "epoch": 0.7588505997028663,
      "grad_norm": 1.6192432641983032,
      "learning_rate": 4.824987317921589e-05,
      "loss": 0.0979,
      "step": 10471
    },
    {
      "epoch": 0.7589230713483349,
      "grad_norm": 1.4405498504638672,
      "learning_rate": 4.823537937531705e-05,
      "loss": 0.0261,
      "step": 10472
    },
    {
      "epoch": 0.7589955429938037,
      "grad_norm": 1.272662878036499,
      "learning_rate": 4.822088557141822e-05,
      "loss": 0.104,
      "step": 10473
    },
    {
      "epoch": 0.7590680146392724,
      "grad_norm": 1.155395269393921,
      "learning_rate": 4.8206391767519385e-05,
      "loss": 0.1037,
      "step": 10474
    },
    {
      "epoch": 0.7591404862847411,
      "grad_norm": 2.5257418155670166,
      "learning_rate": 4.8191897963620555e-05,
      "loss": 0.0519,
      "step": 10475
    },
    {
      "epoch": 0.7592129579302098,
      "grad_norm": 0.506093442440033,
      "learning_rate": 4.8177404159721725e-05,
      "loss": 0.0115,
      "step": 10476
    },
    {
      "epoch": 0.7592854295756785,
      "grad_norm": 1.7209080457687378,
      "learning_rate": 4.816291035582289e-05,
      "loss": 0.0845,
      "step": 10477
    },
    {
      "epoch": 0.7593579012211472,
      "grad_norm": 1.022007942199707,
      "learning_rate": 4.814841655192405e-05,
      "loss": 0.0563,
      "step": 10478
    },
    {
      "epoch": 0.759430372866616,
      "grad_norm": 1.3358513116836548,
      "learning_rate": 4.813392274802522e-05,
      "loss": 0.0358,
      "step": 10479
    },
    {
      "epoch": 0.7595028445120846,
      "grad_norm": 1.2345346212387085,
      "learning_rate": 4.811942894412639e-05,
      "loss": 0.0673,
      "step": 10480
    },
    {
      "epoch": 0.7595753161575534,
      "grad_norm": 1.8889811038970947,
      "learning_rate": 4.8104935140227555e-05,
      "loss": 0.093,
      "step": 10481
    },
    {
      "epoch": 0.7596477878030221,
      "grad_norm": 0.6530252695083618,
      "learning_rate": 4.8090441336328725e-05,
      "loss": 0.0343,
      "step": 10482
    },
    {
      "epoch": 0.7597202594484908,
      "grad_norm": 0.3136526644229889,
      "learning_rate": 4.807594753242989e-05,
      "loss": 0.0171,
      "step": 10483
    },
    {
      "epoch": 0.7597927310939595,
      "grad_norm": 2.23124623298645,
      "learning_rate": 4.806145372853105e-05,
      "loss": 0.0687,
      "step": 10484
    },
    {
      "epoch": 0.7598652027394281,
      "grad_norm": 1.11988365650177,
      "learning_rate": 4.804695992463222e-05,
      "loss": 0.0299,
      "step": 10485
    },
    {
      "epoch": 0.7599376743848969,
      "grad_norm": 2.6906871795654297,
      "learning_rate": 4.803246612073339e-05,
      "loss": 0.1047,
      "step": 10486
    },
    {
      "epoch": 0.7600101460303657,
      "grad_norm": 0.8878928422927856,
      "learning_rate": 4.8017972316834554e-05,
      "loss": 0.0506,
      "step": 10487
    },
    {
      "epoch": 0.7600826176758343,
      "grad_norm": 0.4639122188091278,
      "learning_rate": 4.8003478512935724e-05,
      "loss": 0.0113,
      "step": 10488
    },
    {
      "epoch": 0.760155089321303,
      "grad_norm": 1.57038414478302,
      "learning_rate": 4.798898470903689e-05,
      "loss": 0.0443,
      "step": 10489
    },
    {
      "epoch": 0.7602275609667718,
      "grad_norm": 2.435636520385742,
      "learning_rate": 4.797449090513805e-05,
      "loss": 0.0375,
      "step": 10490
    },
    {
      "epoch": 0.7603000326122404,
      "grad_norm": 1.4064714908599854,
      "learning_rate": 4.795999710123922e-05,
      "loss": 0.0342,
      "step": 10491
    },
    {
      "epoch": 0.7603725042577092,
      "grad_norm": 2.4310531616210938,
      "learning_rate": 4.794550329734039e-05,
      "loss": 0.1206,
      "step": 10492
    },
    {
      "epoch": 0.7604449759031778,
      "grad_norm": 1.6066564321517944,
      "learning_rate": 4.793100949344156e-05,
      "loss": 0.0406,
      "step": 10493
    },
    {
      "epoch": 0.7605174475486466,
      "grad_norm": 2.949489116668701,
      "learning_rate": 4.7916515689542724e-05,
      "loss": 0.0684,
      "step": 10494
    },
    {
      "epoch": 0.7605899191941153,
      "grad_norm": 1.8466941118240356,
      "learning_rate": 4.790202188564389e-05,
      "loss": 0.0446,
      "step": 10495
    },
    {
      "epoch": 0.760662390839584,
      "grad_norm": 0.05773979052901268,
      "learning_rate": 4.788752808174506e-05,
      "loss": 0.0016,
      "step": 10496
    },
    {
      "epoch": 0.7607348624850527,
      "grad_norm": 0.7337090969085693,
      "learning_rate": 4.787303427784622e-05,
      "loss": 0.0252,
      "step": 10497
    },
    {
      "epoch": 0.7608073341305215,
      "grad_norm": 0.8960007429122925,
      "learning_rate": 4.785854047394739e-05,
      "loss": 0.0247,
      "step": 10498
    },
    {
      "epoch": 0.7608798057759901,
      "grad_norm": 5.161813259124756,
      "learning_rate": 4.784404667004856e-05,
      "loss": 0.0262,
      "step": 10499
    },
    {
      "epoch": 0.7609522774214589,
      "grad_norm": 1.278173565864563,
      "learning_rate": 4.7829552866149724e-05,
      "loss": 0.0729,
      "step": 10500
    },
    {
      "epoch": 0.7610247490669275,
      "grad_norm": 1.3110637664794922,
      "learning_rate": 4.781505906225089e-05,
      "loss": 0.0373,
      "step": 10501
    },
    {
      "epoch": 0.7610972207123963,
      "grad_norm": 1.3965051174163818,
      "learning_rate": 4.780056525835206e-05,
      "loss": 0.0358,
      "step": 10502
    },
    {
      "epoch": 0.761169692357865,
      "grad_norm": 0.729829728603363,
      "learning_rate": 4.778607145445322e-05,
      "loss": 0.0295,
      "step": 10503
    },
    {
      "epoch": 0.7612421640033337,
      "grad_norm": 2.6612677574157715,
      "learning_rate": 4.777157765055439e-05,
      "loss": 0.0898,
      "step": 10504
    },
    {
      "epoch": 0.7613146356488024,
      "grad_norm": 1.3070049285888672,
      "learning_rate": 4.775708384665556e-05,
      "loss": 0.0263,
      "step": 10505
    },
    {
      "epoch": 0.7613871072942712,
      "grad_norm": 2.645995616912842,
      "learning_rate": 4.7742590042756724e-05,
      "loss": 0.1123,
      "step": 10506
    },
    {
      "epoch": 0.7614595789397398,
      "grad_norm": 1.1071749925613403,
      "learning_rate": 4.772809623885789e-05,
      "loss": 0.0369,
      "step": 10507
    },
    {
      "epoch": 0.7615320505852086,
      "grad_norm": 0.9266079068183899,
      "learning_rate": 4.771360243495906e-05,
      "loss": 0.0437,
      "step": 10508
    },
    {
      "epoch": 0.7616045222306772,
      "grad_norm": 1.3804447650909424,
      "learning_rate": 4.769910863106023e-05,
      "loss": 0.0365,
      "step": 10509
    },
    {
      "epoch": 0.761676993876146,
      "grad_norm": 0.45540544390678406,
      "learning_rate": 4.768461482716139e-05,
      "loss": 0.0098,
      "step": 10510
    },
    {
      "epoch": 0.7617494655216147,
      "grad_norm": 1.6925885677337646,
      "learning_rate": 4.767012102326256e-05,
      "loss": 0.0275,
      "step": 10511
    },
    {
      "epoch": 0.7618219371670834,
      "grad_norm": 0.7140096426010132,
      "learning_rate": 4.7655627219363724e-05,
      "loss": 0.0091,
      "step": 10512
    },
    {
      "epoch": 0.7618944088125521,
      "grad_norm": 1.4014875888824463,
      "learning_rate": 4.764113341546489e-05,
      "loss": 0.0304,
      "step": 10513
    },
    {
      "epoch": 0.7619668804580207,
      "grad_norm": 0.742094874382019,
      "learning_rate": 4.762663961156606e-05,
      "loss": 0.0249,
      "step": 10514
    },
    {
      "epoch": 0.7620393521034895,
      "grad_norm": 1.5838189125061035,
      "learning_rate": 4.761214580766723e-05,
      "loss": 0.0741,
      "step": 10515
    },
    {
      "epoch": 0.7621118237489583,
      "grad_norm": 3.8447742462158203,
      "learning_rate": 4.759765200376839e-05,
      "loss": 0.0375,
      "step": 10516
    },
    {
      "epoch": 0.7621842953944269,
      "grad_norm": 0.7038118839263916,
      "learning_rate": 4.758315819986956e-05,
      "loss": 0.0308,
      "step": 10517
    },
    {
      "epoch": 0.7622567670398956,
      "grad_norm": 0.9270276427268982,
      "learning_rate": 4.7568664395970724e-05,
      "loss": 0.0122,
      "step": 10518
    },
    {
      "epoch": 0.7623292386853644,
      "grad_norm": 5.6134724617004395,
      "learning_rate": 4.755417059207189e-05,
      "loss": 0.1445,
      "step": 10519
    },
    {
      "epoch": 0.762401710330833,
      "grad_norm": 1.349026083946228,
      "learning_rate": 4.753967678817306e-05,
      "loss": 0.0124,
      "step": 10520
    },
    {
      "epoch": 0.7624741819763018,
      "grad_norm": 1.5885100364685059,
      "learning_rate": 4.752518298427423e-05,
      "loss": 0.0655,
      "step": 10521
    },
    {
      "epoch": 0.7625466536217704,
      "grad_norm": 2.3394453525543213,
      "learning_rate": 4.751068918037539e-05,
      "loss": 0.0324,
      "step": 10522
    },
    {
      "epoch": 0.7626191252672392,
      "grad_norm": 0.2901016175746918,
      "learning_rate": 4.749619537647656e-05,
      "loss": 0.0052,
      "step": 10523
    },
    {
      "epoch": 0.7626915969127079,
      "grad_norm": 1.7889684438705444,
      "learning_rate": 4.7481701572577724e-05,
      "loss": 0.0913,
      "step": 10524
    },
    {
      "epoch": 0.7627640685581766,
      "grad_norm": 1.0486114025115967,
      "learning_rate": 4.746720776867889e-05,
      "loss": 0.0792,
      "step": 10525
    },
    {
      "epoch": 0.7628365402036453,
      "grad_norm": 1.998792290687561,
      "learning_rate": 4.745271396478006e-05,
      "loss": 0.0607,
      "step": 10526
    },
    {
      "epoch": 0.7629090118491141,
      "grad_norm": 0.4872451424598694,
      "learning_rate": 4.743822016088123e-05,
      "loss": 0.0271,
      "step": 10527
    },
    {
      "epoch": 0.7629814834945827,
      "grad_norm": 1.2221050262451172,
      "learning_rate": 4.742372635698239e-05,
      "loss": 0.0189,
      "step": 10528
    },
    {
      "epoch": 0.7630539551400515,
      "grad_norm": 0.5929247736930847,
      "learning_rate": 4.740923255308356e-05,
      "loss": 0.0142,
      "step": 10529
    },
    {
      "epoch": 0.7631264267855201,
      "grad_norm": 0.4138524532318115,
      "learning_rate": 4.7394738749184724e-05,
      "loss": 0.008,
      "step": 10530
    },
    {
      "epoch": 0.7631988984309889,
      "grad_norm": 2.6586451530456543,
      "learning_rate": 4.738024494528589e-05,
      "loss": 0.1011,
      "step": 10531
    },
    {
      "epoch": 0.7632713700764576,
      "grad_norm": 0.47835761308670044,
      "learning_rate": 4.736575114138706e-05,
      "loss": 0.0158,
      "step": 10532
    },
    {
      "epoch": 0.7633438417219263,
      "grad_norm": 3.2745306491851807,
      "learning_rate": 4.735125733748823e-05,
      "loss": 0.0924,
      "step": 10533
    },
    {
      "epoch": 0.763416313367395,
      "grad_norm": 0.7802570462226868,
      "learning_rate": 4.73367635335894e-05,
      "loss": 0.0247,
      "step": 10534
    },
    {
      "epoch": 0.7634887850128638,
      "grad_norm": 1.2806986570358276,
      "learning_rate": 4.732226972969056e-05,
      "loss": 0.0478,
      "step": 10535
    },
    {
      "epoch": 0.7635612566583324,
      "grad_norm": 0.47614648938179016,
      "learning_rate": 4.7307775925791724e-05,
      "loss": 0.0049,
      "step": 10536
    },
    {
      "epoch": 0.7636337283038012,
      "grad_norm": 5.2938947677612305,
      "learning_rate": 4.7293282121892894e-05,
      "loss": 0.0989,
      "step": 10537
    },
    {
      "epoch": 0.7637061999492698,
      "grad_norm": 0.1850712150335312,
      "learning_rate": 4.7278788317994064e-05,
      "loss": 0.0042,
      "step": 10538
    },
    {
      "epoch": 0.7637786715947386,
      "grad_norm": 0.6890836358070374,
      "learning_rate": 4.726429451409523e-05,
      "loss": 0.0174,
      "step": 10539
    },
    {
      "epoch": 0.7638511432402073,
      "grad_norm": 0.5050004124641418,
      "learning_rate": 4.72498007101964e-05,
      "loss": 0.0274,
      "step": 10540
    },
    {
      "epoch": 0.763923614885676,
      "grad_norm": 0.40460819005966187,
      "learning_rate": 4.723530690629756e-05,
      "loss": 0.0147,
      "step": 10541
    },
    {
      "epoch": 0.7639960865311447,
      "grad_norm": 0.5390432476997375,
      "learning_rate": 4.7220813102398724e-05,
      "loss": 0.0156,
      "step": 10542
    },
    {
      "epoch": 0.7640685581766135,
      "grad_norm": 0.8917728066444397,
      "learning_rate": 4.7206319298499894e-05,
      "loss": 0.0096,
      "step": 10543
    },
    {
      "epoch": 0.7641410298220821,
      "grad_norm": 3.805358409881592,
      "learning_rate": 4.7191825494601064e-05,
      "loss": 0.086,
      "step": 10544
    },
    {
      "epoch": 0.7642135014675508,
      "grad_norm": 0.847327709197998,
      "learning_rate": 4.717733169070223e-05,
      "loss": 0.0204,
      "step": 10545
    },
    {
      "epoch": 0.7642859731130195,
      "grad_norm": 0.685390293598175,
      "learning_rate": 4.71628378868034e-05,
      "loss": 0.0255,
      "step": 10546
    },
    {
      "epoch": 0.7643584447584882,
      "grad_norm": 0.6633203029632568,
      "learning_rate": 4.714834408290456e-05,
      "loss": 0.015,
      "step": 10547
    },
    {
      "epoch": 0.764430916403957,
      "grad_norm": 2.3696303367614746,
      "learning_rate": 4.7133850279005723e-05,
      "loss": 0.0462,
      "step": 10548
    },
    {
      "epoch": 0.7645033880494256,
      "grad_norm": 0.9855437874794006,
      "learning_rate": 4.7119356475106893e-05,
      "loss": 0.0387,
      "step": 10549
    },
    {
      "epoch": 0.7645758596948944,
      "grad_norm": 0.2361653596162796,
      "learning_rate": 4.7104862671208064e-05,
      "loss": 0.0043,
      "step": 10550
    },
    {
      "epoch": 0.764648331340363,
      "grad_norm": 2.2965378761291504,
      "learning_rate": 4.709036886730923e-05,
      "loss": 0.0901,
      "step": 10551
    },
    {
      "epoch": 0.7647208029858318,
      "grad_norm": 4.584948539733887,
      "learning_rate": 4.70758750634104e-05,
      "loss": 0.0412,
      "step": 10552
    },
    {
      "epoch": 0.7647932746313005,
      "grad_norm": 1.0470921993255615,
      "learning_rate": 4.706138125951156e-05,
      "loss": 0.0323,
      "step": 10553
    },
    {
      "epoch": 0.7648657462767692,
      "grad_norm": 0.9561635255813599,
      "learning_rate": 4.704688745561272e-05,
      "loss": 0.0138,
      "step": 10554
    },
    {
      "epoch": 0.7649382179222379,
      "grad_norm": 2.2006139755249023,
      "learning_rate": 4.703239365171389e-05,
      "loss": 0.1223,
      "step": 10555
    },
    {
      "epoch": 0.7650106895677067,
      "grad_norm": 3.364001750946045,
      "learning_rate": 4.7017899847815063e-05,
      "loss": 0.0815,
      "step": 10556
    },
    {
      "epoch": 0.7650831612131753,
      "grad_norm": 5.102744102478027,
      "learning_rate": 4.700340604391623e-05,
      "loss": 0.1533,
      "step": 10557
    },
    {
      "epoch": 0.7651556328586441,
      "grad_norm": 2.191318988800049,
      "learning_rate": 4.69889122400174e-05,
      "loss": 0.0319,
      "step": 10558
    },
    {
      "epoch": 0.7652281045041127,
      "grad_norm": 1.87980055809021,
      "learning_rate": 4.697441843611856e-05,
      "loss": 0.0585,
      "step": 10559
    },
    {
      "epoch": 0.7653005761495815,
      "grad_norm": 2.2362587451934814,
      "learning_rate": 4.695992463221972e-05,
      "loss": 0.0116,
      "step": 10560
    },
    {
      "epoch": 0.7653730477950502,
      "grad_norm": 0.36213356256484985,
      "learning_rate": 4.694543082832089e-05,
      "loss": 0.008,
      "step": 10561
    },
    {
      "epoch": 0.7654455194405189,
      "grad_norm": 0.571436882019043,
      "learning_rate": 4.693093702442206e-05,
      "loss": 0.0039,
      "step": 10562
    },
    {
      "epoch": 0.7655179910859876,
      "grad_norm": 1.0845091342926025,
      "learning_rate": 4.6916443220523227e-05,
      "loss": 0.0389,
      "step": 10563
    },
    {
      "epoch": 0.7655904627314564,
      "grad_norm": 1.3926520347595215,
      "learning_rate": 4.69019494166244e-05,
      "loss": 0.0524,
      "step": 10564
    },
    {
      "epoch": 0.765662934376925,
      "grad_norm": 0.7863327264785767,
      "learning_rate": 4.688745561272556e-05,
      "loss": 0.0184,
      "step": 10565
    },
    {
      "epoch": 0.7657354060223938,
      "grad_norm": 7.238831520080566,
      "learning_rate": 4.687296180882672e-05,
      "loss": 0.124,
      "step": 10566
    },
    {
      "epoch": 0.7658078776678624,
      "grad_norm": 1.389332890510559,
      "learning_rate": 4.68584680049279e-05,
      "loss": 0.0836,
      "step": 10567
    },
    {
      "epoch": 0.7658803493133312,
      "grad_norm": 0.8321225643157959,
      "learning_rate": 4.684397420102906e-05,
      "loss": 0.0427,
      "step": 10568
    },
    {
      "epoch": 0.7659528209587999,
      "grad_norm": 0.9573394656181335,
      "learning_rate": 4.6829480397130226e-05,
      "loss": 0.0296,
      "step": 10569
    },
    {
      "epoch": 0.7660252926042685,
      "grad_norm": 1.4621316194534302,
      "learning_rate": 4.6814986593231397e-05,
      "loss": 0.0394,
      "step": 10570
    },
    {
      "epoch": 0.7660977642497373,
      "grad_norm": 0.6825284957885742,
      "learning_rate": 4.680049278933256e-05,
      "loss": 0.0243,
      "step": 10571
    },
    {
      "epoch": 0.766170235895206,
      "grad_norm": 0.8073770999908447,
      "learning_rate": 4.678599898543373e-05,
      "loss": 0.0396,
      "step": 10572
    },
    {
      "epoch": 0.7662427075406747,
      "grad_norm": 1.8300968408584595,
      "learning_rate": 4.67715051815349e-05,
      "loss": 0.0407,
      "step": 10573
    },
    {
      "epoch": 0.7663151791861434,
      "grad_norm": 0.4748651385307312,
      "learning_rate": 4.675701137763606e-05,
      "loss": 0.0089,
      "step": 10574
    },
    {
      "epoch": 0.7663876508316121,
      "grad_norm": 2.3200135231018066,
      "learning_rate": 4.674251757373723e-05,
      "loss": 0.0912,
      "step": 10575
    },
    {
      "epoch": 0.7664601224770808,
      "grad_norm": 1.5358680486679077,
      "learning_rate": 4.6728023769838396e-05,
      "loss": 0.0847,
      "step": 10576
    },
    {
      "epoch": 0.7665325941225496,
      "grad_norm": 0.18761074542999268,
      "learning_rate": 4.671352996593956e-05,
      "loss": 0.0069,
      "step": 10577
    },
    {
      "epoch": 0.7666050657680182,
      "grad_norm": 2.5637240409851074,
      "learning_rate": 4.669903616204073e-05,
      "loss": 0.0864,
      "step": 10578
    },
    {
      "epoch": 0.766677537413487,
      "grad_norm": 2.8001599311828613,
      "learning_rate": 4.66845423581419e-05,
      "loss": 0.0418,
      "step": 10579
    },
    {
      "epoch": 0.7667500090589556,
      "grad_norm": 0.2180977314710617,
      "learning_rate": 4.667004855424306e-05,
      "loss": 0.0088,
      "step": 10580
    },
    {
      "epoch": 0.7668224807044244,
      "grad_norm": 1.2137506008148193,
      "learning_rate": 4.665555475034423e-05,
      "loss": 0.0489,
      "step": 10581
    },
    {
      "epoch": 0.7668949523498931,
      "grad_norm": 1.5430121421813965,
      "learning_rate": 4.6641060946445396e-05,
      "loss": 0.0629,
      "step": 10582
    },
    {
      "epoch": 0.7669674239953618,
      "grad_norm": 1.856779932975769,
      "learning_rate": 4.662656714254656e-05,
      "loss": 0.0187,
      "step": 10583
    },
    {
      "epoch": 0.7670398956408305,
      "grad_norm": 0.8375179767608643,
      "learning_rate": 4.661207333864773e-05,
      "loss": 0.0247,
      "step": 10584
    },
    {
      "epoch": 0.7671123672862993,
      "grad_norm": 1.3078391551971436,
      "learning_rate": 4.65975795347489e-05,
      "loss": 0.0616,
      "step": 10585
    },
    {
      "epoch": 0.7671848389317679,
      "grad_norm": 1.1543619632720947,
      "learning_rate": 4.658308573085006e-05,
      "loss": 0.0318,
      "step": 10586
    },
    {
      "epoch": 0.7672573105772367,
      "grad_norm": 1.8072205781936646,
      "learning_rate": 4.656859192695123e-05,
      "loss": 0.0641,
      "step": 10587
    },
    {
      "epoch": 0.7673297822227053,
      "grad_norm": 1.6762113571166992,
      "learning_rate": 4.6554098123052396e-05,
      "loss": 0.0368,
      "step": 10588
    },
    {
      "epoch": 0.7674022538681741,
      "grad_norm": 1.4150182008743286,
      "learning_rate": 4.653960431915356e-05,
      "loss": 0.0321,
      "step": 10589
    },
    {
      "epoch": 0.7674747255136428,
      "grad_norm": 0.989577054977417,
      "learning_rate": 4.652511051525473e-05,
      "loss": 0.0431,
      "step": 10590
    },
    {
      "epoch": 0.7675471971591115,
      "grad_norm": 2.597248077392578,
      "learning_rate": 4.65106167113559e-05,
      "loss": 0.0485,
      "step": 10591
    },
    {
      "epoch": 0.7676196688045802,
      "grad_norm": 1.9890670776367188,
      "learning_rate": 4.649612290745706e-05,
      "loss": 0.0383,
      "step": 10592
    },
    {
      "epoch": 0.767692140450049,
      "grad_norm": 1.1296342611312866,
      "learning_rate": 4.648162910355823e-05,
      "loss": 0.0508,
      "step": 10593
    },
    {
      "epoch": 0.7677646120955176,
      "grad_norm": 0.3776575028896332,
      "learning_rate": 4.6467135299659396e-05,
      "loss": 0.0052,
      "step": 10594
    },
    {
      "epoch": 0.7678370837409864,
      "grad_norm": 1.8121616840362549,
      "learning_rate": 4.645264149576056e-05,
      "loss": 0.0227,
      "step": 10595
    },
    {
      "epoch": 0.767909555386455,
      "grad_norm": 2.67268443107605,
      "learning_rate": 4.6438147691861736e-05,
      "loss": 0.1331,
      "step": 10596
    },
    {
      "epoch": 0.7679820270319238,
      "grad_norm": 0.9838842153549194,
      "learning_rate": 4.64236538879629e-05,
      "loss": 0.042,
      "step": 10597
    },
    {
      "epoch": 0.7680544986773925,
      "grad_norm": 5.778489589691162,
      "learning_rate": 4.640916008406406e-05,
      "loss": 0.0764,
      "step": 10598
    },
    {
      "epoch": 0.7681269703228611,
      "grad_norm": 4.485405445098877,
      "learning_rate": 4.639466628016523e-05,
      "loss": 0.0787,
      "step": 10599
    },
    {
      "epoch": 0.7681994419683299,
      "grad_norm": 1.12234365940094,
      "learning_rate": 4.6380172476266396e-05,
      "loss": 0.0454,
      "step": 10600
    },
    {
      "epoch": 0.7682719136137987,
      "grad_norm": 0.7366622090339661,
      "learning_rate": 4.6365678672367566e-05,
      "loss": 0.0541,
      "step": 10601
    },
    {
      "epoch": 0.7683443852592673,
      "grad_norm": 1.2678639888763428,
      "learning_rate": 4.6351184868468736e-05,
      "loss": 0.0255,
      "step": 10602
    },
    {
      "epoch": 0.768416856904736,
      "grad_norm": 0.8692836165428162,
      "learning_rate": 4.63366910645699e-05,
      "loss": 0.0346,
      "step": 10603
    },
    {
      "epoch": 0.7684893285502047,
      "grad_norm": 0.9654651880264282,
      "learning_rate": 4.632219726067106e-05,
      "loss": 0.0409,
      "step": 10604
    },
    {
      "epoch": 0.7685618001956734,
      "grad_norm": 0.6170446872711182,
      "learning_rate": 4.630770345677223e-05,
      "loss": 0.018,
      "step": 10605
    },
    {
      "epoch": 0.7686342718411422,
      "grad_norm": 0.3871231973171234,
      "learning_rate": 4.6293209652873396e-05,
      "loss": 0.0211,
      "step": 10606
    },
    {
      "epoch": 0.7687067434866108,
      "grad_norm": 1.160668969154358,
      "learning_rate": 4.6278715848974566e-05,
      "loss": 0.0529,
      "step": 10607
    },
    {
      "epoch": 0.7687792151320796,
      "grad_norm": 0.3546673059463501,
      "learning_rate": 4.6264222045075736e-05,
      "loss": 0.0179,
      "step": 10608
    },
    {
      "epoch": 0.7688516867775483,
      "grad_norm": 3.121652603149414,
      "learning_rate": 4.62497282411769e-05,
      "loss": 0.0583,
      "step": 10609
    },
    {
      "epoch": 0.768924158423017,
      "grad_norm": 1.2608364820480347,
      "learning_rate": 4.623523443727806e-05,
      "loss": 0.0557,
      "step": 10610
    },
    {
      "epoch": 0.7689966300684857,
      "grad_norm": 1.0118697881698608,
      "learning_rate": 4.622074063337923e-05,
      "loss": 0.0518,
      "step": 10611
    },
    {
      "epoch": 0.7690691017139544,
      "grad_norm": 0.6240416169166565,
      "learning_rate": 4.6206246829480396e-05,
      "loss": 0.0361,
      "step": 10612
    },
    {
      "epoch": 0.7691415733594231,
      "grad_norm": 0.3858949840068817,
      "learning_rate": 4.6191753025581566e-05,
      "loss": 0.014,
      "step": 10613
    },
    {
      "epoch": 0.7692140450048919,
      "grad_norm": 1.7469301223754883,
      "learning_rate": 4.6177259221682736e-05,
      "loss": 0.1475,
      "step": 10614
    },
    {
      "epoch": 0.7692865166503605,
      "grad_norm": 0.35287418961524963,
      "learning_rate": 4.61627654177839e-05,
      "loss": 0.0063,
      "step": 10615
    },
    {
      "epoch": 0.7693589882958293,
      "grad_norm": 2.0099544525146484,
      "learning_rate": 4.614827161388507e-05,
      "loss": 0.0371,
      "step": 10616
    },
    {
      "epoch": 0.7694314599412979,
      "grad_norm": 0.7820583581924438,
      "learning_rate": 4.613377780998623e-05,
      "loss": 0.0506,
      "step": 10617
    },
    {
      "epoch": 0.7695039315867667,
      "grad_norm": 2.1418631076812744,
      "learning_rate": 4.6119284006087396e-05,
      "loss": 0.075,
      "step": 10618
    },
    {
      "epoch": 0.7695764032322354,
      "grad_norm": 0.7969845533370972,
      "learning_rate": 4.610479020218857e-05,
      "loss": 0.0249,
      "step": 10619
    },
    {
      "epoch": 0.7696488748777041,
      "grad_norm": 3.6797637939453125,
      "learning_rate": 4.6090296398289736e-05,
      "loss": 0.1578,
      "step": 10620
    },
    {
      "epoch": 0.7697213465231728,
      "grad_norm": 0.4079303443431854,
      "learning_rate": 4.60758025943909e-05,
      "loss": 0.0184,
      "step": 10621
    },
    {
      "epoch": 0.7697938181686416,
      "grad_norm": 0.8726916909217834,
      "learning_rate": 4.606130879049207e-05,
      "loss": 0.0272,
      "step": 10622
    },
    {
      "epoch": 0.7698662898141102,
      "grad_norm": 1.50711190700531,
      "learning_rate": 4.604681498659323e-05,
      "loss": 0.0315,
      "step": 10623
    },
    {
      "epoch": 0.769938761459579,
      "grad_norm": 0.5487151145935059,
      "learning_rate": 4.6032321182694396e-05,
      "loss": 0.0187,
      "step": 10624
    },
    {
      "epoch": 0.7700112331050476,
      "grad_norm": 0.8696156740188599,
      "learning_rate": 4.601782737879557e-05,
      "loss": 0.0258,
      "step": 10625
    },
    {
      "epoch": 0.7700837047505164,
      "grad_norm": 1.2767860889434814,
      "learning_rate": 4.6003333574896736e-05,
      "loss": 0.0282,
      "step": 10626
    },
    {
      "epoch": 0.7701561763959851,
      "grad_norm": 1.4648865461349487,
      "learning_rate": 4.59888397709979e-05,
      "loss": 0.0419,
      "step": 10627
    },
    {
      "epoch": 0.7702286480414537,
      "grad_norm": 0.1999819427728653,
      "learning_rate": 4.597434596709907e-05,
      "loss": 0.0023,
      "step": 10628
    },
    {
      "epoch": 0.7703011196869225,
      "grad_norm": 0.44601720571517944,
      "learning_rate": 4.595985216320023e-05,
      "loss": 0.0091,
      "step": 10629
    },
    {
      "epoch": 0.7703735913323912,
      "grad_norm": 1.128633737564087,
      "learning_rate": 4.59453583593014e-05,
      "loss": 0.0332,
      "step": 10630
    },
    {
      "epoch": 0.7704460629778599,
      "grad_norm": 0.9777262806892395,
      "learning_rate": 4.593086455540257e-05,
      "loss": 0.0373,
      "step": 10631
    },
    {
      "epoch": 0.7705185346233286,
      "grad_norm": 2.9603493213653564,
      "learning_rate": 4.5916370751503736e-05,
      "loss": 0.096,
      "step": 10632
    },
    {
      "epoch": 0.7705910062687973,
      "grad_norm": 1.9629828929901123,
      "learning_rate": 4.59018769476049e-05,
      "loss": 0.0258,
      "step": 10633
    },
    {
      "epoch": 0.770663477914266,
      "grad_norm": 2.181386947631836,
      "learning_rate": 4.588738314370607e-05,
      "loss": 0.0628,
      "step": 10634
    },
    {
      "epoch": 0.7707359495597348,
      "grad_norm": 1.9357433319091797,
      "learning_rate": 4.587288933980723e-05,
      "loss": 0.0255,
      "step": 10635
    },
    {
      "epoch": 0.7708084212052034,
      "grad_norm": 1.1725636720657349,
      "learning_rate": 4.58583955359084e-05,
      "loss": 0.0166,
      "step": 10636
    },
    {
      "epoch": 0.7708808928506722,
      "grad_norm": 1.8248690366744995,
      "learning_rate": 4.584390173200957e-05,
      "loss": 0.0349,
      "step": 10637
    },
    {
      "epoch": 0.7709533644961409,
      "grad_norm": 1.7070748805999756,
      "learning_rate": 4.5829407928110735e-05,
      "loss": 0.0555,
      "step": 10638
    },
    {
      "epoch": 0.7710258361416096,
      "grad_norm": 2.429015874862671,
      "learning_rate": 4.58149141242119e-05,
      "loss": 0.0563,
      "step": 10639
    },
    {
      "epoch": 0.7710983077870783,
      "grad_norm": 0.5620561242103577,
      "learning_rate": 4.580042032031307e-05,
      "loss": 0.0099,
      "step": 10640
    },
    {
      "epoch": 0.771170779432547,
      "grad_norm": 1.4056929349899292,
      "learning_rate": 4.578592651641423e-05,
      "loss": 0.0354,
      "step": 10641
    },
    {
      "epoch": 0.7712432510780157,
      "grad_norm": 0.4501800537109375,
      "learning_rate": 4.57714327125154e-05,
      "loss": 0.0225,
      "step": 10642
    },
    {
      "epoch": 0.7713157227234845,
      "grad_norm": 2.849365472793579,
      "learning_rate": 4.575693890861657e-05,
      "loss": 0.0342,
      "step": 10643
    },
    {
      "epoch": 0.7713881943689531,
      "grad_norm": 1.4207251071929932,
      "learning_rate": 4.5742445104717735e-05,
      "loss": 0.0438,
      "step": 10644
    },
    {
      "epoch": 0.7714606660144219,
      "grad_norm": 3.1403839588165283,
      "learning_rate": 4.57279513008189e-05,
      "loss": 0.0573,
      "step": 10645
    },
    {
      "epoch": 0.7715331376598906,
      "grad_norm": 1.7192693948745728,
      "learning_rate": 4.571345749692007e-05,
      "loss": 0.0412,
      "step": 10646
    },
    {
      "epoch": 0.7716056093053593,
      "grad_norm": 0.17962786555290222,
      "learning_rate": 4.569896369302123e-05,
      "loss": 0.009,
      "step": 10647
    },
    {
      "epoch": 0.771678080950828,
      "grad_norm": 0.45953235030174255,
      "learning_rate": 4.56844698891224e-05,
      "loss": 0.0278,
      "step": 10648
    },
    {
      "epoch": 0.7717505525962967,
      "grad_norm": 0.6829795837402344,
      "learning_rate": 4.566997608522357e-05,
      "loss": 0.0312,
      "step": 10649
    },
    {
      "epoch": 0.7718230242417654,
      "grad_norm": 1.0445233583450317,
      "learning_rate": 4.5655482281324735e-05,
      "loss": 0.0236,
      "step": 10650
    },
    {
      "epoch": 0.7718954958872342,
      "grad_norm": 0.6105993986129761,
      "learning_rate": 4.56409884774259e-05,
      "loss": 0.0132,
      "step": 10651
    },
    {
      "epoch": 0.7719679675327028,
      "grad_norm": 1.0110396146774292,
      "learning_rate": 4.562649467352707e-05,
      "loss": 0.0504,
      "step": 10652
    },
    {
      "epoch": 0.7720404391781716,
      "grad_norm": 2.3556816577911377,
      "learning_rate": 4.561200086962824e-05,
      "loss": 0.1085,
      "step": 10653
    },
    {
      "epoch": 0.7721129108236402,
      "grad_norm": 0.6331175565719604,
      "learning_rate": 4.55975070657294e-05,
      "loss": 0.026,
      "step": 10654
    },
    {
      "epoch": 0.772185382469109,
      "grad_norm": 1.0290615558624268,
      "learning_rate": 4.558301326183057e-05,
      "loss": 0.0229,
      "step": 10655
    },
    {
      "epoch": 0.7722578541145777,
      "grad_norm": 2.177180290222168,
      "learning_rate": 4.5568519457931735e-05,
      "loss": 0.0277,
      "step": 10656
    },
    {
      "epoch": 0.7723303257600463,
      "grad_norm": 1.5949573516845703,
      "learning_rate": 4.5554025654032905e-05,
      "loss": 0.0426,
      "step": 10657
    },
    {
      "epoch": 0.7724027974055151,
      "grad_norm": 0.2774994373321533,
      "learning_rate": 4.553953185013407e-05,
      "loss": 0.0027,
      "step": 10658
    },
    {
      "epoch": 0.7724752690509838,
      "grad_norm": 2.218684673309326,
      "learning_rate": 4.552503804623524e-05,
      "loss": 0.0685,
      "step": 10659
    },
    {
      "epoch": 0.7725477406964525,
      "grad_norm": 1.46061372756958,
      "learning_rate": 4.551054424233641e-05,
      "loss": 0.0564,
      "step": 10660
    },
    {
      "epoch": 0.7726202123419212,
      "grad_norm": 2.0400800704956055,
      "learning_rate": 4.549605043843757e-05,
      "loss": 0.1013,
      "step": 10661
    },
    {
      "epoch": 0.7726926839873899,
      "grad_norm": 1.8029916286468506,
      "learning_rate": 4.5481556634538735e-05,
      "loss": 0.0479,
      "step": 10662
    },
    {
      "epoch": 0.7727651556328586,
      "grad_norm": 1.359657883644104,
      "learning_rate": 4.5467062830639905e-05,
      "loss": 0.0509,
      "step": 10663
    },
    {
      "epoch": 0.7728376272783274,
      "grad_norm": 3.4464426040649414,
      "learning_rate": 4.545256902674107e-05,
      "loss": 0.1353,
      "step": 10664
    },
    {
      "epoch": 0.772910098923796,
      "grad_norm": 2.2835545539855957,
      "learning_rate": 4.543807522284224e-05,
      "loss": 0.0312,
      "step": 10665
    },
    {
      "epoch": 0.7729825705692648,
      "grad_norm": 0.6500076055526733,
      "learning_rate": 4.542358141894341e-05,
      "loss": 0.0261,
      "step": 10666
    },
    {
      "epoch": 0.7730550422147335,
      "grad_norm": 1.796079158782959,
      "learning_rate": 4.540908761504457e-05,
      "loss": 0.092,
      "step": 10667
    },
    {
      "epoch": 0.7731275138602022,
      "grad_norm": 0.028295369818806648,
      "learning_rate": 4.5394593811145735e-05,
      "loss": 0.0004,
      "step": 10668
    },
    {
      "epoch": 0.7731999855056709,
      "grad_norm": 0.4376315772533417,
      "learning_rate": 4.5380100007246905e-05,
      "loss": 0.009,
      "step": 10669
    },
    {
      "epoch": 0.7732724571511396,
      "grad_norm": 1.9225422143936157,
      "learning_rate": 4.536560620334807e-05,
      "loss": 0.0545,
      "step": 10670
    },
    {
      "epoch": 0.7733449287966083,
      "grad_norm": 0.4697006046772003,
      "learning_rate": 4.535111239944924e-05,
      "loss": 0.0126,
      "step": 10671
    },
    {
      "epoch": 0.7734174004420771,
      "grad_norm": 2.2652792930603027,
      "learning_rate": 4.533661859555041e-05,
      "loss": 0.0562,
      "step": 10672
    },
    {
      "epoch": 0.7734898720875457,
      "grad_norm": 1.9953539371490479,
      "learning_rate": 4.532212479165157e-05,
      "loss": 0.1188,
      "step": 10673
    },
    {
      "epoch": 0.7735623437330145,
      "grad_norm": 3.174788475036621,
      "learning_rate": 4.5307630987752735e-05,
      "loss": 0.0796,
      "step": 10674
    },
    {
      "epoch": 0.7736348153784832,
      "grad_norm": 3.084379196166992,
      "learning_rate": 4.5293137183853905e-05,
      "loss": 0.1448,
      "step": 10675
    },
    {
      "epoch": 0.7737072870239519,
      "grad_norm": 1.2112070322036743,
      "learning_rate": 4.527864337995507e-05,
      "loss": 0.0513,
      "step": 10676
    },
    {
      "epoch": 0.7737797586694206,
      "grad_norm": 1.9460484981536865,
      "learning_rate": 4.526414957605624e-05,
      "loss": 0.0437,
      "step": 10677
    },
    {
      "epoch": 0.7738522303148893,
      "grad_norm": 1.0051136016845703,
      "learning_rate": 4.524965577215741e-05,
      "loss": 0.0465,
      "step": 10678
    },
    {
      "epoch": 0.773924701960358,
      "grad_norm": 1.516309380531311,
      "learning_rate": 4.523516196825857e-05,
      "loss": 0.0457,
      "step": 10679
    },
    {
      "epoch": 0.7739971736058268,
      "grad_norm": 1.4785192012786865,
      "learning_rate": 4.5220668164359735e-05,
      "loss": 0.0857,
      "step": 10680
    },
    {
      "epoch": 0.7740696452512954,
      "grad_norm": 0.25457432866096497,
      "learning_rate": 4.5206174360460905e-05,
      "loss": 0.0047,
      "step": 10681
    },
    {
      "epoch": 0.7741421168967642,
      "grad_norm": 0.6451591849327087,
      "learning_rate": 4.5191680556562075e-05,
      "loss": 0.0046,
      "step": 10682
    },
    {
      "epoch": 0.7742145885422329,
      "grad_norm": 2.330387592315674,
      "learning_rate": 4.517718675266324e-05,
      "loss": 0.1497,
      "step": 10683
    },
    {
      "epoch": 0.7742870601877015,
      "grad_norm": 0.7671411037445068,
      "learning_rate": 4.516269294876441e-05,
      "loss": 0.0283,
      "step": 10684
    },
    {
      "epoch": 0.7743595318331703,
      "grad_norm": 2.044034719467163,
      "learning_rate": 4.514819914486557e-05,
      "loss": 0.0634,
      "step": 10685
    },
    {
      "epoch": 0.7744320034786389,
      "grad_norm": 1.8930261135101318,
      "learning_rate": 4.5133705340966735e-05,
      "loss": 0.0483,
      "step": 10686
    },
    {
      "epoch": 0.7745044751241077,
      "grad_norm": 0.6854354739189148,
      "learning_rate": 4.5119211537067905e-05,
      "loss": 0.0103,
      "step": 10687
    },
    {
      "epoch": 0.7745769467695764,
      "grad_norm": 3.1598057746887207,
      "learning_rate": 4.5104717733169075e-05,
      "loss": 0.1026,
      "step": 10688
    },
    {
      "epoch": 0.7746494184150451,
      "grad_norm": 2.6724507808685303,
      "learning_rate": 4.509022392927024e-05,
      "loss": 0.0688,
      "step": 10689
    },
    {
      "epoch": 0.7747218900605138,
      "grad_norm": 1.761681079864502,
      "learning_rate": 4.507573012537141e-05,
      "loss": 0.0353,
      "step": 10690
    },
    {
      "epoch": 0.7747943617059825,
      "grad_norm": 1.5858910083770752,
      "learning_rate": 4.506123632147257e-05,
      "loss": 0.0775,
      "step": 10691
    },
    {
      "epoch": 0.7748668333514512,
      "grad_norm": 2.991288661956787,
      "learning_rate": 4.5046742517573735e-05,
      "loss": 0.0735,
      "step": 10692
    },
    {
      "epoch": 0.77493930499692,
      "grad_norm": 4.690531253814697,
      "learning_rate": 4.5032248713674905e-05,
      "loss": 0.0632,
      "step": 10693
    },
    {
      "epoch": 0.7750117766423886,
      "grad_norm": 0.06909414380788803,
      "learning_rate": 4.5017754909776075e-05,
      "loss": 0.0008,
      "step": 10694
    },
    {
      "epoch": 0.7750842482878574,
      "grad_norm": 0.2934180200099945,
      "learning_rate": 4.500326110587724e-05,
      "loss": 0.0066,
      "step": 10695
    },
    {
      "epoch": 0.7751567199333261,
      "grad_norm": 1.747881531715393,
      "learning_rate": 4.498876730197841e-05,
      "loss": 0.0516,
      "step": 10696
    },
    {
      "epoch": 0.7752291915787948,
      "grad_norm": 0.7407497763633728,
      "learning_rate": 4.497427349807957e-05,
      "loss": 0.0276,
      "step": 10697
    },
    {
      "epoch": 0.7753016632242635,
      "grad_norm": 1.4756932258605957,
      "learning_rate": 4.495977969418074e-05,
      "loss": 0.0427,
      "step": 10698
    },
    {
      "epoch": 0.7753741348697322,
      "grad_norm": 0.7462238073348999,
      "learning_rate": 4.4945285890281904e-05,
      "loss": 0.0262,
      "step": 10699
    },
    {
      "epoch": 0.7754466065152009,
      "grad_norm": 0.8661312460899353,
      "learning_rate": 4.4930792086383075e-05,
      "loss": 0.0194,
      "step": 10700
    },
    {
      "epoch": 0.7755190781606697,
      "grad_norm": 1.48896324634552,
      "learning_rate": 4.4916298282484245e-05,
      "loss": 0.0507,
      "step": 10701
    },
    {
      "epoch": 0.7755915498061383,
      "grad_norm": 0.3362356126308441,
      "learning_rate": 4.490180447858541e-05,
      "loss": 0.0029,
      "step": 10702
    },
    {
      "epoch": 0.7756640214516071,
      "grad_norm": 1.8011473417282104,
      "learning_rate": 4.488731067468657e-05,
      "loss": 0.0603,
      "step": 10703
    },
    {
      "epoch": 0.7757364930970758,
      "grad_norm": 0.17609478533267975,
      "learning_rate": 4.487281687078774e-05,
      "loss": 0.0034,
      "step": 10704
    },
    {
      "epoch": 0.7758089647425445,
      "grad_norm": 0.10727435350418091,
      "learning_rate": 4.4858323066888904e-05,
      "loss": 0.0061,
      "step": 10705
    },
    {
      "epoch": 0.7758814363880132,
      "grad_norm": 1.7746319770812988,
      "learning_rate": 4.4843829262990074e-05,
      "loss": 0.0748,
      "step": 10706
    },
    {
      "epoch": 0.7759539080334819,
      "grad_norm": 3.7524657249450684,
      "learning_rate": 4.4829335459091244e-05,
      "loss": 0.0821,
      "step": 10707
    },
    {
      "epoch": 0.7760263796789506,
      "grad_norm": 1.767529010772705,
      "learning_rate": 4.481484165519241e-05,
      "loss": 0.0369,
      "step": 10708
    },
    {
      "epoch": 0.7760988513244194,
      "grad_norm": 1.243857741355896,
      "learning_rate": 4.480034785129357e-05,
      "loss": 0.023,
      "step": 10709
    },
    {
      "epoch": 0.776171322969888,
      "grad_norm": 1.333282232284546,
      "learning_rate": 4.478585404739474e-05,
      "loss": 0.055,
      "step": 10710
    },
    {
      "epoch": 0.7762437946153568,
      "grad_norm": 0.6105594038963318,
      "learning_rate": 4.477136024349591e-05,
      "loss": 0.0094,
      "step": 10711
    },
    {
      "epoch": 0.7763162662608255,
      "grad_norm": 0.6512668132781982,
      "learning_rate": 4.4756866439597074e-05,
      "loss": 0.0141,
      "step": 10712
    },
    {
      "epoch": 0.7763887379062941,
      "grad_norm": 0.2834913730621338,
      "learning_rate": 4.4742372635698244e-05,
      "loss": 0.0098,
      "step": 10713
    },
    {
      "epoch": 0.7764612095517629,
      "grad_norm": 1.847732424736023,
      "learning_rate": 4.472787883179941e-05,
      "loss": 0.0607,
      "step": 10714
    },
    {
      "epoch": 0.7765336811972315,
      "grad_norm": 0.9896109700202942,
      "learning_rate": 4.471338502790057e-05,
      "loss": 0.068,
      "step": 10715
    },
    {
      "epoch": 0.7766061528427003,
      "grad_norm": 0.48155128955841064,
      "learning_rate": 4.469889122400174e-05,
      "loss": 0.0123,
      "step": 10716
    },
    {
      "epoch": 0.776678624488169,
      "grad_norm": 0.733788013458252,
      "learning_rate": 4.468439742010291e-05,
      "loss": 0.0313,
      "step": 10717
    },
    {
      "epoch": 0.7767510961336377,
      "grad_norm": 0.21250392496585846,
      "learning_rate": 4.4669903616204074e-05,
      "loss": 0.0033,
      "step": 10718
    },
    {
      "epoch": 0.7768235677791064,
      "grad_norm": 1.636465311050415,
      "learning_rate": 4.4655409812305244e-05,
      "loss": 0.054,
      "step": 10719
    },
    {
      "epoch": 0.7768960394245751,
      "grad_norm": 0.2424057573080063,
      "learning_rate": 4.464091600840641e-05,
      "loss": 0.0042,
      "step": 10720
    },
    {
      "epoch": 0.7769685110700438,
      "grad_norm": 2.446354389190674,
      "learning_rate": 4.462642220450757e-05,
      "loss": 0.0737,
      "step": 10721
    },
    {
      "epoch": 0.7770409827155126,
      "grad_norm": 0.9109238386154175,
      "learning_rate": 4.461192840060874e-05,
      "loss": 0.0181,
      "step": 10722
    },
    {
      "epoch": 0.7771134543609812,
      "grad_norm": 1.2138795852661133,
      "learning_rate": 4.459743459670991e-05,
      "loss": 0.0288,
      "step": 10723
    },
    {
      "epoch": 0.77718592600645,
      "grad_norm": 1.033433437347412,
      "learning_rate": 4.4582940792811074e-05,
      "loss": 0.0219,
      "step": 10724
    },
    {
      "epoch": 0.7772583976519187,
      "grad_norm": 0.6837679147720337,
      "learning_rate": 4.4568446988912244e-05,
      "loss": 0.0125,
      "step": 10725
    },
    {
      "epoch": 0.7773308692973874,
      "grad_norm": 0.38971540331840515,
      "learning_rate": 4.455395318501341e-05,
      "loss": 0.0127,
      "step": 10726
    },
    {
      "epoch": 0.7774033409428561,
      "grad_norm": 1.4919970035552979,
      "learning_rate": 4.453945938111457e-05,
      "loss": 0.0805,
      "step": 10727
    },
    {
      "epoch": 0.7774758125883248,
      "grad_norm": 1.2894465923309326,
      "learning_rate": 4.452496557721574e-05,
      "loss": 0.0791,
      "step": 10728
    },
    {
      "epoch": 0.7775482842337935,
      "grad_norm": 0.4655725955963135,
      "learning_rate": 4.451047177331691e-05,
      "loss": 0.0236,
      "step": 10729
    },
    {
      "epoch": 0.7776207558792623,
      "grad_norm": 1.8516075611114502,
      "learning_rate": 4.4495977969418074e-05,
      "loss": 0.0641,
      "step": 10730
    },
    {
      "epoch": 0.7776932275247309,
      "grad_norm": 0.34018197655677795,
      "learning_rate": 4.4481484165519244e-05,
      "loss": 0.005,
      "step": 10731
    },
    {
      "epoch": 0.7777656991701997,
      "grad_norm": 0.09372701495885849,
      "learning_rate": 4.446699036162041e-05,
      "loss": 0.0021,
      "step": 10732
    },
    {
      "epoch": 0.7778381708156684,
      "grad_norm": 3.2204341888427734,
      "learning_rate": 4.445249655772157e-05,
      "loss": 0.049,
      "step": 10733
    },
    {
      "epoch": 0.7779106424611371,
      "grad_norm": 1.7295078039169312,
      "learning_rate": 4.443800275382274e-05,
      "loss": 0.0459,
      "step": 10734
    },
    {
      "epoch": 0.7779831141066058,
      "grad_norm": 1.0707168579101562,
      "learning_rate": 4.442350894992391e-05,
      "loss": 0.0273,
      "step": 10735
    },
    {
      "epoch": 0.7780555857520745,
      "grad_norm": 2.433123826980591,
      "learning_rate": 4.440901514602508e-05,
      "loss": 0.0517,
      "step": 10736
    },
    {
      "epoch": 0.7781280573975432,
      "grad_norm": 1.2691562175750732,
      "learning_rate": 4.4394521342126244e-05,
      "loss": 0.0765,
      "step": 10737
    },
    {
      "epoch": 0.778200529043012,
      "grad_norm": 1.7380386590957642,
      "learning_rate": 4.438002753822741e-05,
      "loss": 0.0669,
      "step": 10738
    },
    {
      "epoch": 0.7782730006884806,
      "grad_norm": 1.1987987756729126,
      "learning_rate": 4.436553373432858e-05,
      "loss": 0.0284,
      "step": 10739
    },
    {
      "epoch": 0.7783454723339494,
      "grad_norm": 1.536526083946228,
      "learning_rate": 4.435103993042975e-05,
      "loss": 0.067,
      "step": 10740
    },
    {
      "epoch": 0.7784179439794181,
      "grad_norm": 0.2504134178161621,
      "learning_rate": 4.433654612653091e-05,
      "loss": 0.0032,
      "step": 10741
    },
    {
      "epoch": 0.7784904156248867,
      "grad_norm": 6.938669681549072,
      "learning_rate": 4.432205232263208e-05,
      "loss": 0.0342,
      "step": 10742
    },
    {
      "epoch": 0.7785628872703555,
      "grad_norm": 3.3097293376922607,
      "learning_rate": 4.4307558518733244e-05,
      "loss": 0.0666,
      "step": 10743
    },
    {
      "epoch": 0.7786353589158241,
      "grad_norm": 0.45286840200424194,
      "learning_rate": 4.429306471483441e-05,
      "loss": 0.0074,
      "step": 10744
    },
    {
      "epoch": 0.7787078305612929,
      "grad_norm": 2.475026845932007,
      "learning_rate": 4.427857091093558e-05,
      "loss": 0.0563,
      "step": 10745
    },
    {
      "epoch": 0.7787803022067616,
      "grad_norm": 0.24256032705307007,
      "learning_rate": 4.426407710703675e-05,
      "loss": 0.0065,
      "step": 10746
    },
    {
      "epoch": 0.7788527738522303,
      "grad_norm": 1.4811078310012817,
      "learning_rate": 4.424958330313791e-05,
      "loss": 0.1241,
      "step": 10747
    },
    {
      "epoch": 0.778925245497699,
      "grad_norm": 0.3524971008300781,
      "learning_rate": 4.423508949923908e-05,
      "loss": 0.0067,
      "step": 10748
    },
    {
      "epoch": 0.7789977171431678,
      "grad_norm": 2.5197088718414307,
      "learning_rate": 4.4220595695340244e-05,
      "loss": 0.0844,
      "step": 10749
    },
    {
      "epoch": 0.7790701887886364,
      "grad_norm": 2.09553861618042,
      "learning_rate": 4.420610189144141e-05,
      "loss": 0.1091,
      "step": 10750
    },
    {
      "epoch": 0.7791426604341052,
      "grad_norm": 0.8432976603507996,
      "learning_rate": 4.419160808754258e-05,
      "loss": 0.0214,
      "step": 10751
    },
    {
      "epoch": 0.7792151320795738,
      "grad_norm": 1.3137977123260498,
      "learning_rate": 4.417711428364375e-05,
      "loss": 0.0176,
      "step": 10752
    },
    {
      "epoch": 0.7792876037250426,
      "grad_norm": 2.856462240219116,
      "learning_rate": 4.416262047974491e-05,
      "loss": 0.0896,
      "step": 10753
    },
    {
      "epoch": 0.7793600753705113,
      "grad_norm": 0.04848224297165871,
      "learning_rate": 4.414812667584608e-05,
      "loss": 0.0005,
      "step": 10754
    },
    {
      "epoch": 0.77943254701598,
      "grad_norm": 1.4755419492721558,
      "learning_rate": 4.4133632871947244e-05,
      "loss": 0.0351,
      "step": 10755
    },
    {
      "epoch": 0.7795050186614487,
      "grad_norm": 0.14928531646728516,
      "learning_rate": 4.411913906804841e-05,
      "loss": 0.0031,
      "step": 10756
    },
    {
      "epoch": 0.7795774903069174,
      "grad_norm": 1.3437014818191528,
      "learning_rate": 4.410464526414958e-05,
      "loss": 0.0233,
      "step": 10757
    },
    {
      "epoch": 0.7796499619523861,
      "grad_norm": 3.431288003921509,
      "learning_rate": 4.409015146025075e-05,
      "loss": 0.0848,
      "step": 10758
    },
    {
      "epoch": 0.7797224335978549,
      "grad_norm": 3.1517446041107178,
      "learning_rate": 4.407565765635191e-05,
      "loss": 0.1416,
      "step": 10759
    },
    {
      "epoch": 0.7797949052433235,
      "grad_norm": 0.9712933897972107,
      "learning_rate": 4.406116385245308e-05,
      "loss": 0.0348,
      "step": 10760
    },
    {
      "epoch": 0.7798673768887923,
      "grad_norm": 1.5374815464019775,
      "learning_rate": 4.4046670048554244e-05,
      "loss": 0.0611,
      "step": 10761
    },
    {
      "epoch": 0.779939848534261,
      "grad_norm": 3.2943637371063232,
      "learning_rate": 4.403217624465541e-05,
      "loss": 0.055,
      "step": 10762
    },
    {
      "epoch": 0.7800123201797297,
      "grad_norm": 0.13295391201972961,
      "learning_rate": 4.401768244075658e-05,
      "loss": 0.0033,
      "step": 10763
    },
    {
      "epoch": 0.7800847918251984,
      "grad_norm": 1.4530149698257446,
      "learning_rate": 4.400318863685775e-05,
      "loss": 0.0588,
      "step": 10764
    },
    {
      "epoch": 0.780157263470667,
      "grad_norm": 1.7009764909744263,
      "learning_rate": 4.398869483295891e-05,
      "loss": 0.0462,
      "step": 10765
    },
    {
      "epoch": 0.7802297351161358,
      "grad_norm": 4.823698997497559,
      "learning_rate": 4.397420102906008e-05,
      "loss": 0.1596,
      "step": 10766
    },
    {
      "epoch": 0.7803022067616046,
      "grad_norm": 0.2995852530002594,
      "learning_rate": 4.3959707225161243e-05,
      "loss": 0.0044,
      "step": 10767
    },
    {
      "epoch": 0.7803746784070732,
      "grad_norm": 1.7817943096160889,
      "learning_rate": 4.394521342126241e-05,
      "loss": 0.0173,
      "step": 10768
    },
    {
      "epoch": 0.780447150052542,
      "grad_norm": 1.15789794921875,
      "learning_rate": 4.3930719617363584e-05,
      "loss": 0.0465,
      "step": 10769
    },
    {
      "epoch": 0.7805196216980107,
      "grad_norm": 1.2093048095703125,
      "learning_rate": 4.391622581346475e-05,
      "loss": 0.0581,
      "step": 10770
    },
    {
      "epoch": 0.7805920933434793,
      "grad_norm": 1.4695875644683838,
      "learning_rate": 4.390173200956591e-05,
      "loss": 0.0665,
      "step": 10771
    },
    {
      "epoch": 0.7806645649889481,
      "grad_norm": 1.4807225465774536,
      "learning_rate": 4.388723820566708e-05,
      "loss": 0.0675,
      "step": 10772
    },
    {
      "epoch": 0.7807370366344167,
      "grad_norm": 1.5816214084625244,
      "learning_rate": 4.387274440176824e-05,
      "loss": 0.0372,
      "step": 10773
    },
    {
      "epoch": 0.7808095082798855,
      "grad_norm": 1.6704729795455933,
      "learning_rate": 4.385825059786941e-05,
      "loss": 0.0511,
      "step": 10774
    },
    {
      "epoch": 0.7808819799253542,
      "grad_norm": 1.1894609928131104,
      "learning_rate": 4.3843756793970583e-05,
      "loss": 0.0346,
      "step": 10775
    },
    {
      "epoch": 0.7809544515708229,
      "grad_norm": 1.2278555631637573,
      "learning_rate": 4.382926299007175e-05,
      "loss": 0.0563,
      "step": 10776
    },
    {
      "epoch": 0.7810269232162916,
      "grad_norm": 0.5501187443733215,
      "learning_rate": 4.381476918617292e-05,
      "loss": 0.0226,
      "step": 10777
    },
    {
      "epoch": 0.7810993948617604,
      "grad_norm": 1.5097243785858154,
      "learning_rate": 4.380027538227408e-05,
      "loss": 0.045,
      "step": 10778
    },
    {
      "epoch": 0.781171866507229,
      "grad_norm": 2.6643612384796143,
      "learning_rate": 4.378578157837524e-05,
      "loss": 0.1229,
      "step": 10779
    },
    {
      "epoch": 0.7812443381526978,
      "grad_norm": 0.19267937541007996,
      "learning_rate": 4.377128777447641e-05,
      "loss": 0.0033,
      "step": 10780
    },
    {
      "epoch": 0.7813168097981664,
      "grad_norm": 0.10805052518844604,
      "learning_rate": 4.375679397057758e-05,
      "loss": 0.0019,
      "step": 10781
    },
    {
      "epoch": 0.7813892814436352,
      "grad_norm": 2.022554874420166,
      "learning_rate": 4.3742300166678747e-05,
      "loss": 0.097,
      "step": 10782
    },
    {
      "epoch": 0.7814617530891039,
      "grad_norm": 1.205716848373413,
      "learning_rate": 4.3727806362779917e-05,
      "loss": 0.0606,
      "step": 10783
    },
    {
      "epoch": 0.7815342247345726,
      "grad_norm": 0.29739415645599365,
      "learning_rate": 4.371331255888108e-05,
      "loss": 0.0122,
      "step": 10784
    },
    {
      "epoch": 0.7816066963800413,
      "grad_norm": 1.6121587753295898,
      "learning_rate": 4.369881875498224e-05,
      "loss": 0.058,
      "step": 10785
    },
    {
      "epoch": 0.7816791680255101,
      "grad_norm": 2.356872797012329,
      "learning_rate": 4.368432495108341e-05,
      "loss": 0.1174,
      "step": 10786
    },
    {
      "epoch": 0.7817516396709787,
      "grad_norm": 0.8141652941703796,
      "learning_rate": 4.366983114718458e-05,
      "loss": 0.0223,
      "step": 10787
    },
    {
      "epoch": 0.7818241113164475,
      "grad_norm": 7.218217372894287,
      "learning_rate": 4.3655337343285746e-05,
      "loss": 0.0925,
      "step": 10788
    },
    {
      "epoch": 0.7818965829619161,
      "grad_norm": 0.45418861508369446,
      "learning_rate": 4.3640843539386916e-05,
      "loss": 0.0106,
      "step": 10789
    },
    {
      "epoch": 0.7819690546073849,
      "grad_norm": 1.6578211784362793,
      "learning_rate": 4.362634973548808e-05,
      "loss": 0.0268,
      "step": 10790
    },
    {
      "epoch": 0.7820415262528536,
      "grad_norm": 1.4405096769332886,
      "learning_rate": 4.361185593158924e-05,
      "loss": 0.0712,
      "step": 10791
    },
    {
      "epoch": 0.7821139978983223,
      "grad_norm": 0.503524661064148,
      "learning_rate": 4.359736212769042e-05,
      "loss": 0.0247,
      "step": 10792
    },
    {
      "epoch": 0.782186469543791,
      "grad_norm": 1.7417449951171875,
      "learning_rate": 4.358286832379158e-05,
      "loss": 0.0661,
      "step": 10793
    },
    {
      "epoch": 0.7822589411892596,
      "grad_norm": 0.388178288936615,
      "learning_rate": 4.3568374519892746e-05,
      "loss": 0.008,
      "step": 10794
    },
    {
      "epoch": 0.7823314128347284,
      "grad_norm": 0.11007934808731079,
      "learning_rate": 4.3553880715993916e-05,
      "loss": 0.0019,
      "step": 10795
    },
    {
      "epoch": 0.7824038844801972,
      "grad_norm": 0.3478167653083801,
      "learning_rate": 4.353938691209508e-05,
      "loss": 0.011,
      "step": 10796
    },
    {
      "epoch": 0.7824763561256658,
      "grad_norm": 0.5851982831954956,
      "learning_rate": 4.352489310819625e-05,
      "loss": 0.0139,
      "step": 10797
    },
    {
      "epoch": 0.7825488277711345,
      "grad_norm": 3.6495628356933594,
      "learning_rate": 4.351039930429742e-05,
      "loss": 0.0391,
      "step": 10798
    },
    {
      "epoch": 0.7826212994166033,
      "grad_norm": 1.03117036819458,
      "learning_rate": 4.349590550039858e-05,
      "loss": 0.0372,
      "step": 10799
    },
    {
      "epoch": 0.7826937710620719,
      "grad_norm": 0.6583589911460876,
      "learning_rate": 4.3481411696499746e-05,
      "loss": 0.0248,
      "step": 10800
    },
    {
      "epoch": 0.7827662427075407,
      "grad_norm": 2.115274667739868,
      "learning_rate": 4.3466917892600916e-05,
      "loss": 0.1002,
      "step": 10801
    },
    {
      "epoch": 0.7828387143530093,
      "grad_norm": 2.671814203262329,
      "learning_rate": 4.345242408870208e-05,
      "loss": 0.0544,
      "step": 10802
    },
    {
      "epoch": 0.7829111859984781,
      "grad_norm": 2.060889959335327,
      "learning_rate": 4.343793028480325e-05,
      "loss": 0.1251,
      "step": 10803
    },
    {
      "epoch": 0.7829836576439468,
      "grad_norm": 0.9975556135177612,
      "learning_rate": 4.342343648090442e-05,
      "loss": 0.0232,
      "step": 10804
    },
    {
      "epoch": 0.7830561292894155,
      "grad_norm": 0.8780497312545776,
      "learning_rate": 4.340894267700558e-05,
      "loss": 0.0174,
      "step": 10805
    },
    {
      "epoch": 0.7831286009348842,
      "grad_norm": 2.356355667114258,
      "learning_rate": 4.3394448873106746e-05,
      "loss": 0.0697,
      "step": 10806
    },
    {
      "epoch": 0.783201072580353,
      "grad_norm": 0.6500704288482666,
      "learning_rate": 4.3379955069207916e-05,
      "loss": 0.0297,
      "step": 10807
    },
    {
      "epoch": 0.7832735442258216,
      "grad_norm": 0.36035189032554626,
      "learning_rate": 4.336546126530908e-05,
      "loss": 0.0209,
      "step": 10808
    },
    {
      "epoch": 0.7833460158712904,
      "grad_norm": 1.290714144706726,
      "learning_rate": 4.335096746141025e-05,
      "loss": 0.0437,
      "step": 10809
    },
    {
      "epoch": 0.783418487516759,
      "grad_norm": 0.4341258704662323,
      "learning_rate": 4.333647365751142e-05,
      "loss": 0.0197,
      "step": 10810
    },
    {
      "epoch": 0.7834909591622278,
      "grad_norm": 0.37190312147140503,
      "learning_rate": 4.332197985361258e-05,
      "loss": 0.0044,
      "step": 10811
    },
    {
      "epoch": 0.7835634308076965,
      "grad_norm": 0.3283887207508087,
      "learning_rate": 4.3307486049713746e-05,
      "loss": 0.0077,
      "step": 10812
    },
    {
      "epoch": 0.7836359024531652,
      "grad_norm": 0.8431601524353027,
      "learning_rate": 4.3292992245814916e-05,
      "loss": 0.0088,
      "step": 10813
    },
    {
      "epoch": 0.7837083740986339,
      "grad_norm": 0.08909248560667038,
      "learning_rate": 4.327849844191608e-05,
      "loss": 0.0012,
      "step": 10814
    },
    {
      "epoch": 0.7837808457441027,
      "grad_norm": 1.5209171772003174,
      "learning_rate": 4.326400463801725e-05,
      "loss": 0.0353,
      "step": 10815
    },
    {
      "epoch": 0.7838533173895713,
      "grad_norm": 1.8296427726745605,
      "learning_rate": 4.324951083411842e-05,
      "loss": 0.0464,
      "step": 10816
    },
    {
      "epoch": 0.7839257890350401,
      "grad_norm": 1.0916829109191895,
      "learning_rate": 4.323501703021958e-05,
      "loss": 0.0086,
      "step": 10817
    },
    {
      "epoch": 0.7839982606805087,
      "grad_norm": 1.9613744020462036,
      "learning_rate": 4.322052322632075e-05,
      "loss": 0.0365,
      "step": 10818
    },
    {
      "epoch": 0.7840707323259775,
      "grad_norm": 0.694007933139801,
      "learning_rate": 4.3206029422421916e-05,
      "loss": 0.0238,
      "step": 10819
    },
    {
      "epoch": 0.7841432039714462,
      "grad_norm": 1.2473756074905396,
      "learning_rate": 4.319153561852308e-05,
      "loss": 0.047,
      "step": 10820
    },
    {
      "epoch": 0.7842156756169149,
      "grad_norm": 0.48347043991088867,
      "learning_rate": 4.3177041814624256e-05,
      "loss": 0.0348,
      "step": 10821
    },
    {
      "epoch": 0.7842881472623836,
      "grad_norm": 0.009362924844026566,
      "learning_rate": 4.316254801072542e-05,
      "loss": 0.0002,
      "step": 10822
    },
    {
      "epoch": 0.7843606189078524,
      "grad_norm": 1.1397405862808228,
      "learning_rate": 4.314805420682658e-05,
      "loss": 0.0461,
      "step": 10823
    },
    {
      "epoch": 0.784433090553321,
      "grad_norm": 0.2840566337108612,
      "learning_rate": 4.313356040292775e-05,
      "loss": 0.0162,
      "step": 10824
    },
    {
      "epoch": 0.7845055621987898,
      "grad_norm": 2.9239718914031982,
      "learning_rate": 4.3119066599028916e-05,
      "loss": 0.0827,
      "step": 10825
    },
    {
      "epoch": 0.7845780338442584,
      "grad_norm": 0.7467357516288757,
      "learning_rate": 4.3104572795130086e-05,
      "loss": 0.0194,
      "step": 10826
    },
    {
      "epoch": 0.7846505054897271,
      "grad_norm": 1.6023391485214233,
      "learning_rate": 4.3090078991231256e-05,
      "loss": 0.0456,
      "step": 10827
    },
    {
      "epoch": 0.7847229771351959,
      "grad_norm": 2.318873405456543,
      "learning_rate": 4.307558518733242e-05,
      "loss": 0.0303,
      "step": 10828
    },
    {
      "epoch": 0.7847954487806645,
      "grad_norm": 0.9619916677474976,
      "learning_rate": 4.306109138343358e-05,
      "loss": 0.038,
      "step": 10829
    },
    {
      "epoch": 0.7848679204261333,
      "grad_norm": 1.1425591707229614,
      "learning_rate": 4.304659757953475e-05,
      "loss": 0.0178,
      "step": 10830
    },
    {
      "epoch": 0.7849403920716019,
      "grad_norm": 0.7862697839736938,
      "learning_rate": 4.3032103775635916e-05,
      "loss": 0.018,
      "step": 10831
    },
    {
      "epoch": 0.7850128637170707,
      "grad_norm": 2.4727227687835693,
      "learning_rate": 4.3017609971737086e-05,
      "loss": 0.1084,
      "step": 10832
    },
    {
      "epoch": 0.7850853353625394,
      "grad_norm": 0.7470743656158447,
      "learning_rate": 4.3003116167838256e-05,
      "loss": 0.0242,
      "step": 10833
    },
    {
      "epoch": 0.7851578070080081,
      "grad_norm": 2.0093376636505127,
      "learning_rate": 4.298862236393942e-05,
      "loss": 0.0992,
      "step": 10834
    },
    {
      "epoch": 0.7852302786534768,
      "grad_norm": 2.6860079765319824,
      "learning_rate": 4.297412856004058e-05,
      "loss": 0.116,
      "step": 10835
    },
    {
      "epoch": 0.7853027502989456,
      "grad_norm": 0.2791631519794464,
      "learning_rate": 4.295963475614175e-05,
      "loss": 0.0045,
      "step": 10836
    },
    {
      "epoch": 0.7853752219444142,
      "grad_norm": 0.47466781735420227,
      "learning_rate": 4.2945140952242916e-05,
      "loss": 0.0147,
      "step": 10837
    },
    {
      "epoch": 0.785447693589883,
      "grad_norm": 4.627139091491699,
      "learning_rate": 4.2930647148344086e-05,
      "loss": 0.0717,
      "step": 10838
    },
    {
      "epoch": 0.7855201652353516,
      "grad_norm": 0.8850008249282837,
      "learning_rate": 4.2916153344445256e-05,
      "loss": 0.032,
      "step": 10839
    },
    {
      "epoch": 0.7855926368808204,
      "grad_norm": 1.208062767982483,
      "learning_rate": 4.290165954054642e-05,
      "loss": 0.0284,
      "step": 10840
    },
    {
      "epoch": 0.7856651085262891,
      "grad_norm": 1.5549476146697998,
      "learning_rate": 4.288716573664758e-05,
      "loss": 0.0308,
      "step": 10841
    },
    {
      "epoch": 0.7857375801717578,
      "grad_norm": 0.07918355613946915,
      "learning_rate": 4.287267193274875e-05,
      "loss": 0.0009,
      "step": 10842
    },
    {
      "epoch": 0.7858100518172265,
      "grad_norm": 3.87308669090271,
      "learning_rate": 4.2858178128849916e-05,
      "loss": 0.1179,
      "step": 10843
    },
    {
      "epoch": 0.7858825234626953,
      "grad_norm": 2.582944393157959,
      "learning_rate": 4.2843684324951086e-05,
      "loss": 0.0596,
      "step": 10844
    },
    {
      "epoch": 0.7859549951081639,
      "grad_norm": 0.8736392855644226,
      "learning_rate": 4.2829190521052256e-05,
      "loss": 0.0294,
      "step": 10845
    },
    {
      "epoch": 0.7860274667536327,
      "grad_norm": 1.0849286317825317,
      "learning_rate": 4.281469671715342e-05,
      "loss": 0.023,
      "step": 10846
    },
    {
      "epoch": 0.7860999383991013,
      "grad_norm": 0.9577874541282654,
      "learning_rate": 4.280020291325458e-05,
      "loss": 0.0257,
      "step": 10847
    },
    {
      "epoch": 0.7861724100445701,
      "grad_norm": 1.7854684591293335,
      "learning_rate": 4.278570910935575e-05,
      "loss": 0.0544,
      "step": 10848
    },
    {
      "epoch": 0.7862448816900388,
      "grad_norm": 0.9155873656272888,
      "learning_rate": 4.2771215305456915e-05,
      "loss": 0.0387,
      "step": 10849
    },
    {
      "epoch": 0.7863173533355075,
      "grad_norm": 1.221431016921997,
      "learning_rate": 4.2756721501558086e-05,
      "loss": 0.0351,
      "step": 10850
    },
    {
      "epoch": 0.7863898249809762,
      "grad_norm": 2.7937521934509277,
      "learning_rate": 4.2742227697659256e-05,
      "loss": 0.0318,
      "step": 10851
    },
    {
      "epoch": 0.786462296626445,
      "grad_norm": 1.6746762990951538,
      "learning_rate": 4.272773389376042e-05,
      "loss": 0.0572,
      "step": 10852
    },
    {
      "epoch": 0.7865347682719136,
      "grad_norm": 2.9325859546661377,
      "learning_rate": 4.271324008986158e-05,
      "loss": 0.1148,
      "step": 10853
    },
    {
      "epoch": 0.7866072399173824,
      "grad_norm": 2.418023109436035,
      "learning_rate": 4.269874628596275e-05,
      "loss": 0.0669,
      "step": 10854
    },
    {
      "epoch": 0.786679711562851,
      "grad_norm": 2.2913122177124023,
      "learning_rate": 4.268425248206392e-05,
      "loss": 0.0469,
      "step": 10855
    },
    {
      "epoch": 0.7867521832083197,
      "grad_norm": 2.2568838596343994,
      "learning_rate": 4.2669758678165085e-05,
      "loss": 0.0631,
      "step": 10856
    },
    {
      "epoch": 0.7868246548537885,
      "grad_norm": 0.41608646512031555,
      "learning_rate": 4.2655264874266255e-05,
      "loss": 0.0139,
      "step": 10857
    },
    {
      "epoch": 0.7868971264992571,
      "grad_norm": 2.225008487701416,
      "learning_rate": 4.264077107036742e-05,
      "loss": 0.0508,
      "step": 10858
    },
    {
      "epoch": 0.7869695981447259,
      "grad_norm": 0.1022731214761734,
      "learning_rate": 4.262627726646859e-05,
      "loss": 0.0022,
      "step": 10859
    },
    {
      "epoch": 0.7870420697901945,
      "grad_norm": 1.8955823183059692,
      "learning_rate": 4.261178346256975e-05,
      "loss": 0.0426,
      "step": 10860
    },
    {
      "epoch": 0.7871145414356633,
      "grad_norm": 0.5454948544502258,
      "learning_rate": 4.259728965867092e-05,
      "loss": 0.0256,
      "step": 10861
    },
    {
      "epoch": 0.787187013081132,
      "grad_norm": 0.7866775989532471,
      "learning_rate": 4.258279585477209e-05,
      "loss": 0.0176,
      "step": 10862
    },
    {
      "epoch": 0.7872594847266007,
      "grad_norm": 0.33682963252067566,
      "learning_rate": 4.2568302050873255e-05,
      "loss": 0.0146,
      "step": 10863
    },
    {
      "epoch": 0.7873319563720694,
      "grad_norm": 6.65995454788208,
      "learning_rate": 4.255380824697442e-05,
      "loss": 0.1248,
      "step": 10864
    },
    {
      "epoch": 0.7874044280175382,
      "grad_norm": 1.033286213874817,
      "learning_rate": 4.253931444307559e-05,
      "loss": 0.0513,
      "step": 10865
    },
    {
      "epoch": 0.7874768996630068,
      "grad_norm": 1.9341076612472534,
      "learning_rate": 4.252482063917675e-05,
      "loss": 0.0673,
      "step": 10866
    },
    {
      "epoch": 0.7875493713084756,
      "grad_norm": 0.583239734172821,
      "learning_rate": 4.251032683527792e-05,
      "loss": 0.0152,
      "step": 10867
    },
    {
      "epoch": 0.7876218429539442,
      "grad_norm": 0.8815439343452454,
      "learning_rate": 4.249583303137909e-05,
      "loss": 0.0254,
      "step": 10868
    },
    {
      "epoch": 0.787694314599413,
      "grad_norm": 1.0881253480911255,
      "learning_rate": 4.2481339227480255e-05,
      "loss": 0.0179,
      "step": 10869
    },
    {
      "epoch": 0.7877667862448817,
      "grad_norm": 3.2462658882141113,
      "learning_rate": 4.246684542358142e-05,
      "loss": 0.0636,
      "step": 10870
    },
    {
      "epoch": 0.7878392578903504,
      "grad_norm": 2.208674430847168,
      "learning_rate": 4.245235161968259e-05,
      "loss": 0.0602,
      "step": 10871
    },
    {
      "epoch": 0.7879117295358191,
      "grad_norm": 1.4923744201660156,
      "learning_rate": 4.243785781578375e-05,
      "loss": 0.0855,
      "step": 10872
    },
    {
      "epoch": 0.7879842011812879,
      "grad_norm": 1.3571338653564453,
      "learning_rate": 4.242336401188492e-05,
      "loss": 0.0437,
      "step": 10873
    },
    {
      "epoch": 0.7880566728267565,
      "grad_norm": 1.7343416213989258,
      "learning_rate": 4.240887020798609e-05,
      "loss": 0.0549,
      "step": 10874
    },
    {
      "epoch": 0.7881291444722253,
      "grad_norm": 1.3230069875717163,
      "learning_rate": 4.2394376404087255e-05,
      "loss": 0.0412,
      "step": 10875
    },
    {
      "epoch": 0.7882016161176939,
      "grad_norm": 2.1458537578582764,
      "learning_rate": 4.237988260018842e-05,
      "loss": 0.0375,
      "step": 10876
    },
    {
      "epoch": 0.7882740877631627,
      "grad_norm": 1.3185827732086182,
      "learning_rate": 4.236538879628959e-05,
      "loss": 0.0242,
      "step": 10877
    },
    {
      "epoch": 0.7883465594086314,
      "grad_norm": 1.6129436492919922,
      "learning_rate": 4.235089499239075e-05,
      "loss": 0.0206,
      "step": 10878
    },
    {
      "epoch": 0.7884190310541,
      "grad_norm": 0.4785701036453247,
      "learning_rate": 4.233640118849192e-05,
      "loss": 0.01,
      "step": 10879
    },
    {
      "epoch": 0.7884915026995688,
      "grad_norm": 0.3010210394859314,
      "learning_rate": 4.232190738459309e-05,
      "loss": 0.0048,
      "step": 10880
    },
    {
      "epoch": 0.7885639743450376,
      "grad_norm": 0.28408899903297424,
      "learning_rate": 4.2307413580694255e-05,
      "loss": 0.0068,
      "step": 10881
    },
    {
      "epoch": 0.7886364459905062,
      "grad_norm": 2.4294073581695557,
      "learning_rate": 4.229291977679542e-05,
      "loss": 0.068,
      "step": 10882
    },
    {
      "epoch": 0.788708917635975,
      "grad_norm": 1.356932282447815,
      "learning_rate": 4.227842597289659e-05,
      "loss": 0.0262,
      "step": 10883
    },
    {
      "epoch": 0.7887813892814436,
      "grad_norm": 4.213289737701416,
      "learning_rate": 4.226393216899776e-05,
      "loss": 0.0565,
      "step": 10884
    },
    {
      "epoch": 0.7888538609269123,
      "grad_norm": 0.12505437433719635,
      "learning_rate": 4.224943836509892e-05,
      "loss": 0.0054,
      "step": 10885
    },
    {
      "epoch": 0.7889263325723811,
      "grad_norm": 0.8986287117004395,
      "learning_rate": 4.223494456120009e-05,
      "loss": 0.0673,
      "step": 10886
    },
    {
      "epoch": 0.7889988042178497,
      "grad_norm": 1.846794843673706,
      "learning_rate": 4.2220450757301255e-05,
      "loss": 0.078,
      "step": 10887
    },
    {
      "epoch": 0.7890712758633185,
      "grad_norm": 1.1301299333572388,
      "learning_rate": 4.220595695340242e-05,
      "loss": 0.0582,
      "step": 10888
    },
    {
      "epoch": 0.7891437475087872,
      "grad_norm": 3.010885715484619,
      "learning_rate": 4.219146314950359e-05,
      "loss": 0.0825,
      "step": 10889
    },
    {
      "epoch": 0.7892162191542559,
      "grad_norm": 0.2016814798116684,
      "learning_rate": 4.217696934560476e-05,
      "loss": 0.0074,
      "step": 10890
    },
    {
      "epoch": 0.7892886907997246,
      "grad_norm": 1.651798963546753,
      "learning_rate": 4.216247554170592e-05,
      "loss": 0.0669,
      "step": 10891
    },
    {
      "epoch": 0.7893611624451933,
      "grad_norm": 1.7083303928375244,
      "learning_rate": 4.214798173780709e-05,
      "loss": 0.0735,
      "step": 10892
    },
    {
      "epoch": 0.789433634090662,
      "grad_norm": 1.6480026245117188,
      "learning_rate": 4.2133487933908255e-05,
      "loss": 0.0395,
      "step": 10893
    },
    {
      "epoch": 0.7895061057361308,
      "grad_norm": 0.5821035504341125,
      "learning_rate": 4.211899413000942e-05,
      "loss": 0.0077,
      "step": 10894
    },
    {
      "epoch": 0.7895785773815994,
      "grad_norm": 2.2050135135650635,
      "learning_rate": 4.210450032611059e-05,
      "loss": 0.0302,
      "step": 10895
    },
    {
      "epoch": 0.7896510490270682,
      "grad_norm": 1.7517876625061035,
      "learning_rate": 4.209000652221176e-05,
      "loss": 0.062,
      "step": 10896
    },
    {
      "epoch": 0.7897235206725368,
      "grad_norm": 1.1257206201553345,
      "learning_rate": 4.207551271831292e-05,
      "loss": 0.0265,
      "step": 10897
    },
    {
      "epoch": 0.7897959923180056,
      "grad_norm": 0.5192939043045044,
      "learning_rate": 4.206101891441409e-05,
      "loss": 0.0239,
      "step": 10898
    },
    {
      "epoch": 0.7898684639634743,
      "grad_norm": 0.5475500822067261,
      "learning_rate": 4.2046525110515255e-05,
      "loss": 0.0069,
      "step": 10899
    },
    {
      "epoch": 0.789940935608943,
      "grad_norm": 0.5428135991096497,
      "learning_rate": 4.2032031306616425e-05,
      "loss": 0.0083,
      "step": 10900
    },
    {
      "epoch": 0.7900134072544117,
      "grad_norm": 0.4515933096408844,
      "learning_rate": 4.201753750271759e-05,
      "loss": 0.0104,
      "step": 10901
    },
    {
      "epoch": 0.7900858788998805,
      "grad_norm": 0.2535252273082733,
      "learning_rate": 4.200304369881876e-05,
      "loss": 0.0053,
      "step": 10902
    },
    {
      "epoch": 0.7901583505453491,
      "grad_norm": 1.0290554761886597,
      "learning_rate": 4.198854989491993e-05,
      "loss": 0.0606,
      "step": 10903
    },
    {
      "epoch": 0.7902308221908179,
      "grad_norm": 2.8696115016937256,
      "learning_rate": 4.197405609102109e-05,
      "loss": 0.1014,
      "step": 10904
    },
    {
      "epoch": 0.7903032938362865,
      "grad_norm": 1.2313320636749268,
      "learning_rate": 4.1959562287122255e-05,
      "loss": 0.0515,
      "step": 10905
    },
    {
      "epoch": 0.7903757654817553,
      "grad_norm": 0.9054657816886902,
      "learning_rate": 4.1945068483223425e-05,
      "loss": 0.0386,
      "step": 10906
    },
    {
      "epoch": 0.790448237127224,
      "grad_norm": 1.0761486291885376,
      "learning_rate": 4.193057467932459e-05,
      "loss": 0.0328,
      "step": 10907
    },
    {
      "epoch": 0.7905207087726926,
      "grad_norm": 1.443041443824768,
      "learning_rate": 4.191608087542576e-05,
      "loss": 0.0797,
      "step": 10908
    },
    {
      "epoch": 0.7905931804181614,
      "grad_norm": 1.7884373664855957,
      "learning_rate": 4.190158707152693e-05,
      "loss": 0.0475,
      "step": 10909
    },
    {
      "epoch": 0.7906656520636302,
      "grad_norm": 1.9831229448318481,
      "learning_rate": 4.188709326762809e-05,
      "loss": 0.0317,
      "step": 10910
    },
    {
      "epoch": 0.7907381237090988,
      "grad_norm": 1.5386230945587158,
      "learning_rate": 4.1872599463729255e-05,
      "loss": 0.0194,
      "step": 10911
    },
    {
      "epoch": 0.7908105953545675,
      "grad_norm": 0.5160220861434937,
      "learning_rate": 4.1858105659830425e-05,
      "loss": 0.011,
      "step": 10912
    },
    {
      "epoch": 0.7908830670000362,
      "grad_norm": 0.2740335464477539,
      "learning_rate": 4.1843611855931595e-05,
      "loss": 0.0055,
      "step": 10913
    },
    {
      "epoch": 0.7909555386455049,
      "grad_norm": 2.1473047733306885,
      "learning_rate": 4.182911805203276e-05,
      "loss": 0.1037,
      "step": 10914
    },
    {
      "epoch": 0.7910280102909737,
      "grad_norm": 1.2932507991790771,
      "learning_rate": 4.181462424813393e-05,
      "loss": 0.0549,
      "step": 10915
    },
    {
      "epoch": 0.7911004819364423,
      "grad_norm": 0.5891846418380737,
      "learning_rate": 4.180013044423509e-05,
      "loss": 0.0147,
      "step": 10916
    },
    {
      "epoch": 0.7911729535819111,
      "grad_norm": 0.8855951428413391,
      "learning_rate": 4.1785636640336254e-05,
      "loss": 0.0097,
      "step": 10917
    },
    {
      "epoch": 0.7912454252273798,
      "grad_norm": 3.567883014678955,
      "learning_rate": 4.1771142836437424e-05,
      "loss": 0.1623,
      "step": 10918
    },
    {
      "epoch": 0.7913178968728485,
      "grad_norm": 1.8794063329696655,
      "learning_rate": 4.1756649032538594e-05,
      "loss": 0.0471,
      "step": 10919
    },
    {
      "epoch": 0.7913903685183172,
      "grad_norm": 0.6222610473632812,
      "learning_rate": 4.174215522863976e-05,
      "loss": 0.0245,
      "step": 10920
    },
    {
      "epoch": 0.7914628401637859,
      "grad_norm": 2.5270633697509766,
      "learning_rate": 4.172766142474093e-05,
      "loss": 0.0998,
      "step": 10921
    },
    {
      "epoch": 0.7915353118092546,
      "grad_norm": 3.037466287612915,
      "learning_rate": 4.171316762084209e-05,
      "loss": 0.1374,
      "step": 10922
    },
    {
      "epoch": 0.7916077834547234,
      "grad_norm": 2.5923612117767334,
      "learning_rate": 4.1698673816943254e-05,
      "loss": 0.0907,
      "step": 10923
    },
    {
      "epoch": 0.791680255100192,
      "grad_norm": 1.9695781469345093,
      "learning_rate": 4.1684180013044424e-05,
      "loss": 0.0565,
      "step": 10924
    },
    {
      "epoch": 0.7917527267456608,
      "grad_norm": 0.8154229521751404,
      "learning_rate": 4.1669686209145594e-05,
      "loss": 0.0153,
      "step": 10925
    },
    {
      "epoch": 0.7918251983911295,
      "grad_norm": 0.572489857673645,
      "learning_rate": 4.165519240524676e-05,
      "loss": 0.011,
      "step": 10926
    },
    {
      "epoch": 0.7918976700365982,
      "grad_norm": 3.0207133293151855,
      "learning_rate": 4.164069860134793e-05,
      "loss": 0.0885,
      "step": 10927
    },
    {
      "epoch": 0.7919701416820669,
      "grad_norm": 2.673527479171753,
      "learning_rate": 4.162620479744909e-05,
      "loss": 0.1362,
      "step": 10928
    },
    {
      "epoch": 0.7920426133275356,
      "grad_norm": 0.7763611078262329,
      "learning_rate": 4.1611710993550254e-05,
      "loss": 0.0174,
      "step": 10929
    },
    {
      "epoch": 0.7921150849730043,
      "grad_norm": 1.8994321823120117,
      "learning_rate": 4.1597217189651424e-05,
      "loss": 0.037,
      "step": 10930
    },
    {
      "epoch": 0.7921875566184731,
      "grad_norm": 1.2990827560424805,
      "learning_rate": 4.1582723385752594e-05,
      "loss": 0.0292,
      "step": 10931
    },
    {
      "epoch": 0.7922600282639417,
      "grad_norm": 0.6950741410255432,
      "learning_rate": 4.156822958185376e-05,
      "loss": 0.0375,
      "step": 10932
    },
    {
      "epoch": 0.7923324999094105,
      "grad_norm": 0.9720726609230042,
      "learning_rate": 4.155373577795493e-05,
      "loss": 0.0257,
      "step": 10933
    },
    {
      "epoch": 0.7924049715548791,
      "grad_norm": 1.2241096496582031,
      "learning_rate": 4.153924197405609e-05,
      "loss": 0.0233,
      "step": 10934
    },
    {
      "epoch": 0.7924774432003479,
      "grad_norm": 0.9002581238746643,
      "learning_rate": 4.1524748170157254e-05,
      "loss": 0.0119,
      "step": 10935
    },
    {
      "epoch": 0.7925499148458166,
      "grad_norm": 1.3124876022338867,
      "learning_rate": 4.151025436625843e-05,
      "loss": 0.0372,
      "step": 10936
    },
    {
      "epoch": 0.7926223864912852,
      "grad_norm": 1.122424602508545,
      "learning_rate": 4.1495760562359594e-05,
      "loss": 0.0146,
      "step": 10937
    },
    {
      "epoch": 0.792694858136754,
      "grad_norm": 1.262220859527588,
      "learning_rate": 4.148126675846076e-05,
      "loss": 0.0318,
      "step": 10938
    },
    {
      "epoch": 0.7927673297822228,
      "grad_norm": 3.0033600330352783,
      "learning_rate": 4.146677295456193e-05,
      "loss": 0.1042,
      "step": 10939
    },
    {
      "epoch": 0.7928398014276914,
      "grad_norm": 0.8067460656166077,
      "learning_rate": 4.145227915066309e-05,
      "loss": 0.0289,
      "step": 10940
    },
    {
      "epoch": 0.7929122730731601,
      "grad_norm": 0.8673168420791626,
      "learning_rate": 4.143778534676426e-05,
      "loss": 0.0252,
      "step": 10941
    },
    {
      "epoch": 0.7929847447186288,
      "grad_norm": 4.519305229187012,
      "learning_rate": 4.142329154286543e-05,
      "loss": 0.1016,
      "step": 10942
    },
    {
      "epoch": 0.7930572163640975,
      "grad_norm": 0.7948768734931946,
      "learning_rate": 4.1408797738966594e-05,
      "loss": 0.0137,
      "step": 10943
    },
    {
      "epoch": 0.7931296880095663,
      "grad_norm": 0.4804833233356476,
      "learning_rate": 4.1394303935067764e-05,
      "loss": 0.0174,
      "step": 10944
    },
    {
      "epoch": 0.7932021596550349,
      "grad_norm": 3.269901752471924,
      "learning_rate": 4.137981013116893e-05,
      "loss": 0.0317,
      "step": 10945
    },
    {
      "epoch": 0.7932746313005037,
      "grad_norm": 2.3901333808898926,
      "learning_rate": 4.136531632727009e-05,
      "loss": 0.1211,
      "step": 10946
    },
    {
      "epoch": 0.7933471029459724,
      "grad_norm": 1.1061453819274902,
      "learning_rate": 4.135082252337126e-05,
      "loss": 0.0078,
      "step": 10947
    },
    {
      "epoch": 0.7934195745914411,
      "grad_norm": 1.6738629341125488,
      "learning_rate": 4.133632871947243e-05,
      "loss": 0.0963,
      "step": 10948
    },
    {
      "epoch": 0.7934920462369098,
      "grad_norm": 1.1249510049819946,
      "learning_rate": 4.1321834915573594e-05,
      "loss": 0.0308,
      "step": 10949
    },
    {
      "epoch": 0.7935645178823785,
      "grad_norm": 0.9563658237457275,
      "learning_rate": 4.1307341111674764e-05,
      "loss": 0.0293,
      "step": 10950
    },
    {
      "epoch": 0.7936369895278472,
      "grad_norm": 0.15012480318546295,
      "learning_rate": 4.129284730777593e-05,
      "loss": 0.0046,
      "step": 10951
    },
    {
      "epoch": 0.793709461173316,
      "grad_norm": 0.5753961801528931,
      "learning_rate": 4.127835350387709e-05,
      "loss": 0.0037,
      "step": 10952
    },
    {
      "epoch": 0.7937819328187846,
      "grad_norm": 2.539261817932129,
      "learning_rate": 4.126385969997826e-05,
      "loss": 0.101,
      "step": 10953
    },
    {
      "epoch": 0.7938544044642534,
      "grad_norm": 1.7422469854354858,
      "learning_rate": 4.124936589607943e-05,
      "loss": 0.0215,
      "step": 10954
    },
    {
      "epoch": 0.7939268761097221,
      "grad_norm": 0.9070027470588684,
      "learning_rate": 4.1234872092180594e-05,
      "loss": 0.014,
      "step": 10955
    },
    {
      "epoch": 0.7939993477551908,
      "grad_norm": 2.0417275428771973,
      "learning_rate": 4.1220378288281764e-05,
      "loss": 0.1135,
      "step": 10956
    },
    {
      "epoch": 0.7940718194006595,
      "grad_norm": 1.4229804277420044,
      "learning_rate": 4.120588448438293e-05,
      "loss": 0.0698,
      "step": 10957
    },
    {
      "epoch": 0.7941442910461282,
      "grad_norm": 2.2443020343780518,
      "learning_rate": 4.119139068048409e-05,
      "loss": 0.0677,
      "step": 10958
    },
    {
      "epoch": 0.7942167626915969,
      "grad_norm": 0.6293938159942627,
      "learning_rate": 4.117689687658526e-05,
      "loss": 0.0253,
      "step": 10959
    },
    {
      "epoch": 0.7942892343370657,
      "grad_norm": 1.7850910425186157,
      "learning_rate": 4.116240307268643e-05,
      "loss": 0.047,
      "step": 10960
    },
    {
      "epoch": 0.7943617059825343,
      "grad_norm": 1.4141963720321655,
      "learning_rate": 4.1147909268787594e-05,
      "loss": 0.0406,
      "step": 10961
    },
    {
      "epoch": 0.7944341776280031,
      "grad_norm": 3.0014047622680664,
      "learning_rate": 4.1133415464888764e-05,
      "loss": 0.0904,
      "step": 10962
    },
    {
      "epoch": 0.7945066492734717,
      "grad_norm": 1.1567844152450562,
      "learning_rate": 4.111892166098993e-05,
      "loss": 0.0351,
      "step": 10963
    },
    {
      "epoch": 0.7945791209189405,
      "grad_norm": 0.8896160125732422,
      "learning_rate": 4.110442785709109e-05,
      "loss": 0.0287,
      "step": 10964
    },
    {
      "epoch": 0.7946515925644092,
      "grad_norm": 2.7244105339050293,
      "learning_rate": 4.108993405319227e-05,
      "loss": 0.1077,
      "step": 10965
    },
    {
      "epoch": 0.7947240642098778,
      "grad_norm": 0.8879379630088806,
      "learning_rate": 4.107544024929343e-05,
      "loss": 0.0294,
      "step": 10966
    },
    {
      "epoch": 0.7947965358553466,
      "grad_norm": 4.355486869812012,
      "learning_rate": 4.1060946445394594e-05,
      "loss": 0.156,
      "step": 10967
    },
    {
      "epoch": 0.7948690075008153,
      "grad_norm": 2.0296902656555176,
      "learning_rate": 4.1046452641495764e-05,
      "loss": 0.0691,
      "step": 10968
    },
    {
      "epoch": 0.794941479146284,
      "grad_norm": 0.0947638601064682,
      "learning_rate": 4.103195883759693e-05,
      "loss": 0.0016,
      "step": 10969
    },
    {
      "epoch": 0.7950139507917527,
      "grad_norm": 0.9955138564109802,
      "learning_rate": 4.10174650336981e-05,
      "loss": 0.0223,
      "step": 10970
    },
    {
      "epoch": 0.7950864224372214,
      "grad_norm": 0.8150995373725891,
      "learning_rate": 4.100297122979927e-05,
      "loss": 0.016,
      "step": 10971
    },
    {
      "epoch": 0.7951588940826901,
      "grad_norm": 0.47615912556648254,
      "learning_rate": 4.098847742590043e-05,
      "loss": 0.0176,
      "step": 10972
    },
    {
      "epoch": 0.7952313657281589,
      "grad_norm": 0.5640416741371155,
      "learning_rate": 4.0973983622001594e-05,
      "loss": 0.0165,
      "step": 10973
    },
    {
      "epoch": 0.7953038373736275,
      "grad_norm": 0.6883699297904968,
      "learning_rate": 4.0959489818102764e-05,
      "loss": 0.0186,
      "step": 10974
    },
    {
      "epoch": 0.7953763090190963,
      "grad_norm": 0.39057159423828125,
      "learning_rate": 4.094499601420393e-05,
      "loss": 0.0295,
      "step": 10975
    },
    {
      "epoch": 0.795448780664565,
      "grad_norm": 1.3675590753555298,
      "learning_rate": 4.09305022103051e-05,
      "loss": 0.0689,
      "step": 10976
    },
    {
      "epoch": 0.7955212523100337,
      "grad_norm": 1.5425134897232056,
      "learning_rate": 4.091600840640627e-05,
      "loss": 0.0495,
      "step": 10977
    },
    {
      "epoch": 0.7955937239555024,
      "grad_norm": 2.697213649749756,
      "learning_rate": 4.090151460250743e-05,
      "loss": 0.028,
      "step": 10978
    },
    {
      "epoch": 0.7956661956009711,
      "grad_norm": 2.1066579818725586,
      "learning_rate": 4.0887020798608593e-05,
      "loss": 0.1067,
      "step": 10979
    },
    {
      "epoch": 0.7957386672464398,
      "grad_norm": 0.5210224986076355,
      "learning_rate": 4.0872526994709764e-05,
      "loss": 0.008,
      "step": 10980
    },
    {
      "epoch": 0.7958111388919086,
      "grad_norm": 1.772667407989502,
      "learning_rate": 4.085803319081093e-05,
      "loss": 0.047,
      "step": 10981
    },
    {
      "epoch": 0.7958836105373772,
      "grad_norm": 2.4610018730163574,
      "learning_rate": 4.08435393869121e-05,
      "loss": 0.078,
      "step": 10982
    },
    {
      "epoch": 0.795956082182846,
      "grad_norm": 1.6815810203552246,
      "learning_rate": 4.082904558301327e-05,
      "loss": 0.0766,
      "step": 10983
    },
    {
      "epoch": 0.7960285538283147,
      "grad_norm": 3.5114619731903076,
      "learning_rate": 4.081455177911443e-05,
      "loss": 0.1547,
      "step": 10984
    },
    {
      "epoch": 0.7961010254737834,
      "grad_norm": 1.8214665651321411,
      "learning_rate": 4.08000579752156e-05,
      "loss": 0.0607,
      "step": 10985
    },
    {
      "epoch": 0.7961734971192521,
      "grad_norm": 0.3555302619934082,
      "learning_rate": 4.0785564171316763e-05,
      "loss": 0.0056,
      "step": 10986
    },
    {
      "epoch": 0.7962459687647208,
      "grad_norm": 3.0400185585021973,
      "learning_rate": 4.077107036741793e-05,
      "loss": 0.0711,
      "step": 10987
    },
    {
      "epoch": 0.7963184404101895,
      "grad_norm": 1.878714680671692,
      "learning_rate": 4.07565765635191e-05,
      "loss": 0.0637,
      "step": 10988
    },
    {
      "epoch": 0.7963909120556583,
      "grad_norm": 0.23260410130023956,
      "learning_rate": 4.074208275962027e-05,
      "loss": 0.0061,
      "step": 10989
    },
    {
      "epoch": 0.7964633837011269,
      "grad_norm": 0.085679791867733,
      "learning_rate": 4.072758895572143e-05,
      "loss": 0.0015,
      "step": 10990
    },
    {
      "epoch": 0.7965358553465957,
      "grad_norm": 1.5557478666305542,
      "learning_rate": 4.07130951518226e-05,
      "loss": 0.0634,
      "step": 10991
    },
    {
      "epoch": 0.7966083269920644,
      "grad_norm": 0.7605173587799072,
      "learning_rate": 4.069860134792376e-05,
      "loss": 0.0122,
      "step": 10992
    },
    {
      "epoch": 0.796680798637533,
      "grad_norm": 0.38096266984939575,
      "learning_rate": 4.0684107544024927e-05,
      "loss": 0.0076,
      "step": 10993
    },
    {
      "epoch": 0.7967532702830018,
      "grad_norm": 1.275393009185791,
      "learning_rate": 4.06696137401261e-05,
      "loss": 0.0426,
      "step": 10994
    },
    {
      "epoch": 0.7968257419284704,
      "grad_norm": 1.914962649345398,
      "learning_rate": 4.065511993622727e-05,
      "loss": 0.0431,
      "step": 10995
    },
    {
      "epoch": 0.7968982135739392,
      "grad_norm": 1.790265440940857,
      "learning_rate": 4.064062613232843e-05,
      "loss": 0.0329,
      "step": 10996
    },
    {
      "epoch": 0.796970685219408,
      "grad_norm": 1.974300503730774,
      "learning_rate": 4.06261323284296e-05,
      "loss": 0.0661,
      "step": 10997
    },
    {
      "epoch": 0.7970431568648766,
      "grad_norm": 0.3248221278190613,
      "learning_rate": 4.061163852453076e-05,
      "loss": 0.0055,
      "step": 10998
    },
    {
      "epoch": 0.7971156285103453,
      "grad_norm": 1.4134373664855957,
      "learning_rate": 4.059714472063193e-05,
      "loss": 0.0568,
      "step": 10999
    },
    {
      "epoch": 0.797188100155814,
      "grad_norm": 2.973088264465332,
      "learning_rate": 4.05826509167331e-05,
      "loss": 0.0212,
      "step": 11000
    },
    {
      "epoch": 0.7972605718012827,
      "grad_norm": 0.5886894464492798,
      "learning_rate": 4.0568157112834267e-05,
      "loss": 0.0181,
      "step": 11001
    },
    {
      "epoch": 0.7973330434467515,
      "grad_norm": 0.042190730571746826,
      "learning_rate": 4.055366330893543e-05,
      "loss": 0.0005,
      "step": 11002
    },
    {
      "epoch": 0.7974055150922201,
      "grad_norm": 0.6119677424430847,
      "learning_rate": 4.05391695050366e-05,
      "loss": 0.0166,
      "step": 11003
    },
    {
      "epoch": 0.7974779867376889,
      "grad_norm": 0.30636143684387207,
      "learning_rate": 4.052467570113776e-05,
      "loss": 0.0082,
      "step": 11004
    },
    {
      "epoch": 0.7975504583831576,
      "grad_norm": 1.9970158338546753,
      "learning_rate": 4.051018189723893e-05,
      "loss": 0.0988,
      "step": 11005
    },
    {
      "epoch": 0.7976229300286263,
      "grad_norm": 0.9729544520378113,
      "learning_rate": 4.04956880933401e-05,
      "loss": 0.0464,
      "step": 11006
    },
    {
      "epoch": 0.797695401674095,
      "grad_norm": 0.38230466842651367,
      "learning_rate": 4.0481194289441266e-05,
      "loss": 0.0165,
      "step": 11007
    },
    {
      "epoch": 0.7977678733195637,
      "grad_norm": 0.5868312120437622,
      "learning_rate": 4.046670048554243e-05,
      "loss": 0.014,
      "step": 11008
    },
    {
      "epoch": 0.7978403449650324,
      "grad_norm": 2.1740007400512695,
      "learning_rate": 4.04522066816436e-05,
      "loss": 0.0679,
      "step": 11009
    },
    {
      "epoch": 0.7979128166105012,
      "grad_norm": 1.3561564683914185,
      "learning_rate": 4.043771287774476e-05,
      "loss": 0.0157,
      "step": 11010
    },
    {
      "epoch": 0.7979852882559698,
      "grad_norm": 6.392637729644775,
      "learning_rate": 4.042321907384593e-05,
      "loss": 0.1041,
      "step": 11011
    },
    {
      "epoch": 0.7980577599014386,
      "grad_norm": 5.449417591094971,
      "learning_rate": 4.04087252699471e-05,
      "loss": 0.0937,
      "step": 11012
    },
    {
      "epoch": 0.7981302315469073,
      "grad_norm": 2.507652997970581,
      "learning_rate": 4.0394231466048266e-05,
      "loss": 0.0493,
      "step": 11013
    },
    {
      "epoch": 0.798202703192376,
      "grad_norm": 0.5579882264137268,
      "learning_rate": 4.037973766214943e-05,
      "loss": 0.0134,
      "step": 11014
    },
    {
      "epoch": 0.7982751748378447,
      "grad_norm": 1.242456078529358,
      "learning_rate": 4.03652438582506e-05,
      "loss": 0.0369,
      "step": 11015
    },
    {
      "epoch": 0.7983476464833134,
      "grad_norm": 1.8457081317901611,
      "learning_rate": 4.035075005435176e-05,
      "loss": 0.0562,
      "step": 11016
    },
    {
      "epoch": 0.7984201181287821,
      "grad_norm": 1.040596604347229,
      "learning_rate": 4.033625625045293e-05,
      "loss": 0.0524,
      "step": 11017
    },
    {
      "epoch": 0.7984925897742509,
      "grad_norm": 2.14825439453125,
      "learning_rate": 4.03217624465541e-05,
      "loss": 0.0731,
      "step": 11018
    },
    {
      "epoch": 0.7985650614197195,
      "grad_norm": 2.0177628993988037,
      "learning_rate": 4.0307268642655266e-05,
      "loss": 0.0146,
      "step": 11019
    },
    {
      "epoch": 0.7986375330651883,
      "grad_norm": 4.427477836608887,
      "learning_rate": 4.0292774838756436e-05,
      "loss": 0.0627,
      "step": 11020
    },
    {
      "epoch": 0.798710004710657,
      "grad_norm": 1.5673112869262695,
      "learning_rate": 4.02782810348576e-05,
      "loss": 0.0921,
      "step": 11021
    },
    {
      "epoch": 0.7987824763561256,
      "grad_norm": 2.3426365852355957,
      "learning_rate": 4.026378723095876e-05,
      "loss": 0.1464,
      "step": 11022
    },
    {
      "epoch": 0.7988549480015944,
      "grad_norm": 3.393200635910034,
      "learning_rate": 4.024929342705994e-05,
      "loss": 0.1218,
      "step": 11023
    },
    {
      "epoch": 0.798927419647063,
      "grad_norm": 0.5087299346923828,
      "learning_rate": 4.02347996231611e-05,
      "loss": 0.0056,
      "step": 11024
    },
    {
      "epoch": 0.7989998912925318,
      "grad_norm": 2.3356432914733887,
      "learning_rate": 4.0220305819262266e-05,
      "loss": 0.063,
      "step": 11025
    },
    {
      "epoch": 0.7990723629380005,
      "grad_norm": 1.2927162647247314,
      "learning_rate": 4.0205812015363436e-05,
      "loss": 0.049,
      "step": 11026
    },
    {
      "epoch": 0.7991448345834692,
      "grad_norm": 3.0237677097320557,
      "learning_rate": 4.01913182114646e-05,
      "loss": 0.2251,
      "step": 11027
    },
    {
      "epoch": 0.7992173062289379,
      "grad_norm": 1.937268853187561,
      "learning_rate": 4.017682440756577e-05,
      "loss": 0.0912,
      "step": 11028
    },
    {
      "epoch": 0.7992897778744067,
      "grad_norm": 1.2539271116256714,
      "learning_rate": 4.016233060366694e-05,
      "loss": 0.0319,
      "step": 11029
    },
    {
      "epoch": 0.7993622495198753,
      "grad_norm": 1.127832293510437,
      "learning_rate": 4.01478367997681e-05,
      "loss": 0.0245,
      "step": 11030
    },
    {
      "epoch": 0.7994347211653441,
      "grad_norm": 1.8661607503890991,
      "learning_rate": 4.0133342995869266e-05,
      "loss": 0.0616,
      "step": 11031
    },
    {
      "epoch": 0.7995071928108127,
      "grad_norm": 1.7635663747787476,
      "learning_rate": 4.0118849191970436e-05,
      "loss": 0.0529,
      "step": 11032
    },
    {
      "epoch": 0.7995796644562815,
      "grad_norm": 0.8932346701622009,
      "learning_rate": 4.01043553880716e-05,
      "loss": 0.0354,
      "step": 11033
    },
    {
      "epoch": 0.7996521361017502,
      "grad_norm": 1.0675630569458008,
      "learning_rate": 4.008986158417277e-05,
      "loss": 0.0372,
      "step": 11034
    },
    {
      "epoch": 0.7997246077472189,
      "grad_norm": 1.1682121753692627,
      "learning_rate": 4.007536778027394e-05,
      "loss": 0.0179,
      "step": 11035
    },
    {
      "epoch": 0.7997970793926876,
      "grad_norm": 3.2809550762176514,
      "learning_rate": 4.00608739763751e-05,
      "loss": 0.0459,
      "step": 11036
    },
    {
      "epoch": 0.7998695510381563,
      "grad_norm": 1.1096692085266113,
      "learning_rate": 4.0046380172476266e-05,
      "loss": 0.0258,
      "step": 11037
    },
    {
      "epoch": 0.799942022683625,
      "grad_norm": 1.439705729484558,
      "learning_rate": 4.0031886368577436e-05,
      "loss": 0.0405,
      "step": 11038
    },
    {
      "epoch": 0.8000144943290938,
      "grad_norm": 1.5207699537277222,
      "learning_rate": 4.00173925646786e-05,
      "loss": 0.0487,
      "step": 11039
    },
    {
      "epoch": 0.8000869659745624,
      "grad_norm": 0.11797847598791122,
      "learning_rate": 4.000289876077977e-05,
      "loss": 0.003,
      "step": 11040
    },
    {
      "epoch": 0.8001594376200312,
      "grad_norm": 3.8760826587677,
      "learning_rate": 3.998840495688094e-05,
      "loss": 0.0518,
      "step": 11041
    },
    {
      "epoch": 0.8002319092654999,
      "grad_norm": 1.647324562072754,
      "learning_rate": 3.99739111529821e-05,
      "loss": 0.0359,
      "step": 11042
    },
    {
      "epoch": 0.8003043809109686,
      "grad_norm": 1.294019341468811,
      "learning_rate": 3.9959417349083266e-05,
      "loss": 0.0451,
      "step": 11043
    },
    {
      "epoch": 0.8003768525564373,
      "grad_norm": 0.3704151511192322,
      "learning_rate": 3.9944923545184436e-05,
      "loss": 0.0112,
      "step": 11044
    },
    {
      "epoch": 0.800449324201906,
      "grad_norm": 0.821868896484375,
      "learning_rate": 3.99304297412856e-05,
      "loss": 0.033,
      "step": 11045
    },
    {
      "epoch": 0.8005217958473747,
      "grad_norm": 0.16224703192710876,
      "learning_rate": 3.991593593738677e-05,
      "loss": 0.0022,
      "step": 11046
    },
    {
      "epoch": 0.8005942674928435,
      "grad_norm": 2.373058557510376,
      "learning_rate": 3.990144213348794e-05,
      "loss": 0.0469,
      "step": 11047
    },
    {
      "epoch": 0.8006667391383121,
      "grad_norm": 5.976937770843506,
      "learning_rate": 3.98869483295891e-05,
      "loss": 0.1571,
      "step": 11048
    },
    {
      "epoch": 0.8007392107837809,
      "grad_norm": 2.429701566696167,
      "learning_rate": 3.9872454525690266e-05,
      "loss": 0.0674,
      "step": 11049
    },
    {
      "epoch": 0.8008116824292496,
      "grad_norm": 0.5952699184417725,
      "learning_rate": 3.9857960721791436e-05,
      "loss": 0.0132,
      "step": 11050
    },
    {
      "epoch": 0.8008841540747182,
      "grad_norm": 0.9970957636833191,
      "learning_rate": 3.98434669178926e-05,
      "loss": 0.0113,
      "step": 11051
    },
    {
      "epoch": 0.800956625720187,
      "grad_norm": 1.130898118019104,
      "learning_rate": 3.982897311399377e-05,
      "loss": 0.0795,
      "step": 11052
    },
    {
      "epoch": 0.8010290973656556,
      "grad_norm": 0.4887431263923645,
      "learning_rate": 3.981447931009494e-05,
      "loss": 0.0142,
      "step": 11053
    },
    {
      "epoch": 0.8011015690111244,
      "grad_norm": 1.9655174016952515,
      "learning_rate": 3.97999855061961e-05,
      "loss": 0.0623,
      "step": 11054
    },
    {
      "epoch": 0.8011740406565931,
      "grad_norm": 2.3117055892944336,
      "learning_rate": 3.9785491702297266e-05,
      "loss": 0.0395,
      "step": 11055
    },
    {
      "epoch": 0.8012465123020618,
      "grad_norm": 0.1897682249546051,
      "learning_rate": 3.9770997898398436e-05,
      "loss": 0.007,
      "step": 11056
    },
    {
      "epoch": 0.8013189839475305,
      "grad_norm": 0.9338342547416687,
      "learning_rate": 3.9756504094499606e-05,
      "loss": 0.0364,
      "step": 11057
    },
    {
      "epoch": 0.8013914555929993,
      "grad_norm": 2.759800434112549,
      "learning_rate": 3.974201029060077e-05,
      "loss": 0.1333,
      "step": 11058
    },
    {
      "epoch": 0.8014639272384679,
      "grad_norm": 0.618139922618866,
      "learning_rate": 3.972751648670194e-05,
      "loss": 0.0139,
      "step": 11059
    },
    {
      "epoch": 0.8015363988839367,
      "grad_norm": 0.9276787638664246,
      "learning_rate": 3.97130226828031e-05,
      "loss": 0.0342,
      "step": 11060
    },
    {
      "epoch": 0.8016088705294053,
      "grad_norm": 0.7949754595756531,
      "learning_rate": 3.969852887890427e-05,
      "loss": 0.0244,
      "step": 11061
    },
    {
      "epoch": 0.8016813421748741,
      "grad_norm": 0.35666191577911377,
      "learning_rate": 3.9684035075005436e-05,
      "loss": 0.0049,
      "step": 11062
    },
    {
      "epoch": 0.8017538138203428,
      "grad_norm": 2.029984951019287,
      "learning_rate": 3.9669541271106606e-05,
      "loss": 0.0552,
      "step": 11063
    },
    {
      "epoch": 0.8018262854658115,
      "grad_norm": 2.0529682636260986,
      "learning_rate": 3.9655047467207776e-05,
      "loss": 0.0985,
      "step": 11064
    },
    {
      "epoch": 0.8018987571112802,
      "grad_norm": 0.4451170861721039,
      "learning_rate": 3.964055366330894e-05,
      "loss": 0.0101,
      "step": 11065
    },
    {
      "epoch": 0.801971228756749,
      "grad_norm": 1.3306206464767456,
      "learning_rate": 3.96260598594101e-05,
      "loss": 0.0328,
      "step": 11066
    },
    {
      "epoch": 0.8020437004022176,
      "grad_norm": 1.6435834169387817,
      "learning_rate": 3.961156605551127e-05,
      "loss": 0.0606,
      "step": 11067
    },
    {
      "epoch": 0.8021161720476864,
      "grad_norm": 0.07517556101083755,
      "learning_rate": 3.9597072251612435e-05,
      "loss": 0.001,
      "step": 11068
    },
    {
      "epoch": 0.802188643693155,
      "grad_norm": 0.3313855230808258,
      "learning_rate": 3.9582578447713605e-05,
      "loss": 0.005,
      "step": 11069
    },
    {
      "epoch": 0.8022611153386238,
      "grad_norm": 0.13995850086212158,
      "learning_rate": 3.9568084643814776e-05,
      "loss": 0.0037,
      "step": 11070
    },
    {
      "epoch": 0.8023335869840925,
      "grad_norm": 1.4104138612747192,
      "learning_rate": 3.955359083991594e-05,
      "loss": 0.0534,
      "step": 11071
    },
    {
      "epoch": 0.8024060586295612,
      "grad_norm": 10.500168800354004,
      "learning_rate": 3.95390970360171e-05,
      "loss": 0.0593,
      "step": 11072
    },
    {
      "epoch": 0.8024785302750299,
      "grad_norm": 2.2390573024749756,
      "learning_rate": 3.952460323211827e-05,
      "loss": 0.0999,
      "step": 11073
    },
    {
      "epoch": 0.8025510019204986,
      "grad_norm": 1.2733888626098633,
      "learning_rate": 3.9510109428219435e-05,
      "loss": 0.0762,
      "step": 11074
    },
    {
      "epoch": 0.8026234735659673,
      "grad_norm": 0.09913191199302673,
      "learning_rate": 3.9495615624320605e-05,
      "loss": 0.0011,
      "step": 11075
    },
    {
      "epoch": 0.8026959452114361,
      "grad_norm": 2.093248128890991,
      "learning_rate": 3.9481121820421775e-05,
      "loss": 0.0585,
      "step": 11076
    },
    {
      "epoch": 0.8027684168569047,
      "grad_norm": 1.0407687425613403,
      "learning_rate": 3.946662801652294e-05,
      "loss": 0.0224,
      "step": 11077
    },
    {
      "epoch": 0.8028408885023735,
      "grad_norm": 5.278214931488037,
      "learning_rate": 3.94521342126241e-05,
      "loss": 0.0982,
      "step": 11078
    },
    {
      "epoch": 0.8029133601478422,
      "grad_norm": 1.974259853363037,
      "learning_rate": 3.943764040872527e-05,
      "loss": 0.0319,
      "step": 11079
    },
    {
      "epoch": 0.8029858317933108,
      "grad_norm": 0.20201238989830017,
      "learning_rate": 3.9423146604826435e-05,
      "loss": 0.007,
      "step": 11080
    },
    {
      "epoch": 0.8030583034387796,
      "grad_norm": 3.2702322006225586,
      "learning_rate": 3.9408652800927605e-05,
      "loss": 0.1677,
      "step": 11081
    },
    {
      "epoch": 0.8031307750842482,
      "grad_norm": 4.453063488006592,
      "learning_rate": 3.9394158997028775e-05,
      "loss": 0.0801,
      "step": 11082
    },
    {
      "epoch": 0.803203246729717,
      "grad_norm": 0.2464449405670166,
      "learning_rate": 3.937966519312994e-05,
      "loss": 0.0024,
      "step": 11083
    },
    {
      "epoch": 0.8032757183751857,
      "grad_norm": 0.27101805806159973,
      "learning_rate": 3.93651713892311e-05,
      "loss": 0.01,
      "step": 11084
    },
    {
      "epoch": 0.8033481900206544,
      "grad_norm": 4.707928657531738,
      "learning_rate": 3.935067758533227e-05,
      "loss": 0.0915,
      "step": 11085
    },
    {
      "epoch": 0.8034206616661231,
      "grad_norm": 0.6636248826980591,
      "learning_rate": 3.933618378143344e-05,
      "loss": 0.0073,
      "step": 11086
    },
    {
      "epoch": 0.8034931333115919,
      "grad_norm": 7.864235877990723,
      "learning_rate": 3.9321689977534605e-05,
      "loss": 0.1869,
      "step": 11087
    },
    {
      "epoch": 0.8035656049570605,
      "grad_norm": 1.040108561515808,
      "learning_rate": 3.9307196173635775e-05,
      "loss": 0.0165,
      "step": 11088
    },
    {
      "epoch": 0.8036380766025293,
      "grad_norm": 0.728144109249115,
      "learning_rate": 3.929270236973694e-05,
      "loss": 0.0235,
      "step": 11089
    },
    {
      "epoch": 0.8037105482479979,
      "grad_norm": 2.3217201232910156,
      "learning_rate": 3.92782085658381e-05,
      "loss": 0.1077,
      "step": 11090
    },
    {
      "epoch": 0.8037830198934667,
      "grad_norm": 1.7055827379226685,
      "learning_rate": 3.926371476193927e-05,
      "loss": 0.0569,
      "step": 11091
    },
    {
      "epoch": 0.8038554915389354,
      "grad_norm": 1.4463071823120117,
      "learning_rate": 3.924922095804044e-05,
      "loss": 0.0489,
      "step": 11092
    },
    {
      "epoch": 0.8039279631844041,
      "grad_norm": 1.0985954999923706,
      "learning_rate": 3.9234727154141605e-05,
      "loss": 0.0473,
      "step": 11093
    },
    {
      "epoch": 0.8040004348298728,
      "grad_norm": 1.3020967245101929,
      "learning_rate": 3.9220233350242775e-05,
      "loss": 0.0391,
      "step": 11094
    },
    {
      "epoch": 0.8040729064753416,
      "grad_norm": 0.5765807628631592,
      "learning_rate": 3.920573954634394e-05,
      "loss": 0.0083,
      "step": 11095
    },
    {
      "epoch": 0.8041453781208102,
      "grad_norm": 0.12888599932193756,
      "learning_rate": 3.91912457424451e-05,
      "loss": 0.003,
      "step": 11096
    },
    {
      "epoch": 0.804217849766279,
      "grad_norm": 0.8256610035896301,
      "learning_rate": 3.917675193854627e-05,
      "loss": 0.0108,
      "step": 11097
    },
    {
      "epoch": 0.8042903214117476,
      "grad_norm": 0.41390517354011536,
      "learning_rate": 3.916225813464744e-05,
      "loss": 0.0187,
      "step": 11098
    },
    {
      "epoch": 0.8043627930572164,
      "grad_norm": 0.9310798645019531,
      "learning_rate": 3.9147764330748605e-05,
      "loss": 0.0478,
      "step": 11099
    },
    {
      "epoch": 0.8044352647026851,
      "grad_norm": 3.9776716232299805,
      "learning_rate": 3.9133270526849775e-05,
      "loss": 0.0405,
      "step": 11100
    },
    {
      "epoch": 0.8045077363481538,
      "grad_norm": 0.47873547673225403,
      "learning_rate": 3.911877672295094e-05,
      "loss": 0.0069,
      "step": 11101
    },
    {
      "epoch": 0.8045802079936225,
      "grad_norm": 0.4346039295196533,
      "learning_rate": 3.910428291905211e-05,
      "loss": 0.0192,
      "step": 11102
    },
    {
      "epoch": 0.8046526796390912,
      "grad_norm": 1.3540639877319336,
      "learning_rate": 3.908978911515327e-05,
      "loss": 0.0841,
      "step": 11103
    },
    {
      "epoch": 0.8047251512845599,
      "grad_norm": 0.5193777084350586,
      "learning_rate": 3.907529531125444e-05,
      "loss": 0.0154,
      "step": 11104
    },
    {
      "epoch": 0.8047976229300287,
      "grad_norm": 3.5360710620880127,
      "learning_rate": 3.906080150735561e-05,
      "loss": 0.1125,
      "step": 11105
    },
    {
      "epoch": 0.8048700945754973,
      "grad_norm": 3.216158866882324,
      "learning_rate": 3.9046307703456775e-05,
      "loss": 0.0739,
      "step": 11106
    },
    {
      "epoch": 0.804942566220966,
      "grad_norm": 0.8480595350265503,
      "learning_rate": 3.903181389955794e-05,
      "loss": 0.0182,
      "step": 11107
    },
    {
      "epoch": 0.8050150378664348,
      "grad_norm": 1.086887001991272,
      "learning_rate": 3.901732009565911e-05,
      "loss": 0.0316,
      "step": 11108
    },
    {
      "epoch": 0.8050875095119034,
      "grad_norm": 4.5084919929504395,
      "learning_rate": 3.900282629176028e-05,
      "loss": 0.0939,
      "step": 11109
    },
    {
      "epoch": 0.8051599811573722,
      "grad_norm": 0.4191068112850189,
      "learning_rate": 3.898833248786144e-05,
      "loss": 0.0175,
      "step": 11110
    },
    {
      "epoch": 0.8052324528028408,
      "grad_norm": 1.2453489303588867,
      "learning_rate": 3.897383868396261e-05,
      "loss": 0.0436,
      "step": 11111
    },
    {
      "epoch": 0.8053049244483096,
      "grad_norm": 1.714970350265503,
      "learning_rate": 3.8959344880063775e-05,
      "loss": 0.0246,
      "step": 11112
    },
    {
      "epoch": 0.8053773960937783,
      "grad_norm": 0.2278539538383484,
      "learning_rate": 3.894485107616494e-05,
      "loss": 0.004,
      "step": 11113
    },
    {
      "epoch": 0.805449867739247,
      "grad_norm": 0.9909449815750122,
      "learning_rate": 3.893035727226611e-05,
      "loss": 0.0146,
      "step": 11114
    },
    {
      "epoch": 0.8055223393847157,
      "grad_norm": 1.1565499305725098,
      "learning_rate": 3.891586346836728e-05,
      "loss": 0.0236,
      "step": 11115
    },
    {
      "epoch": 0.8055948110301845,
      "grad_norm": 1.0141217708587646,
      "learning_rate": 3.890136966446844e-05,
      "loss": 0.0521,
      "step": 11116
    },
    {
      "epoch": 0.8056672826756531,
      "grad_norm": 0.47242552042007446,
      "learning_rate": 3.888687586056961e-05,
      "loss": 0.0193,
      "step": 11117
    },
    {
      "epoch": 0.8057397543211219,
      "grad_norm": 0.059404876083135605,
      "learning_rate": 3.8872382056670775e-05,
      "loss": 0.0007,
      "step": 11118
    },
    {
      "epoch": 0.8058122259665905,
      "grad_norm": 1.8853397369384766,
      "learning_rate": 3.885788825277194e-05,
      "loss": 0.0223,
      "step": 11119
    },
    {
      "epoch": 0.8058846976120593,
      "grad_norm": 1.0765599012374878,
      "learning_rate": 3.884339444887311e-05,
      "loss": 0.08,
      "step": 11120
    },
    {
      "epoch": 0.805957169257528,
      "grad_norm": 2.9983415603637695,
      "learning_rate": 3.882890064497428e-05,
      "loss": 0.0682,
      "step": 11121
    },
    {
      "epoch": 0.8060296409029967,
      "grad_norm": 0.8750147223472595,
      "learning_rate": 3.881440684107544e-05,
      "loss": 0.0202,
      "step": 11122
    },
    {
      "epoch": 0.8061021125484654,
      "grad_norm": 1.230889081954956,
      "learning_rate": 3.879991303717661e-05,
      "loss": 0.0419,
      "step": 11123
    },
    {
      "epoch": 0.8061745841939342,
      "grad_norm": 0.5763670802116394,
      "learning_rate": 3.8785419233277775e-05,
      "loss": 0.0279,
      "step": 11124
    },
    {
      "epoch": 0.8062470558394028,
      "grad_norm": 0.4234306812286377,
      "learning_rate": 3.877092542937894e-05,
      "loss": 0.0136,
      "step": 11125
    },
    {
      "epoch": 0.8063195274848716,
      "grad_norm": 1.6731517314910889,
      "learning_rate": 3.875643162548011e-05,
      "loss": 0.0313,
      "step": 11126
    },
    {
      "epoch": 0.8063919991303402,
      "grad_norm": 2.280974864959717,
      "learning_rate": 3.874193782158128e-05,
      "loss": 0.0288,
      "step": 11127
    },
    {
      "epoch": 0.806464470775809,
      "grad_norm": 1.3288285732269287,
      "learning_rate": 3.872744401768244e-05,
      "loss": 0.0653,
      "step": 11128
    },
    {
      "epoch": 0.8065369424212777,
      "grad_norm": 1.431806206703186,
      "learning_rate": 3.871295021378361e-05,
      "loss": 0.0509,
      "step": 11129
    },
    {
      "epoch": 0.8066094140667464,
      "grad_norm": 0.5711164474487305,
      "learning_rate": 3.8698456409884775e-05,
      "loss": 0.0049,
      "step": 11130
    },
    {
      "epoch": 0.8066818857122151,
      "grad_norm": 0.898590087890625,
      "learning_rate": 3.868396260598594e-05,
      "loss": 0.0129,
      "step": 11131
    },
    {
      "epoch": 0.8067543573576839,
      "grad_norm": 2.792659282684326,
      "learning_rate": 3.866946880208711e-05,
      "loss": 0.1186,
      "step": 11132
    },
    {
      "epoch": 0.8068268290031525,
      "grad_norm": 2.8125905990600586,
      "learning_rate": 3.865497499818828e-05,
      "loss": 0.0956,
      "step": 11133
    },
    {
      "epoch": 0.8068993006486213,
      "grad_norm": 1.644721269607544,
      "learning_rate": 3.864048119428944e-05,
      "loss": 0.086,
      "step": 11134
    },
    {
      "epoch": 0.8069717722940899,
      "grad_norm": 5.011617183685303,
      "learning_rate": 3.862598739039061e-05,
      "loss": 0.1125,
      "step": 11135
    },
    {
      "epoch": 0.8070442439395586,
      "grad_norm": 1.127677321434021,
      "learning_rate": 3.8611493586491774e-05,
      "loss": 0.0289,
      "step": 11136
    },
    {
      "epoch": 0.8071167155850274,
      "grad_norm": 1.7927247285842896,
      "learning_rate": 3.859699978259294e-05,
      "loss": 0.0853,
      "step": 11137
    },
    {
      "epoch": 0.807189187230496,
      "grad_norm": 2.475531578063965,
      "learning_rate": 3.8582505978694114e-05,
      "loss": 0.1279,
      "step": 11138
    },
    {
      "epoch": 0.8072616588759648,
      "grad_norm": 2.900024652481079,
      "learning_rate": 3.856801217479528e-05,
      "loss": 0.0556,
      "step": 11139
    },
    {
      "epoch": 0.8073341305214334,
      "grad_norm": 1.0464547872543335,
      "learning_rate": 3.855351837089644e-05,
      "loss": 0.041,
      "step": 11140
    },
    {
      "epoch": 0.8074066021669022,
      "grad_norm": 0.16347657144069672,
      "learning_rate": 3.853902456699761e-05,
      "loss": 0.004,
      "step": 11141
    },
    {
      "epoch": 0.8074790738123709,
      "grad_norm": 1.7079150676727295,
      "learning_rate": 3.8524530763098774e-05,
      "loss": 0.0521,
      "step": 11142
    },
    {
      "epoch": 0.8075515454578396,
      "grad_norm": 1.802833080291748,
      "learning_rate": 3.8510036959199944e-05,
      "loss": 0.074,
      "step": 11143
    },
    {
      "epoch": 0.8076240171033083,
      "grad_norm": 1.537227749824524,
      "learning_rate": 3.8495543155301114e-05,
      "loss": 0.0322,
      "step": 11144
    },
    {
      "epoch": 0.8076964887487771,
      "grad_norm": 0.8053199648857117,
      "learning_rate": 3.848104935140228e-05,
      "loss": 0.03,
      "step": 11145
    },
    {
      "epoch": 0.8077689603942457,
      "grad_norm": 1.7602916955947876,
      "learning_rate": 3.846655554750345e-05,
      "loss": 0.0638,
      "step": 11146
    },
    {
      "epoch": 0.8078414320397145,
      "grad_norm": 1.2916194200515747,
      "learning_rate": 3.845206174360461e-05,
      "loss": 0.0318,
      "step": 11147
    },
    {
      "epoch": 0.8079139036851831,
      "grad_norm": 2.1231937408447266,
      "learning_rate": 3.8437567939705774e-05,
      "loss": 0.0215,
      "step": 11148
    },
    {
      "epoch": 0.8079863753306519,
      "grad_norm": 1.0852223634719849,
      "learning_rate": 3.8423074135806944e-05,
      "loss": 0.0825,
      "step": 11149
    },
    {
      "epoch": 0.8080588469761206,
      "grad_norm": 0.4834699332714081,
      "learning_rate": 3.8408580331908114e-05,
      "loss": 0.0189,
      "step": 11150
    },
    {
      "epoch": 0.8081313186215893,
      "grad_norm": 1.4658310413360596,
      "learning_rate": 3.839408652800928e-05,
      "loss": 0.0756,
      "step": 11151
    },
    {
      "epoch": 0.808203790267058,
      "grad_norm": 2.609297275543213,
      "learning_rate": 3.837959272411045e-05,
      "loss": 0.0851,
      "step": 11152
    },
    {
      "epoch": 0.8082762619125268,
      "grad_norm": 2.7468583583831787,
      "learning_rate": 3.836509892021161e-05,
      "loss": 0.0684,
      "step": 11153
    },
    {
      "epoch": 0.8083487335579954,
      "grad_norm": 1.8108733892440796,
      "learning_rate": 3.8350605116312774e-05,
      "loss": 0.068,
      "step": 11154
    },
    {
      "epoch": 0.8084212052034642,
      "grad_norm": 3.328767776489258,
      "learning_rate": 3.8336111312413944e-05,
      "loss": 0.082,
      "step": 11155
    },
    {
      "epoch": 0.8084936768489328,
      "grad_norm": 1.122269868850708,
      "learning_rate": 3.8321617508515114e-05,
      "loss": 0.0787,
      "step": 11156
    },
    {
      "epoch": 0.8085661484944016,
      "grad_norm": 2.5555899143218994,
      "learning_rate": 3.830712370461628e-05,
      "loss": 0.0154,
      "step": 11157
    },
    {
      "epoch": 0.8086386201398703,
      "grad_norm": 0.7944667339324951,
      "learning_rate": 3.829262990071745e-05,
      "loss": 0.0502,
      "step": 11158
    },
    {
      "epoch": 0.808711091785339,
      "grad_norm": 0.569667637348175,
      "learning_rate": 3.827813609681861e-05,
      "loss": 0.0141,
      "step": 11159
    },
    {
      "epoch": 0.8087835634308077,
      "grad_norm": 7.997453212738037,
      "learning_rate": 3.8263642292919774e-05,
      "loss": 0.1006,
      "step": 11160
    },
    {
      "epoch": 0.8088560350762765,
      "grad_norm": 1.5719865560531616,
      "learning_rate": 3.8249148489020944e-05,
      "loss": 0.0706,
      "step": 11161
    },
    {
      "epoch": 0.8089285067217451,
      "grad_norm": 1.7266721725463867,
      "learning_rate": 3.8234654685122114e-05,
      "loss": 0.0533,
      "step": 11162
    },
    {
      "epoch": 0.8090009783672139,
      "grad_norm": 0.7618634104728699,
      "learning_rate": 3.822016088122328e-05,
      "loss": 0.0112,
      "step": 11163
    },
    {
      "epoch": 0.8090734500126825,
      "grad_norm": 0.6673532724380493,
      "learning_rate": 3.820566707732445e-05,
      "loss": 0.0134,
      "step": 11164
    },
    {
      "epoch": 0.8091459216581512,
      "grad_norm": 0.9269980788230896,
      "learning_rate": 3.819117327342561e-05,
      "loss": 0.0651,
      "step": 11165
    },
    {
      "epoch": 0.80921839330362,
      "grad_norm": 3.793917179107666,
      "learning_rate": 3.8176679469526774e-05,
      "loss": 0.0524,
      "step": 11166
    },
    {
      "epoch": 0.8092908649490886,
      "grad_norm": 3.020906686782837,
      "learning_rate": 3.816218566562795e-05,
      "loss": 0.0632,
      "step": 11167
    },
    {
      "epoch": 0.8093633365945574,
      "grad_norm": 0.6942923069000244,
      "learning_rate": 3.8147691861729114e-05,
      "loss": 0.0308,
      "step": 11168
    },
    {
      "epoch": 0.8094358082400261,
      "grad_norm": 1.5683969259262085,
      "learning_rate": 3.813319805783028e-05,
      "loss": 0.0808,
      "step": 11169
    },
    {
      "epoch": 0.8095082798854948,
      "grad_norm": 1.685195803642273,
      "learning_rate": 3.811870425393145e-05,
      "loss": 0.0522,
      "step": 11170
    },
    {
      "epoch": 0.8095807515309635,
      "grad_norm": 2.1994850635528564,
      "learning_rate": 3.810421045003261e-05,
      "loss": 0.1244,
      "step": 11171
    },
    {
      "epoch": 0.8096532231764322,
      "grad_norm": 0.7198817729949951,
      "learning_rate": 3.808971664613378e-05,
      "loss": 0.0228,
      "step": 11172
    },
    {
      "epoch": 0.8097256948219009,
      "grad_norm": 1.319172739982605,
      "learning_rate": 3.807522284223495e-05,
      "loss": 0.0367,
      "step": 11173
    },
    {
      "epoch": 0.8097981664673697,
      "grad_norm": 1.0781642198562622,
      "learning_rate": 3.8060729038336114e-05,
      "loss": 0.0328,
      "step": 11174
    },
    {
      "epoch": 0.8098706381128383,
      "grad_norm": 1.4951519966125488,
      "learning_rate": 3.804623523443728e-05,
      "loss": 0.0305,
      "step": 11175
    },
    {
      "epoch": 0.8099431097583071,
      "grad_norm": 0.31508293747901917,
      "learning_rate": 3.803174143053845e-05,
      "loss": 0.0043,
      "step": 11176
    },
    {
      "epoch": 0.8100155814037757,
      "grad_norm": 1.5650697946548462,
      "learning_rate": 3.801724762663961e-05,
      "loss": 0.0516,
      "step": 11177
    },
    {
      "epoch": 0.8100880530492445,
      "grad_norm": 0.3989544212818146,
      "learning_rate": 3.800275382274078e-05,
      "loss": 0.0104,
      "step": 11178
    },
    {
      "epoch": 0.8101605246947132,
      "grad_norm": 4.174962520599365,
      "learning_rate": 3.798826001884195e-05,
      "loss": 0.0466,
      "step": 11179
    },
    {
      "epoch": 0.8102329963401819,
      "grad_norm": 0.32849299907684326,
      "learning_rate": 3.7973766214943114e-05,
      "loss": 0.0073,
      "step": 11180
    },
    {
      "epoch": 0.8103054679856506,
      "grad_norm": 0.5024791359901428,
      "learning_rate": 3.795927241104428e-05,
      "loss": 0.0098,
      "step": 11181
    },
    {
      "epoch": 0.8103779396311194,
      "grad_norm": 0.5119255185127258,
      "learning_rate": 3.794477860714545e-05,
      "loss": 0.0053,
      "step": 11182
    },
    {
      "epoch": 0.810450411276588,
      "grad_norm": 1.2460049390792847,
      "learning_rate": 3.793028480324661e-05,
      "loss": 0.0234,
      "step": 11183
    },
    {
      "epoch": 0.8105228829220568,
      "grad_norm": 0.997995913028717,
      "learning_rate": 3.791579099934778e-05,
      "loss": 0.04,
      "step": 11184
    },
    {
      "epoch": 0.8105953545675254,
      "grad_norm": 0.8772193789482117,
      "learning_rate": 3.790129719544895e-05,
      "loss": 0.0192,
      "step": 11185
    },
    {
      "epoch": 0.8106678262129942,
      "grad_norm": 1.2902790307998657,
      "learning_rate": 3.7886803391550114e-05,
      "loss": 0.0364,
      "step": 11186
    },
    {
      "epoch": 0.8107402978584629,
      "grad_norm": 1.2919663190841675,
      "learning_rate": 3.7872309587651284e-05,
      "loss": 0.0088,
      "step": 11187
    },
    {
      "epoch": 0.8108127695039316,
      "grad_norm": 1.3379632234573364,
      "learning_rate": 3.785781578375245e-05,
      "loss": 0.0268,
      "step": 11188
    },
    {
      "epoch": 0.8108852411494003,
      "grad_norm": 1.233136773109436,
      "learning_rate": 3.784332197985361e-05,
      "loss": 0.022,
      "step": 11189
    },
    {
      "epoch": 0.8109577127948691,
      "grad_norm": 0.20382222533226013,
      "learning_rate": 3.782882817595478e-05,
      "loss": 0.0044,
      "step": 11190
    },
    {
      "epoch": 0.8110301844403377,
      "grad_norm": 0.08749374747276306,
      "learning_rate": 3.781433437205595e-05,
      "loss": 0.0011,
      "step": 11191
    },
    {
      "epoch": 0.8111026560858065,
      "grad_norm": 1.8693702220916748,
      "learning_rate": 3.7799840568157114e-05,
      "loss": 0.0463,
      "step": 11192
    },
    {
      "epoch": 0.8111751277312751,
      "grad_norm": 3.104759693145752,
      "learning_rate": 3.7785346764258284e-05,
      "loss": 0.0393,
      "step": 11193
    },
    {
      "epoch": 0.8112475993767438,
      "grad_norm": 4.85911750793457,
      "learning_rate": 3.777085296035945e-05,
      "loss": 0.1168,
      "step": 11194
    },
    {
      "epoch": 0.8113200710222126,
      "grad_norm": 1.3352060317993164,
      "learning_rate": 3.775635915646061e-05,
      "loss": 0.0353,
      "step": 11195
    },
    {
      "epoch": 0.8113925426676812,
      "grad_norm": 0.5031552314758301,
      "learning_rate": 3.774186535256179e-05,
      "loss": 0.0078,
      "step": 11196
    },
    {
      "epoch": 0.81146501431315,
      "grad_norm": 2.2643446922302246,
      "learning_rate": 3.772737154866295e-05,
      "loss": 0.1138,
      "step": 11197
    },
    {
      "epoch": 0.8115374859586187,
      "grad_norm": 0.021654853597283363,
      "learning_rate": 3.7712877744764113e-05,
      "loss": 0.0005,
      "step": 11198
    },
    {
      "epoch": 0.8116099576040874,
      "grad_norm": 0.7640295624732971,
      "learning_rate": 3.7698383940865283e-05,
      "loss": 0.0245,
      "step": 11199
    },
    {
      "epoch": 0.8116824292495561,
      "grad_norm": 3.3059780597686768,
      "learning_rate": 3.768389013696645e-05,
      "loss": 0.0725,
      "step": 11200
    },
    {
      "epoch": 0.8117549008950248,
      "grad_norm": 2.565124750137329,
      "learning_rate": 3.766939633306762e-05,
      "loss": 0.0628,
      "step": 11201
    },
    {
      "epoch": 0.8118273725404935,
      "grad_norm": 0.9856578707695007,
      "learning_rate": 3.765490252916879e-05,
      "loss": 0.0258,
      "step": 11202
    },
    {
      "epoch": 0.8118998441859623,
      "grad_norm": 0.8178259134292603,
      "learning_rate": 3.764040872526995e-05,
      "loss": 0.0307,
      "step": 11203
    },
    {
      "epoch": 0.8119723158314309,
      "grad_norm": 2.907998561859131,
      "learning_rate": 3.762591492137111e-05,
      "loss": 0.0758,
      "step": 11204
    },
    {
      "epoch": 0.8120447874768997,
      "grad_norm": 4.679069995880127,
      "learning_rate": 3.7611421117472283e-05,
      "loss": 0.1843,
      "step": 11205
    },
    {
      "epoch": 0.8121172591223683,
      "grad_norm": 1.7105953693389893,
      "learning_rate": 3.759692731357345e-05,
      "loss": 0.0443,
      "step": 11206
    },
    {
      "epoch": 0.8121897307678371,
      "grad_norm": 0.9191391468048096,
      "learning_rate": 3.758243350967462e-05,
      "loss": 0.0275,
      "step": 11207
    },
    {
      "epoch": 0.8122622024133058,
      "grad_norm": 1.6573258638381958,
      "learning_rate": 3.756793970577579e-05,
      "loss": 0.0574,
      "step": 11208
    },
    {
      "epoch": 0.8123346740587745,
      "grad_norm": 0.7412161827087402,
      "learning_rate": 3.755344590187695e-05,
      "loss": 0.025,
      "step": 11209
    },
    {
      "epoch": 0.8124071457042432,
      "grad_norm": 0.9546987414360046,
      "learning_rate": 3.753895209797811e-05,
      "loss": 0.0411,
      "step": 11210
    },
    {
      "epoch": 0.812479617349712,
      "grad_norm": 5.185550689697266,
      "learning_rate": 3.752445829407928e-05,
      "loss": 0.1162,
      "step": 11211
    },
    {
      "epoch": 0.8125520889951806,
      "grad_norm": 1.0971935987472534,
      "learning_rate": 3.7509964490180447e-05,
      "loss": 0.0188,
      "step": 11212
    },
    {
      "epoch": 0.8126245606406494,
      "grad_norm": 0.6468917727470398,
      "learning_rate": 3.7495470686281617e-05,
      "loss": 0.011,
      "step": 11213
    },
    {
      "epoch": 0.812697032286118,
      "grad_norm": 0.8753036856651306,
      "learning_rate": 3.748097688238279e-05,
      "loss": 0.0421,
      "step": 11214
    },
    {
      "epoch": 0.8127695039315868,
      "grad_norm": 4.578013896942139,
      "learning_rate": 3.746648307848395e-05,
      "loss": 0.0824,
      "step": 11215
    },
    {
      "epoch": 0.8128419755770555,
      "grad_norm": 0.8771681785583496,
      "learning_rate": 3.745198927458511e-05,
      "loss": 0.0237,
      "step": 11216
    },
    {
      "epoch": 0.8129144472225242,
      "grad_norm": 1.6634522676467896,
      "learning_rate": 3.743749547068628e-05,
      "loss": 0.0436,
      "step": 11217
    },
    {
      "epoch": 0.8129869188679929,
      "grad_norm": 2.2263615131378174,
      "learning_rate": 3.7423001666787446e-05,
      "loss": 0.0823,
      "step": 11218
    },
    {
      "epoch": 0.8130593905134617,
      "grad_norm": 1.1503565311431885,
      "learning_rate": 3.7408507862888616e-05,
      "loss": 0.0187,
      "step": 11219
    },
    {
      "epoch": 0.8131318621589303,
      "grad_norm": 1.1302582025527954,
      "learning_rate": 3.7394014058989787e-05,
      "loss": 0.0588,
      "step": 11220
    },
    {
      "epoch": 0.813204333804399,
      "grad_norm": 0.10954857617616653,
      "learning_rate": 3.737952025509095e-05,
      "loss": 0.0017,
      "step": 11221
    },
    {
      "epoch": 0.8132768054498677,
      "grad_norm": 1.4543122053146362,
      "learning_rate": 3.736502645119211e-05,
      "loss": 0.0353,
      "step": 11222
    },
    {
      "epoch": 0.8133492770953364,
      "grad_norm": 1.3173352479934692,
      "learning_rate": 3.735053264729328e-05,
      "loss": 0.0424,
      "step": 11223
    },
    {
      "epoch": 0.8134217487408052,
      "grad_norm": 1.1357427835464478,
      "learning_rate": 3.7336038843394446e-05,
      "loss": 0.0256,
      "step": 11224
    },
    {
      "epoch": 0.8134942203862738,
      "grad_norm": 1.5011147260665894,
      "learning_rate": 3.732154503949562e-05,
      "loss": 0.0292,
      "step": 11225
    },
    {
      "epoch": 0.8135666920317426,
      "grad_norm": 2.586299419403076,
      "learning_rate": 3.7307051235596786e-05,
      "loss": 0.1112,
      "step": 11226
    },
    {
      "epoch": 0.8136391636772113,
      "grad_norm": 4.114457130432129,
      "learning_rate": 3.729255743169795e-05,
      "loss": 0.0457,
      "step": 11227
    },
    {
      "epoch": 0.81371163532268,
      "grad_norm": 0.6006986498832703,
      "learning_rate": 3.727806362779912e-05,
      "loss": 0.0257,
      "step": 11228
    },
    {
      "epoch": 0.8137841069681487,
      "grad_norm": 0.9208298325538635,
      "learning_rate": 3.726356982390028e-05,
      "loss": 0.0131,
      "step": 11229
    },
    {
      "epoch": 0.8138565786136174,
      "grad_norm": 0.37895262241363525,
      "learning_rate": 3.724907602000145e-05,
      "loss": 0.0132,
      "step": 11230
    },
    {
      "epoch": 0.8139290502590861,
      "grad_norm": 0.46126487851142883,
      "learning_rate": 3.723458221610262e-05,
      "loss": 0.0193,
      "step": 11231
    },
    {
      "epoch": 0.8140015219045549,
      "grad_norm": 2.9672844409942627,
      "learning_rate": 3.7220088412203786e-05,
      "loss": 0.1884,
      "step": 11232
    },
    {
      "epoch": 0.8140739935500235,
      "grad_norm": 0.5104625225067139,
      "learning_rate": 3.720559460830495e-05,
      "loss": 0.0115,
      "step": 11233
    },
    {
      "epoch": 0.8141464651954923,
      "grad_norm": 0.6814863681793213,
      "learning_rate": 3.719110080440612e-05,
      "loss": 0.0365,
      "step": 11234
    },
    {
      "epoch": 0.814218936840961,
      "grad_norm": 2.7874650955200195,
      "learning_rate": 3.717660700050728e-05,
      "loss": 0.0903,
      "step": 11235
    },
    {
      "epoch": 0.8142914084864297,
      "grad_norm": 3.015791893005371,
      "learning_rate": 3.716211319660845e-05,
      "loss": 0.0664,
      "step": 11236
    },
    {
      "epoch": 0.8143638801318984,
      "grad_norm": 0.2475990206003189,
      "learning_rate": 3.714761939270962e-05,
      "loss": 0.0098,
      "step": 11237
    },
    {
      "epoch": 0.8144363517773671,
      "grad_norm": 0.22815607488155365,
      "learning_rate": 3.7133125588810786e-05,
      "loss": 0.0044,
      "step": 11238
    },
    {
      "epoch": 0.8145088234228358,
      "grad_norm": 0.673511803150177,
      "learning_rate": 3.711863178491195e-05,
      "loss": 0.0325,
      "step": 11239
    },
    {
      "epoch": 0.8145812950683046,
      "grad_norm": 1.7856372594833374,
      "learning_rate": 3.710413798101312e-05,
      "loss": 0.0454,
      "step": 11240
    },
    {
      "epoch": 0.8146537667137732,
      "grad_norm": 1.4564071893692017,
      "learning_rate": 3.708964417711428e-05,
      "loss": 0.0182,
      "step": 11241
    },
    {
      "epoch": 0.814726238359242,
      "grad_norm": 0.6246238350868225,
      "learning_rate": 3.707515037321545e-05,
      "loss": 0.0101,
      "step": 11242
    },
    {
      "epoch": 0.8147987100047106,
      "grad_norm": 2.8456194400787354,
      "learning_rate": 3.706065656931662e-05,
      "loss": 0.1296,
      "step": 11243
    },
    {
      "epoch": 0.8148711816501794,
      "grad_norm": 0.9090917706489563,
      "learning_rate": 3.7046162765417786e-05,
      "loss": 0.0554,
      "step": 11244
    },
    {
      "epoch": 0.8149436532956481,
      "grad_norm": 2.5866127014160156,
      "learning_rate": 3.703166896151895e-05,
      "loss": 0.0476,
      "step": 11245
    },
    {
      "epoch": 0.8150161249411167,
      "grad_norm": 0.5582849383354187,
      "learning_rate": 3.701717515762012e-05,
      "loss": 0.0269,
      "step": 11246
    },
    {
      "epoch": 0.8150885965865855,
      "grad_norm": 0.9495202302932739,
      "learning_rate": 3.700268135372128e-05,
      "loss": 0.0145,
      "step": 11247
    },
    {
      "epoch": 0.8151610682320543,
      "grad_norm": 0.06895506381988525,
      "learning_rate": 3.698818754982245e-05,
      "loss": 0.0013,
      "step": 11248
    },
    {
      "epoch": 0.8152335398775229,
      "grad_norm": 3.3476922512054443,
      "learning_rate": 3.697369374592362e-05,
      "loss": 0.0584,
      "step": 11249
    },
    {
      "epoch": 0.8153060115229916,
      "grad_norm": 1.0307388305664062,
      "learning_rate": 3.6959199942024786e-05,
      "loss": 0.0282,
      "step": 11250
    },
    {
      "epoch": 0.8153784831684603,
      "grad_norm": 1.7991273403167725,
      "learning_rate": 3.694470613812595e-05,
      "loss": 0.07,
      "step": 11251
    },
    {
      "epoch": 0.815450954813929,
      "grad_norm": 3.1810503005981445,
      "learning_rate": 3.693021233422712e-05,
      "loss": 0.0126,
      "step": 11252
    },
    {
      "epoch": 0.8155234264593978,
      "grad_norm": 2.4449689388275146,
      "learning_rate": 3.691571853032829e-05,
      "loss": 0.053,
      "step": 11253
    },
    {
      "epoch": 0.8155958981048664,
      "grad_norm": 2.1825923919677734,
      "learning_rate": 3.690122472642945e-05,
      "loss": 0.0388,
      "step": 11254
    },
    {
      "epoch": 0.8156683697503352,
      "grad_norm": 2.317481756210327,
      "learning_rate": 3.688673092253062e-05,
      "loss": 0.0674,
      "step": 11255
    },
    {
      "epoch": 0.8157408413958039,
      "grad_norm": 1.0000944137573242,
      "learning_rate": 3.6872237118631786e-05,
      "loss": 0.0162,
      "step": 11256
    },
    {
      "epoch": 0.8158133130412726,
      "grad_norm": 1.1779754161834717,
      "learning_rate": 3.685774331473295e-05,
      "loss": 0.0071,
      "step": 11257
    },
    {
      "epoch": 0.8158857846867413,
      "grad_norm": 2.961519956588745,
      "learning_rate": 3.684324951083412e-05,
      "loss": 0.0826,
      "step": 11258
    },
    {
      "epoch": 0.81595825633221,
      "grad_norm": 0.296347439289093,
      "learning_rate": 3.682875570693529e-05,
      "loss": 0.004,
      "step": 11259
    },
    {
      "epoch": 0.8160307279776787,
      "grad_norm": 1.0215508937835693,
      "learning_rate": 3.681426190303645e-05,
      "loss": 0.0203,
      "step": 11260
    },
    {
      "epoch": 0.8161031996231475,
      "grad_norm": 2.538691282272339,
      "learning_rate": 3.679976809913762e-05,
      "loss": 0.1141,
      "step": 11261
    },
    {
      "epoch": 0.8161756712686161,
      "grad_norm": 2.85683536529541,
      "learning_rate": 3.6785274295238786e-05,
      "loss": 0.0168,
      "step": 11262
    },
    {
      "epoch": 0.8162481429140849,
      "grad_norm": 0.6378834843635559,
      "learning_rate": 3.677078049133995e-05,
      "loss": 0.0267,
      "step": 11263
    },
    {
      "epoch": 0.8163206145595536,
      "grad_norm": 1.5528020858764648,
      "learning_rate": 3.675628668744112e-05,
      "loss": 0.0332,
      "step": 11264
    },
    {
      "epoch": 0.8163930862050223,
      "grad_norm": 0.779756486415863,
      "learning_rate": 3.674179288354229e-05,
      "loss": 0.0365,
      "step": 11265
    },
    {
      "epoch": 0.816465557850491,
      "grad_norm": 0.35693901777267456,
      "learning_rate": 3.672729907964346e-05,
      "loss": 0.0087,
      "step": 11266
    },
    {
      "epoch": 0.8165380294959597,
      "grad_norm": 1.3302193880081177,
      "learning_rate": 3.671280527574462e-05,
      "loss": 0.0271,
      "step": 11267
    },
    {
      "epoch": 0.8166105011414284,
      "grad_norm": 0.20438575744628906,
      "learning_rate": 3.6698311471845786e-05,
      "loss": 0.012,
      "step": 11268
    },
    {
      "epoch": 0.8166829727868972,
      "grad_norm": 1.5928200483322144,
      "learning_rate": 3.6683817667946956e-05,
      "loss": 0.0985,
      "step": 11269
    },
    {
      "epoch": 0.8167554444323658,
      "grad_norm": 2.226712226867676,
      "learning_rate": 3.666932386404812e-05,
      "loss": 0.0485,
      "step": 11270
    },
    {
      "epoch": 0.8168279160778346,
      "grad_norm": 0.9989550709724426,
      "learning_rate": 3.665483006014929e-05,
      "loss": 0.0307,
      "step": 11271
    },
    {
      "epoch": 0.8169003877233033,
      "grad_norm": 0.8061464428901672,
      "learning_rate": 3.664033625625046e-05,
      "loss": 0.0351,
      "step": 11272
    },
    {
      "epoch": 0.816972859368772,
      "grad_norm": 0.5549520254135132,
      "learning_rate": 3.662584245235162e-05,
      "loss": 0.0051,
      "step": 11273
    },
    {
      "epoch": 0.8170453310142407,
      "grad_norm": 0.3790922462940216,
      "learning_rate": 3.6611348648452786e-05,
      "loss": 0.0025,
      "step": 11274
    },
    {
      "epoch": 0.8171178026597093,
      "grad_norm": 2.3165314197540283,
      "learning_rate": 3.6596854844553956e-05,
      "loss": 0.0805,
      "step": 11275
    },
    {
      "epoch": 0.8171902743051781,
      "grad_norm": 0.34649035334587097,
      "learning_rate": 3.658236104065512e-05,
      "loss": 0.0108,
      "step": 11276
    },
    {
      "epoch": 0.8172627459506469,
      "grad_norm": 5.0318827629089355,
      "learning_rate": 3.656786723675629e-05,
      "loss": 0.0567,
      "step": 11277
    },
    {
      "epoch": 0.8173352175961155,
      "grad_norm": 1.2770140171051025,
      "learning_rate": 3.655337343285746e-05,
      "loss": 0.017,
      "step": 11278
    },
    {
      "epoch": 0.8174076892415842,
      "grad_norm": 1.208287000656128,
      "learning_rate": 3.653887962895862e-05,
      "loss": 0.0144,
      "step": 11279
    },
    {
      "epoch": 0.8174801608870529,
      "grad_norm": 0.32287925481796265,
      "learning_rate": 3.6524385825059785e-05,
      "loss": 0.0077,
      "step": 11280
    },
    {
      "epoch": 0.8175526325325216,
      "grad_norm": 0.31637662649154663,
      "learning_rate": 3.6509892021160956e-05,
      "loss": 0.004,
      "step": 11281
    },
    {
      "epoch": 0.8176251041779904,
      "grad_norm": 0.7007818222045898,
      "learning_rate": 3.6495398217262126e-05,
      "loss": 0.0182,
      "step": 11282
    },
    {
      "epoch": 0.817697575823459,
      "grad_norm": 1.3867884874343872,
      "learning_rate": 3.648090441336329e-05,
      "loss": 0.0233,
      "step": 11283
    },
    {
      "epoch": 0.8177700474689278,
      "grad_norm": 3.1547696590423584,
      "learning_rate": 3.646641060946446e-05,
      "loss": 0.0718,
      "step": 11284
    },
    {
      "epoch": 0.8178425191143965,
      "grad_norm": 2.5768187046051025,
      "learning_rate": 3.645191680556562e-05,
      "loss": 0.0855,
      "step": 11285
    },
    {
      "epoch": 0.8179149907598652,
      "grad_norm": 0.2663152813911438,
      "learning_rate": 3.6437423001666785e-05,
      "loss": 0.0109,
      "step": 11286
    },
    {
      "epoch": 0.8179874624053339,
      "grad_norm": 3.453237295150757,
      "learning_rate": 3.6422929197767955e-05,
      "loss": 0.0638,
      "step": 11287
    },
    {
      "epoch": 0.8180599340508026,
      "grad_norm": 1.5952353477478027,
      "learning_rate": 3.6408435393869125e-05,
      "loss": 0.0515,
      "step": 11288
    },
    {
      "epoch": 0.8181324056962713,
      "grad_norm": 1.2244946956634521,
      "learning_rate": 3.639394158997029e-05,
      "loss": 0.0404,
      "step": 11289
    },
    {
      "epoch": 0.8182048773417401,
      "grad_norm": 1.4974710941314697,
      "learning_rate": 3.637944778607146e-05,
      "loss": 0.0398,
      "step": 11290
    },
    {
      "epoch": 0.8182773489872087,
      "grad_norm": 1.2208179235458374,
      "learning_rate": 3.636495398217262e-05,
      "loss": 0.0133,
      "step": 11291
    },
    {
      "epoch": 0.8183498206326775,
      "grad_norm": 0.08083202689886093,
      "learning_rate": 3.6350460178273785e-05,
      "loss": 0.0009,
      "step": 11292
    },
    {
      "epoch": 0.8184222922781462,
      "grad_norm": 3.6177313327789307,
      "learning_rate": 3.6335966374374955e-05,
      "loss": 0.0686,
      "step": 11293
    },
    {
      "epoch": 0.8184947639236149,
      "grad_norm": 0.22977451980113983,
      "learning_rate": 3.6321472570476125e-05,
      "loss": 0.0048,
      "step": 11294
    },
    {
      "epoch": 0.8185672355690836,
      "grad_norm": 2.561650514602661,
      "learning_rate": 3.630697876657729e-05,
      "loss": 0.1392,
      "step": 11295
    },
    {
      "epoch": 0.8186397072145523,
      "grad_norm": 1.465896725654602,
      "learning_rate": 3.629248496267846e-05,
      "loss": 0.1091,
      "step": 11296
    },
    {
      "epoch": 0.818712178860021,
      "grad_norm": 2.557692766189575,
      "learning_rate": 3.627799115877962e-05,
      "loss": 0.0792,
      "step": 11297
    },
    {
      "epoch": 0.8187846505054898,
      "grad_norm": 2.1320817470550537,
      "learning_rate": 3.6263497354880785e-05,
      "loss": 0.0771,
      "step": 11298
    },
    {
      "epoch": 0.8188571221509584,
      "grad_norm": 0.6177921295166016,
      "learning_rate": 3.6249003550981955e-05,
      "loss": 0.0095,
      "step": 11299
    },
    {
      "epoch": 0.8189295937964272,
      "grad_norm": 2.273561477661133,
      "learning_rate": 3.6234509747083125e-05,
      "loss": 0.0282,
      "step": 11300
    },
    {
      "epoch": 0.8190020654418959,
      "grad_norm": 1.749176025390625,
      "learning_rate": 3.622001594318429e-05,
      "loss": 0.0544,
      "step": 11301
    },
    {
      "epoch": 0.8190745370873646,
      "grad_norm": 3.744743824005127,
      "learning_rate": 3.620552213928546e-05,
      "loss": 0.0873,
      "step": 11302
    },
    {
      "epoch": 0.8191470087328333,
      "grad_norm": 1.4098304510116577,
      "learning_rate": 3.619102833538662e-05,
      "loss": 0.0569,
      "step": 11303
    },
    {
      "epoch": 0.819219480378302,
      "grad_norm": 3.1707849502563477,
      "learning_rate": 3.6176534531487785e-05,
      "loss": 0.0646,
      "step": 11304
    },
    {
      "epoch": 0.8192919520237707,
      "grad_norm": 0.10859318822622299,
      "learning_rate": 3.6162040727588955e-05,
      "loss": 0.0015,
      "step": 11305
    },
    {
      "epoch": 0.8193644236692395,
      "grad_norm": 0.378371000289917,
      "learning_rate": 3.6147546923690125e-05,
      "loss": 0.004,
      "step": 11306
    },
    {
      "epoch": 0.8194368953147081,
      "grad_norm": 1.6429632902145386,
      "learning_rate": 3.6133053119791295e-05,
      "loss": 0.036,
      "step": 11307
    },
    {
      "epoch": 0.8195093669601768,
      "grad_norm": 2.0683038234710693,
      "learning_rate": 3.611855931589246e-05,
      "loss": 0.0679,
      "step": 11308
    },
    {
      "epoch": 0.8195818386056456,
      "grad_norm": 1.2623858451843262,
      "learning_rate": 3.610406551199362e-05,
      "loss": 0.0414,
      "step": 11309
    },
    {
      "epoch": 0.8196543102511142,
      "grad_norm": 0.4451102614402771,
      "learning_rate": 3.608957170809479e-05,
      "loss": 0.0089,
      "step": 11310
    },
    {
      "epoch": 0.819726781896583,
      "grad_norm": 5.1634931564331055,
      "learning_rate": 3.607507790419596e-05,
      "loss": 0.0678,
      "step": 11311
    },
    {
      "epoch": 0.8197992535420516,
      "grad_norm": 3.4040331840515137,
      "learning_rate": 3.6060584100297125e-05,
      "loss": 0.0327,
      "step": 11312
    },
    {
      "epoch": 0.8198717251875204,
      "grad_norm": 0.9919715523719788,
      "learning_rate": 3.6046090296398295e-05,
      "loss": 0.0265,
      "step": 11313
    },
    {
      "epoch": 0.8199441968329891,
      "grad_norm": 0.040421098470687866,
      "learning_rate": 3.603159649249946e-05,
      "loss": 0.0006,
      "step": 11314
    },
    {
      "epoch": 0.8200166684784578,
      "grad_norm": 3.09270977973938,
      "learning_rate": 3.601710268860062e-05,
      "loss": 0.0373,
      "step": 11315
    },
    {
      "epoch": 0.8200891401239265,
      "grad_norm": 0.9614869356155396,
      "learning_rate": 3.600260888470179e-05,
      "loss": 0.0383,
      "step": 11316
    },
    {
      "epoch": 0.8201616117693952,
      "grad_norm": 0.5094402432441711,
      "learning_rate": 3.598811508080296e-05,
      "loss": 0.0089,
      "step": 11317
    },
    {
      "epoch": 0.8202340834148639,
      "grad_norm": 1.5392175912857056,
      "learning_rate": 3.5973621276904125e-05,
      "loss": 0.0709,
      "step": 11318
    },
    {
      "epoch": 0.8203065550603327,
      "grad_norm": 1.3754911422729492,
      "learning_rate": 3.5959127473005295e-05,
      "loss": 0.0148,
      "step": 11319
    },
    {
      "epoch": 0.8203790267058013,
      "grad_norm": 1.4209729433059692,
      "learning_rate": 3.594463366910646e-05,
      "loss": 0.0387,
      "step": 11320
    },
    {
      "epoch": 0.8204514983512701,
      "grad_norm": 6.503864765167236,
      "learning_rate": 3.593013986520762e-05,
      "loss": 0.2009,
      "step": 11321
    },
    {
      "epoch": 0.8205239699967388,
      "grad_norm": 2.4276506900787354,
      "learning_rate": 3.591564606130879e-05,
      "loss": 0.0507,
      "step": 11322
    },
    {
      "epoch": 0.8205964416422075,
      "grad_norm": 2.2325925827026367,
      "learning_rate": 3.590115225740996e-05,
      "loss": 0.0761,
      "step": 11323
    },
    {
      "epoch": 0.8206689132876762,
      "grad_norm": 0.5534606575965881,
      "learning_rate": 3.5886658453511125e-05,
      "loss": 0.0154,
      "step": 11324
    },
    {
      "epoch": 0.8207413849331449,
      "grad_norm": 0.9461169838905334,
      "learning_rate": 3.5872164649612295e-05,
      "loss": 0.0168,
      "step": 11325
    },
    {
      "epoch": 0.8208138565786136,
      "grad_norm": 1.2539702653884888,
      "learning_rate": 3.585767084571346e-05,
      "loss": 0.0246,
      "step": 11326
    },
    {
      "epoch": 0.8208863282240824,
      "grad_norm": 1.0752495527267456,
      "learning_rate": 3.584317704181462e-05,
      "loss": 0.0237,
      "step": 11327
    },
    {
      "epoch": 0.820958799869551,
      "grad_norm": 0.34204337000846863,
      "learning_rate": 3.582868323791579e-05,
      "loss": 0.0032,
      "step": 11328
    },
    {
      "epoch": 0.8210312715150198,
      "grad_norm": 3.558978796005249,
      "learning_rate": 3.581418943401696e-05,
      "loss": 0.0273,
      "step": 11329
    },
    {
      "epoch": 0.8211037431604885,
      "grad_norm": 0.06711062788963318,
      "learning_rate": 3.5799695630118125e-05,
      "loss": 0.001,
      "step": 11330
    },
    {
      "epoch": 0.8211762148059571,
      "grad_norm": 1.014883279800415,
      "learning_rate": 3.5785201826219295e-05,
      "loss": 0.0233,
      "step": 11331
    },
    {
      "epoch": 0.8212486864514259,
      "grad_norm": 0.4268400967121124,
      "learning_rate": 3.577070802232046e-05,
      "loss": 0.0042,
      "step": 11332
    },
    {
      "epoch": 0.8213211580968945,
      "grad_norm": 1.1244312524795532,
      "learning_rate": 3.575621421842162e-05,
      "loss": 0.0271,
      "step": 11333
    },
    {
      "epoch": 0.8213936297423633,
      "grad_norm": 0.4898875057697296,
      "learning_rate": 3.574172041452279e-05,
      "loss": 0.0132,
      "step": 11334
    },
    {
      "epoch": 0.821466101387832,
      "grad_norm": 0.17842864990234375,
      "learning_rate": 3.572722661062396e-05,
      "loss": 0.0114,
      "step": 11335
    },
    {
      "epoch": 0.8215385730333007,
      "grad_norm": 1.5282026529312134,
      "learning_rate": 3.5712732806725125e-05,
      "loss": 0.0917,
      "step": 11336
    },
    {
      "epoch": 0.8216110446787694,
      "grad_norm": 1.5226348638534546,
      "learning_rate": 3.5698239002826295e-05,
      "loss": 0.0201,
      "step": 11337
    },
    {
      "epoch": 0.8216835163242382,
      "grad_norm": 1.995938777923584,
      "learning_rate": 3.568374519892746e-05,
      "loss": 0.0313,
      "step": 11338
    },
    {
      "epoch": 0.8217559879697068,
      "grad_norm": 2.024167537689209,
      "learning_rate": 3.566925139502862e-05,
      "loss": 0.0619,
      "step": 11339
    },
    {
      "epoch": 0.8218284596151756,
      "grad_norm": 7.596307277679443,
      "learning_rate": 3.56547575911298e-05,
      "loss": 0.1603,
      "step": 11340
    },
    {
      "epoch": 0.8219009312606442,
      "grad_norm": 1.55231773853302,
      "learning_rate": 3.564026378723096e-05,
      "loss": 0.0301,
      "step": 11341
    },
    {
      "epoch": 0.821973402906113,
      "grad_norm": 0.5121769905090332,
      "learning_rate": 3.5625769983332125e-05,
      "loss": 0.0182,
      "step": 11342
    },
    {
      "epoch": 0.8220458745515817,
      "grad_norm": 1.2727857828140259,
      "learning_rate": 3.5611276179433295e-05,
      "loss": 0.0197,
      "step": 11343
    },
    {
      "epoch": 0.8221183461970504,
      "grad_norm": 0.925504744052887,
      "learning_rate": 3.559678237553446e-05,
      "loss": 0.0294,
      "step": 11344
    },
    {
      "epoch": 0.8221908178425191,
      "grad_norm": 1.4510327577590942,
      "learning_rate": 3.558228857163563e-05,
      "loss": 0.0337,
      "step": 11345
    },
    {
      "epoch": 0.8222632894879878,
      "grad_norm": 2.534414768218994,
      "learning_rate": 3.55677947677368e-05,
      "loss": 0.0997,
      "step": 11346
    },
    {
      "epoch": 0.8223357611334565,
      "grad_norm": 1.4677331447601318,
      "learning_rate": 3.555330096383796e-05,
      "loss": 0.1106,
      "step": 11347
    },
    {
      "epoch": 0.8224082327789253,
      "grad_norm": 1.1739771366119385,
      "learning_rate": 3.553880715993913e-05,
      "loss": 0.0183,
      "step": 11348
    },
    {
      "epoch": 0.8224807044243939,
      "grad_norm": 1.7369956970214844,
      "learning_rate": 3.5524313356040294e-05,
      "loss": 0.0431,
      "step": 11349
    },
    {
      "epoch": 0.8225531760698627,
      "grad_norm": 1.8624656200408936,
      "learning_rate": 3.550981955214146e-05,
      "loss": 0.0792,
      "step": 11350
    },
    {
      "epoch": 0.8226256477153314,
      "grad_norm": 1.509494662284851,
      "learning_rate": 3.549532574824263e-05,
      "loss": 0.0828,
      "step": 11351
    },
    {
      "epoch": 0.8226981193608001,
      "grad_norm": 1.2028337717056274,
      "learning_rate": 3.54808319443438e-05,
      "loss": 0.0291,
      "step": 11352
    },
    {
      "epoch": 0.8227705910062688,
      "grad_norm": 1.751259446144104,
      "learning_rate": 3.546633814044496e-05,
      "loss": 0.0755,
      "step": 11353
    },
    {
      "epoch": 0.8228430626517375,
      "grad_norm": 0.7492761015892029,
      "learning_rate": 3.545184433654613e-05,
      "loss": 0.0342,
      "step": 11354
    },
    {
      "epoch": 0.8229155342972062,
      "grad_norm": 1.7225182056427002,
      "learning_rate": 3.5437350532647294e-05,
      "loss": 0.1133,
      "step": 11355
    },
    {
      "epoch": 0.822988005942675,
      "grad_norm": 3.520637273788452,
      "learning_rate": 3.542285672874846e-05,
      "loss": 0.0981,
      "step": 11356
    },
    {
      "epoch": 0.8230604775881436,
      "grad_norm": 0.7822564244270325,
      "learning_rate": 3.540836292484963e-05,
      "loss": 0.0239,
      "step": 11357
    },
    {
      "epoch": 0.8231329492336124,
      "grad_norm": 0.7055180668830872,
      "learning_rate": 3.53938691209508e-05,
      "loss": 0.0296,
      "step": 11358
    },
    {
      "epoch": 0.8232054208790811,
      "grad_norm": 0.2323313057422638,
      "learning_rate": 3.537937531705196e-05,
      "loss": 0.008,
      "step": 11359
    },
    {
      "epoch": 0.8232778925245497,
      "grad_norm": 0.8599575757980347,
      "learning_rate": 3.536488151315313e-05,
      "loss": 0.0498,
      "step": 11360
    },
    {
      "epoch": 0.8233503641700185,
      "grad_norm": 0.8409358263015747,
      "learning_rate": 3.5350387709254294e-05,
      "loss": 0.0285,
      "step": 11361
    },
    {
      "epoch": 0.8234228358154871,
      "grad_norm": 1.6064869165420532,
      "learning_rate": 3.533589390535546e-05,
      "loss": 0.0973,
      "step": 11362
    },
    {
      "epoch": 0.8234953074609559,
      "grad_norm": 0.6704728603363037,
      "learning_rate": 3.532140010145663e-05,
      "loss": 0.0126,
      "step": 11363
    },
    {
      "epoch": 0.8235677791064246,
      "grad_norm": 1.7310389280319214,
      "learning_rate": 3.53069062975578e-05,
      "loss": 0.0245,
      "step": 11364
    },
    {
      "epoch": 0.8236402507518933,
      "grad_norm": 2.8584535121917725,
      "learning_rate": 3.529241249365896e-05,
      "loss": 0.0671,
      "step": 11365
    },
    {
      "epoch": 0.823712722397362,
      "grad_norm": 0.633911669254303,
      "learning_rate": 3.527791868976013e-05,
      "loss": 0.0174,
      "step": 11366
    },
    {
      "epoch": 0.8237851940428308,
      "grad_norm": 1.5502585172653198,
      "learning_rate": 3.5263424885861294e-05,
      "loss": 0.0591,
      "step": 11367
    },
    {
      "epoch": 0.8238576656882994,
      "grad_norm": 2.311906576156616,
      "learning_rate": 3.524893108196246e-05,
      "loss": 0.0617,
      "step": 11368
    },
    {
      "epoch": 0.8239301373337682,
      "grad_norm": 2.8976399898529053,
      "learning_rate": 3.5234437278063634e-05,
      "loss": 0.0516,
      "step": 11369
    },
    {
      "epoch": 0.8240026089792368,
      "grad_norm": 1.0949195623397827,
      "learning_rate": 3.52199434741648e-05,
      "loss": 0.0241,
      "step": 11370
    },
    {
      "epoch": 0.8240750806247056,
      "grad_norm": 2.3522446155548096,
      "learning_rate": 3.520544967026596e-05,
      "loss": 0.0463,
      "step": 11371
    },
    {
      "epoch": 0.8241475522701743,
      "grad_norm": 0.7215570211410522,
      "learning_rate": 3.519095586636713e-05,
      "loss": 0.0062,
      "step": 11372
    },
    {
      "epoch": 0.824220023915643,
      "grad_norm": 0.04182879999279976,
      "learning_rate": 3.5176462062468294e-05,
      "loss": 0.0009,
      "step": 11373
    },
    {
      "epoch": 0.8242924955611117,
      "grad_norm": 2.701335906982422,
      "learning_rate": 3.5161968258569464e-05,
      "loss": 0.0957,
      "step": 11374
    },
    {
      "epoch": 0.8243649672065805,
      "grad_norm": 1.3900763988494873,
      "learning_rate": 3.5147474454670634e-05,
      "loss": 0.0141,
      "step": 11375
    },
    {
      "epoch": 0.8244374388520491,
      "grad_norm": 0.64615398645401,
      "learning_rate": 3.51329806507718e-05,
      "loss": 0.0162,
      "step": 11376
    },
    {
      "epoch": 0.8245099104975179,
      "grad_norm": 1.3722741603851318,
      "learning_rate": 3.511848684687296e-05,
      "loss": 0.0177,
      "step": 11377
    },
    {
      "epoch": 0.8245823821429865,
      "grad_norm": 3.6971709728240967,
      "learning_rate": 3.510399304297413e-05,
      "loss": 0.1248,
      "step": 11378
    },
    {
      "epoch": 0.8246548537884553,
      "grad_norm": 1.9294548034667969,
      "learning_rate": 3.5089499239075294e-05,
      "loss": 0.0868,
      "step": 11379
    },
    {
      "epoch": 0.824727325433924,
      "grad_norm": 0.9298552870750427,
      "learning_rate": 3.5075005435176464e-05,
      "loss": 0.0261,
      "step": 11380
    },
    {
      "epoch": 0.8247997970793927,
      "grad_norm": 0.4232844114303589,
      "learning_rate": 3.5060511631277634e-05,
      "loss": 0.0067,
      "step": 11381
    },
    {
      "epoch": 0.8248722687248614,
      "grad_norm": 0.6053792238235474,
      "learning_rate": 3.50460178273788e-05,
      "loss": 0.0107,
      "step": 11382
    },
    {
      "epoch": 0.82494474037033,
      "grad_norm": 0.7350805401802063,
      "learning_rate": 3.503152402347996e-05,
      "loss": 0.0176,
      "step": 11383
    },
    {
      "epoch": 0.8250172120157988,
      "grad_norm": 0.7559952139854431,
      "learning_rate": 3.501703021958113e-05,
      "loss": 0.0321,
      "step": 11384
    },
    {
      "epoch": 0.8250896836612676,
      "grad_norm": 2.412456750869751,
      "learning_rate": 3.5002536415682294e-05,
      "loss": 0.0704,
      "step": 11385
    },
    {
      "epoch": 0.8251621553067362,
      "grad_norm": 1.500335693359375,
      "learning_rate": 3.4988042611783464e-05,
      "loss": 0.0231,
      "step": 11386
    },
    {
      "epoch": 0.825234626952205,
      "grad_norm": 1.408755898475647,
      "learning_rate": 3.4973548807884634e-05,
      "loss": 0.0474,
      "step": 11387
    },
    {
      "epoch": 0.8253070985976737,
      "grad_norm": 1.4048882722854614,
      "learning_rate": 3.49590550039858e-05,
      "loss": 0.037,
      "step": 11388
    },
    {
      "epoch": 0.8253795702431423,
      "grad_norm": 0.8236592411994934,
      "learning_rate": 3.494456120008697e-05,
      "loss": 0.0359,
      "step": 11389
    },
    {
      "epoch": 0.8254520418886111,
      "grad_norm": 0.3590511083602905,
      "learning_rate": 3.493006739618813e-05,
      "loss": 0.0143,
      "step": 11390
    },
    {
      "epoch": 0.8255245135340797,
      "grad_norm": 1.8120442628860474,
      "learning_rate": 3.4915573592289294e-05,
      "loss": 0.036,
      "step": 11391
    },
    {
      "epoch": 0.8255969851795485,
      "grad_norm": 0.3688671290874481,
      "learning_rate": 3.490107978839047e-05,
      "loss": 0.0139,
      "step": 11392
    },
    {
      "epoch": 0.8256694568250172,
      "grad_norm": 2.6504061222076416,
      "learning_rate": 3.4886585984491634e-05,
      "loss": 0.101,
      "step": 11393
    },
    {
      "epoch": 0.8257419284704859,
      "grad_norm": 1.078768253326416,
      "learning_rate": 3.48720921805928e-05,
      "loss": 0.0214,
      "step": 11394
    },
    {
      "epoch": 0.8258144001159546,
      "grad_norm": 1.4908779859542847,
      "learning_rate": 3.485759837669397e-05,
      "loss": 0.0504,
      "step": 11395
    },
    {
      "epoch": 0.8258868717614234,
      "grad_norm": 2.3590662479400635,
      "learning_rate": 3.484310457279513e-05,
      "loss": 0.0998,
      "step": 11396
    },
    {
      "epoch": 0.825959343406892,
      "grad_norm": 1.3380128145217896,
      "learning_rate": 3.4828610768896294e-05,
      "loss": 0.0428,
      "step": 11397
    },
    {
      "epoch": 0.8260318150523608,
      "grad_norm": 0.6297324299812317,
      "learning_rate": 3.481411696499747e-05,
      "loss": 0.0066,
      "step": 11398
    },
    {
      "epoch": 0.8261042866978294,
      "grad_norm": 0.13168007135391235,
      "learning_rate": 3.4799623161098634e-05,
      "loss": 0.003,
      "step": 11399
    },
    {
      "epoch": 0.8261767583432982,
      "grad_norm": 1.165392518043518,
      "learning_rate": 3.47851293571998e-05,
      "loss": 0.0749,
      "step": 11400
    },
    {
      "epoch": 0.8262492299887669,
      "grad_norm": 3.4945313930511475,
      "learning_rate": 3.477063555330097e-05,
      "loss": 0.0987,
      "step": 11401
    },
    {
      "epoch": 0.8263217016342356,
      "grad_norm": 0.5272507667541504,
      "learning_rate": 3.475614174940213e-05,
      "loss": 0.0206,
      "step": 11402
    },
    {
      "epoch": 0.8263941732797043,
      "grad_norm": 1.229482889175415,
      "learning_rate": 3.47416479455033e-05,
      "loss": 0.0446,
      "step": 11403
    },
    {
      "epoch": 0.8264666449251731,
      "grad_norm": 1.3942266702651978,
      "learning_rate": 3.472715414160447e-05,
      "loss": 0.0487,
      "step": 11404
    },
    {
      "epoch": 0.8265391165706417,
      "grad_norm": 0.7386152744293213,
      "learning_rate": 3.4712660337705634e-05,
      "loss": 0.0272,
      "step": 11405
    },
    {
      "epoch": 0.8266115882161105,
      "grad_norm": 0.27660322189331055,
      "learning_rate": 3.46981665338068e-05,
      "loss": 0.0029,
      "step": 11406
    },
    {
      "epoch": 0.8266840598615791,
      "grad_norm": 2.1413631439208984,
      "learning_rate": 3.468367272990797e-05,
      "loss": 0.0738,
      "step": 11407
    },
    {
      "epoch": 0.8267565315070479,
      "grad_norm": 3.1015236377716064,
      "learning_rate": 3.466917892600913e-05,
      "loss": 0.1098,
      "step": 11408
    },
    {
      "epoch": 0.8268290031525166,
      "grad_norm": 1.1590713262557983,
      "learning_rate": 3.46546851221103e-05,
      "loss": 0.0672,
      "step": 11409
    },
    {
      "epoch": 0.8269014747979853,
      "grad_norm": 1.0612138509750366,
      "learning_rate": 3.464019131821147e-05,
      "loss": 0.0156,
      "step": 11410
    },
    {
      "epoch": 0.826973946443454,
      "grad_norm": 1.3754912614822388,
      "learning_rate": 3.4625697514312634e-05,
      "loss": 0.0322,
      "step": 11411
    },
    {
      "epoch": 0.8270464180889228,
      "grad_norm": 9.273947715759277,
      "learning_rate": 3.46112037104138e-05,
      "loss": 0.1001,
      "step": 11412
    },
    {
      "epoch": 0.8271188897343914,
      "grad_norm": 1.302984595298767,
      "learning_rate": 3.459670990651497e-05,
      "loss": 0.0343,
      "step": 11413
    },
    {
      "epoch": 0.8271913613798602,
      "grad_norm": 0.8328826427459717,
      "learning_rate": 3.458221610261613e-05,
      "loss": 0.0105,
      "step": 11414
    },
    {
      "epoch": 0.8272638330253288,
      "grad_norm": 1.487636923789978,
      "learning_rate": 3.45677222987173e-05,
      "loss": 0.068,
      "step": 11415
    },
    {
      "epoch": 0.8273363046707976,
      "grad_norm": 0.8186066150665283,
      "learning_rate": 3.455322849481847e-05,
      "loss": 0.0353,
      "step": 11416
    },
    {
      "epoch": 0.8274087763162663,
      "grad_norm": 1.1956572532653809,
      "learning_rate": 3.4538734690919633e-05,
      "loss": 0.026,
      "step": 11417
    },
    {
      "epoch": 0.827481247961735,
      "grad_norm": 2.3842830657958984,
      "learning_rate": 3.45242408870208e-05,
      "loss": 0.0284,
      "step": 11418
    },
    {
      "epoch": 0.8275537196072037,
      "grad_norm": 0.18616360425949097,
      "learning_rate": 3.450974708312197e-05,
      "loss": 0.0104,
      "step": 11419
    },
    {
      "epoch": 0.8276261912526723,
      "grad_norm": 0.3611232042312622,
      "learning_rate": 3.449525327922313e-05,
      "loss": 0.0066,
      "step": 11420
    },
    {
      "epoch": 0.8276986628981411,
      "grad_norm": 0.7790091633796692,
      "learning_rate": 3.44807594753243e-05,
      "loss": 0.0226,
      "step": 11421
    },
    {
      "epoch": 0.8277711345436098,
      "grad_norm": 1.9094078540802002,
      "learning_rate": 3.446626567142547e-05,
      "loss": 0.0219,
      "step": 11422
    },
    {
      "epoch": 0.8278436061890785,
      "grad_norm": 1.2808634042739868,
      "learning_rate": 3.445177186752663e-05,
      "loss": 0.0783,
      "step": 11423
    },
    {
      "epoch": 0.8279160778345472,
      "grad_norm": 0.899315595626831,
      "learning_rate": 3.4437278063627797e-05,
      "loss": 0.0159,
      "step": 11424
    },
    {
      "epoch": 0.827988549480016,
      "grad_norm": 1.7951769828796387,
      "learning_rate": 3.442278425972897e-05,
      "loss": 0.0347,
      "step": 11425
    },
    {
      "epoch": 0.8280610211254846,
      "grad_norm": 0.22556351125240326,
      "learning_rate": 3.440829045583014e-05,
      "loss": 0.0022,
      "step": 11426
    },
    {
      "epoch": 0.8281334927709534,
      "grad_norm": 1.4686169624328613,
      "learning_rate": 3.439379665193131e-05,
      "loss": 0.078,
      "step": 11427
    },
    {
      "epoch": 0.828205964416422,
      "grad_norm": 0.5293810367584229,
      "learning_rate": 3.437930284803247e-05,
      "loss": 0.0067,
      "step": 11428
    },
    {
      "epoch": 0.8282784360618908,
      "grad_norm": 0.08984721451997757,
      "learning_rate": 3.436480904413363e-05,
      "loss": 0.0011,
      "step": 11429
    },
    {
      "epoch": 0.8283509077073595,
      "grad_norm": 1.3443279266357422,
      "learning_rate": 3.43503152402348e-05,
      "loss": 0.0084,
      "step": 11430
    },
    {
      "epoch": 0.8284233793528282,
      "grad_norm": 1.012381911277771,
      "learning_rate": 3.4335821436335967e-05,
      "loss": 0.0586,
      "step": 11431
    },
    {
      "epoch": 0.8284958509982969,
      "grad_norm": 0.386039137840271,
      "learning_rate": 3.4321327632437137e-05,
      "loss": 0.0109,
      "step": 11432
    },
    {
      "epoch": 0.8285683226437657,
      "grad_norm": 4.3835248947143555,
      "learning_rate": 3.4306833828538307e-05,
      "loss": 0.1016,
      "step": 11433
    },
    {
      "epoch": 0.8286407942892343,
      "grad_norm": 1.8308779001235962,
      "learning_rate": 3.429234002463947e-05,
      "loss": 0.04,
      "step": 11434
    },
    {
      "epoch": 0.8287132659347031,
      "grad_norm": 3.303344488143921,
      "learning_rate": 3.427784622074063e-05,
      "loss": 0.1338,
      "step": 11435
    },
    {
      "epoch": 0.8287857375801717,
      "grad_norm": 0.19587454199790955,
      "learning_rate": 3.42633524168418e-05,
      "loss": 0.0047,
      "step": 11436
    },
    {
      "epoch": 0.8288582092256405,
      "grad_norm": 1.6180306673049927,
      "learning_rate": 3.4248858612942966e-05,
      "loss": 0.0585,
      "step": 11437
    },
    {
      "epoch": 0.8289306808711092,
      "grad_norm": 1.4896619319915771,
      "learning_rate": 3.4234364809044136e-05,
      "loss": 0.0779,
      "step": 11438
    },
    {
      "epoch": 0.8290031525165779,
      "grad_norm": 1.3574379682540894,
      "learning_rate": 3.4219871005145307e-05,
      "loss": 0.0405,
      "step": 11439
    },
    {
      "epoch": 0.8290756241620466,
      "grad_norm": 3.08335542678833,
      "learning_rate": 3.420537720124647e-05,
      "loss": 0.047,
      "step": 11440
    },
    {
      "epoch": 0.8291480958075154,
      "grad_norm": 2.3933563232421875,
      "learning_rate": 3.419088339734763e-05,
      "loss": 0.0423,
      "step": 11441
    },
    {
      "epoch": 0.829220567452984,
      "grad_norm": 0.5088218450546265,
      "learning_rate": 3.41763895934488e-05,
      "loss": 0.0228,
      "step": 11442
    },
    {
      "epoch": 0.8292930390984528,
      "grad_norm": 0.45415374636650085,
      "learning_rate": 3.4161895789549966e-05,
      "loss": 0.0115,
      "step": 11443
    },
    {
      "epoch": 0.8293655107439214,
      "grad_norm": 0.8271790146827698,
      "learning_rate": 3.4147401985651136e-05,
      "loss": 0.0213,
      "step": 11444
    },
    {
      "epoch": 0.8294379823893901,
      "grad_norm": 0.8966783881187439,
      "learning_rate": 3.4132908181752306e-05,
      "loss": 0.0086,
      "step": 11445
    },
    {
      "epoch": 0.8295104540348589,
      "grad_norm": 0.837239146232605,
      "learning_rate": 3.411841437785347e-05,
      "loss": 0.0083,
      "step": 11446
    },
    {
      "epoch": 0.8295829256803275,
      "grad_norm": 3.7748959064483643,
      "learning_rate": 3.410392057395463e-05,
      "loss": 0.0609,
      "step": 11447
    },
    {
      "epoch": 0.8296553973257963,
      "grad_norm": 0.9412623643875122,
      "learning_rate": 3.40894267700558e-05,
      "loss": 0.0244,
      "step": 11448
    },
    {
      "epoch": 0.829727868971265,
      "grad_norm": 2.327012062072754,
      "learning_rate": 3.4074932966156966e-05,
      "loss": 0.0508,
      "step": 11449
    },
    {
      "epoch": 0.8298003406167337,
      "grad_norm": 0.7852983474731445,
      "learning_rate": 3.4060439162258136e-05,
      "loss": 0.0292,
      "step": 11450
    },
    {
      "epoch": 0.8298728122622024,
      "grad_norm": 1.3758487701416016,
      "learning_rate": 3.4045945358359306e-05,
      "loss": 0.0488,
      "step": 11451
    },
    {
      "epoch": 0.8299452839076711,
      "grad_norm": 0.6004839539527893,
      "learning_rate": 3.403145155446047e-05,
      "loss": 0.0075,
      "step": 11452
    },
    {
      "epoch": 0.8300177555531398,
      "grad_norm": 0.7587184906005859,
      "learning_rate": 3.401695775056163e-05,
      "loss": 0.0152,
      "step": 11453
    },
    {
      "epoch": 0.8300902271986086,
      "grad_norm": 0.8127679228782654,
      "learning_rate": 3.40024639466628e-05,
      "loss": 0.0337,
      "step": 11454
    },
    {
      "epoch": 0.8301626988440772,
      "grad_norm": 1.1550114154815674,
      "learning_rate": 3.398797014276397e-05,
      "loss": 0.0507,
      "step": 11455
    },
    {
      "epoch": 0.830235170489546,
      "grad_norm": 1.0985568761825562,
      "learning_rate": 3.3973476338865136e-05,
      "loss": 0.0537,
      "step": 11456
    },
    {
      "epoch": 0.8303076421350146,
      "grad_norm": 0.5762338638305664,
      "learning_rate": 3.3958982534966306e-05,
      "loss": 0.0262,
      "step": 11457
    },
    {
      "epoch": 0.8303801137804834,
      "grad_norm": 0.17863589525222778,
      "learning_rate": 3.394448873106747e-05,
      "loss": 0.002,
      "step": 11458
    },
    {
      "epoch": 0.8304525854259521,
      "grad_norm": 0.22526486217975616,
      "learning_rate": 3.392999492716863e-05,
      "loss": 0.0054,
      "step": 11459
    },
    {
      "epoch": 0.8305250570714208,
      "grad_norm": 1.557631492614746,
      "learning_rate": 3.39155011232698e-05,
      "loss": 0.0805,
      "step": 11460
    },
    {
      "epoch": 0.8305975287168895,
      "grad_norm": 0.6608707904815674,
      "learning_rate": 3.390100731937097e-05,
      "loss": 0.0232,
      "step": 11461
    },
    {
      "epoch": 0.8306700003623583,
      "grad_norm": 1.5594096183776855,
      "learning_rate": 3.3886513515472136e-05,
      "loss": 0.0344,
      "step": 11462
    },
    {
      "epoch": 0.8307424720078269,
      "grad_norm": 0.7003506422042847,
      "learning_rate": 3.3872019711573306e-05,
      "loss": 0.0211,
      "step": 11463
    },
    {
      "epoch": 0.8308149436532957,
      "grad_norm": 1.524850845336914,
      "learning_rate": 3.385752590767447e-05,
      "loss": 0.0464,
      "step": 11464
    },
    {
      "epoch": 0.8308874152987643,
      "grad_norm": 1.6217265129089355,
      "learning_rate": 3.384303210377563e-05,
      "loss": 0.0627,
      "step": 11465
    },
    {
      "epoch": 0.8309598869442331,
      "grad_norm": 0.41214925050735474,
      "learning_rate": 3.38285382998768e-05,
      "loss": 0.024,
      "step": 11466
    },
    {
      "epoch": 0.8310323585897018,
      "grad_norm": 0.32764866948127747,
      "learning_rate": 3.381404449597797e-05,
      "loss": 0.0159,
      "step": 11467
    },
    {
      "epoch": 0.8311048302351705,
      "grad_norm": 0.6372086405754089,
      "learning_rate": 3.379955069207914e-05,
      "loss": 0.0131,
      "step": 11468
    },
    {
      "epoch": 0.8311773018806392,
      "grad_norm": 1.9493193626403809,
      "learning_rate": 3.3785056888180306e-05,
      "loss": 0.0243,
      "step": 11469
    },
    {
      "epoch": 0.831249773526108,
      "grad_norm": 1.7022682428359985,
      "learning_rate": 3.377056308428147e-05,
      "loss": 0.0409,
      "step": 11470
    },
    {
      "epoch": 0.8313222451715766,
      "grad_norm": 1.2372242212295532,
      "learning_rate": 3.375606928038264e-05,
      "loss": 0.0233,
      "step": 11471
    },
    {
      "epoch": 0.8313947168170454,
      "grad_norm": 1.235171914100647,
      "learning_rate": 3.37415754764838e-05,
      "loss": 0.0588,
      "step": 11472
    },
    {
      "epoch": 0.831467188462514,
      "grad_norm": 1.3424923419952393,
      "learning_rate": 3.372708167258497e-05,
      "loss": 0.0293,
      "step": 11473
    },
    {
      "epoch": 0.8315396601079827,
      "grad_norm": 1.0156100988388062,
      "learning_rate": 3.371258786868614e-05,
      "loss": 0.0497,
      "step": 11474
    },
    {
      "epoch": 0.8316121317534515,
      "grad_norm": 0.9225105047225952,
      "learning_rate": 3.3698094064787306e-05,
      "loss": 0.0102,
      "step": 11475
    },
    {
      "epoch": 0.8316846033989201,
      "grad_norm": 1.5079952478408813,
      "learning_rate": 3.368360026088847e-05,
      "loss": 0.0146,
      "step": 11476
    },
    {
      "epoch": 0.8317570750443889,
      "grad_norm": 0.43913984298706055,
      "learning_rate": 3.366910645698964e-05,
      "loss": 0.0202,
      "step": 11477
    },
    {
      "epoch": 0.8318295466898576,
      "grad_norm": 2.030979871749878,
      "learning_rate": 3.36546126530908e-05,
      "loss": 0.0686,
      "step": 11478
    },
    {
      "epoch": 0.8319020183353263,
      "grad_norm": 1.3859024047851562,
      "learning_rate": 3.364011884919197e-05,
      "loss": 0.029,
      "step": 11479
    },
    {
      "epoch": 0.831974489980795,
      "grad_norm": 0.8168702721595764,
      "learning_rate": 3.362562504529314e-05,
      "loss": 0.0315,
      "step": 11480
    },
    {
      "epoch": 0.8320469616262637,
      "grad_norm": 2.192692995071411,
      "learning_rate": 3.3611131241394306e-05,
      "loss": 0.0423,
      "step": 11481
    },
    {
      "epoch": 0.8321194332717324,
      "grad_norm": 1.7338402271270752,
      "learning_rate": 3.359663743749547e-05,
      "loss": 0.0459,
      "step": 11482
    },
    {
      "epoch": 0.8321919049172012,
      "grad_norm": 2.025696277618408,
      "learning_rate": 3.358214363359664e-05,
      "loss": 0.0329,
      "step": 11483
    },
    {
      "epoch": 0.8322643765626698,
      "grad_norm": 5.3041605949401855,
      "learning_rate": 3.356764982969781e-05,
      "loss": 0.1114,
      "step": 11484
    },
    {
      "epoch": 0.8323368482081386,
      "grad_norm": 2.4271068572998047,
      "learning_rate": 3.355315602579897e-05,
      "loss": 0.1373,
      "step": 11485
    },
    {
      "epoch": 0.8324093198536072,
      "grad_norm": 1.4706557989120483,
      "learning_rate": 3.353866222190014e-05,
      "loss": 0.0596,
      "step": 11486
    },
    {
      "epoch": 0.832481791499076,
      "grad_norm": 0.26918601989746094,
      "learning_rate": 3.3524168418001306e-05,
      "loss": 0.0081,
      "step": 11487
    },
    {
      "epoch": 0.8325542631445447,
      "grad_norm": 2.6994688510894775,
      "learning_rate": 3.350967461410247e-05,
      "loss": 0.1106,
      "step": 11488
    },
    {
      "epoch": 0.8326267347900134,
      "grad_norm": 1.0340378284454346,
      "learning_rate": 3.349518081020364e-05,
      "loss": 0.0144,
      "step": 11489
    },
    {
      "epoch": 0.8326992064354821,
      "grad_norm": 1.6295372247695923,
      "learning_rate": 3.348068700630481e-05,
      "loss": 0.0511,
      "step": 11490
    },
    {
      "epoch": 0.8327716780809509,
      "grad_norm": 0.8023605346679688,
      "learning_rate": 3.346619320240597e-05,
      "loss": 0.0184,
      "step": 11491
    },
    {
      "epoch": 0.8328441497264195,
      "grad_norm": 3.2089133262634277,
      "learning_rate": 3.345169939850714e-05,
      "loss": 0.1332,
      "step": 11492
    },
    {
      "epoch": 0.8329166213718883,
      "grad_norm": 0.22656765580177307,
      "learning_rate": 3.3437205594608306e-05,
      "loss": 0.0107,
      "step": 11493
    },
    {
      "epoch": 0.8329890930173569,
      "grad_norm": 3.8982248306274414,
      "learning_rate": 3.342271179070947e-05,
      "loss": 0.0313,
      "step": 11494
    },
    {
      "epoch": 0.8330615646628257,
      "grad_norm": 0.42280545830726624,
      "learning_rate": 3.340821798681064e-05,
      "loss": 0.013,
      "step": 11495
    },
    {
      "epoch": 0.8331340363082944,
      "grad_norm": 4.121004581451416,
      "learning_rate": 3.339372418291181e-05,
      "loss": 0.068,
      "step": 11496
    },
    {
      "epoch": 0.833206507953763,
      "grad_norm": 1.9467748403549194,
      "learning_rate": 3.337923037901297e-05,
      "loss": 0.0232,
      "step": 11497
    },
    {
      "epoch": 0.8332789795992318,
      "grad_norm": 2.657089948654175,
      "learning_rate": 3.336473657511414e-05,
      "loss": 0.0659,
      "step": 11498
    },
    {
      "epoch": 0.8333514512447006,
      "grad_norm": 1.4010162353515625,
      "learning_rate": 3.3350242771215305e-05,
      "loss": 0.0455,
      "step": 11499
    },
    {
      "epoch": 0.8334239228901692,
      "grad_norm": 1.1954121589660645,
      "learning_rate": 3.333574896731647e-05,
      "loss": 0.0197,
      "step": 11500
    },
    {
      "epoch": 0.833496394535638,
      "grad_norm": 0.192517951130867,
      "learning_rate": 3.332125516341764e-05,
      "loss": 0.0034,
      "step": 11501
    },
    {
      "epoch": 0.8335688661811066,
      "grad_norm": 0.3137034475803375,
      "learning_rate": 3.330676135951881e-05,
      "loss": 0.0072,
      "step": 11502
    },
    {
      "epoch": 0.8336413378265753,
      "grad_norm": 1.2788699865341187,
      "learning_rate": 3.329226755561997e-05,
      "loss": 0.0325,
      "step": 11503
    },
    {
      "epoch": 0.8337138094720441,
      "grad_norm": 0.631732702255249,
      "learning_rate": 3.327777375172114e-05,
      "loss": 0.0166,
      "step": 11504
    },
    {
      "epoch": 0.8337862811175127,
      "grad_norm": 4.953127861022949,
      "learning_rate": 3.3263279947822305e-05,
      "loss": 0.0441,
      "step": 11505
    },
    {
      "epoch": 0.8338587527629815,
      "grad_norm": 0.9109155535697937,
      "learning_rate": 3.324878614392347e-05,
      "loss": 0.0359,
      "step": 11506
    },
    {
      "epoch": 0.8339312244084502,
      "grad_norm": 3.081369638442993,
      "learning_rate": 3.323429234002464e-05,
      "loss": 0.0247,
      "step": 11507
    },
    {
      "epoch": 0.8340036960539189,
      "grad_norm": 2.4184932708740234,
      "learning_rate": 3.321979853612581e-05,
      "loss": 0.0703,
      "step": 11508
    },
    {
      "epoch": 0.8340761676993876,
      "grad_norm": 0.7285966873168945,
      "learning_rate": 3.320530473222698e-05,
      "loss": 0.0339,
      "step": 11509
    },
    {
      "epoch": 0.8341486393448563,
      "grad_norm": 0.7296608686447144,
      "learning_rate": 3.319081092832814e-05,
      "loss": 0.0237,
      "step": 11510
    },
    {
      "epoch": 0.834221110990325,
      "grad_norm": 5.295395851135254,
      "learning_rate": 3.3176317124429305e-05,
      "loss": 0.0634,
      "step": 11511
    },
    {
      "epoch": 0.8342935826357938,
      "grad_norm": 0.6063275933265686,
      "learning_rate": 3.3161823320530475e-05,
      "loss": 0.0128,
      "step": 11512
    },
    {
      "epoch": 0.8343660542812624,
      "grad_norm": 2.213085889816284,
      "learning_rate": 3.3147329516631645e-05,
      "loss": 0.06,
      "step": 11513
    },
    {
      "epoch": 0.8344385259267312,
      "grad_norm": 1.7999252080917358,
      "learning_rate": 3.313283571273281e-05,
      "loss": 0.0269,
      "step": 11514
    },
    {
      "epoch": 0.8345109975721999,
      "grad_norm": 1.9683096408843994,
      "learning_rate": 3.311834190883398e-05,
      "loss": 0.0506,
      "step": 11515
    },
    {
      "epoch": 0.8345834692176686,
      "grad_norm": 1.0621705055236816,
      "learning_rate": 3.310384810493514e-05,
      "loss": 0.0483,
      "step": 11516
    },
    {
      "epoch": 0.8346559408631373,
      "grad_norm": 0.7208340764045715,
      "learning_rate": 3.3089354301036305e-05,
      "loss": 0.0137,
      "step": 11517
    },
    {
      "epoch": 0.834728412508606,
      "grad_norm": 0.4034952223300934,
      "learning_rate": 3.3074860497137475e-05,
      "loss": 0.0062,
      "step": 11518
    },
    {
      "epoch": 0.8348008841540747,
      "grad_norm": 3.069274663925171,
      "learning_rate": 3.3060366693238645e-05,
      "loss": 0.0758,
      "step": 11519
    },
    {
      "epoch": 0.8348733557995435,
      "grad_norm": 2.241637945175171,
      "learning_rate": 3.304587288933981e-05,
      "loss": 0.0142,
      "step": 11520
    },
    {
      "epoch": 0.8349458274450121,
      "grad_norm": 1.322823405265808,
      "learning_rate": 3.303137908544098e-05,
      "loss": 0.0661,
      "step": 11521
    },
    {
      "epoch": 0.8350182990904809,
      "grad_norm": 3.917097568511963,
      "learning_rate": 3.301688528154214e-05,
      "loss": 0.1699,
      "step": 11522
    },
    {
      "epoch": 0.8350907707359495,
      "grad_norm": 1.3094911575317383,
      "learning_rate": 3.3002391477643305e-05,
      "loss": 0.0242,
      "step": 11523
    },
    {
      "epoch": 0.8351632423814183,
      "grad_norm": 2.0437679290771484,
      "learning_rate": 3.2987897673744475e-05,
      "loss": 0.0208,
      "step": 11524
    },
    {
      "epoch": 0.835235714026887,
      "grad_norm": 0.2194194197654724,
      "learning_rate": 3.2973403869845645e-05,
      "loss": 0.0075,
      "step": 11525
    },
    {
      "epoch": 0.8353081856723557,
      "grad_norm": 0.2010272890329361,
      "learning_rate": 3.295891006594681e-05,
      "loss": 0.0016,
      "step": 11526
    },
    {
      "epoch": 0.8353806573178244,
      "grad_norm": 0.42034414410591125,
      "learning_rate": 3.294441626204798e-05,
      "loss": 0.017,
      "step": 11527
    },
    {
      "epoch": 0.8354531289632932,
      "grad_norm": 2.373749256134033,
      "learning_rate": 3.292992245814914e-05,
      "loss": 0.069,
      "step": 11528
    },
    {
      "epoch": 0.8355256006087618,
      "grad_norm": 0.23252315819263458,
      "learning_rate": 3.2915428654250305e-05,
      "loss": 0.0057,
      "step": 11529
    },
    {
      "epoch": 0.8355980722542306,
      "grad_norm": 2.118187427520752,
      "learning_rate": 3.2900934850351475e-05,
      "loss": 0.0452,
      "step": 11530
    },
    {
      "epoch": 0.8356705438996992,
      "grad_norm": 2.4574387073516846,
      "learning_rate": 3.2886441046452645e-05,
      "loss": 0.0818,
      "step": 11531
    },
    {
      "epoch": 0.8357430155451679,
      "grad_norm": 1.4443798065185547,
      "learning_rate": 3.287194724255381e-05,
      "loss": 0.0597,
      "step": 11532
    },
    {
      "epoch": 0.8358154871906367,
      "grad_norm": 2.0362579822540283,
      "learning_rate": 3.285745343865498e-05,
      "loss": 0.0312,
      "step": 11533
    },
    {
      "epoch": 0.8358879588361053,
      "grad_norm": 1.700862169265747,
      "learning_rate": 3.284295963475614e-05,
      "loss": 0.0546,
      "step": 11534
    },
    {
      "epoch": 0.8359604304815741,
      "grad_norm": 3.4500627517700195,
      "learning_rate": 3.2828465830857305e-05,
      "loss": 0.0986,
      "step": 11535
    },
    {
      "epoch": 0.8360329021270428,
      "grad_norm": 3.4518940448760986,
      "learning_rate": 3.2813972026958475e-05,
      "loss": 0.0428,
      "step": 11536
    },
    {
      "epoch": 0.8361053737725115,
      "grad_norm": 0.9432293772697449,
      "learning_rate": 3.2799478223059645e-05,
      "loss": 0.0376,
      "step": 11537
    },
    {
      "epoch": 0.8361778454179802,
      "grad_norm": 0.7584227919578552,
      "learning_rate": 3.278498441916081e-05,
      "loss": 0.0145,
      "step": 11538
    },
    {
      "epoch": 0.8362503170634489,
      "grad_norm": 1.0379908084869385,
      "learning_rate": 3.277049061526198e-05,
      "loss": 0.0499,
      "step": 11539
    },
    {
      "epoch": 0.8363227887089176,
      "grad_norm": 2.132150411605835,
      "learning_rate": 3.275599681136314e-05,
      "loss": 0.0536,
      "step": 11540
    },
    {
      "epoch": 0.8363952603543864,
      "grad_norm": 2.4427030086517334,
      "learning_rate": 3.2741503007464305e-05,
      "loss": 0.121,
      "step": 11541
    },
    {
      "epoch": 0.836467731999855,
      "grad_norm": 0.8628240823745728,
      "learning_rate": 3.272700920356548e-05,
      "loss": 0.0054,
      "step": 11542
    },
    {
      "epoch": 0.8365402036453238,
      "grad_norm": 2.9307947158813477,
      "learning_rate": 3.2712515399666645e-05,
      "loss": 0.0422,
      "step": 11543
    },
    {
      "epoch": 0.8366126752907925,
      "grad_norm": 1.045279622077942,
      "learning_rate": 3.269802159576781e-05,
      "loss": 0.0307,
      "step": 11544
    },
    {
      "epoch": 0.8366851469362612,
      "grad_norm": 0.03848729655146599,
      "learning_rate": 3.268352779186898e-05,
      "loss": 0.0009,
      "step": 11545
    },
    {
      "epoch": 0.8367576185817299,
      "grad_norm": 1.3822332620620728,
      "learning_rate": 3.266903398797014e-05,
      "loss": 0.016,
      "step": 11546
    },
    {
      "epoch": 0.8368300902271986,
      "grad_norm": 2.404818058013916,
      "learning_rate": 3.265454018407131e-05,
      "loss": 0.0812,
      "step": 11547
    },
    {
      "epoch": 0.8369025618726673,
      "grad_norm": 3.699106454849243,
      "learning_rate": 3.264004638017248e-05,
      "loss": 0.1651,
      "step": 11548
    },
    {
      "epoch": 0.8369750335181361,
      "grad_norm": 0.40538567304611206,
      "learning_rate": 3.2625552576273645e-05,
      "loss": 0.0032,
      "step": 11549
    },
    {
      "epoch": 0.8370475051636047,
      "grad_norm": 0.282900333404541,
      "learning_rate": 3.2611058772374815e-05,
      "loss": 0.0037,
      "step": 11550
    },
    {
      "epoch": 0.8371199768090735,
      "grad_norm": 0.35932695865631104,
      "learning_rate": 3.259656496847598e-05,
      "loss": 0.0166,
      "step": 11551
    },
    {
      "epoch": 0.8371924484545422,
      "grad_norm": 1.4878369569778442,
      "learning_rate": 3.258207116457714e-05,
      "loss": 0.0194,
      "step": 11552
    },
    {
      "epoch": 0.8372649201000109,
      "grad_norm": 1.144758939743042,
      "learning_rate": 3.256757736067831e-05,
      "loss": 0.04,
      "step": 11553
    },
    {
      "epoch": 0.8373373917454796,
      "grad_norm": 1.699750304222107,
      "learning_rate": 3.255308355677948e-05,
      "loss": 0.0297,
      "step": 11554
    },
    {
      "epoch": 0.8374098633909483,
      "grad_norm": 2.623826503753662,
      "learning_rate": 3.2538589752880645e-05,
      "loss": 0.0483,
      "step": 11555
    },
    {
      "epoch": 0.837482335036417,
      "grad_norm": 1.279399037361145,
      "learning_rate": 3.2524095948981815e-05,
      "loss": 0.0375,
      "step": 11556
    },
    {
      "epoch": 0.8375548066818858,
      "grad_norm": 0.817419171333313,
      "learning_rate": 3.250960214508298e-05,
      "loss": 0.0231,
      "step": 11557
    },
    {
      "epoch": 0.8376272783273544,
      "grad_norm": 1.6348923444747925,
      "learning_rate": 3.249510834118414e-05,
      "loss": 0.0577,
      "step": 11558
    },
    {
      "epoch": 0.8376997499728231,
      "grad_norm": 0.6785088181495667,
      "learning_rate": 3.248061453728531e-05,
      "loss": 0.01,
      "step": 11559
    },
    {
      "epoch": 0.8377722216182918,
      "grad_norm": 0.49612855911254883,
      "learning_rate": 3.246612073338648e-05,
      "loss": 0.0178,
      "step": 11560
    },
    {
      "epoch": 0.8378446932637605,
      "grad_norm": 0.4592505991458893,
      "learning_rate": 3.2451626929487645e-05,
      "loss": 0.0177,
      "step": 11561
    },
    {
      "epoch": 0.8379171649092293,
      "grad_norm": 1.4958417415618896,
      "learning_rate": 3.2437133125588815e-05,
      "loss": 0.0402,
      "step": 11562
    },
    {
      "epoch": 0.8379896365546979,
      "grad_norm": 0.6135649085044861,
      "learning_rate": 3.242263932168998e-05,
      "loss": 0.0231,
      "step": 11563
    },
    {
      "epoch": 0.8380621082001667,
      "grad_norm": 0.37094029784202576,
      "learning_rate": 3.240814551779114e-05,
      "loss": 0.0063,
      "step": 11564
    },
    {
      "epoch": 0.8381345798456354,
      "grad_norm": 3.498358964920044,
      "learning_rate": 3.239365171389232e-05,
      "loss": 0.0537,
      "step": 11565
    },
    {
      "epoch": 0.8382070514911041,
      "grad_norm": 1.10325026512146,
      "learning_rate": 3.237915790999348e-05,
      "loss": 0.0386,
      "step": 11566
    },
    {
      "epoch": 0.8382795231365728,
      "grad_norm": 3.8552467823028564,
      "learning_rate": 3.2364664106094644e-05,
      "loss": 0.078,
      "step": 11567
    },
    {
      "epoch": 0.8383519947820415,
      "grad_norm": 1.550265908241272,
      "learning_rate": 3.2350170302195814e-05,
      "loss": 0.0388,
      "step": 11568
    },
    {
      "epoch": 0.8384244664275102,
      "grad_norm": 2.83650803565979,
      "learning_rate": 3.233567649829698e-05,
      "loss": 0.0467,
      "step": 11569
    },
    {
      "epoch": 0.838496938072979,
      "grad_norm": 0.06069384515285492,
      "learning_rate": 3.232118269439815e-05,
      "loss": 0.0011,
      "step": 11570
    },
    {
      "epoch": 0.8385694097184476,
      "grad_norm": 1.9562621116638184,
      "learning_rate": 3.230668889049932e-05,
      "loss": 0.0138,
      "step": 11571
    },
    {
      "epoch": 0.8386418813639164,
      "grad_norm": 0.45898938179016113,
      "learning_rate": 3.229219508660048e-05,
      "loss": 0.0239,
      "step": 11572
    },
    {
      "epoch": 0.8387143530093851,
      "grad_norm": 1.1901687383651733,
      "learning_rate": 3.2277701282701644e-05,
      "loss": 0.0371,
      "step": 11573
    },
    {
      "epoch": 0.8387868246548538,
      "grad_norm": 2.095557689666748,
      "learning_rate": 3.2263207478802814e-05,
      "loss": 0.0409,
      "step": 11574
    },
    {
      "epoch": 0.8388592963003225,
      "grad_norm": 2.719722270965576,
      "learning_rate": 3.224871367490398e-05,
      "loss": 0.0743,
      "step": 11575
    },
    {
      "epoch": 0.8389317679457912,
      "grad_norm": 2.4661755561828613,
      "learning_rate": 3.223421987100515e-05,
      "loss": 0.0413,
      "step": 11576
    },
    {
      "epoch": 0.8390042395912599,
      "grad_norm": 2.4704644680023193,
      "learning_rate": 3.221972606710632e-05,
      "loss": 0.0615,
      "step": 11577
    },
    {
      "epoch": 0.8390767112367287,
      "grad_norm": 0.29505428671836853,
      "learning_rate": 3.220523226320748e-05,
      "loss": 0.0027,
      "step": 11578
    },
    {
      "epoch": 0.8391491828821973,
      "grad_norm": 0.8012393116950989,
      "learning_rate": 3.2190738459308644e-05,
      "loss": 0.0181,
      "step": 11579
    },
    {
      "epoch": 0.8392216545276661,
      "grad_norm": 2.493321418762207,
      "learning_rate": 3.2176244655409814e-05,
      "loss": 0.1046,
      "step": 11580
    },
    {
      "epoch": 0.8392941261731348,
      "grad_norm": 4.892950534820557,
      "learning_rate": 3.216175085151098e-05,
      "loss": 0.0606,
      "step": 11581
    },
    {
      "epoch": 0.8393665978186035,
      "grad_norm": 1.8320562839508057,
      "learning_rate": 3.214725704761215e-05,
      "loss": 0.0307,
      "step": 11582
    },
    {
      "epoch": 0.8394390694640722,
      "grad_norm": 2.2446224689483643,
      "learning_rate": 3.213276324371332e-05,
      "loss": 0.0775,
      "step": 11583
    },
    {
      "epoch": 0.8395115411095408,
      "grad_norm": 2.0456385612487793,
      "learning_rate": 3.211826943981448e-05,
      "loss": 0.062,
      "step": 11584
    },
    {
      "epoch": 0.8395840127550096,
      "grad_norm": 1.3320753574371338,
      "learning_rate": 3.2103775635915644e-05,
      "loss": 0.0295,
      "step": 11585
    },
    {
      "epoch": 0.8396564844004784,
      "grad_norm": 1.2611991167068481,
      "learning_rate": 3.2089281832016814e-05,
      "loss": 0.0229,
      "step": 11586
    },
    {
      "epoch": 0.839728956045947,
      "grad_norm": 1.1138713359832764,
      "learning_rate": 3.207478802811798e-05,
      "loss": 0.0368,
      "step": 11587
    },
    {
      "epoch": 0.8398014276914157,
      "grad_norm": 3.4298768043518066,
      "learning_rate": 3.206029422421915e-05,
      "loss": 0.0902,
      "step": 11588
    },
    {
      "epoch": 0.8398738993368844,
      "grad_norm": 0.9742603898048401,
      "learning_rate": 3.204580042032032e-05,
      "loss": 0.0469,
      "step": 11589
    },
    {
      "epoch": 0.8399463709823531,
      "grad_norm": 2.914905548095703,
      "learning_rate": 3.203130661642148e-05,
      "loss": 0.0705,
      "step": 11590
    },
    {
      "epoch": 0.8400188426278219,
      "grad_norm": 0.06138221174478531,
      "learning_rate": 3.201681281252265e-05,
      "loss": 0.0008,
      "step": 11591
    },
    {
      "epoch": 0.8400913142732905,
      "grad_norm": 0.6217292547225952,
      "learning_rate": 3.2002319008623814e-05,
      "loss": 0.0276,
      "step": 11592
    },
    {
      "epoch": 0.8401637859187593,
      "grad_norm": 0.04496973752975464,
      "learning_rate": 3.198782520472498e-05,
      "loss": 0.0009,
      "step": 11593
    },
    {
      "epoch": 0.840236257564228,
      "grad_norm": 3.0322189331054688,
      "learning_rate": 3.1973331400826154e-05,
      "loss": 0.0592,
      "step": 11594
    },
    {
      "epoch": 0.8403087292096967,
      "grad_norm": 0.8144006729125977,
      "learning_rate": 3.195883759692732e-05,
      "loss": 0.0181,
      "step": 11595
    },
    {
      "epoch": 0.8403812008551654,
      "grad_norm": 2.482459783554077,
      "learning_rate": 3.194434379302848e-05,
      "loss": 0.0834,
      "step": 11596
    },
    {
      "epoch": 0.8404536725006341,
      "grad_norm": 0.45314696431159973,
      "learning_rate": 3.192984998912965e-05,
      "loss": 0.0125,
      "step": 11597
    },
    {
      "epoch": 0.8405261441461028,
      "grad_norm": 0.4974093735218048,
      "learning_rate": 3.1915356185230814e-05,
      "loss": 0.0105,
      "step": 11598
    },
    {
      "epoch": 0.8405986157915716,
      "grad_norm": 1.1414536237716675,
      "learning_rate": 3.1900862381331984e-05,
      "loss": 0.0473,
      "step": 11599
    },
    {
      "epoch": 0.8406710874370402,
      "grad_norm": 0.1381266713142395,
      "learning_rate": 3.1886368577433154e-05,
      "loss": 0.0009,
      "step": 11600
    },
    {
      "epoch": 0.840743559082509,
      "grad_norm": 0.40447330474853516,
      "learning_rate": 3.187187477353432e-05,
      "loss": 0.0021,
      "step": 11601
    },
    {
      "epoch": 0.8408160307279777,
      "grad_norm": 6.1271748542785645,
      "learning_rate": 3.185738096963548e-05,
      "loss": 0.0239,
      "step": 11602
    },
    {
      "epoch": 0.8408885023734464,
      "grad_norm": 0.39380505681037903,
      "learning_rate": 3.184288716573665e-05,
      "loss": 0.0087,
      "step": 11603
    },
    {
      "epoch": 0.8409609740189151,
      "grad_norm": 0.2794499397277832,
      "learning_rate": 3.1828393361837814e-05,
      "loss": 0.0112,
      "step": 11604
    },
    {
      "epoch": 0.8410334456643838,
      "grad_norm": 0.48454299569129944,
      "learning_rate": 3.1813899557938984e-05,
      "loss": 0.0191,
      "step": 11605
    },
    {
      "epoch": 0.8411059173098525,
      "grad_norm": 0.9675264358520508,
      "learning_rate": 3.1799405754040154e-05,
      "loss": 0.0405,
      "step": 11606
    },
    {
      "epoch": 0.8411783889553213,
      "grad_norm": 1.0825563669204712,
      "learning_rate": 3.178491195014132e-05,
      "loss": 0.0601,
      "step": 11607
    },
    {
      "epoch": 0.8412508606007899,
      "grad_norm": 1.0419996976852417,
      "learning_rate": 3.177041814624248e-05,
      "loss": 0.0304,
      "step": 11608
    },
    {
      "epoch": 0.8413233322462587,
      "grad_norm": 0.9055584669113159,
      "learning_rate": 3.175592434234365e-05,
      "loss": 0.0111,
      "step": 11609
    },
    {
      "epoch": 0.8413958038917274,
      "grad_norm": 2.850694417953491,
      "learning_rate": 3.1741430538444814e-05,
      "loss": 0.0359,
      "step": 11610
    },
    {
      "epoch": 0.841468275537196,
      "grad_norm": 3.159947633743286,
      "learning_rate": 3.1726936734545984e-05,
      "loss": 0.0554,
      "step": 11611
    },
    {
      "epoch": 0.8415407471826648,
      "grad_norm": 0.052981190383434296,
      "learning_rate": 3.1712442930647154e-05,
      "loss": 0.0011,
      "step": 11612
    },
    {
      "epoch": 0.8416132188281334,
      "grad_norm": 2.0694198608398438,
      "learning_rate": 3.169794912674832e-05,
      "loss": 0.0303,
      "step": 11613
    },
    {
      "epoch": 0.8416856904736022,
      "grad_norm": 0.4397306740283966,
      "learning_rate": 3.168345532284948e-05,
      "loss": 0.0089,
      "step": 11614
    },
    {
      "epoch": 0.841758162119071,
      "grad_norm": 0.22843700647354126,
      "learning_rate": 3.166896151895065e-05,
      "loss": 0.0111,
      "step": 11615
    },
    {
      "epoch": 0.8418306337645396,
      "grad_norm": 0.6151212453842163,
      "learning_rate": 3.1654467715051814e-05,
      "loss": 0.0246,
      "step": 11616
    },
    {
      "epoch": 0.8419031054100083,
      "grad_norm": 2.347526788711548,
      "learning_rate": 3.1639973911152984e-05,
      "loss": 0.0495,
      "step": 11617
    },
    {
      "epoch": 0.8419755770554771,
      "grad_norm": 1.3681002855300903,
      "learning_rate": 3.1625480107254154e-05,
      "loss": 0.0194,
      "step": 11618
    },
    {
      "epoch": 0.8420480487009457,
      "grad_norm": 1.0481573343276978,
      "learning_rate": 3.161098630335532e-05,
      "loss": 0.0188,
      "step": 11619
    },
    {
      "epoch": 0.8421205203464145,
      "grad_norm": 2.206404685974121,
      "learning_rate": 3.159649249945648e-05,
      "loss": 0.0905,
      "step": 11620
    },
    {
      "epoch": 0.8421929919918831,
      "grad_norm": 0.1232491210103035,
      "learning_rate": 3.158199869555765e-05,
      "loss": 0.0018,
      "step": 11621
    },
    {
      "epoch": 0.8422654636373519,
      "grad_norm": 0.998604953289032,
      "learning_rate": 3.1567504891658814e-05,
      "loss": 0.0545,
      "step": 11622
    },
    {
      "epoch": 0.8423379352828206,
      "grad_norm": 0.22710780799388885,
      "learning_rate": 3.1553011087759984e-05,
      "loss": 0.0059,
      "step": 11623
    },
    {
      "epoch": 0.8424104069282893,
      "grad_norm": 2.874838352203369,
      "learning_rate": 3.1538517283861154e-05,
      "loss": 0.1341,
      "step": 11624
    },
    {
      "epoch": 0.842482878573758,
      "grad_norm": 1.6326125860214233,
      "learning_rate": 3.152402347996232e-05,
      "loss": 0.0261,
      "step": 11625
    },
    {
      "epoch": 0.8425553502192267,
      "grad_norm": 1.3132261037826538,
      "learning_rate": 3.150952967606348e-05,
      "loss": 0.0096,
      "step": 11626
    },
    {
      "epoch": 0.8426278218646954,
      "grad_norm": 0.6270917057991028,
      "learning_rate": 3.149503587216465e-05,
      "loss": 0.0156,
      "step": 11627
    },
    {
      "epoch": 0.8427002935101642,
      "grad_norm": 0.34055253863334656,
      "learning_rate": 3.148054206826582e-05,
      "loss": 0.0047,
      "step": 11628
    },
    {
      "epoch": 0.8427727651556328,
      "grad_norm": 0.20055179297924042,
      "learning_rate": 3.146604826436699e-05,
      "loss": 0.0046,
      "step": 11629
    },
    {
      "epoch": 0.8428452368011016,
      "grad_norm": 0.9131907224655151,
      "learning_rate": 3.1451554460468154e-05,
      "loss": 0.0226,
      "step": 11630
    },
    {
      "epoch": 0.8429177084465703,
      "grad_norm": 0.4420558214187622,
      "learning_rate": 3.143706065656932e-05,
      "loss": 0.0226,
      "step": 11631
    },
    {
      "epoch": 0.842990180092039,
      "grad_norm": 1.1604561805725098,
      "learning_rate": 3.142256685267049e-05,
      "loss": 0.0453,
      "step": 11632
    },
    {
      "epoch": 0.8430626517375077,
      "grad_norm": 2.4666619300842285,
      "learning_rate": 3.140807304877165e-05,
      "loss": 0.1827,
      "step": 11633
    },
    {
      "epoch": 0.8431351233829764,
      "grad_norm": 1.54048752784729,
      "learning_rate": 3.139357924487282e-05,
      "loss": 0.0328,
      "step": 11634
    },
    {
      "epoch": 0.8432075950284451,
      "grad_norm": 1.4054561853408813,
      "learning_rate": 3.137908544097399e-05,
      "loss": 0.0462,
      "step": 11635
    },
    {
      "epoch": 0.8432800666739139,
      "grad_norm": 4.066060543060303,
      "learning_rate": 3.1364591637075153e-05,
      "loss": 0.0855,
      "step": 11636
    },
    {
      "epoch": 0.8433525383193825,
      "grad_norm": 1.7612026929855347,
      "learning_rate": 3.135009783317632e-05,
      "loss": 0.0515,
      "step": 11637
    },
    {
      "epoch": 0.8434250099648513,
      "grad_norm": 0.3116137981414795,
      "learning_rate": 3.133560402927749e-05,
      "loss": 0.0104,
      "step": 11638
    },
    {
      "epoch": 0.84349748161032,
      "grad_norm": 0.42625439167022705,
      "learning_rate": 3.132111022537865e-05,
      "loss": 0.0043,
      "step": 11639
    },
    {
      "epoch": 0.8435699532557887,
      "grad_norm": 2.2523322105407715,
      "learning_rate": 3.130661642147982e-05,
      "loss": 0.1115,
      "step": 11640
    },
    {
      "epoch": 0.8436424249012574,
      "grad_norm": 1.5146420001983643,
      "learning_rate": 3.129212261758099e-05,
      "loss": 0.0204,
      "step": 11641
    },
    {
      "epoch": 0.843714896546726,
      "grad_norm": 2.452746629714966,
      "learning_rate": 3.127762881368215e-05,
      "loss": 0.1096,
      "step": 11642
    },
    {
      "epoch": 0.8437873681921948,
      "grad_norm": 6.414195537567139,
      "learning_rate": 3.1263135009783317e-05,
      "loss": 0.0791,
      "step": 11643
    },
    {
      "epoch": 0.8438598398376636,
      "grad_norm": 0.9583966135978699,
      "learning_rate": 3.124864120588449e-05,
      "loss": 0.0338,
      "step": 11644
    },
    {
      "epoch": 0.8439323114831322,
      "grad_norm": 0.9284915328025818,
      "learning_rate": 3.123414740198565e-05,
      "loss": 0.0295,
      "step": 11645
    },
    {
      "epoch": 0.8440047831286009,
      "grad_norm": 1.1199508905410767,
      "learning_rate": 3.121965359808682e-05,
      "loss": 0.0499,
      "step": 11646
    },
    {
      "epoch": 0.8440772547740697,
      "grad_norm": 0.4308706820011139,
      "learning_rate": 3.120515979418799e-05,
      "loss": 0.0196,
      "step": 11647
    },
    {
      "epoch": 0.8441497264195383,
      "grad_norm": 1.65738844871521,
      "learning_rate": 3.119066599028915e-05,
      "loss": 0.0619,
      "step": 11648
    },
    {
      "epoch": 0.8442221980650071,
      "grad_norm": 1.4020012617111206,
      "learning_rate": 3.1176172186390316e-05,
      "loss": 0.0175,
      "step": 11649
    },
    {
      "epoch": 0.8442946697104757,
      "grad_norm": 1.5733510255813599,
      "learning_rate": 3.1161678382491487e-05,
      "loss": 0.0233,
      "step": 11650
    },
    {
      "epoch": 0.8443671413559445,
      "grad_norm": 2.9520163536071777,
      "learning_rate": 3.114718457859265e-05,
      "loss": 0.0874,
      "step": 11651
    },
    {
      "epoch": 0.8444396130014132,
      "grad_norm": 3.022568702697754,
      "learning_rate": 3.113269077469382e-05,
      "loss": 0.0846,
      "step": 11652
    },
    {
      "epoch": 0.8445120846468819,
      "grad_norm": 0.7504851222038269,
      "learning_rate": 3.111819697079499e-05,
      "loss": 0.0105,
      "step": 11653
    },
    {
      "epoch": 0.8445845562923506,
      "grad_norm": 0.5773028135299683,
      "learning_rate": 3.110370316689615e-05,
      "loss": 0.0225,
      "step": 11654
    },
    {
      "epoch": 0.8446570279378194,
      "grad_norm": 1.457918643951416,
      "learning_rate": 3.1089209362997316e-05,
      "loss": 0.0471,
      "step": 11655
    },
    {
      "epoch": 0.844729499583288,
      "grad_norm": 1.521820306777954,
      "learning_rate": 3.1074715559098486e-05,
      "loss": 0.013,
      "step": 11656
    },
    {
      "epoch": 0.8448019712287568,
      "grad_norm": 1.6981420516967773,
      "learning_rate": 3.1060221755199656e-05,
      "loss": 0.0588,
      "step": 11657
    },
    {
      "epoch": 0.8448744428742254,
      "grad_norm": 0.43978047370910645,
      "learning_rate": 3.104572795130082e-05,
      "loss": 0.0195,
      "step": 11658
    },
    {
      "epoch": 0.8449469145196942,
      "grad_norm": 0.16887545585632324,
      "learning_rate": 3.103123414740199e-05,
      "loss": 0.0066,
      "step": 11659
    },
    {
      "epoch": 0.8450193861651629,
      "grad_norm": 1.5443933010101318,
      "learning_rate": 3.101674034350315e-05,
      "loss": 0.0939,
      "step": 11660
    },
    {
      "epoch": 0.8450918578106316,
      "grad_norm": 3.3558766841888428,
      "learning_rate": 3.1002246539604316e-05,
      "loss": 0.0447,
      "step": 11661
    },
    {
      "epoch": 0.8451643294561003,
      "grad_norm": 0.5088323950767517,
      "learning_rate": 3.0987752735705486e-05,
      "loss": 0.0245,
      "step": 11662
    },
    {
      "epoch": 0.845236801101569,
      "grad_norm": 1.0161913633346558,
      "learning_rate": 3.0973258931806656e-05,
      "loss": 0.0208,
      "step": 11663
    },
    {
      "epoch": 0.8453092727470377,
      "grad_norm": 1.6975122690200806,
      "learning_rate": 3.095876512790782e-05,
      "loss": 0.0179,
      "step": 11664
    },
    {
      "epoch": 0.8453817443925065,
      "grad_norm": 2.930938482284546,
      "learning_rate": 3.094427132400899e-05,
      "loss": 0.0859,
      "step": 11665
    },
    {
      "epoch": 0.8454542160379751,
      "grad_norm": 0.4128120243549347,
      "learning_rate": 3.092977752011015e-05,
      "loss": 0.0082,
      "step": 11666
    },
    {
      "epoch": 0.8455266876834439,
      "grad_norm": 0.974632740020752,
      "learning_rate": 3.0915283716211316e-05,
      "loss": 0.0266,
      "step": 11667
    },
    {
      "epoch": 0.8455991593289126,
      "grad_norm": 1.6029993295669556,
      "learning_rate": 3.0900789912312486e-05,
      "loss": 0.0359,
      "step": 11668
    },
    {
      "epoch": 0.8456716309743812,
      "grad_norm": 0.6285766363143921,
      "learning_rate": 3.0886296108413656e-05,
      "loss": 0.0309,
      "step": 11669
    },
    {
      "epoch": 0.84574410261985,
      "grad_norm": 0.035971499979496,
      "learning_rate": 3.0871802304514826e-05,
      "loss": 0.0008,
      "step": 11670
    },
    {
      "epoch": 0.8458165742653186,
      "grad_norm": 0.19614243507385254,
      "learning_rate": 3.085730850061599e-05,
      "loss": 0.0081,
      "step": 11671
    },
    {
      "epoch": 0.8458890459107874,
      "grad_norm": 0.6775194406509399,
      "learning_rate": 3.084281469671715e-05,
      "loss": 0.0175,
      "step": 11672
    },
    {
      "epoch": 0.8459615175562561,
      "grad_norm": 2.4414899349212646,
      "learning_rate": 3.082832089281832e-05,
      "loss": 0.0757,
      "step": 11673
    },
    {
      "epoch": 0.8460339892017248,
      "grad_norm": 0.736355721950531,
      "learning_rate": 3.0813827088919486e-05,
      "loss": 0.0264,
      "step": 11674
    },
    {
      "epoch": 0.8461064608471935,
      "grad_norm": 0.5289750695228577,
      "learning_rate": 3.0799333285020656e-05,
      "loss": 0.0173,
      "step": 11675
    },
    {
      "epoch": 0.8461789324926623,
      "grad_norm": 0.06499619781970978,
      "learning_rate": 3.0784839481121826e-05,
      "loss": 0.0011,
      "step": 11676
    },
    {
      "epoch": 0.8462514041381309,
      "grad_norm": 1.5918362140655518,
      "learning_rate": 3.077034567722299e-05,
      "loss": 0.0303,
      "step": 11677
    },
    {
      "epoch": 0.8463238757835997,
      "grad_norm": 2.456324338912964,
      "learning_rate": 3.075585187332415e-05,
      "loss": 0.0326,
      "step": 11678
    },
    {
      "epoch": 0.8463963474290683,
      "grad_norm": 0.6875173449516296,
      "learning_rate": 3.074135806942532e-05,
      "loss": 0.0295,
      "step": 11679
    },
    {
      "epoch": 0.8464688190745371,
      "grad_norm": 1.2527741193771362,
      "learning_rate": 3.0726864265526486e-05,
      "loss": 0.0702,
      "step": 11680
    },
    {
      "epoch": 0.8465412907200058,
      "grad_norm": 1.1001032590866089,
      "learning_rate": 3.0712370461627656e-05,
      "loss": 0.0504,
      "step": 11681
    },
    {
      "epoch": 0.8466137623654745,
      "grad_norm": 2.129639148712158,
      "learning_rate": 3.0697876657728826e-05,
      "loss": 0.0952,
      "step": 11682
    },
    {
      "epoch": 0.8466862340109432,
      "grad_norm": 0.06420426815748215,
      "learning_rate": 3.068338285382999e-05,
      "loss": 0.0014,
      "step": 11683
    },
    {
      "epoch": 0.846758705656412,
      "grad_norm": 1.0346766710281372,
      "learning_rate": 3.066888904993115e-05,
      "loss": 0.0399,
      "step": 11684
    },
    {
      "epoch": 0.8468311773018806,
      "grad_norm": 1.8437535762786865,
      "learning_rate": 3.065439524603232e-05,
      "loss": 0.0773,
      "step": 11685
    },
    {
      "epoch": 0.8469036489473494,
      "grad_norm": 1.5696024894714355,
      "learning_rate": 3.063990144213349e-05,
      "loss": 0.0198,
      "step": 11686
    },
    {
      "epoch": 0.846976120592818,
      "grad_norm": 1.700866460800171,
      "learning_rate": 3.0625407638234656e-05,
      "loss": 0.1215,
      "step": 11687
    },
    {
      "epoch": 0.8470485922382868,
      "grad_norm": 1.5449469089508057,
      "learning_rate": 3.0610913834335826e-05,
      "loss": 0.0235,
      "step": 11688
    },
    {
      "epoch": 0.8471210638837555,
      "grad_norm": 1.6831976175308228,
      "learning_rate": 3.059642003043699e-05,
      "loss": 0.0544,
      "step": 11689
    },
    {
      "epoch": 0.8471935355292242,
      "grad_norm": 1.2043437957763672,
      "learning_rate": 3.058192622653815e-05,
      "loss": 0.0524,
      "step": 11690
    },
    {
      "epoch": 0.8472660071746929,
      "grad_norm": 0.26662224531173706,
      "learning_rate": 3.056743242263932e-05,
      "loss": 0.0147,
      "step": 11691
    },
    {
      "epoch": 0.8473384788201617,
      "grad_norm": 2.1501801013946533,
      "learning_rate": 3.055293861874049e-05,
      "loss": 0.0696,
      "step": 11692
    },
    {
      "epoch": 0.8474109504656303,
      "grad_norm": 1.9654923677444458,
      "learning_rate": 3.0538444814841656e-05,
      "loss": 0.0382,
      "step": 11693
    },
    {
      "epoch": 0.8474834221110991,
      "grad_norm": 1.2925924062728882,
      "learning_rate": 3.0523951010942826e-05,
      "loss": 0.0712,
      "step": 11694
    },
    {
      "epoch": 0.8475558937565677,
      "grad_norm": 0.3858897387981415,
      "learning_rate": 3.050945720704399e-05,
      "loss": 0.0094,
      "step": 11695
    },
    {
      "epoch": 0.8476283654020365,
      "grad_norm": 0.5371310710906982,
      "learning_rate": 3.0494963403145156e-05,
      "loss": 0.0119,
      "step": 11696
    },
    {
      "epoch": 0.8477008370475052,
      "grad_norm": 1.3672411441802979,
      "learning_rate": 3.0480469599246326e-05,
      "loss": 0.0338,
      "step": 11697
    },
    {
      "epoch": 0.8477733086929738,
      "grad_norm": 2.2328951358795166,
      "learning_rate": 3.046597579534749e-05,
      "loss": 0.0431,
      "step": 11698
    },
    {
      "epoch": 0.8478457803384426,
      "grad_norm": 1.2932908535003662,
      "learning_rate": 3.0451481991448656e-05,
      "loss": 0.0569,
      "step": 11699
    },
    {
      "epoch": 0.8479182519839112,
      "grad_norm": 1.1364343166351318,
      "learning_rate": 3.0436988187549826e-05,
      "loss": 0.0124,
      "step": 11700
    },
    {
      "epoch": 0.84799072362938,
      "grad_norm": 5.677700042724609,
      "learning_rate": 3.042249438365099e-05,
      "loss": 0.0632,
      "step": 11701
    },
    {
      "epoch": 0.8480631952748487,
      "grad_norm": 1.2803300619125366,
      "learning_rate": 3.0408000579752156e-05,
      "loss": 0.0211,
      "step": 11702
    },
    {
      "epoch": 0.8481356669203174,
      "grad_norm": 0.15117017924785614,
      "learning_rate": 3.0393506775853326e-05,
      "loss": 0.0075,
      "step": 11703
    },
    {
      "epoch": 0.8482081385657861,
      "grad_norm": 1.2004727125167847,
      "learning_rate": 3.037901297195449e-05,
      "loss": 0.0396,
      "step": 11704
    },
    {
      "epoch": 0.8482806102112549,
      "grad_norm": 0.6502376794815063,
      "learning_rate": 3.0364519168055656e-05,
      "loss": 0.0329,
      "step": 11705
    },
    {
      "epoch": 0.8483530818567235,
      "grad_norm": 1.546566367149353,
      "learning_rate": 3.0350025364156826e-05,
      "loss": 0.0726,
      "step": 11706
    },
    {
      "epoch": 0.8484255535021923,
      "grad_norm": 1.0083653926849365,
      "learning_rate": 3.033553156025799e-05,
      "loss": 0.022,
      "step": 11707
    },
    {
      "epoch": 0.8484980251476609,
      "grad_norm": 0.956889808177948,
      "learning_rate": 3.0321037756359156e-05,
      "loss": 0.05,
      "step": 11708
    },
    {
      "epoch": 0.8485704967931297,
      "grad_norm": 0.230635404586792,
      "learning_rate": 3.0306543952460326e-05,
      "loss": 0.0033,
      "step": 11709
    },
    {
      "epoch": 0.8486429684385984,
      "grad_norm": 0.8184778094291687,
      "learning_rate": 3.029205014856149e-05,
      "loss": 0.0165,
      "step": 11710
    },
    {
      "epoch": 0.8487154400840671,
      "grad_norm": 0.36802318692207336,
      "learning_rate": 3.0277556344662662e-05,
      "loss": 0.0074,
      "step": 11711
    },
    {
      "epoch": 0.8487879117295358,
      "grad_norm": 1.0605182647705078,
      "learning_rate": 3.0263062540763826e-05,
      "loss": 0.0521,
      "step": 11712
    },
    {
      "epoch": 0.8488603833750046,
      "grad_norm": 1.560139775276184,
      "learning_rate": 3.0248568736864992e-05,
      "loss": 0.0284,
      "step": 11713
    },
    {
      "epoch": 0.8489328550204732,
      "grad_norm": 0.48375216126441956,
      "learning_rate": 3.0234074932966162e-05,
      "loss": 0.0059,
      "step": 11714
    },
    {
      "epoch": 0.849005326665942,
      "grad_norm": 3.8361308574676514,
      "learning_rate": 3.0219581129067326e-05,
      "loss": 0.1234,
      "step": 11715
    },
    {
      "epoch": 0.8490777983114106,
      "grad_norm": 0.47724929451942444,
      "learning_rate": 3.0205087325168492e-05,
      "loss": 0.0086,
      "step": 11716
    },
    {
      "epoch": 0.8491502699568794,
      "grad_norm": 1.0496258735656738,
      "learning_rate": 3.0190593521269662e-05,
      "loss": 0.028,
      "step": 11717
    },
    {
      "epoch": 0.8492227416023481,
      "grad_norm": 0.46605584025382996,
      "learning_rate": 3.0176099717370825e-05,
      "loss": 0.0224,
      "step": 11718
    },
    {
      "epoch": 0.8492952132478168,
      "grad_norm": 4.498736381530762,
      "learning_rate": 3.0161605913471992e-05,
      "loss": 0.107,
      "step": 11719
    },
    {
      "epoch": 0.8493676848932855,
      "grad_norm": 1.1703779697418213,
      "learning_rate": 3.0147112109573162e-05,
      "loss": 0.0229,
      "step": 11720
    },
    {
      "epoch": 0.8494401565387543,
      "grad_norm": 1.9680529832839966,
      "learning_rate": 3.0132618305674325e-05,
      "loss": 0.0974,
      "step": 11721
    },
    {
      "epoch": 0.8495126281842229,
      "grad_norm": 0.9276854395866394,
      "learning_rate": 3.0118124501775492e-05,
      "loss": 0.0328,
      "step": 11722
    },
    {
      "epoch": 0.8495850998296917,
      "grad_norm": 0.7104935050010681,
      "learning_rate": 3.0103630697876662e-05,
      "loss": 0.0258,
      "step": 11723
    },
    {
      "epoch": 0.8496575714751603,
      "grad_norm": 1.1862200498580933,
      "learning_rate": 3.0089136893977825e-05,
      "loss": 0.0092,
      "step": 11724
    },
    {
      "epoch": 0.849730043120629,
      "grad_norm": 0.7927069067955017,
      "learning_rate": 3.0074643090078992e-05,
      "loss": 0.0201,
      "step": 11725
    },
    {
      "epoch": 0.8498025147660978,
      "grad_norm": 0.5179257392883301,
      "learning_rate": 3.0060149286180162e-05,
      "loss": 0.0087,
      "step": 11726
    },
    {
      "epoch": 0.8498749864115664,
      "grad_norm": 1.58858060836792,
      "learning_rate": 3.0045655482281325e-05,
      "loss": 0.0503,
      "step": 11727
    },
    {
      "epoch": 0.8499474580570352,
      "grad_norm": 1.7214255332946777,
      "learning_rate": 3.0031161678382492e-05,
      "loss": 0.0506,
      "step": 11728
    },
    {
      "epoch": 0.8500199297025038,
      "grad_norm": 1.0003241300582886,
      "learning_rate": 3.0016667874483662e-05,
      "loss": 0.0276,
      "step": 11729
    },
    {
      "epoch": 0.8500924013479726,
      "grad_norm": 0.8704789876937866,
      "learning_rate": 3.0002174070584825e-05,
      "loss": 0.0163,
      "step": 11730
    },
    {
      "epoch": 0.8501648729934413,
      "grad_norm": 1.276389241218567,
      "learning_rate": 2.9987680266685992e-05,
      "loss": 0.0619,
      "step": 11731
    },
    {
      "epoch": 0.85023734463891,
      "grad_norm": 4.152894496917725,
      "learning_rate": 2.9973186462787162e-05,
      "loss": 0.1287,
      "step": 11732
    },
    {
      "epoch": 0.8503098162843787,
      "grad_norm": 0.3718562424182892,
      "learning_rate": 2.9958692658888325e-05,
      "loss": 0.008,
      "step": 11733
    },
    {
      "epoch": 0.8503822879298475,
      "grad_norm": 1.9708094596862793,
      "learning_rate": 2.9944198854989492e-05,
      "loss": 0.0161,
      "step": 11734
    },
    {
      "epoch": 0.8504547595753161,
      "grad_norm": 0.019631782546639442,
      "learning_rate": 2.9929705051090662e-05,
      "loss": 0.0005,
      "step": 11735
    },
    {
      "epoch": 0.8505272312207849,
      "grad_norm": 1.288203477859497,
      "learning_rate": 2.9915211247191825e-05,
      "loss": 0.05,
      "step": 11736
    },
    {
      "epoch": 0.8505997028662535,
      "grad_norm": 1.5546367168426514,
      "learning_rate": 2.9900717443292992e-05,
      "loss": 0.0484,
      "step": 11737
    },
    {
      "epoch": 0.8506721745117223,
      "grad_norm": 4.2345685958862305,
      "learning_rate": 2.9886223639394162e-05,
      "loss": 0.0715,
      "step": 11738
    },
    {
      "epoch": 0.850744646157191,
      "grad_norm": 0.5257530808448792,
      "learning_rate": 2.9871729835495325e-05,
      "loss": 0.0292,
      "step": 11739
    },
    {
      "epoch": 0.8508171178026597,
      "grad_norm": 3.457916736602783,
      "learning_rate": 2.9857236031596492e-05,
      "loss": 0.1206,
      "step": 11740
    },
    {
      "epoch": 0.8508895894481284,
      "grad_norm": 1.10822331905365,
      "learning_rate": 2.9842742227697662e-05,
      "loss": 0.0162,
      "step": 11741
    },
    {
      "epoch": 0.8509620610935972,
      "grad_norm": 1.4192636013031006,
      "learning_rate": 2.982824842379883e-05,
      "loss": 0.0059,
      "step": 11742
    },
    {
      "epoch": 0.8510345327390658,
      "grad_norm": 1.723238229751587,
      "learning_rate": 2.9813754619899992e-05,
      "loss": 0.0443,
      "step": 11743
    },
    {
      "epoch": 0.8511070043845346,
      "grad_norm": 0.6793213486671448,
      "learning_rate": 2.9799260816001162e-05,
      "loss": 0.0236,
      "step": 11744
    },
    {
      "epoch": 0.8511794760300032,
      "grad_norm": 4.135544776916504,
      "learning_rate": 2.978476701210233e-05,
      "loss": 0.0335,
      "step": 11745
    },
    {
      "epoch": 0.851251947675472,
      "grad_norm": 0.457740843296051,
      "learning_rate": 2.977027320820349e-05,
      "loss": 0.0197,
      "step": 11746
    },
    {
      "epoch": 0.8513244193209407,
      "grad_norm": 0.4569876492023468,
      "learning_rate": 2.975577940430466e-05,
      "loss": 0.0136,
      "step": 11747
    },
    {
      "epoch": 0.8513968909664094,
      "grad_norm": 1.005995750427246,
      "learning_rate": 2.974128560040583e-05,
      "loss": 0.0298,
      "step": 11748
    },
    {
      "epoch": 0.8514693626118781,
      "grad_norm": 3.0241146087646484,
      "learning_rate": 2.972679179650699e-05,
      "loss": 0.0641,
      "step": 11749
    },
    {
      "epoch": 0.8515418342573469,
      "grad_norm": 0.42698606848716736,
      "learning_rate": 2.971229799260816e-05,
      "loss": 0.0064,
      "step": 11750
    },
    {
      "epoch": 0.8516143059028155,
      "grad_norm": 3.1893398761749268,
      "learning_rate": 2.9697804188709328e-05,
      "loss": 0.0839,
      "step": 11751
    },
    {
      "epoch": 0.8516867775482843,
      "grad_norm": 1.1770797967910767,
      "learning_rate": 2.96833103848105e-05,
      "loss": 0.0112,
      "step": 11752
    },
    {
      "epoch": 0.8517592491937529,
      "grad_norm": 2.8659470081329346,
      "learning_rate": 2.966881658091166e-05,
      "loss": 0.1029,
      "step": 11753
    },
    {
      "epoch": 0.8518317208392217,
      "grad_norm": 5.1241455078125,
      "learning_rate": 2.9654322777012828e-05,
      "loss": 0.119,
      "step": 11754
    },
    {
      "epoch": 0.8519041924846904,
      "grad_norm": 2.324608325958252,
      "learning_rate": 2.9639828973113998e-05,
      "loss": 0.0482,
      "step": 11755
    },
    {
      "epoch": 0.851976664130159,
      "grad_norm": 0.8833281397819519,
      "learning_rate": 2.962533516921516e-05,
      "loss": 0.0299,
      "step": 11756
    },
    {
      "epoch": 0.8520491357756278,
      "grad_norm": 0.15924733877182007,
      "learning_rate": 2.9610841365316328e-05,
      "loss": 0.0093,
      "step": 11757
    },
    {
      "epoch": 0.8521216074210965,
      "grad_norm": 2.0052590370178223,
      "learning_rate": 2.9596347561417498e-05,
      "loss": 0.0297,
      "step": 11758
    },
    {
      "epoch": 0.8521940790665652,
      "grad_norm": 0.8645223379135132,
      "learning_rate": 2.958185375751866e-05,
      "loss": 0.0225,
      "step": 11759
    },
    {
      "epoch": 0.8522665507120339,
      "grad_norm": 0.36628827452659607,
      "learning_rate": 2.9567359953619828e-05,
      "loss": 0.0284,
      "step": 11760
    },
    {
      "epoch": 0.8523390223575026,
      "grad_norm": 1.5179752111434937,
      "learning_rate": 2.9552866149720998e-05,
      "loss": 0.0495,
      "step": 11761
    },
    {
      "epoch": 0.8524114940029713,
      "grad_norm": 0.273100346326828,
      "learning_rate": 2.953837234582216e-05,
      "loss": 0.0054,
      "step": 11762
    },
    {
      "epoch": 0.8524839656484401,
      "grad_norm": 0.9257992506027222,
      "learning_rate": 2.9523878541923328e-05,
      "loss": 0.0456,
      "step": 11763
    },
    {
      "epoch": 0.8525564372939087,
      "grad_norm": 0.4517078399658203,
      "learning_rate": 2.9509384738024498e-05,
      "loss": 0.0089,
      "step": 11764
    },
    {
      "epoch": 0.8526289089393775,
      "grad_norm": 2.7070472240448,
      "learning_rate": 2.949489093412566e-05,
      "loss": 0.1025,
      "step": 11765
    },
    {
      "epoch": 0.8527013805848461,
      "grad_norm": 1.6937077045440674,
      "learning_rate": 2.9480397130226828e-05,
      "loss": 0.03,
      "step": 11766
    },
    {
      "epoch": 0.8527738522303149,
      "grad_norm": 0.7842679619789124,
      "learning_rate": 2.9465903326327998e-05,
      "loss": 0.0116,
      "step": 11767
    },
    {
      "epoch": 0.8528463238757836,
      "grad_norm": 0.680059552192688,
      "learning_rate": 2.9451409522429165e-05,
      "loss": 0.0304,
      "step": 11768
    },
    {
      "epoch": 0.8529187955212523,
      "grad_norm": 2.233222723007202,
      "learning_rate": 2.9436915718530328e-05,
      "loss": 0.0423,
      "step": 11769
    },
    {
      "epoch": 0.852991267166721,
      "grad_norm": 3.5336992740631104,
      "learning_rate": 2.9422421914631498e-05,
      "loss": 0.078,
      "step": 11770
    },
    {
      "epoch": 0.8530637388121898,
      "grad_norm": 2.019564628601074,
      "learning_rate": 2.9407928110732665e-05,
      "loss": 0.0379,
      "step": 11771
    },
    {
      "epoch": 0.8531362104576584,
      "grad_norm": 0.8654126524925232,
      "learning_rate": 2.9393434306833828e-05,
      "loss": 0.0153,
      "step": 11772
    },
    {
      "epoch": 0.8532086821031272,
      "grad_norm": 1.469950795173645,
      "learning_rate": 2.9378940502934998e-05,
      "loss": 0.0165,
      "step": 11773
    },
    {
      "epoch": 0.8532811537485958,
      "grad_norm": 1.8231703042984009,
      "learning_rate": 2.9364446699036165e-05,
      "loss": 0.0565,
      "step": 11774
    },
    {
      "epoch": 0.8533536253940646,
      "grad_norm": 1.1638277769088745,
      "learning_rate": 2.9349952895137328e-05,
      "loss": 0.0154,
      "step": 11775
    },
    {
      "epoch": 0.8534260970395333,
      "grad_norm": 0.6154621243476868,
      "learning_rate": 2.9335459091238498e-05,
      "loss": 0.0092,
      "step": 11776
    },
    {
      "epoch": 0.853498568685002,
      "grad_norm": 1.514317274093628,
      "learning_rate": 2.9320965287339665e-05,
      "loss": 0.0577,
      "step": 11777
    },
    {
      "epoch": 0.8535710403304707,
      "grad_norm": 0.6898263096809387,
      "learning_rate": 2.9306471483440828e-05,
      "loss": 0.0096,
      "step": 11778
    },
    {
      "epoch": 0.8536435119759395,
      "grad_norm": 1.6445614099502563,
      "learning_rate": 2.9291977679541998e-05,
      "loss": 0.0323,
      "step": 11779
    },
    {
      "epoch": 0.8537159836214081,
      "grad_norm": 0.4294387996196747,
      "learning_rate": 2.9277483875643165e-05,
      "loss": 0.0107,
      "step": 11780
    },
    {
      "epoch": 0.8537884552668769,
      "grad_norm": 1.0582250356674194,
      "learning_rate": 2.9262990071744328e-05,
      "loss": 0.024,
      "step": 11781
    },
    {
      "epoch": 0.8538609269123455,
      "grad_norm": 3.072122573852539,
      "learning_rate": 2.9248496267845498e-05,
      "loss": 0.0493,
      "step": 11782
    },
    {
      "epoch": 0.8539333985578142,
      "grad_norm": 0.19358061254024506,
      "learning_rate": 2.9234002463946664e-05,
      "loss": 0.0039,
      "step": 11783
    },
    {
      "epoch": 0.854005870203283,
      "grad_norm": 3.1512489318847656,
      "learning_rate": 2.9219508660047828e-05,
      "loss": 0.0734,
      "step": 11784
    },
    {
      "epoch": 0.8540783418487516,
      "grad_norm": 5.365081310272217,
      "learning_rate": 2.9205014856148998e-05,
      "loss": 0.1803,
      "step": 11785
    },
    {
      "epoch": 0.8541508134942204,
      "grad_norm": 1.6870146989822388,
      "learning_rate": 2.9190521052250164e-05,
      "loss": 0.1116,
      "step": 11786
    },
    {
      "epoch": 0.8542232851396891,
      "grad_norm": 0.37842968106269836,
      "learning_rate": 2.9176027248351328e-05,
      "loss": 0.0111,
      "step": 11787
    },
    {
      "epoch": 0.8542957567851578,
      "grad_norm": 1.6910239458084106,
      "learning_rate": 2.9161533444452498e-05,
      "loss": 0.0665,
      "step": 11788
    },
    {
      "epoch": 0.8543682284306265,
      "grad_norm": 0.06468303501605988,
      "learning_rate": 2.9147039640553664e-05,
      "loss": 0.001,
      "step": 11789
    },
    {
      "epoch": 0.8544407000760952,
      "grad_norm": 2.7365880012512207,
      "learning_rate": 2.9132545836654828e-05,
      "loss": 0.0314,
      "step": 11790
    },
    {
      "epoch": 0.8545131717215639,
      "grad_norm": 1.125778079032898,
      "learning_rate": 2.9118052032755998e-05,
      "loss": 0.037,
      "step": 11791
    },
    {
      "epoch": 0.8545856433670327,
      "grad_norm": 2.7980518341064453,
      "learning_rate": 2.9103558228857164e-05,
      "loss": 0.046,
      "step": 11792
    },
    {
      "epoch": 0.8546581150125013,
      "grad_norm": 1.5643388032913208,
      "learning_rate": 2.9089064424958334e-05,
      "loss": 0.0527,
      "step": 11793
    },
    {
      "epoch": 0.8547305866579701,
      "grad_norm": 2.5603837966918945,
      "learning_rate": 2.9074570621059498e-05,
      "loss": 0.0524,
      "step": 11794
    },
    {
      "epoch": 0.8548030583034388,
      "grad_norm": 0.520383358001709,
      "learning_rate": 2.9060076817160664e-05,
      "loss": 0.0138,
      "step": 11795
    },
    {
      "epoch": 0.8548755299489075,
      "grad_norm": 1.0121022462844849,
      "learning_rate": 2.9045583013261834e-05,
      "loss": 0.0229,
      "step": 11796
    },
    {
      "epoch": 0.8549480015943762,
      "grad_norm": 1.400508999824524,
      "learning_rate": 2.9031089209363e-05,
      "loss": 0.0278,
      "step": 11797
    },
    {
      "epoch": 0.8550204732398449,
      "grad_norm": 0.5893170237541199,
      "learning_rate": 2.9016595405464164e-05,
      "loss": 0.0209,
      "step": 11798
    },
    {
      "epoch": 0.8550929448853136,
      "grad_norm": 0.40136465430259705,
      "learning_rate": 2.9002101601565334e-05,
      "loss": 0.0109,
      "step": 11799
    },
    {
      "epoch": 0.8551654165307824,
      "grad_norm": 2.222403049468994,
      "learning_rate": 2.89876077976665e-05,
      "loss": 0.0175,
      "step": 11800
    },
    {
      "epoch": 0.855237888176251,
      "grad_norm": 3.2265892028808594,
      "learning_rate": 2.8973113993767664e-05,
      "loss": 0.0897,
      "step": 11801
    },
    {
      "epoch": 0.8553103598217198,
      "grad_norm": 1.3263379335403442,
      "learning_rate": 2.8958620189868834e-05,
      "loss": 0.0287,
      "step": 11802
    },
    {
      "epoch": 0.8553828314671884,
      "grad_norm": 1.4247803688049316,
      "learning_rate": 2.894412638597e-05,
      "loss": 0.0522,
      "step": 11803
    },
    {
      "epoch": 0.8554553031126572,
      "grad_norm": 2.014418601989746,
      "learning_rate": 2.8929632582071164e-05,
      "loss": 0.0684,
      "step": 11804
    },
    {
      "epoch": 0.8555277747581259,
      "grad_norm": 1.018347144126892,
      "learning_rate": 2.8915138778172334e-05,
      "loss": 0.036,
      "step": 11805
    },
    {
      "epoch": 0.8556002464035946,
      "grad_norm": 0.8948798775672913,
      "learning_rate": 2.89006449742735e-05,
      "loss": 0.026,
      "step": 11806
    },
    {
      "epoch": 0.8556727180490633,
      "grad_norm": 2.135343551635742,
      "learning_rate": 2.8886151170374664e-05,
      "loss": 0.0634,
      "step": 11807
    },
    {
      "epoch": 0.8557451896945321,
      "grad_norm": 0.13259470462799072,
      "learning_rate": 2.8871657366475834e-05,
      "loss": 0.0113,
      "step": 11808
    },
    {
      "epoch": 0.8558176613400007,
      "grad_norm": 0.4258958101272583,
      "learning_rate": 2.8857163562577e-05,
      "loss": 0.0068,
      "step": 11809
    },
    {
      "epoch": 0.8558901329854695,
      "grad_norm": 2.075678825378418,
      "learning_rate": 2.8842669758678164e-05,
      "loss": 0.0806,
      "step": 11810
    },
    {
      "epoch": 0.8559626046309381,
      "grad_norm": 4.107437610626221,
      "learning_rate": 2.8828175954779334e-05,
      "loss": 0.0774,
      "step": 11811
    },
    {
      "epoch": 0.8560350762764068,
      "grad_norm": 0.9224065542221069,
      "learning_rate": 2.88136821508805e-05,
      "loss": 0.0293,
      "step": 11812
    },
    {
      "epoch": 0.8561075479218756,
      "grad_norm": 0.707567572593689,
      "learning_rate": 2.8799188346981664e-05,
      "loss": 0.0165,
      "step": 11813
    },
    {
      "epoch": 0.8561800195673442,
      "grad_norm": 1.3838812112808228,
      "learning_rate": 2.8784694543082834e-05,
      "loss": 0.0444,
      "step": 11814
    },
    {
      "epoch": 0.856252491212813,
      "grad_norm": 1.013486385345459,
      "learning_rate": 2.8770200739184e-05,
      "loss": 0.0103,
      "step": 11815
    },
    {
      "epoch": 0.8563249628582817,
      "grad_norm": 1.3856688737869263,
      "learning_rate": 2.8755706935285164e-05,
      "loss": 0.0186,
      "step": 11816
    },
    {
      "epoch": 0.8563974345037504,
      "grad_norm": 0.9682080149650574,
      "learning_rate": 2.8741213131386334e-05,
      "loss": 0.015,
      "step": 11817
    },
    {
      "epoch": 0.8564699061492191,
      "grad_norm": 2.6350207328796387,
      "learning_rate": 2.87267193274875e-05,
      "loss": 0.0874,
      "step": 11818
    },
    {
      "epoch": 0.8565423777946878,
      "grad_norm": 3.1200883388519287,
      "learning_rate": 2.8712225523588664e-05,
      "loss": 0.0641,
      "step": 11819
    },
    {
      "epoch": 0.8566148494401565,
      "grad_norm": 0.37955865263938904,
      "learning_rate": 2.8697731719689834e-05,
      "loss": 0.0078,
      "step": 11820
    },
    {
      "epoch": 0.8566873210856253,
      "grad_norm": 0.8173720836639404,
      "learning_rate": 2.8683237915791e-05,
      "loss": 0.0264,
      "step": 11821
    },
    {
      "epoch": 0.8567597927310939,
      "grad_norm": 1.2552820444107056,
      "learning_rate": 2.8668744111892164e-05,
      "loss": 0.0096,
      "step": 11822
    },
    {
      "epoch": 0.8568322643765627,
      "grad_norm": 1.2667211294174194,
      "learning_rate": 2.8654250307993337e-05,
      "loss": 0.0198,
      "step": 11823
    },
    {
      "epoch": 0.8569047360220314,
      "grad_norm": 0.024834224954247475,
      "learning_rate": 2.86397565040945e-05,
      "loss": 0.0004,
      "step": 11824
    },
    {
      "epoch": 0.8569772076675001,
      "grad_norm": 1.4649205207824707,
      "learning_rate": 2.8625262700195664e-05,
      "loss": 0.0407,
      "step": 11825
    },
    {
      "epoch": 0.8570496793129688,
      "grad_norm": 1.5651122331619263,
      "learning_rate": 2.8610768896296837e-05,
      "loss": 0.0372,
      "step": 11826
    },
    {
      "epoch": 0.8571221509584375,
      "grad_norm": 1.4803792238235474,
      "learning_rate": 2.8596275092398e-05,
      "loss": 0.0295,
      "step": 11827
    },
    {
      "epoch": 0.8571946226039062,
      "grad_norm": 0.34097009897232056,
      "learning_rate": 2.8581781288499164e-05,
      "loss": 0.0128,
      "step": 11828
    },
    {
      "epoch": 0.857267094249375,
      "grad_norm": 0.8932129740715027,
      "learning_rate": 2.8567287484600337e-05,
      "loss": 0.0228,
      "step": 11829
    },
    {
      "epoch": 0.8573395658948436,
      "grad_norm": 0.6050588488578796,
      "learning_rate": 2.85527936807015e-05,
      "loss": 0.0212,
      "step": 11830
    },
    {
      "epoch": 0.8574120375403124,
      "grad_norm": 1.3170915842056274,
      "learning_rate": 2.8538299876802667e-05,
      "loss": 0.0317,
      "step": 11831
    },
    {
      "epoch": 0.8574845091857811,
      "grad_norm": 0.13377124071121216,
      "learning_rate": 2.8523806072903837e-05,
      "loss": 0.0017,
      "step": 11832
    },
    {
      "epoch": 0.8575569808312498,
      "grad_norm": 1.0248528718948364,
      "learning_rate": 2.8509312269005e-05,
      "loss": 0.0527,
      "step": 11833
    },
    {
      "epoch": 0.8576294524767185,
      "grad_norm": 1.7319419384002686,
      "learning_rate": 2.849481846510617e-05,
      "loss": 0.0282,
      "step": 11834
    },
    {
      "epoch": 0.8577019241221872,
      "grad_norm": 0.18162448704242706,
      "learning_rate": 2.8480324661207337e-05,
      "loss": 0.0014,
      "step": 11835
    },
    {
      "epoch": 0.8577743957676559,
      "grad_norm": 3.3229072093963623,
      "learning_rate": 2.84658308573085e-05,
      "loss": 0.0929,
      "step": 11836
    },
    {
      "epoch": 0.8578468674131247,
      "grad_norm": 1.1277625560760498,
      "learning_rate": 2.845133705340967e-05,
      "loss": 0.0197,
      "step": 11837
    },
    {
      "epoch": 0.8579193390585933,
      "grad_norm": 3.051994800567627,
      "learning_rate": 2.8436843249510837e-05,
      "loss": 0.0458,
      "step": 11838
    },
    {
      "epoch": 0.857991810704062,
      "grad_norm": 1.7040126323699951,
      "learning_rate": 2.8422349445612e-05,
      "loss": 0.0582,
      "step": 11839
    },
    {
      "epoch": 0.8580642823495307,
      "grad_norm": 1.9056297540664673,
      "learning_rate": 2.840785564171317e-05,
      "loss": 0.0542,
      "step": 11840
    },
    {
      "epoch": 0.8581367539949994,
      "grad_norm": 1.862251877784729,
      "learning_rate": 2.8393361837814337e-05,
      "loss": 0.0399,
      "step": 11841
    },
    {
      "epoch": 0.8582092256404682,
      "grad_norm": 0.29089775681495667,
      "learning_rate": 2.83788680339155e-05,
      "loss": 0.0199,
      "step": 11842
    },
    {
      "epoch": 0.8582816972859368,
      "grad_norm": 1.19394850730896,
      "learning_rate": 2.836437423001667e-05,
      "loss": 0.0424,
      "step": 11843
    },
    {
      "epoch": 0.8583541689314056,
      "grad_norm": 1.22782301902771,
      "learning_rate": 2.8349880426117837e-05,
      "loss": 0.0614,
      "step": 11844
    },
    {
      "epoch": 0.8584266405768743,
      "grad_norm": 0.5306981801986694,
      "learning_rate": 2.8335386622219e-05,
      "loss": 0.012,
      "step": 11845
    },
    {
      "epoch": 0.858499112222343,
      "grad_norm": 2.941563367843628,
      "learning_rate": 2.832089281832017e-05,
      "loss": 0.0442,
      "step": 11846
    },
    {
      "epoch": 0.8585715838678117,
      "grad_norm": 0.6431915163993835,
      "learning_rate": 2.8306399014421337e-05,
      "loss": 0.0051,
      "step": 11847
    },
    {
      "epoch": 0.8586440555132804,
      "grad_norm": 1.131174087524414,
      "learning_rate": 2.82919052105225e-05,
      "loss": 0.0248,
      "step": 11848
    },
    {
      "epoch": 0.8587165271587491,
      "grad_norm": 1.786623477935791,
      "learning_rate": 2.827741140662367e-05,
      "loss": 0.0423,
      "step": 11849
    },
    {
      "epoch": 0.8587889988042179,
      "grad_norm": 10.297898292541504,
      "learning_rate": 2.8262917602724837e-05,
      "loss": 0.1313,
      "step": 11850
    },
    {
      "epoch": 0.8588614704496865,
      "grad_norm": 2.0329113006591797,
      "learning_rate": 2.8248423798826e-05,
      "loss": 0.0219,
      "step": 11851
    },
    {
      "epoch": 0.8589339420951553,
      "grad_norm": 0.819860577583313,
      "learning_rate": 2.8233929994927173e-05,
      "loss": 0.0215,
      "step": 11852
    },
    {
      "epoch": 0.859006413740624,
      "grad_norm": 0.9463898539543152,
      "learning_rate": 2.8219436191028337e-05,
      "loss": 0.0376,
      "step": 11853
    },
    {
      "epoch": 0.8590788853860927,
      "grad_norm": 1.032077431678772,
      "learning_rate": 2.82049423871295e-05,
      "loss": 0.0262,
      "step": 11854
    },
    {
      "epoch": 0.8591513570315614,
      "grad_norm": 2.6669137477874756,
      "learning_rate": 2.8190448583230673e-05,
      "loss": 0.0269,
      "step": 11855
    },
    {
      "epoch": 0.8592238286770301,
      "grad_norm": 1.5089260339736938,
      "learning_rate": 2.8175954779331837e-05,
      "loss": 0.0366,
      "step": 11856
    },
    {
      "epoch": 0.8592963003224988,
      "grad_norm": 4.228588104248047,
      "learning_rate": 2.8161460975433003e-05,
      "loss": 0.1726,
      "step": 11857
    },
    {
      "epoch": 0.8593687719679676,
      "grad_norm": 0.9929172992706299,
      "learning_rate": 2.8146967171534173e-05,
      "loss": 0.0242,
      "step": 11858
    },
    {
      "epoch": 0.8594412436134362,
      "grad_norm": 0.3402520716190338,
      "learning_rate": 2.8132473367635337e-05,
      "loss": 0.0046,
      "step": 11859
    },
    {
      "epoch": 0.859513715258905,
      "grad_norm": 0.3648757040500641,
      "learning_rate": 2.8117979563736503e-05,
      "loss": 0.0085,
      "step": 11860
    },
    {
      "epoch": 0.8595861869043737,
      "grad_norm": 0.6760772466659546,
      "learning_rate": 2.8103485759837673e-05,
      "loss": 0.011,
      "step": 11861
    },
    {
      "epoch": 0.8596586585498424,
      "grad_norm": 3.787360191345215,
      "learning_rate": 2.8088991955938837e-05,
      "loss": 0.0612,
      "step": 11862
    },
    {
      "epoch": 0.8597311301953111,
      "grad_norm": 0.5237215161323547,
      "learning_rate": 2.8074498152040003e-05,
      "loss": 0.0087,
      "step": 11863
    },
    {
      "epoch": 0.8598036018407798,
      "grad_norm": 2.514498472213745,
      "learning_rate": 2.8060004348141173e-05,
      "loss": 0.0824,
      "step": 11864
    },
    {
      "epoch": 0.8598760734862485,
      "grad_norm": 0.7206408381462097,
      "learning_rate": 2.8045510544242337e-05,
      "loss": 0.0129,
      "step": 11865
    },
    {
      "epoch": 0.8599485451317173,
      "grad_norm": 3.0770699977874756,
      "learning_rate": 2.8031016740343503e-05,
      "loss": 0.0526,
      "step": 11866
    },
    {
      "epoch": 0.8600210167771859,
      "grad_norm": 2.1522629261016846,
      "learning_rate": 2.8016522936444673e-05,
      "loss": 0.024,
      "step": 11867
    },
    {
      "epoch": 0.8600934884226547,
      "grad_norm": 0.786275327205658,
      "learning_rate": 2.8002029132545836e-05,
      "loss": 0.0061,
      "step": 11868
    },
    {
      "epoch": 0.8601659600681233,
      "grad_norm": 3.513754367828369,
      "learning_rate": 2.7987535328647003e-05,
      "loss": 0.053,
      "step": 11869
    },
    {
      "epoch": 0.860238431713592,
      "grad_norm": 1.7699224948883057,
      "learning_rate": 2.7973041524748173e-05,
      "loss": 0.0508,
      "step": 11870
    },
    {
      "epoch": 0.8603109033590608,
      "grad_norm": 1.3219642639160156,
      "learning_rate": 2.7958547720849336e-05,
      "loss": 0.0528,
      "step": 11871
    },
    {
      "epoch": 0.8603833750045294,
      "grad_norm": 2.3945400714874268,
      "learning_rate": 2.7944053916950503e-05,
      "loss": 0.0603,
      "step": 11872
    },
    {
      "epoch": 0.8604558466499982,
      "grad_norm": 2.1754043102264404,
      "learning_rate": 2.7929560113051673e-05,
      "loss": 0.0515,
      "step": 11873
    },
    {
      "epoch": 0.8605283182954669,
      "grad_norm": 0.2560230493545532,
      "learning_rate": 2.7915066309152836e-05,
      "loss": 0.0075,
      "step": 11874
    },
    {
      "epoch": 0.8606007899409356,
      "grad_norm": 0.29012566804885864,
      "learning_rate": 2.7900572505254006e-05,
      "loss": 0.0039,
      "step": 11875
    },
    {
      "epoch": 0.8606732615864043,
      "grad_norm": 2.172797441482544,
      "learning_rate": 2.7886078701355173e-05,
      "loss": 0.0329,
      "step": 11876
    },
    {
      "epoch": 0.860745733231873,
      "grad_norm": 3.492914915084839,
      "learning_rate": 2.7871584897456336e-05,
      "loss": 0.047,
      "step": 11877
    },
    {
      "epoch": 0.8608182048773417,
      "grad_norm": 0.4430457651615143,
      "learning_rate": 2.7857091093557506e-05,
      "loss": 0.0037,
      "step": 11878
    },
    {
      "epoch": 0.8608906765228105,
      "grad_norm": 0.5754220485687256,
      "learning_rate": 2.7842597289658673e-05,
      "loss": 0.0099,
      "step": 11879
    },
    {
      "epoch": 0.8609631481682791,
      "grad_norm": 1.2760764360427856,
      "learning_rate": 2.7828103485759836e-05,
      "loss": 0.0305,
      "step": 11880
    },
    {
      "epoch": 0.8610356198137479,
      "grad_norm": 0.5248662233352661,
      "learning_rate": 2.781360968186101e-05,
      "loss": 0.0127,
      "step": 11881
    },
    {
      "epoch": 0.8611080914592166,
      "grad_norm": 2.7869439125061035,
      "learning_rate": 2.7799115877962173e-05,
      "loss": 0.0371,
      "step": 11882
    },
    {
      "epoch": 0.8611805631046853,
      "grad_norm": 1.6360849142074585,
      "learning_rate": 2.7784622074063336e-05,
      "loss": 0.0784,
      "step": 11883
    },
    {
      "epoch": 0.861253034750154,
      "grad_norm": 2.9825637340545654,
      "learning_rate": 2.777012827016451e-05,
      "loss": 0.0591,
      "step": 11884
    },
    {
      "epoch": 0.8613255063956227,
      "grad_norm": 0.43045592308044434,
      "learning_rate": 2.7755634466265673e-05,
      "loss": 0.0095,
      "step": 11885
    },
    {
      "epoch": 0.8613979780410914,
      "grad_norm": 0.5441715121269226,
      "learning_rate": 2.774114066236684e-05,
      "loss": 0.0196,
      "step": 11886
    },
    {
      "epoch": 0.8614704496865602,
      "grad_norm": 1.3039377927780151,
      "learning_rate": 2.772664685846801e-05,
      "loss": 0.0262,
      "step": 11887
    },
    {
      "epoch": 0.8615429213320288,
      "grad_norm": 1.9669795036315918,
      "learning_rate": 2.7712153054569173e-05,
      "loss": 0.057,
      "step": 11888
    },
    {
      "epoch": 0.8616153929774976,
      "grad_norm": 2.431582450866699,
      "learning_rate": 2.769765925067034e-05,
      "loss": 0.0429,
      "step": 11889
    },
    {
      "epoch": 0.8616878646229663,
      "grad_norm": 0.53130042552948,
      "learning_rate": 2.768316544677151e-05,
      "loss": 0.0059,
      "step": 11890
    },
    {
      "epoch": 0.861760336268435,
      "grad_norm": 2.9831748008728027,
      "learning_rate": 2.7668671642872673e-05,
      "loss": 0.0913,
      "step": 11891
    },
    {
      "epoch": 0.8618328079139037,
      "grad_norm": 0.17929646372795105,
      "learning_rate": 2.765417783897384e-05,
      "loss": 0.0042,
      "step": 11892
    },
    {
      "epoch": 0.8619052795593724,
      "grad_norm": 0.657966136932373,
      "learning_rate": 2.763968403507501e-05,
      "loss": 0.0149,
      "step": 11893
    },
    {
      "epoch": 0.8619777512048411,
      "grad_norm": 0.4743892252445221,
      "learning_rate": 2.7625190231176173e-05,
      "loss": 0.0201,
      "step": 11894
    },
    {
      "epoch": 0.8620502228503099,
      "grad_norm": 0.27300673723220825,
      "learning_rate": 2.761069642727734e-05,
      "loss": 0.0036,
      "step": 11895
    },
    {
      "epoch": 0.8621226944957785,
      "grad_norm": 4.3954572677612305,
      "learning_rate": 2.759620262337851e-05,
      "loss": 0.1198,
      "step": 11896
    },
    {
      "epoch": 0.8621951661412472,
      "grad_norm": 0.4096505045890808,
      "learning_rate": 2.7581708819479673e-05,
      "loss": 0.0132,
      "step": 11897
    },
    {
      "epoch": 0.862267637786716,
      "grad_norm": 1.9958339929580688,
      "learning_rate": 2.756721501558084e-05,
      "loss": 0.0927,
      "step": 11898
    },
    {
      "epoch": 0.8623401094321846,
      "grad_norm": 0.019312763586640358,
      "learning_rate": 2.755272121168201e-05,
      "loss": 0.0003,
      "step": 11899
    },
    {
      "epoch": 0.8624125810776534,
      "grad_norm": 0.2246427834033966,
      "learning_rate": 2.7538227407783173e-05,
      "loss": 0.003,
      "step": 11900
    },
    {
      "epoch": 0.862485052723122,
      "grad_norm": 0.4301169514656067,
      "learning_rate": 2.752373360388434e-05,
      "loss": 0.0177,
      "step": 11901
    },
    {
      "epoch": 0.8625575243685908,
      "grad_norm": 1.7374987602233887,
      "learning_rate": 2.750923979998551e-05,
      "loss": 0.0269,
      "step": 11902
    },
    {
      "epoch": 0.8626299960140595,
      "grad_norm": 1.4637641906738281,
      "learning_rate": 2.7494745996086673e-05,
      "loss": 0.0233,
      "step": 11903
    },
    {
      "epoch": 0.8627024676595282,
      "grad_norm": 4.450868129730225,
      "learning_rate": 2.748025219218784e-05,
      "loss": 0.1314,
      "step": 11904
    },
    {
      "epoch": 0.8627749393049969,
      "grad_norm": 0.7038388252258301,
      "learning_rate": 2.746575838828901e-05,
      "loss": 0.0291,
      "step": 11905
    },
    {
      "epoch": 0.8628474109504656,
      "grad_norm": 3.091292142868042,
      "learning_rate": 2.7451264584390173e-05,
      "loss": 0.0398,
      "step": 11906
    },
    {
      "epoch": 0.8629198825959343,
      "grad_norm": 1.7442690134048462,
      "learning_rate": 2.743677078049134e-05,
      "loss": 0.0251,
      "step": 11907
    },
    {
      "epoch": 0.8629923542414031,
      "grad_norm": 0.9564009308815002,
      "learning_rate": 2.742227697659251e-05,
      "loss": 0.0142,
      "step": 11908
    },
    {
      "epoch": 0.8630648258868717,
      "grad_norm": 0.5563420653343201,
      "learning_rate": 2.7407783172693672e-05,
      "loss": 0.0117,
      "step": 11909
    },
    {
      "epoch": 0.8631372975323405,
      "grad_norm": 5.199710369110107,
      "learning_rate": 2.739328936879484e-05,
      "loss": 0.0967,
      "step": 11910
    },
    {
      "epoch": 0.8632097691778092,
      "grad_norm": 2.556344509124756,
      "learning_rate": 2.737879556489601e-05,
      "loss": 0.1054,
      "step": 11911
    },
    {
      "epoch": 0.8632822408232779,
      "grad_norm": 2.503772020339966,
      "learning_rate": 2.7364301760997176e-05,
      "loss": 0.0362,
      "step": 11912
    },
    {
      "epoch": 0.8633547124687466,
      "grad_norm": 3.8431882858276367,
      "learning_rate": 2.7349807957098346e-05,
      "loss": 0.1613,
      "step": 11913
    },
    {
      "epoch": 0.8634271841142153,
      "grad_norm": 0.7870041728019714,
      "learning_rate": 2.733531415319951e-05,
      "loss": 0.0238,
      "step": 11914
    },
    {
      "epoch": 0.863499655759684,
      "grad_norm": 1.5077515840530396,
      "learning_rate": 2.7320820349300676e-05,
      "loss": 0.054,
      "step": 11915
    },
    {
      "epoch": 0.8635721274051528,
      "grad_norm": 0.8116567134857178,
      "learning_rate": 2.7306326545401846e-05,
      "loss": 0.0292,
      "step": 11916
    },
    {
      "epoch": 0.8636445990506214,
      "grad_norm": 1.192144513130188,
      "learning_rate": 2.729183274150301e-05,
      "loss": 0.0174,
      "step": 11917
    },
    {
      "epoch": 0.8637170706960902,
      "grad_norm": 0.700164794921875,
      "learning_rate": 2.7277338937604176e-05,
      "loss": 0.0069,
      "step": 11918
    },
    {
      "epoch": 0.8637895423415589,
      "grad_norm": 2.974973201751709,
      "learning_rate": 2.7262845133705346e-05,
      "loss": 0.0742,
      "step": 11919
    },
    {
      "epoch": 0.8638620139870276,
      "grad_norm": 0.19796122610569,
      "learning_rate": 2.724835132980651e-05,
      "loss": 0.0039,
      "step": 11920
    },
    {
      "epoch": 0.8639344856324963,
      "grad_norm": 2.557088851928711,
      "learning_rate": 2.7233857525907676e-05,
      "loss": 0.052,
      "step": 11921
    },
    {
      "epoch": 0.864006957277965,
      "grad_norm": 3.373622417449951,
      "learning_rate": 2.7219363722008846e-05,
      "loss": 0.0481,
      "step": 11922
    },
    {
      "epoch": 0.8640794289234337,
      "grad_norm": 0.44379666447639465,
      "learning_rate": 2.720486991811001e-05,
      "loss": 0.0108,
      "step": 11923
    },
    {
      "epoch": 0.8641519005689025,
      "grad_norm": 0.010955097153782845,
      "learning_rate": 2.7190376114211176e-05,
      "loss": 0.0003,
      "step": 11924
    },
    {
      "epoch": 0.8642243722143711,
      "grad_norm": 1.650367021560669,
      "learning_rate": 2.7175882310312346e-05,
      "loss": 0.016,
      "step": 11925
    },
    {
      "epoch": 0.8642968438598398,
      "grad_norm": 0.7983818650245667,
      "learning_rate": 2.716138850641351e-05,
      "loss": 0.0296,
      "step": 11926
    },
    {
      "epoch": 0.8643693155053086,
      "grad_norm": 1.4348556995391846,
      "learning_rate": 2.7146894702514676e-05,
      "loss": 0.0115,
      "step": 11927
    },
    {
      "epoch": 0.8644417871507772,
      "grad_norm": 4.49143123626709,
      "learning_rate": 2.7132400898615846e-05,
      "loss": 0.1045,
      "step": 11928
    },
    {
      "epoch": 0.864514258796246,
      "grad_norm": 0.3126947283744812,
      "learning_rate": 2.711790709471701e-05,
      "loss": 0.0135,
      "step": 11929
    },
    {
      "epoch": 0.8645867304417146,
      "grad_norm": 2.2785143852233887,
      "learning_rate": 2.7103413290818176e-05,
      "loss": 0.0674,
      "step": 11930
    },
    {
      "epoch": 0.8646592020871834,
      "grad_norm": 1.816800594329834,
      "learning_rate": 2.7088919486919346e-05,
      "loss": 0.0258,
      "step": 11931
    },
    {
      "epoch": 0.8647316737326521,
      "grad_norm": 2.000027656555176,
      "learning_rate": 2.707442568302051e-05,
      "loss": 0.1042,
      "step": 11932
    },
    {
      "epoch": 0.8648041453781208,
      "grad_norm": 0.14260903000831604,
      "learning_rate": 2.7059931879121675e-05,
      "loss": 0.0019,
      "step": 11933
    },
    {
      "epoch": 0.8648766170235895,
      "grad_norm": 12.976099967956543,
      "learning_rate": 2.7045438075222845e-05,
      "loss": 0.1228,
      "step": 11934
    },
    {
      "epoch": 0.8649490886690583,
      "grad_norm": 2.183258295059204,
      "learning_rate": 2.703094427132401e-05,
      "loss": 0.092,
      "step": 11935
    },
    {
      "epoch": 0.8650215603145269,
      "grad_norm": 2.735265016555786,
      "learning_rate": 2.7016450467425175e-05,
      "loss": 0.1512,
      "step": 11936
    },
    {
      "epoch": 0.8650940319599957,
      "grad_norm": 0.9695513248443604,
      "learning_rate": 2.7001956663526345e-05,
      "loss": 0.045,
      "step": 11937
    },
    {
      "epoch": 0.8651665036054643,
      "grad_norm": 0.7098323702812195,
      "learning_rate": 2.698746285962751e-05,
      "loss": 0.0079,
      "step": 11938
    },
    {
      "epoch": 0.8652389752509331,
      "grad_norm": 1.9255847930908203,
      "learning_rate": 2.6972969055728675e-05,
      "loss": 0.0551,
      "step": 11939
    },
    {
      "epoch": 0.8653114468964018,
      "grad_norm": 0.01165657490491867,
      "learning_rate": 2.6958475251829845e-05,
      "loss": 0.0003,
      "step": 11940
    },
    {
      "epoch": 0.8653839185418705,
      "grad_norm": 1.57683527469635,
      "learning_rate": 2.6943981447931012e-05,
      "loss": 0.0714,
      "step": 11941
    },
    {
      "epoch": 0.8654563901873392,
      "grad_norm": 1.3015387058258057,
      "learning_rate": 2.6929487644032175e-05,
      "loss": 0.066,
      "step": 11942
    },
    {
      "epoch": 0.8655288618328079,
      "grad_norm": 1.281062126159668,
      "learning_rate": 2.6914993840133345e-05,
      "loss": 0.0358,
      "step": 11943
    },
    {
      "epoch": 0.8656013334782766,
      "grad_norm": 0.7765287756919861,
      "learning_rate": 2.6900500036234512e-05,
      "loss": 0.0219,
      "step": 11944
    },
    {
      "epoch": 0.8656738051237454,
      "grad_norm": 1.2741090059280396,
      "learning_rate": 2.6886006232335675e-05,
      "loss": 0.0638,
      "step": 11945
    },
    {
      "epoch": 0.865746276769214,
      "grad_norm": 0.760067343711853,
      "learning_rate": 2.6871512428436845e-05,
      "loss": 0.0233,
      "step": 11946
    },
    {
      "epoch": 0.8658187484146828,
      "grad_norm": 0.680853545665741,
      "learning_rate": 2.6857018624538012e-05,
      "loss": 0.0183,
      "step": 11947
    },
    {
      "epoch": 0.8658912200601515,
      "grad_norm": 0.2319154441356659,
      "learning_rate": 2.6842524820639175e-05,
      "loss": 0.0044,
      "step": 11948
    },
    {
      "epoch": 0.8659636917056202,
      "grad_norm": 1.3022596836090088,
      "learning_rate": 2.6828031016740345e-05,
      "loss": 0.0477,
      "step": 11949
    },
    {
      "epoch": 0.8660361633510889,
      "grad_norm": 1.3906124830245972,
      "learning_rate": 2.6813537212841512e-05,
      "loss": 0.0149,
      "step": 11950
    },
    {
      "epoch": 0.8661086349965575,
      "grad_norm": 0.9711175560951233,
      "learning_rate": 2.6799043408942675e-05,
      "loss": 0.0143,
      "step": 11951
    },
    {
      "epoch": 0.8661811066420263,
      "grad_norm": 0.5087700486183167,
      "learning_rate": 2.6784549605043845e-05,
      "loss": 0.0113,
      "step": 11952
    },
    {
      "epoch": 0.866253578287495,
      "grad_norm": 0.42711395025253296,
      "learning_rate": 2.6770055801145012e-05,
      "loss": 0.003,
      "step": 11953
    },
    {
      "epoch": 0.8663260499329637,
      "grad_norm": 0.20642220973968506,
      "learning_rate": 2.6755561997246182e-05,
      "loss": 0.0027,
      "step": 11954
    },
    {
      "epoch": 0.8663985215784324,
      "grad_norm": 0.39598387479782104,
      "learning_rate": 2.6741068193347345e-05,
      "loss": 0.0047,
      "step": 11955
    },
    {
      "epoch": 0.8664709932239012,
      "grad_norm": 1.5952467918395996,
      "learning_rate": 2.6726574389448512e-05,
      "loss": 0.0513,
      "step": 11956
    },
    {
      "epoch": 0.8665434648693698,
      "grad_norm": 2.676687717437744,
      "learning_rate": 2.6712080585549682e-05,
      "loss": 0.1084,
      "step": 11957
    },
    {
      "epoch": 0.8666159365148386,
      "grad_norm": 0.7737387418746948,
      "learning_rate": 2.6697586781650845e-05,
      "loss": 0.0274,
      "step": 11958
    },
    {
      "epoch": 0.8666884081603072,
      "grad_norm": 0.4876123070716858,
      "learning_rate": 2.6683092977752012e-05,
      "loss": 0.0111,
      "step": 11959
    },
    {
      "epoch": 0.866760879805776,
      "grad_norm": 0.8048429489135742,
      "learning_rate": 2.6668599173853182e-05,
      "loss": 0.0168,
      "step": 11960
    },
    {
      "epoch": 0.8668333514512447,
      "grad_norm": 0.3708741068840027,
      "learning_rate": 2.6654105369954345e-05,
      "loss": 0.0078,
      "step": 11961
    },
    {
      "epoch": 0.8669058230967134,
      "grad_norm": 1.1395498514175415,
      "learning_rate": 2.663961156605551e-05,
      "loss": 0.0297,
      "step": 11962
    },
    {
      "epoch": 0.8669782947421821,
      "grad_norm": 3.562648057937622,
      "learning_rate": 2.6625117762156682e-05,
      "loss": 0.0803,
      "step": 11963
    },
    {
      "epoch": 0.8670507663876509,
      "grad_norm": 1.4653385877609253,
      "learning_rate": 2.6610623958257845e-05,
      "loss": 0.0337,
      "step": 11964
    },
    {
      "epoch": 0.8671232380331195,
      "grad_norm": 0.4576760232448578,
      "learning_rate": 2.659613015435901e-05,
      "loss": 0.0106,
      "step": 11965
    },
    {
      "epoch": 0.8671957096785883,
      "grad_norm": 1.58577299118042,
      "learning_rate": 2.658163635046018e-05,
      "loss": 0.0618,
      "step": 11966
    },
    {
      "epoch": 0.8672681813240569,
      "grad_norm": 0.7956387996673584,
      "learning_rate": 2.6567142546561345e-05,
      "loss": 0.0173,
      "step": 11967
    },
    {
      "epoch": 0.8673406529695257,
      "grad_norm": 1.3797779083251953,
      "learning_rate": 2.655264874266251e-05,
      "loss": 0.0451,
      "step": 11968
    },
    {
      "epoch": 0.8674131246149944,
      "grad_norm": 0.35639262199401855,
      "learning_rate": 2.653815493876368e-05,
      "loss": 0.0204,
      "step": 11969
    },
    {
      "epoch": 0.8674855962604631,
      "grad_norm": 0.4174915552139282,
      "learning_rate": 2.6523661134864848e-05,
      "loss": 0.0042,
      "step": 11970
    },
    {
      "epoch": 0.8675580679059318,
      "grad_norm": 2.176119327545166,
      "learning_rate": 2.650916733096601e-05,
      "loss": 0.0869,
      "step": 11971
    },
    {
      "epoch": 0.8676305395514005,
      "grad_norm": 2.0516767501831055,
      "learning_rate": 2.649467352706718e-05,
      "loss": 0.0678,
      "step": 11972
    },
    {
      "epoch": 0.8677030111968692,
      "grad_norm": 1.3686224222183228,
      "learning_rate": 2.6480179723168348e-05,
      "loss": 0.0254,
      "step": 11973
    },
    {
      "epoch": 0.867775482842338,
      "grad_norm": 1.7367099523544312,
      "learning_rate": 2.646568591926951e-05,
      "loss": 0.056,
      "step": 11974
    },
    {
      "epoch": 0.8678479544878066,
      "grad_norm": 0.29363182187080383,
      "learning_rate": 2.645119211537068e-05,
      "loss": 0.0055,
      "step": 11975
    },
    {
      "epoch": 0.8679204261332754,
      "grad_norm": 1.8902888298034668,
      "learning_rate": 2.6436698311471848e-05,
      "loss": 0.0257,
      "step": 11976
    },
    {
      "epoch": 0.8679928977787441,
      "grad_norm": 4.148977756500244,
      "learning_rate": 2.642220450757301e-05,
      "loss": 0.0978,
      "step": 11977
    },
    {
      "epoch": 0.8680653694242128,
      "grad_norm": 7.624790191650391,
      "learning_rate": 2.640771070367418e-05,
      "loss": 0.0697,
      "step": 11978
    },
    {
      "epoch": 0.8681378410696815,
      "grad_norm": 0.44484663009643555,
      "learning_rate": 2.6393216899775348e-05,
      "loss": 0.0055,
      "step": 11979
    },
    {
      "epoch": 0.8682103127151501,
      "grad_norm": 2.543668508529663,
      "learning_rate": 2.637872309587651e-05,
      "loss": 0.1239,
      "step": 11980
    },
    {
      "epoch": 0.8682827843606189,
      "grad_norm": 1.004857063293457,
      "learning_rate": 2.636422929197768e-05,
      "loss": 0.0323,
      "step": 11981
    },
    {
      "epoch": 0.8683552560060877,
      "grad_norm": 0.2702298164367676,
      "learning_rate": 2.6349735488078848e-05,
      "loss": 0.0059,
      "step": 11982
    },
    {
      "epoch": 0.8684277276515563,
      "grad_norm": 0.8012564778327942,
      "learning_rate": 2.633524168418001e-05,
      "loss": 0.0198,
      "step": 11983
    },
    {
      "epoch": 0.868500199297025,
      "grad_norm": 1.0735399723052979,
      "learning_rate": 2.632074788028118e-05,
      "loss": 0.0244,
      "step": 11984
    },
    {
      "epoch": 0.8685726709424938,
      "grad_norm": 2.646167755126953,
      "learning_rate": 2.6306254076382348e-05,
      "loss": 0.0706,
      "step": 11985
    },
    {
      "epoch": 0.8686451425879624,
      "grad_norm": 0.47488003969192505,
      "learning_rate": 2.629176027248351e-05,
      "loss": 0.011,
      "step": 11986
    },
    {
      "epoch": 0.8687176142334312,
      "grad_norm": 0.9836028814315796,
      "learning_rate": 2.627726646858468e-05,
      "loss": 0.0095,
      "step": 11987
    },
    {
      "epoch": 0.8687900858788998,
      "grad_norm": 0.3424419164657593,
      "learning_rate": 2.6262772664685848e-05,
      "loss": 0.0141,
      "step": 11988
    },
    {
      "epoch": 0.8688625575243686,
      "grad_norm": 1.0120760202407837,
      "learning_rate": 2.624827886078701e-05,
      "loss": 0.0284,
      "step": 11989
    },
    {
      "epoch": 0.8689350291698373,
      "grad_norm": 3.0246493816375732,
      "learning_rate": 2.623378505688818e-05,
      "loss": 0.0656,
      "step": 11990
    },
    {
      "epoch": 0.869007500815306,
      "grad_norm": 0.9350200891494751,
      "learning_rate": 2.6219291252989348e-05,
      "loss": 0.0282,
      "step": 11991
    },
    {
      "epoch": 0.8690799724607747,
      "grad_norm": 0.03655160963535309,
      "learning_rate": 2.620479744909051e-05,
      "loss": 0.0006,
      "step": 11992
    },
    {
      "epoch": 0.8691524441062435,
      "grad_norm": 4.400817394256592,
      "learning_rate": 2.619030364519168e-05,
      "loss": 0.1431,
      "step": 11993
    },
    {
      "epoch": 0.8692249157517121,
      "grad_norm": 1.414588451385498,
      "learning_rate": 2.6175809841292848e-05,
      "loss": 0.0391,
      "step": 11994
    },
    {
      "epoch": 0.8692973873971809,
      "grad_norm": 1.6611913442611694,
      "learning_rate": 2.6161316037394018e-05,
      "loss": 0.0222,
      "step": 11995
    },
    {
      "epoch": 0.8693698590426495,
      "grad_norm": 1.2203598022460938,
      "learning_rate": 2.6146822233495185e-05,
      "loss": 0.0598,
      "step": 11996
    },
    {
      "epoch": 0.8694423306881183,
      "grad_norm": 2.921766996383667,
      "learning_rate": 2.6132328429596348e-05,
      "loss": 0.0411,
      "step": 11997
    },
    {
      "epoch": 0.869514802333587,
      "grad_norm": 0.4563831090927124,
      "learning_rate": 2.6117834625697518e-05,
      "loss": 0.0139,
      "step": 11998
    },
    {
      "epoch": 0.8695872739790557,
      "grad_norm": 1.747849941253662,
      "learning_rate": 2.6103340821798684e-05,
      "loss": 0.0309,
      "step": 11999
    },
    {
      "epoch": 0.8696597456245244,
      "grad_norm": 0.7329097986221313,
      "learning_rate": 2.6088847017899848e-05,
      "loss": 0.0279,
      "step": 12000
    },
    {
      "epoch": 0.8697322172699932,
      "grad_norm": 0.08060308545827866,
      "learning_rate": 2.6074353214001018e-05,
      "loss": 0.0017,
      "step": 12001
    },
    {
      "epoch": 0.8698046889154618,
      "grad_norm": 2.8184690475463867,
      "learning_rate": 2.6059859410102184e-05,
      "loss": 0.0903,
      "step": 12002
    },
    {
      "epoch": 0.8698771605609306,
      "grad_norm": 0.03208872675895691,
      "learning_rate": 2.6045365606203348e-05,
      "loss": 0.0006,
      "step": 12003
    },
    {
      "epoch": 0.8699496322063992,
      "grad_norm": 2.8112692832946777,
      "learning_rate": 2.6030871802304518e-05,
      "loss": 0.073,
      "step": 12004
    },
    {
      "epoch": 0.870022103851868,
      "grad_norm": 0.7640182971954346,
      "learning_rate": 2.6016377998405684e-05,
      "loss": 0.0099,
      "step": 12005
    },
    {
      "epoch": 0.8700945754973367,
      "grad_norm": 1.3349179029464722,
      "learning_rate": 2.6001884194506848e-05,
      "loss": 0.0719,
      "step": 12006
    },
    {
      "epoch": 0.8701670471428053,
      "grad_norm": 1.2850621938705444,
      "learning_rate": 2.5987390390608018e-05,
      "loss": 0.039,
      "step": 12007
    },
    {
      "epoch": 0.8702395187882741,
      "grad_norm": 2.9779958724975586,
      "learning_rate": 2.5972896586709184e-05,
      "loss": 0.0737,
      "step": 12008
    },
    {
      "epoch": 0.8703119904337427,
      "grad_norm": 0.92693692445755,
      "learning_rate": 2.5958402782810348e-05,
      "loss": 0.0165,
      "step": 12009
    },
    {
      "epoch": 0.8703844620792115,
      "grad_norm": 0.09747467935085297,
      "learning_rate": 2.5943908978911518e-05,
      "loss": 0.0015,
      "step": 12010
    },
    {
      "epoch": 0.8704569337246802,
      "grad_norm": 0.36211875081062317,
      "learning_rate": 2.5929415175012684e-05,
      "loss": 0.011,
      "step": 12011
    },
    {
      "epoch": 0.8705294053701489,
      "grad_norm": 3.063969373703003,
      "learning_rate": 2.5914921371113848e-05,
      "loss": 0.0778,
      "step": 12012
    },
    {
      "epoch": 0.8706018770156176,
      "grad_norm": 0.39529114961624146,
      "learning_rate": 2.5900427567215018e-05,
      "loss": 0.0176,
      "step": 12013
    },
    {
      "epoch": 0.8706743486610864,
      "grad_norm": 0.545028805732727,
      "learning_rate": 2.5885933763316184e-05,
      "loss": 0.016,
      "step": 12014
    },
    {
      "epoch": 0.870746820306555,
      "grad_norm": 2.332785129547119,
      "learning_rate": 2.5871439959417347e-05,
      "loss": 0.0956,
      "step": 12015
    },
    {
      "epoch": 0.8708192919520238,
      "grad_norm": 1.0160188674926758,
      "learning_rate": 2.5856946155518518e-05,
      "loss": 0.0147,
      "step": 12016
    },
    {
      "epoch": 0.8708917635974924,
      "grad_norm": 1.2173224687576294,
      "learning_rate": 2.5842452351619684e-05,
      "loss": 0.0355,
      "step": 12017
    },
    {
      "epoch": 0.8709642352429612,
      "grad_norm": 1.0591411590576172,
      "learning_rate": 2.5827958547720847e-05,
      "loss": 0.0401,
      "step": 12018
    },
    {
      "epoch": 0.8710367068884299,
      "grad_norm": 0.1470750868320465,
      "learning_rate": 2.5813464743822017e-05,
      "loss": 0.004,
      "step": 12019
    },
    {
      "epoch": 0.8711091785338986,
      "grad_norm": 0.5671865940093994,
      "learning_rate": 2.5798970939923184e-05,
      "loss": 0.008,
      "step": 12020
    },
    {
      "epoch": 0.8711816501793673,
      "grad_norm": 2.166172504425049,
      "learning_rate": 2.5784477136024347e-05,
      "loss": 0.0555,
      "step": 12021
    },
    {
      "epoch": 0.8712541218248361,
      "grad_norm": 0.47185400128364563,
      "learning_rate": 2.5769983332125517e-05,
      "loss": 0.0112,
      "step": 12022
    },
    {
      "epoch": 0.8713265934703047,
      "grad_norm": 0.8672259449958801,
      "learning_rate": 2.5755489528226684e-05,
      "loss": 0.0382,
      "step": 12023
    },
    {
      "epoch": 0.8713990651157735,
      "grad_norm": 4.518017768859863,
      "learning_rate": 2.5740995724327847e-05,
      "loss": 0.0724,
      "step": 12024
    },
    {
      "epoch": 0.8714715367612421,
      "grad_norm": 1.6079858541488647,
      "learning_rate": 2.572650192042902e-05,
      "loss": 0.0294,
      "step": 12025
    },
    {
      "epoch": 0.8715440084067109,
      "grad_norm": 0.5197848081588745,
      "learning_rate": 2.5712008116530184e-05,
      "loss": 0.0104,
      "step": 12026
    },
    {
      "epoch": 0.8716164800521796,
      "grad_norm": 1.1136987209320068,
      "learning_rate": 2.5697514312631347e-05,
      "loss": 0.039,
      "step": 12027
    },
    {
      "epoch": 0.8716889516976483,
      "grad_norm": 2.1360743045806885,
      "learning_rate": 2.568302050873252e-05,
      "loss": 0.0715,
      "step": 12028
    },
    {
      "epoch": 0.871761423343117,
      "grad_norm": 1.1648170948028564,
      "learning_rate": 2.5668526704833684e-05,
      "loss": 0.0094,
      "step": 12029
    },
    {
      "epoch": 0.8718338949885858,
      "grad_norm": 2.395749568939209,
      "learning_rate": 2.565403290093485e-05,
      "loss": 0.085,
      "step": 12030
    },
    {
      "epoch": 0.8719063666340544,
      "grad_norm": 1.3197287321090698,
      "learning_rate": 2.563953909703602e-05,
      "loss": 0.0066,
      "step": 12031
    },
    {
      "epoch": 0.8719788382795232,
      "grad_norm": 2.655911684036255,
      "learning_rate": 2.5625045293137184e-05,
      "loss": 0.1012,
      "step": 12032
    },
    {
      "epoch": 0.8720513099249918,
      "grad_norm": 0.314162015914917,
      "learning_rate": 2.561055148923835e-05,
      "loss": 0.0108,
      "step": 12033
    },
    {
      "epoch": 0.8721237815704606,
      "grad_norm": 0.23271077871322632,
      "learning_rate": 2.559605768533952e-05,
      "loss": 0.0055,
      "step": 12034
    },
    {
      "epoch": 0.8721962532159293,
      "grad_norm": 0.4824734330177307,
      "learning_rate": 2.5581563881440684e-05,
      "loss": 0.008,
      "step": 12035
    },
    {
      "epoch": 0.872268724861398,
      "grad_norm": 1.7103136777877808,
      "learning_rate": 2.5567070077541854e-05,
      "loss": 0.0593,
      "step": 12036
    },
    {
      "epoch": 0.8723411965068667,
      "grad_norm": 1.5535833835601807,
      "learning_rate": 2.555257627364302e-05,
      "loss": 0.0609,
      "step": 12037
    },
    {
      "epoch": 0.8724136681523355,
      "grad_norm": 3.6523752212524414,
      "learning_rate": 2.5538082469744184e-05,
      "loss": 0.0891,
      "step": 12038
    },
    {
      "epoch": 0.8724861397978041,
      "grad_norm": 4.739774703979492,
      "learning_rate": 2.5523588665845354e-05,
      "loss": 0.1186,
      "step": 12039
    },
    {
      "epoch": 0.8725586114432728,
      "grad_norm": 1.562205195426941,
      "learning_rate": 2.550909486194652e-05,
      "loss": 0.0581,
      "step": 12040
    },
    {
      "epoch": 0.8726310830887415,
      "grad_norm": 0.5612277984619141,
      "learning_rate": 2.5494601058047684e-05,
      "loss": 0.0132,
      "step": 12041
    },
    {
      "epoch": 0.8727035547342102,
      "grad_norm": 1.5667659044265747,
      "learning_rate": 2.5480107254148854e-05,
      "loss": 0.0179,
      "step": 12042
    },
    {
      "epoch": 0.872776026379679,
      "grad_norm": 1.8461410999298096,
      "learning_rate": 2.546561345025002e-05,
      "loss": 0.049,
      "step": 12043
    },
    {
      "epoch": 0.8728484980251476,
      "grad_norm": 1.0045167207717896,
      "learning_rate": 2.5451119646351184e-05,
      "loss": 0.0188,
      "step": 12044
    },
    {
      "epoch": 0.8729209696706164,
      "grad_norm": 0.8345557451248169,
      "learning_rate": 2.5436625842452354e-05,
      "loss": 0.0512,
      "step": 12045
    },
    {
      "epoch": 0.872993441316085,
      "grad_norm": 1.0388514995574951,
      "learning_rate": 2.542213203855352e-05,
      "loss": 0.0168,
      "step": 12046
    },
    {
      "epoch": 0.8730659129615538,
      "grad_norm": 0.9798686504364014,
      "learning_rate": 2.5407638234654684e-05,
      "loss": 0.0335,
      "step": 12047
    },
    {
      "epoch": 0.8731383846070225,
      "grad_norm": 0.10092626512050629,
      "learning_rate": 2.5393144430755854e-05,
      "loss": 0.0016,
      "step": 12048
    },
    {
      "epoch": 0.8732108562524912,
      "grad_norm": 1.2817951440811157,
      "learning_rate": 2.537865062685702e-05,
      "loss": 0.029,
      "step": 12049
    },
    {
      "epoch": 0.8732833278979599,
      "grad_norm": 3.5388543605804443,
      "learning_rate": 2.5364156822958184e-05,
      "loss": 0.0838,
      "step": 12050
    },
    {
      "epoch": 0.8733557995434287,
      "grad_norm": 0.8200118541717529,
      "learning_rate": 2.5349663019059357e-05,
      "loss": 0.0438,
      "step": 12051
    },
    {
      "epoch": 0.8734282711888973,
      "grad_norm": 2.1908562183380127,
      "learning_rate": 2.533516921516052e-05,
      "loss": 0.0211,
      "step": 12052
    },
    {
      "epoch": 0.8735007428343661,
      "grad_norm": 0.7262089252471924,
      "learning_rate": 2.5320675411261684e-05,
      "loss": 0.0342,
      "step": 12053
    },
    {
      "epoch": 0.8735732144798347,
      "grad_norm": 0.7602793574333191,
      "learning_rate": 2.5306181607362857e-05,
      "loss": 0.0097,
      "step": 12054
    },
    {
      "epoch": 0.8736456861253035,
      "grad_norm": 1.0621806383132935,
      "learning_rate": 2.529168780346402e-05,
      "loss": 0.0267,
      "step": 12055
    },
    {
      "epoch": 0.8737181577707722,
      "grad_norm": 1.9702463150024414,
      "learning_rate": 2.5277193999565184e-05,
      "loss": 0.0974,
      "step": 12056
    },
    {
      "epoch": 0.8737906294162409,
      "grad_norm": 2.4355204105377197,
      "learning_rate": 2.5262700195666357e-05,
      "loss": 0.0669,
      "step": 12057
    },
    {
      "epoch": 0.8738631010617096,
      "grad_norm": 2.170792579650879,
      "learning_rate": 2.524820639176752e-05,
      "loss": 0.0605,
      "step": 12058
    },
    {
      "epoch": 0.8739355727071784,
      "grad_norm": 1.7240689992904663,
      "learning_rate": 2.5233712587868687e-05,
      "loss": 0.0256,
      "step": 12059
    },
    {
      "epoch": 0.874008044352647,
      "grad_norm": 1.5768803358078003,
      "learning_rate": 2.5219218783969857e-05,
      "loss": 0.0421,
      "step": 12060
    },
    {
      "epoch": 0.8740805159981158,
      "grad_norm": 3.9208436012268066,
      "learning_rate": 2.520472498007102e-05,
      "loss": 0.1213,
      "step": 12061
    },
    {
      "epoch": 0.8741529876435844,
      "grad_norm": 1.619581937789917,
      "learning_rate": 2.5190231176172187e-05,
      "loss": 0.0901,
      "step": 12062
    },
    {
      "epoch": 0.8742254592890532,
      "grad_norm": 1.572721242904663,
      "learning_rate": 2.5175737372273357e-05,
      "loss": 0.0862,
      "step": 12063
    },
    {
      "epoch": 0.8742979309345219,
      "grad_norm": 1.2745773792266846,
      "learning_rate": 2.516124356837452e-05,
      "loss": 0.0607,
      "step": 12064
    },
    {
      "epoch": 0.8743704025799905,
      "grad_norm": 0.311616450548172,
      "learning_rate": 2.5146749764475687e-05,
      "loss": 0.0062,
      "step": 12065
    },
    {
      "epoch": 0.8744428742254593,
      "grad_norm": 1.6370054483413696,
      "learning_rate": 2.5132255960576857e-05,
      "loss": 0.0272,
      "step": 12066
    },
    {
      "epoch": 0.874515345870928,
      "grad_norm": 3.086728572845459,
      "learning_rate": 2.511776215667802e-05,
      "loss": 0.0366,
      "step": 12067
    },
    {
      "epoch": 0.8745878175163967,
      "grad_norm": 0.29023656249046326,
      "learning_rate": 2.5103268352779187e-05,
      "loss": 0.0075,
      "step": 12068
    },
    {
      "epoch": 0.8746602891618654,
      "grad_norm": 1.558302879333496,
      "learning_rate": 2.5088774548880357e-05,
      "loss": 0.0319,
      "step": 12069
    },
    {
      "epoch": 0.8747327608073341,
      "grad_norm": 1.4803627729415894,
      "learning_rate": 2.507428074498152e-05,
      "loss": 0.0218,
      "step": 12070
    },
    {
      "epoch": 0.8748052324528028,
      "grad_norm": 1.7866995334625244,
      "learning_rate": 2.5059786941082687e-05,
      "loss": 0.0692,
      "step": 12071
    },
    {
      "epoch": 0.8748777040982716,
      "grad_norm": 1.1458964347839355,
      "learning_rate": 2.5045293137183857e-05,
      "loss": 0.0266,
      "step": 12072
    },
    {
      "epoch": 0.8749501757437402,
      "grad_norm": 1.1832728385925293,
      "learning_rate": 2.503079933328502e-05,
      "loss": 0.0272,
      "step": 12073
    },
    {
      "epoch": 0.875022647389209,
      "grad_norm": 0.259829580783844,
      "learning_rate": 2.5016305529386187e-05,
      "loss": 0.0008,
      "step": 12074
    },
    {
      "epoch": 0.8750951190346777,
      "grad_norm": 1.501437783241272,
      "learning_rate": 2.5001811725487357e-05,
      "loss": 0.0532,
      "step": 12075
    },
    {
      "epoch": 0.8751675906801464,
      "grad_norm": 1.125395655632019,
      "learning_rate": 2.498731792158852e-05,
      "loss": 0.0739,
      "step": 12076
    },
    {
      "epoch": 0.8752400623256151,
      "grad_norm": 1.5098085403442383,
      "learning_rate": 2.497282411768969e-05,
      "loss": 0.0397,
      "step": 12077
    },
    {
      "epoch": 0.8753125339710838,
      "grad_norm": 1.7636929750442505,
      "learning_rate": 2.4958330313790857e-05,
      "loss": 0.1002,
      "step": 12078
    },
    {
      "epoch": 0.8753850056165525,
      "grad_norm": 2.9591102600097656,
      "learning_rate": 2.494383650989202e-05,
      "loss": 0.1439,
      "step": 12079
    },
    {
      "epoch": 0.8754574772620213,
      "grad_norm": 0.5655530095100403,
      "learning_rate": 2.492934270599319e-05,
      "loss": 0.0088,
      "step": 12080
    },
    {
      "epoch": 0.8755299489074899,
      "grad_norm": 2.8342556953430176,
      "learning_rate": 2.4914848902094357e-05,
      "loss": 0.1172,
      "step": 12081
    },
    {
      "epoch": 0.8756024205529587,
      "grad_norm": 0.5829846858978271,
      "learning_rate": 2.490035509819552e-05,
      "loss": 0.0144,
      "step": 12082
    },
    {
      "epoch": 0.8756748921984273,
      "grad_norm": 5.425317764282227,
      "learning_rate": 2.488586129429669e-05,
      "loss": 0.103,
      "step": 12083
    },
    {
      "epoch": 0.8757473638438961,
      "grad_norm": 3.067436933517456,
      "learning_rate": 2.4871367490397856e-05,
      "loss": 0.0177,
      "step": 12084
    },
    {
      "epoch": 0.8758198354893648,
      "grad_norm": 1.637937307357788,
      "learning_rate": 2.4856873686499023e-05,
      "loss": 0.0583,
      "step": 12085
    },
    {
      "epoch": 0.8758923071348335,
      "grad_norm": 3.9778661727905273,
      "learning_rate": 2.484237988260019e-05,
      "loss": 0.0498,
      "step": 12086
    },
    {
      "epoch": 0.8759647787803022,
      "grad_norm": 0.6948792934417725,
      "learning_rate": 2.4827886078701356e-05,
      "loss": 0.0278,
      "step": 12087
    },
    {
      "epoch": 0.876037250425771,
      "grad_norm": 0.45114460587501526,
      "learning_rate": 2.4813392274802523e-05,
      "loss": 0.0096,
      "step": 12088
    },
    {
      "epoch": 0.8761097220712396,
      "grad_norm": 1.242387056350708,
      "learning_rate": 2.479889847090369e-05,
      "loss": 0.078,
      "step": 12089
    },
    {
      "epoch": 0.8761821937167084,
      "grad_norm": 1.283698320388794,
      "learning_rate": 2.4784404667004856e-05,
      "loss": 0.0357,
      "step": 12090
    },
    {
      "epoch": 0.876254665362177,
      "grad_norm": 2.2933647632598877,
      "learning_rate": 2.4769910863106023e-05,
      "loss": 0.0898,
      "step": 12091
    },
    {
      "epoch": 0.8763271370076458,
      "grad_norm": 0.4756237268447876,
      "learning_rate": 2.475541705920719e-05,
      "loss": 0.009,
      "step": 12092
    },
    {
      "epoch": 0.8763996086531145,
      "grad_norm": 1.89210045337677,
      "learning_rate": 2.4740923255308356e-05,
      "loss": 0.0345,
      "step": 12093
    },
    {
      "epoch": 0.8764720802985831,
      "grad_norm": 0.6658703088760376,
      "learning_rate": 2.4726429451409523e-05,
      "loss": 0.0172,
      "step": 12094
    },
    {
      "epoch": 0.8765445519440519,
      "grad_norm": 3.4352214336395264,
      "learning_rate": 2.471193564751069e-05,
      "loss": 0.0743,
      "step": 12095
    },
    {
      "epoch": 0.8766170235895206,
      "grad_norm": 0.44017311930656433,
      "learning_rate": 2.4697441843611856e-05,
      "loss": 0.0103,
      "step": 12096
    },
    {
      "epoch": 0.8766894952349893,
      "grad_norm": 0.10159812122583389,
      "learning_rate": 2.4682948039713026e-05,
      "loss": 0.0034,
      "step": 12097
    },
    {
      "epoch": 0.876761966880458,
      "grad_norm": 1.4701377153396606,
      "learning_rate": 2.466845423581419e-05,
      "loss": 0.0241,
      "step": 12098
    },
    {
      "epoch": 0.8768344385259267,
      "grad_norm": 2.7329015731811523,
      "learning_rate": 2.4653960431915356e-05,
      "loss": 0.068,
      "step": 12099
    },
    {
      "epoch": 0.8769069101713954,
      "grad_norm": 1.1932305097579956,
      "learning_rate": 2.4639466628016526e-05,
      "loss": 0.0323,
      "step": 12100
    },
    {
      "epoch": 0.8769793818168642,
      "grad_norm": 1.47854483127594,
      "learning_rate": 2.462497282411769e-05,
      "loss": 0.0521,
      "step": 12101
    },
    {
      "epoch": 0.8770518534623328,
      "grad_norm": 0.9165659546852112,
      "learning_rate": 2.4610479020218856e-05,
      "loss": 0.0423,
      "step": 12102
    },
    {
      "epoch": 0.8771243251078016,
      "grad_norm": 0.5765451192855835,
      "learning_rate": 2.4595985216320026e-05,
      "loss": 0.0163,
      "step": 12103
    },
    {
      "epoch": 0.8771967967532703,
      "grad_norm": 2.862281084060669,
      "learning_rate": 2.458149141242119e-05,
      "loss": 0.0954,
      "step": 12104
    },
    {
      "epoch": 0.877269268398739,
      "grad_norm": 0.5331965684890747,
      "learning_rate": 2.4566997608522356e-05,
      "loss": 0.0145,
      "step": 12105
    },
    {
      "epoch": 0.8773417400442077,
      "grad_norm": 1.1362359523773193,
      "learning_rate": 2.4552503804623526e-05,
      "loss": 0.0276,
      "step": 12106
    },
    {
      "epoch": 0.8774142116896764,
      "grad_norm": 1.2430475950241089,
      "learning_rate": 2.4538010000724693e-05,
      "loss": 0.044,
      "step": 12107
    },
    {
      "epoch": 0.8774866833351451,
      "grad_norm": 3.8424930572509766,
      "learning_rate": 2.4523516196825856e-05,
      "loss": 0.2425,
      "step": 12108
    },
    {
      "epoch": 0.8775591549806139,
      "grad_norm": 1.088870882987976,
      "learning_rate": 2.4509022392927026e-05,
      "loss": 0.0357,
      "step": 12109
    },
    {
      "epoch": 0.8776316266260825,
      "grad_norm": 1.3349281549453735,
      "learning_rate": 2.4494528589028193e-05,
      "loss": 0.0477,
      "step": 12110
    },
    {
      "epoch": 0.8777040982715513,
      "grad_norm": 1.8794214725494385,
      "learning_rate": 2.4480034785129356e-05,
      "loss": 0.0341,
      "step": 12111
    },
    {
      "epoch": 0.8777765699170199,
      "grad_norm": 1.8268898725509644,
      "learning_rate": 2.4465540981230526e-05,
      "loss": 0.0581,
      "step": 12112
    },
    {
      "epoch": 0.8778490415624887,
      "grad_norm": 0.7366757392883301,
      "learning_rate": 2.4451047177331693e-05,
      "loss": 0.0286,
      "step": 12113
    },
    {
      "epoch": 0.8779215132079574,
      "grad_norm": 0.48330157995224,
      "learning_rate": 2.443655337343286e-05,
      "loss": 0.0099,
      "step": 12114
    },
    {
      "epoch": 0.8779939848534261,
      "grad_norm": 1.479552984237671,
      "learning_rate": 2.4422059569534026e-05,
      "loss": 0.0265,
      "step": 12115
    },
    {
      "epoch": 0.8780664564988948,
      "grad_norm": 1.0392556190490723,
      "learning_rate": 2.4407565765635193e-05,
      "loss": 0.0276,
      "step": 12116
    },
    {
      "epoch": 0.8781389281443636,
      "grad_norm": 0.9645476937294006,
      "learning_rate": 2.439307196173636e-05,
      "loss": 0.018,
      "step": 12117
    },
    {
      "epoch": 0.8782113997898322,
      "grad_norm": 0.8238962888717651,
      "learning_rate": 2.4378578157837526e-05,
      "loss": 0.0262,
      "step": 12118
    },
    {
      "epoch": 0.878283871435301,
      "grad_norm": 0.6734351515769958,
      "learning_rate": 2.4364084353938693e-05,
      "loss": 0.0107,
      "step": 12119
    },
    {
      "epoch": 0.8783563430807696,
      "grad_norm": 0.3468511700630188,
      "learning_rate": 2.434959055003986e-05,
      "loss": 0.0083,
      "step": 12120
    },
    {
      "epoch": 0.8784288147262383,
      "grad_norm": 0.2591090500354767,
      "learning_rate": 2.4335096746141026e-05,
      "loss": 0.0043,
      "step": 12121
    },
    {
      "epoch": 0.8785012863717071,
      "grad_norm": 0.0991050973534584,
      "learning_rate": 2.4320602942242193e-05,
      "loss": 0.0017,
      "step": 12122
    },
    {
      "epoch": 0.8785737580171757,
      "grad_norm": 1.4134479761123657,
      "learning_rate": 2.430610913834336e-05,
      "loss": 0.0419,
      "step": 12123
    },
    {
      "epoch": 0.8786462296626445,
      "grad_norm": 1.252933144569397,
      "learning_rate": 2.4291615334444526e-05,
      "loss": 0.0467,
      "step": 12124
    },
    {
      "epoch": 0.8787187013081132,
      "grad_norm": 1.5430690050125122,
      "learning_rate": 2.4277121530545693e-05,
      "loss": 0.0395,
      "step": 12125
    },
    {
      "epoch": 0.8787911729535819,
      "grad_norm": 0.25750911235809326,
      "learning_rate": 2.4262627726646863e-05,
      "loss": 0.0047,
      "step": 12126
    },
    {
      "epoch": 0.8788636445990506,
      "grad_norm": 1.2875332832336426,
      "learning_rate": 2.4248133922748026e-05,
      "loss": 0.0341,
      "step": 12127
    },
    {
      "epoch": 0.8789361162445193,
      "grad_norm": 0.21795423328876495,
      "learning_rate": 2.4233640118849192e-05,
      "loss": 0.0063,
      "step": 12128
    },
    {
      "epoch": 0.879008587889988,
      "grad_norm": 2.219350814819336,
      "learning_rate": 2.4219146314950362e-05,
      "loss": 0.0425,
      "step": 12129
    },
    {
      "epoch": 0.8790810595354568,
      "grad_norm": 0.45893657207489014,
      "learning_rate": 2.4204652511051526e-05,
      "loss": 0.0128,
      "step": 12130
    },
    {
      "epoch": 0.8791535311809254,
      "grad_norm": 0.7109854817390442,
      "learning_rate": 2.4190158707152692e-05,
      "loss": 0.0104,
      "step": 12131
    },
    {
      "epoch": 0.8792260028263942,
      "grad_norm": 1.1019359827041626,
      "learning_rate": 2.4175664903253862e-05,
      "loss": 0.0095,
      "step": 12132
    },
    {
      "epoch": 0.8792984744718629,
      "grad_norm": 2.337233066558838,
      "learning_rate": 2.4161171099355026e-05,
      "loss": 0.0468,
      "step": 12133
    },
    {
      "epoch": 0.8793709461173316,
      "grad_norm": 0.5348807573318481,
      "learning_rate": 2.4146677295456192e-05,
      "loss": 0.0028,
      "step": 12134
    },
    {
      "epoch": 0.8794434177628003,
      "grad_norm": 4.488985061645508,
      "learning_rate": 2.4132183491557362e-05,
      "loss": 0.1511,
      "step": 12135
    },
    {
      "epoch": 0.879515889408269,
      "grad_norm": 3.2092106342315674,
      "learning_rate": 2.4117689687658526e-05,
      "loss": 0.0328,
      "step": 12136
    },
    {
      "epoch": 0.8795883610537377,
      "grad_norm": 0.279776006937027,
      "learning_rate": 2.4103195883759692e-05,
      "loss": 0.0028,
      "step": 12137
    },
    {
      "epoch": 0.8796608326992065,
      "grad_norm": 4.201857089996338,
      "learning_rate": 2.4088702079860862e-05,
      "loss": 0.0905,
      "step": 12138
    },
    {
      "epoch": 0.8797333043446751,
      "grad_norm": 0.7140673995018005,
      "learning_rate": 2.4074208275962026e-05,
      "loss": 0.0124,
      "step": 12139
    },
    {
      "epoch": 0.8798057759901439,
      "grad_norm": 1.7155933380126953,
      "learning_rate": 2.4059714472063196e-05,
      "loss": 0.0364,
      "step": 12140
    },
    {
      "epoch": 0.8798782476356126,
      "grad_norm": 1.0479437112808228,
      "learning_rate": 2.4045220668164362e-05,
      "loss": 0.0227,
      "step": 12141
    },
    {
      "epoch": 0.8799507192810813,
      "grad_norm": 1.2698783874511719,
      "learning_rate": 2.4030726864265526e-05,
      "loss": 0.0211,
      "step": 12142
    },
    {
      "epoch": 0.88002319092655,
      "grad_norm": 1.1976009607315063,
      "learning_rate": 2.4016233060366696e-05,
      "loss": 0.0233,
      "step": 12143
    },
    {
      "epoch": 0.8800956625720187,
      "grad_norm": 0.9000863432884216,
      "learning_rate": 2.4001739256467862e-05,
      "loss": 0.0198,
      "step": 12144
    },
    {
      "epoch": 0.8801681342174874,
      "grad_norm": 1.2442431449890137,
      "learning_rate": 2.3987245452569025e-05,
      "loss": 0.0468,
      "step": 12145
    },
    {
      "epoch": 0.8802406058629562,
      "grad_norm": 0.7917584776878357,
      "learning_rate": 2.3972751648670196e-05,
      "loss": 0.018,
      "step": 12146
    },
    {
      "epoch": 0.8803130775084248,
      "grad_norm": 2.2023701667785645,
      "learning_rate": 2.3958257844771362e-05,
      "loss": 0.0401,
      "step": 12147
    },
    {
      "epoch": 0.8803855491538936,
      "grad_norm": 1.7479809522628784,
      "learning_rate": 2.394376404087253e-05,
      "loss": 0.0327,
      "step": 12148
    },
    {
      "epoch": 0.8804580207993622,
      "grad_norm": 2.158900737762451,
      "learning_rate": 2.3929270236973695e-05,
      "loss": 0.0567,
      "step": 12149
    },
    {
      "epoch": 0.880530492444831,
      "grad_norm": 2.044631242752075,
      "learning_rate": 2.3914776433074862e-05,
      "loss": 0.0649,
      "step": 12150
    },
    {
      "epoch": 0.8806029640902997,
      "grad_norm": 2.3223893642425537,
      "learning_rate": 2.390028262917603e-05,
      "loss": 0.0656,
      "step": 12151
    },
    {
      "epoch": 0.8806754357357683,
      "grad_norm": 0.31319093704223633,
      "learning_rate": 2.3885788825277195e-05,
      "loss": 0.0048,
      "step": 12152
    },
    {
      "epoch": 0.8807479073812371,
      "grad_norm": 0.5509513020515442,
      "learning_rate": 2.3871295021378362e-05,
      "loss": 0.0162,
      "step": 12153
    },
    {
      "epoch": 0.8808203790267058,
      "grad_norm": 1.7336591482162476,
      "learning_rate": 2.385680121747953e-05,
      "loss": 0.0232,
      "step": 12154
    },
    {
      "epoch": 0.8808928506721745,
      "grad_norm": 7.7430500984191895,
      "learning_rate": 2.3842307413580695e-05,
      "loss": 0.0454,
      "step": 12155
    },
    {
      "epoch": 0.8809653223176432,
      "grad_norm": 1.087695837020874,
      "learning_rate": 2.3827813609681862e-05,
      "loss": 0.0175,
      "step": 12156
    },
    {
      "epoch": 0.8810377939631119,
      "grad_norm": 1.153140664100647,
      "learning_rate": 2.381331980578303e-05,
      "loss": 0.031,
      "step": 12157
    },
    {
      "epoch": 0.8811102656085806,
      "grad_norm": 1.6730754375457764,
      "learning_rate": 2.3798826001884195e-05,
      "loss": 0.0473,
      "step": 12158
    },
    {
      "epoch": 0.8811827372540494,
      "grad_norm": 0.6008220314979553,
      "learning_rate": 2.3784332197985362e-05,
      "loss": 0.018,
      "step": 12159
    },
    {
      "epoch": 0.881255208899518,
      "grad_norm": 2.4162545204162598,
      "learning_rate": 2.376983839408653e-05,
      "loss": 0.0298,
      "step": 12160
    },
    {
      "epoch": 0.8813276805449868,
      "grad_norm": 0.8394962549209595,
      "learning_rate": 2.3755344590187695e-05,
      "loss": 0.0188,
      "step": 12161
    },
    {
      "epoch": 0.8814001521904555,
      "grad_norm": 2.212493896484375,
      "learning_rate": 2.3740850786288862e-05,
      "loss": 0.0892,
      "step": 12162
    },
    {
      "epoch": 0.8814726238359242,
      "grad_norm": 2.4522011280059814,
      "learning_rate": 2.372635698239003e-05,
      "loss": 0.0407,
      "step": 12163
    },
    {
      "epoch": 0.8815450954813929,
      "grad_norm": 2.9130964279174805,
      "learning_rate": 2.3711863178491195e-05,
      "loss": 0.0261,
      "step": 12164
    },
    {
      "epoch": 0.8816175671268616,
      "grad_norm": 0.7424588203430176,
      "learning_rate": 2.3697369374592362e-05,
      "loss": 0.004,
      "step": 12165
    },
    {
      "epoch": 0.8816900387723303,
      "grad_norm": 0.9338946342468262,
      "learning_rate": 2.368287557069353e-05,
      "loss": 0.0609,
      "step": 12166
    },
    {
      "epoch": 0.8817625104177991,
      "grad_norm": 1.3072612285614014,
      "learning_rate": 2.36683817667947e-05,
      "loss": 0.0125,
      "step": 12167
    },
    {
      "epoch": 0.8818349820632677,
      "grad_norm": 2.0444424152374268,
      "learning_rate": 2.3653887962895862e-05,
      "loss": 0.0462,
      "step": 12168
    },
    {
      "epoch": 0.8819074537087365,
      "grad_norm": 2.6754653453826904,
      "learning_rate": 2.3639394158997032e-05,
      "loss": 0.0319,
      "step": 12169
    },
    {
      "epoch": 0.8819799253542052,
      "grad_norm": 0.9023599624633789,
      "learning_rate": 2.36249003550982e-05,
      "loss": 0.018,
      "step": 12170
    },
    {
      "epoch": 0.8820523969996739,
      "grad_norm": 1.2249852418899536,
      "learning_rate": 2.3610406551199362e-05,
      "loss": 0.0567,
      "step": 12171
    },
    {
      "epoch": 0.8821248686451426,
      "grad_norm": 1.2604032754898071,
      "learning_rate": 2.3595912747300532e-05,
      "loss": 0.0715,
      "step": 12172
    },
    {
      "epoch": 0.8821973402906113,
      "grad_norm": 1.0681204795837402,
      "learning_rate": 2.35814189434017e-05,
      "loss": 0.0299,
      "step": 12173
    },
    {
      "epoch": 0.88226981193608,
      "grad_norm": 0.42292946577072144,
      "learning_rate": 2.3566925139502862e-05,
      "loss": 0.0039,
      "step": 12174
    },
    {
      "epoch": 0.8823422835815488,
      "grad_norm": 2.2179834842681885,
      "learning_rate": 2.3552431335604032e-05,
      "loss": 0.0525,
      "step": 12175
    },
    {
      "epoch": 0.8824147552270174,
      "grad_norm": 0.8327970504760742,
      "learning_rate": 2.35379375317052e-05,
      "loss": 0.0315,
      "step": 12176
    },
    {
      "epoch": 0.8824872268724862,
      "grad_norm": 0.28347185254096985,
      "learning_rate": 2.352344372780636e-05,
      "loss": 0.0122,
      "step": 12177
    },
    {
      "epoch": 0.8825596985179549,
      "grad_norm": 1.591145634651184,
      "learning_rate": 2.3508949923907532e-05,
      "loss": 0.0452,
      "step": 12178
    },
    {
      "epoch": 0.8826321701634235,
      "grad_norm": 2.1439201831817627,
      "learning_rate": 2.34944561200087e-05,
      "loss": 0.0269,
      "step": 12179
    },
    {
      "epoch": 0.8827046418088923,
      "grad_norm": 2.0491349697113037,
      "learning_rate": 2.347996231610986e-05,
      "loss": 0.0545,
      "step": 12180
    },
    {
      "epoch": 0.8827771134543609,
      "grad_norm": 1.1772574186325073,
      "learning_rate": 2.346546851221103e-05,
      "loss": 0.0192,
      "step": 12181
    },
    {
      "epoch": 0.8828495850998297,
      "grad_norm": 2.0671305656433105,
      "learning_rate": 2.34509747083122e-05,
      "loss": 0.0415,
      "step": 12182
    },
    {
      "epoch": 0.8829220567452984,
      "grad_norm": 1.6855947971343994,
      "learning_rate": 2.343648090441336e-05,
      "loss": 0.0656,
      "step": 12183
    },
    {
      "epoch": 0.8829945283907671,
      "grad_norm": 3.114173650741577,
      "learning_rate": 2.342198710051453e-05,
      "loss": 0.0458,
      "step": 12184
    },
    {
      "epoch": 0.8830670000362358,
      "grad_norm": 1.4839189052581787,
      "learning_rate": 2.3407493296615698e-05,
      "loss": 0.0602,
      "step": 12185
    },
    {
      "epoch": 0.8831394716817045,
      "grad_norm": 1.8985751867294312,
      "learning_rate": 2.3392999492716865e-05,
      "loss": 0.0958,
      "step": 12186
    },
    {
      "epoch": 0.8832119433271732,
      "grad_norm": 0.4953727424144745,
      "learning_rate": 2.337850568881803e-05,
      "loss": 0.0049,
      "step": 12187
    },
    {
      "epoch": 0.883284414972642,
      "grad_norm": 1.253873586654663,
      "learning_rate": 2.3364011884919198e-05,
      "loss": 0.064,
      "step": 12188
    },
    {
      "epoch": 0.8833568866181106,
      "grad_norm": 1.2951985597610474,
      "learning_rate": 2.3349518081020365e-05,
      "loss": 0.0352,
      "step": 12189
    },
    {
      "epoch": 0.8834293582635794,
      "grad_norm": 0.6505936980247498,
      "learning_rate": 2.333502427712153e-05,
      "loss": 0.0203,
      "step": 12190
    },
    {
      "epoch": 0.8835018299090481,
      "grad_norm": 0.531679093837738,
      "learning_rate": 2.3320530473222698e-05,
      "loss": 0.0234,
      "step": 12191
    },
    {
      "epoch": 0.8835743015545168,
      "grad_norm": 1.1339921951293945,
      "learning_rate": 2.3306036669323865e-05,
      "loss": 0.03,
      "step": 12192
    },
    {
      "epoch": 0.8836467731999855,
      "grad_norm": 0.9313345551490784,
      "learning_rate": 2.329154286542503e-05,
      "loss": 0.0198,
      "step": 12193
    },
    {
      "epoch": 0.8837192448454542,
      "grad_norm": 0.35135364532470703,
      "learning_rate": 2.3277049061526198e-05,
      "loss": 0.0087,
      "step": 12194
    },
    {
      "epoch": 0.8837917164909229,
      "grad_norm": 2.0736374855041504,
      "learning_rate": 2.3262555257627365e-05,
      "loss": 0.0534,
      "step": 12195
    },
    {
      "epoch": 0.8838641881363917,
      "grad_norm": 1.3326228857040405,
      "learning_rate": 2.324806145372853e-05,
      "loss": 0.0407,
      "step": 12196
    },
    {
      "epoch": 0.8839366597818603,
      "grad_norm": 0.7004213333129883,
      "learning_rate": 2.3233567649829698e-05,
      "loss": 0.0204,
      "step": 12197
    },
    {
      "epoch": 0.8840091314273291,
      "grad_norm": 1.735302209854126,
      "learning_rate": 2.3219073845930868e-05,
      "loss": 0.0218,
      "step": 12198
    },
    {
      "epoch": 0.8840816030727978,
      "grad_norm": 0.017227258533239365,
      "learning_rate": 2.320458004203203e-05,
      "loss": 0.0003,
      "step": 12199
    },
    {
      "epoch": 0.8841540747182665,
      "grad_norm": 0.5666782855987549,
      "learning_rate": 2.3190086238133198e-05,
      "loss": 0.0065,
      "step": 12200
    },
    {
      "epoch": 0.8842265463637352,
      "grad_norm": 0.4048411250114441,
      "learning_rate": 2.3175592434234368e-05,
      "loss": 0.0129,
      "step": 12201
    },
    {
      "epoch": 0.8842990180092039,
      "grad_norm": 1.3675670623779297,
      "learning_rate": 2.316109863033553e-05,
      "loss": 0.0178,
      "step": 12202
    },
    {
      "epoch": 0.8843714896546726,
      "grad_norm": 0.9120859503746033,
      "learning_rate": 2.3146604826436698e-05,
      "loss": 0.023,
      "step": 12203
    },
    {
      "epoch": 0.8844439613001414,
      "grad_norm": 1.2711526155471802,
      "learning_rate": 2.3132111022537868e-05,
      "loss": 0.0382,
      "step": 12204
    },
    {
      "epoch": 0.88451643294561,
      "grad_norm": 0.29618167877197266,
      "learning_rate": 2.311761721863903e-05,
      "loss": 0.023,
      "step": 12205
    },
    {
      "epoch": 0.8845889045910788,
      "grad_norm": 0.9861536622047424,
      "learning_rate": 2.3103123414740198e-05,
      "loss": 0.0268,
      "step": 12206
    },
    {
      "epoch": 0.8846613762365475,
      "grad_norm": 0.5024194717407227,
      "learning_rate": 2.3088629610841368e-05,
      "loss": 0.0075,
      "step": 12207
    },
    {
      "epoch": 0.8847338478820161,
      "grad_norm": 0.06663399189710617,
      "learning_rate": 2.3074135806942535e-05,
      "loss": 0.0013,
      "step": 12208
    },
    {
      "epoch": 0.8848063195274849,
      "grad_norm": 0.8500149250030518,
      "learning_rate": 2.3059642003043698e-05,
      "loss": 0.009,
      "step": 12209
    },
    {
      "epoch": 0.8848787911729535,
      "grad_norm": 3.7051379680633545,
      "learning_rate": 2.3045148199144868e-05,
      "loss": 0.0197,
      "step": 12210
    },
    {
      "epoch": 0.8849512628184223,
      "grad_norm": 2.220618963241577,
      "learning_rate": 2.3030654395246035e-05,
      "loss": 0.0444,
      "step": 12211
    },
    {
      "epoch": 0.885023734463891,
      "grad_norm": 5.60326623916626,
      "learning_rate": 2.3016160591347198e-05,
      "loss": 0.0548,
      "step": 12212
    },
    {
      "epoch": 0.8850962061093597,
      "grad_norm": 1.724425196647644,
      "learning_rate": 2.3001666787448368e-05,
      "loss": 0.014,
      "step": 12213
    },
    {
      "epoch": 0.8851686777548284,
      "grad_norm": 2.791030168533325,
      "learning_rate": 2.2987172983549534e-05,
      "loss": 0.0154,
      "step": 12214
    },
    {
      "epoch": 0.8852411494002972,
      "grad_norm": 5.374680519104004,
      "learning_rate": 2.29726791796507e-05,
      "loss": 0.1391,
      "step": 12215
    },
    {
      "epoch": 0.8853136210457658,
      "grad_norm": 2.2176401615142822,
      "learning_rate": 2.2958185375751868e-05,
      "loss": 0.0306,
      "step": 12216
    },
    {
      "epoch": 0.8853860926912346,
      "grad_norm": 0.482164204120636,
      "learning_rate": 2.2943691571853034e-05,
      "loss": 0.0029,
      "step": 12217
    },
    {
      "epoch": 0.8854585643367032,
      "grad_norm": 0.3614320456981659,
      "learning_rate": 2.29291977679542e-05,
      "loss": 0.0136,
      "step": 12218
    },
    {
      "epoch": 0.885531035982172,
      "grad_norm": 1.7293263673782349,
      "learning_rate": 2.2914703964055368e-05,
      "loss": 0.0714,
      "step": 12219
    },
    {
      "epoch": 0.8856035076276407,
      "grad_norm": 1.413884162902832,
      "learning_rate": 2.2900210160156534e-05,
      "loss": 0.0538,
      "step": 12220
    },
    {
      "epoch": 0.8856759792731094,
      "grad_norm": 1.8419631719589233,
      "learning_rate": 2.28857163562577e-05,
      "loss": 0.0198,
      "step": 12221
    },
    {
      "epoch": 0.8857484509185781,
      "grad_norm": 0.3103451132774353,
      "learning_rate": 2.2871222552358868e-05,
      "loss": 0.0088,
      "step": 12222
    },
    {
      "epoch": 0.8858209225640468,
      "grad_norm": 2.326545238494873,
      "learning_rate": 2.2856728748460034e-05,
      "loss": 0.0277,
      "step": 12223
    },
    {
      "epoch": 0.8858933942095155,
      "grad_norm": 5.295845985412598,
      "learning_rate": 2.28422349445612e-05,
      "loss": 0.0659,
      "step": 12224
    },
    {
      "epoch": 0.8859658658549843,
      "grad_norm": 1.5325825214385986,
      "learning_rate": 2.2827741140662368e-05,
      "loss": 0.0454,
      "step": 12225
    },
    {
      "epoch": 0.8860383375004529,
      "grad_norm": 1.7085192203521729,
      "learning_rate": 2.2813247336763534e-05,
      "loss": 0.0424,
      "step": 12226
    },
    {
      "epoch": 0.8861108091459217,
      "grad_norm": 2.8460938930511475,
      "learning_rate": 2.27987535328647e-05,
      "loss": 0.0453,
      "step": 12227
    },
    {
      "epoch": 0.8861832807913904,
      "grad_norm": 1.4713187217712402,
      "learning_rate": 2.2784259728965868e-05,
      "loss": 0.0595,
      "step": 12228
    },
    {
      "epoch": 0.8862557524368591,
      "grad_norm": 5.2615156173706055,
      "learning_rate": 2.2769765925067034e-05,
      "loss": 0.038,
      "step": 12229
    },
    {
      "epoch": 0.8863282240823278,
      "grad_norm": 1.0705550909042358,
      "learning_rate": 2.2755272121168204e-05,
      "loss": 0.0304,
      "step": 12230
    },
    {
      "epoch": 0.8864006957277965,
      "grad_norm": 0.40051931142807007,
      "learning_rate": 2.2740778317269368e-05,
      "loss": 0.0049,
      "step": 12231
    },
    {
      "epoch": 0.8864731673732652,
      "grad_norm": 1.7958825826644897,
      "learning_rate": 2.2726284513370534e-05,
      "loss": 0.0308,
      "step": 12232
    },
    {
      "epoch": 0.886545639018734,
      "grad_norm": 2.5134544372558594,
      "learning_rate": 2.2711790709471704e-05,
      "loss": 0.0607,
      "step": 12233
    },
    {
      "epoch": 0.8866181106642026,
      "grad_norm": 2.906928062438965,
      "learning_rate": 2.2697296905572867e-05,
      "loss": 0.0602,
      "step": 12234
    },
    {
      "epoch": 0.8866905823096713,
      "grad_norm": 1.218438982963562,
      "learning_rate": 2.2682803101674034e-05,
      "loss": 0.0096,
      "step": 12235
    },
    {
      "epoch": 0.8867630539551401,
      "grad_norm": 0.03599366918206215,
      "learning_rate": 2.2668309297775204e-05,
      "loss": 0.0007,
      "step": 12236
    },
    {
      "epoch": 0.8868355256006087,
      "grad_norm": 0.20509086549282074,
      "learning_rate": 2.2653815493876367e-05,
      "loss": 0.0045,
      "step": 12237
    },
    {
      "epoch": 0.8869079972460775,
      "grad_norm": 1.4778488874435425,
      "learning_rate": 2.2639321689977534e-05,
      "loss": 0.0601,
      "step": 12238
    },
    {
      "epoch": 0.8869804688915461,
      "grad_norm": 1.3909388780593872,
      "learning_rate": 2.2624827886078704e-05,
      "loss": 0.029,
      "step": 12239
    },
    {
      "epoch": 0.8870529405370149,
      "grad_norm": 0.6058522462844849,
      "learning_rate": 2.2610334082179867e-05,
      "loss": 0.0179,
      "step": 12240
    },
    {
      "epoch": 0.8871254121824836,
      "grad_norm": 0.3719208240509033,
      "learning_rate": 2.2595840278281037e-05,
      "loss": 0.006,
      "step": 12241
    },
    {
      "epoch": 0.8871978838279523,
      "grad_norm": 1.4002841711044312,
      "learning_rate": 2.2581346474382204e-05,
      "loss": 0.0275,
      "step": 12242
    },
    {
      "epoch": 0.887270355473421,
      "grad_norm": 1.4125335216522217,
      "learning_rate": 2.2566852670483367e-05,
      "loss": 0.0644,
      "step": 12243
    },
    {
      "epoch": 0.8873428271188898,
      "grad_norm": 1.4642161130905151,
      "learning_rate": 2.2552358866584537e-05,
      "loss": 0.0469,
      "step": 12244
    },
    {
      "epoch": 0.8874152987643584,
      "grad_norm": 1.5042684078216553,
      "learning_rate": 2.2537865062685704e-05,
      "loss": 0.0601,
      "step": 12245
    },
    {
      "epoch": 0.8874877704098272,
      "grad_norm": 0.1477784514427185,
      "learning_rate": 2.2523371258786867e-05,
      "loss": 0.0031,
      "step": 12246
    },
    {
      "epoch": 0.8875602420552958,
      "grad_norm": 1.5465971231460571,
      "learning_rate": 2.2508877454888037e-05,
      "loss": 0.0231,
      "step": 12247
    },
    {
      "epoch": 0.8876327137007646,
      "grad_norm": 2.484069585800171,
      "learning_rate": 2.2494383650989204e-05,
      "loss": 0.0725,
      "step": 12248
    },
    {
      "epoch": 0.8877051853462333,
      "grad_norm": 1.7556750774383545,
      "learning_rate": 2.247988984709037e-05,
      "loss": 0.0733,
      "step": 12249
    },
    {
      "epoch": 0.887777656991702,
      "grad_norm": 1.4222743511199951,
      "learning_rate": 2.2465396043191537e-05,
      "loss": 0.0415,
      "step": 12250
    },
    {
      "epoch": 0.8878501286371707,
      "grad_norm": 1.087620496749878,
      "learning_rate": 2.2450902239292704e-05,
      "loss": 0.0411,
      "step": 12251
    },
    {
      "epoch": 0.8879226002826394,
      "grad_norm": 0.47251707315444946,
      "learning_rate": 2.243640843539387e-05,
      "loss": 0.0125,
      "step": 12252
    },
    {
      "epoch": 0.8879950719281081,
      "grad_norm": 2.0295886993408203,
      "learning_rate": 2.2421914631495037e-05,
      "loss": 0.1079,
      "step": 12253
    },
    {
      "epoch": 0.8880675435735769,
      "grad_norm": 2.3689167499542236,
      "learning_rate": 2.2407420827596204e-05,
      "loss": 0.0573,
      "step": 12254
    },
    {
      "epoch": 0.8881400152190455,
      "grad_norm": 0.6198177337646484,
      "learning_rate": 2.239292702369737e-05,
      "loss": 0.0409,
      "step": 12255
    },
    {
      "epoch": 0.8882124868645143,
      "grad_norm": 0.5197045803070068,
      "learning_rate": 2.2378433219798537e-05,
      "loss": 0.0086,
      "step": 12256
    },
    {
      "epoch": 0.888284958509983,
      "grad_norm": 1.5814672708511353,
      "learning_rate": 2.2363939415899704e-05,
      "loss": 0.0309,
      "step": 12257
    },
    {
      "epoch": 0.8883574301554517,
      "grad_norm": 0.5040233135223389,
      "learning_rate": 2.234944561200087e-05,
      "loss": 0.019,
      "step": 12258
    },
    {
      "epoch": 0.8884299018009204,
      "grad_norm": 2.42319917678833,
      "learning_rate": 2.2334951808102037e-05,
      "loss": 0.075,
      "step": 12259
    },
    {
      "epoch": 0.888502373446389,
      "grad_norm": 0.8512843251228333,
      "learning_rate": 2.2320458004203204e-05,
      "loss": 0.0302,
      "step": 12260
    },
    {
      "epoch": 0.8885748450918578,
      "grad_norm": 1.7356784343719482,
      "learning_rate": 2.230596420030437e-05,
      "loss": 0.0773,
      "step": 12261
    },
    {
      "epoch": 0.8886473167373266,
      "grad_norm": 0.5519234538078308,
      "learning_rate": 2.2291470396405537e-05,
      "loss": 0.0129,
      "step": 12262
    },
    {
      "epoch": 0.8887197883827952,
      "grad_norm": 1.5266797542572021,
      "learning_rate": 2.2276976592506704e-05,
      "loss": 0.0226,
      "step": 12263
    },
    {
      "epoch": 0.888792260028264,
      "grad_norm": 7.197412490844727,
      "learning_rate": 2.226248278860787e-05,
      "loss": 0.0576,
      "step": 12264
    },
    {
      "epoch": 0.8888647316737327,
      "grad_norm": 0.9160075783729553,
      "learning_rate": 2.2247988984709037e-05,
      "loss": 0.0186,
      "step": 12265
    },
    {
      "epoch": 0.8889372033192013,
      "grad_norm": 0.1658908575773239,
      "learning_rate": 2.2233495180810204e-05,
      "loss": 0.0036,
      "step": 12266
    },
    {
      "epoch": 0.8890096749646701,
      "grad_norm": 1.6598138809204102,
      "learning_rate": 2.221900137691137e-05,
      "loss": 0.0495,
      "step": 12267
    },
    {
      "epoch": 0.8890821466101387,
      "grad_norm": 1.3454009294509888,
      "learning_rate": 2.220450757301254e-05,
      "loss": 0.0451,
      "step": 12268
    },
    {
      "epoch": 0.8891546182556075,
      "grad_norm": 2.5881550312042236,
      "learning_rate": 2.2190013769113704e-05,
      "loss": 0.0668,
      "step": 12269
    },
    {
      "epoch": 0.8892270899010762,
      "grad_norm": 4.300216197967529,
      "learning_rate": 2.2175519965214874e-05,
      "loss": 0.0612,
      "step": 12270
    },
    {
      "epoch": 0.8892995615465449,
      "grad_norm": 0.5195449590682983,
      "learning_rate": 2.216102616131604e-05,
      "loss": 0.0094,
      "step": 12271
    },
    {
      "epoch": 0.8893720331920136,
      "grad_norm": 0.9037777781486511,
      "learning_rate": 2.2146532357417204e-05,
      "loss": 0.0392,
      "step": 12272
    },
    {
      "epoch": 0.8894445048374824,
      "grad_norm": 2.763728380203247,
      "learning_rate": 2.2132038553518374e-05,
      "loss": 0.0796,
      "step": 12273
    },
    {
      "epoch": 0.889516976482951,
      "grad_norm": 1.2605235576629639,
      "learning_rate": 2.211754474961954e-05,
      "loss": 0.0874,
      "step": 12274
    },
    {
      "epoch": 0.8895894481284198,
      "grad_norm": 1.9589285850524902,
      "learning_rate": 2.2103050945720703e-05,
      "loss": 0.1003,
      "step": 12275
    },
    {
      "epoch": 0.8896619197738884,
      "grad_norm": 3.5933525562286377,
      "learning_rate": 2.2088557141821874e-05,
      "loss": 0.0499,
      "step": 12276
    },
    {
      "epoch": 0.8897343914193572,
      "grad_norm": 3.6064469814300537,
      "learning_rate": 2.207406333792304e-05,
      "loss": 0.1731,
      "step": 12277
    },
    {
      "epoch": 0.8898068630648259,
      "grad_norm": 0.8193399906158447,
      "learning_rate": 2.2059569534024203e-05,
      "loss": 0.0233,
      "step": 12278
    },
    {
      "epoch": 0.8898793347102946,
      "grad_norm": 0.21435712277889252,
      "learning_rate": 2.2045075730125373e-05,
      "loss": 0.0044,
      "step": 12279
    },
    {
      "epoch": 0.8899518063557633,
      "grad_norm": 1.8512070178985596,
      "learning_rate": 2.203058192622654e-05,
      "loss": 0.0142,
      "step": 12280
    },
    {
      "epoch": 0.8900242780012321,
      "grad_norm": 0.44407686591148376,
      "learning_rate": 2.2016088122327703e-05,
      "loss": 0.003,
      "step": 12281
    },
    {
      "epoch": 0.8900967496467007,
      "grad_norm": 2.1107444763183594,
      "learning_rate": 2.2001594318428873e-05,
      "loss": 0.0476,
      "step": 12282
    },
    {
      "epoch": 0.8901692212921695,
      "grad_norm": 0.23948024213314056,
      "learning_rate": 2.198710051453004e-05,
      "loss": 0.0066,
      "step": 12283
    },
    {
      "epoch": 0.8902416929376381,
      "grad_norm": 1.5888612270355225,
      "learning_rate": 2.1972606710631203e-05,
      "loss": 0.0442,
      "step": 12284
    },
    {
      "epoch": 0.8903141645831069,
      "grad_norm": 1.4452344179153442,
      "learning_rate": 2.1958112906732373e-05,
      "loss": 0.0313,
      "step": 12285
    },
    {
      "epoch": 0.8903866362285756,
      "grad_norm": 1.1105848550796509,
      "learning_rate": 2.194361910283354e-05,
      "loss": 0.0365,
      "step": 12286
    },
    {
      "epoch": 0.8904591078740443,
      "grad_norm": 1.273000955581665,
      "learning_rate": 2.1929125298934707e-05,
      "loss": 0.0254,
      "step": 12287
    },
    {
      "epoch": 0.890531579519513,
      "grad_norm": 2.7591192722320557,
      "learning_rate": 2.1914631495035873e-05,
      "loss": 0.0184,
      "step": 12288
    },
    {
      "epoch": 0.8906040511649816,
      "grad_norm": 0.8120496869087219,
      "learning_rate": 2.190013769113704e-05,
      "loss": 0.0579,
      "step": 12289
    },
    {
      "epoch": 0.8906765228104504,
      "grad_norm": 2.661181926727295,
      "learning_rate": 2.1885643887238207e-05,
      "loss": 0.0699,
      "step": 12290
    },
    {
      "epoch": 0.8907489944559192,
      "grad_norm": 1.8726670742034912,
      "learning_rate": 2.1871150083339373e-05,
      "loss": 0.0429,
      "step": 12291
    },
    {
      "epoch": 0.8908214661013878,
      "grad_norm": 0.10915592312812805,
      "learning_rate": 2.185665627944054e-05,
      "loss": 0.0016,
      "step": 12292
    },
    {
      "epoch": 0.8908939377468565,
      "grad_norm": 1.1734778881072998,
      "learning_rate": 2.1842162475541707e-05,
      "loss": 0.049,
      "step": 12293
    },
    {
      "epoch": 0.8909664093923253,
      "grad_norm": 0.4969964027404785,
      "learning_rate": 2.1827668671642873e-05,
      "loss": 0.0192,
      "step": 12294
    },
    {
      "epoch": 0.8910388810377939,
      "grad_norm": 0.36966952681541443,
      "learning_rate": 2.181317486774404e-05,
      "loss": 0.0063,
      "step": 12295
    },
    {
      "epoch": 0.8911113526832627,
      "grad_norm": 0.14814633131027222,
      "learning_rate": 2.179868106384521e-05,
      "loss": 0.0056,
      "step": 12296
    },
    {
      "epoch": 0.8911838243287313,
      "grad_norm": 2.7898991107940674,
      "learning_rate": 2.1784187259946373e-05,
      "loss": 0.0833,
      "step": 12297
    },
    {
      "epoch": 0.8912562959742001,
      "grad_norm": 0.599941074848175,
      "learning_rate": 2.176969345604754e-05,
      "loss": 0.0279,
      "step": 12298
    },
    {
      "epoch": 0.8913287676196688,
      "grad_norm": 0.8296744227409363,
      "learning_rate": 2.175519965214871e-05,
      "loss": 0.0133,
      "step": 12299
    },
    {
      "epoch": 0.8914012392651375,
      "grad_norm": 2.533620834350586,
      "learning_rate": 2.1740705848249873e-05,
      "loss": 0.0683,
      "step": 12300
    },
    {
      "epoch": 0.8914737109106062,
      "grad_norm": 1.218998908996582,
      "learning_rate": 2.172621204435104e-05,
      "loss": 0.0173,
      "step": 12301
    },
    {
      "epoch": 0.891546182556075,
      "grad_norm": 1.6204324960708618,
      "learning_rate": 2.171171824045221e-05,
      "loss": 0.0421,
      "step": 12302
    },
    {
      "epoch": 0.8916186542015436,
      "grad_norm": 0.32081833481788635,
      "learning_rate": 2.1697224436553373e-05,
      "loss": 0.0106,
      "step": 12303
    },
    {
      "epoch": 0.8916911258470124,
      "grad_norm": 3.4522714614868164,
      "learning_rate": 2.168273063265454e-05,
      "loss": 0.1167,
      "step": 12304
    },
    {
      "epoch": 0.891763597492481,
      "grad_norm": 0.6894285678863525,
      "learning_rate": 2.166823682875571e-05,
      "loss": 0.0147,
      "step": 12305
    },
    {
      "epoch": 0.8918360691379498,
      "grad_norm": 3.5183138847351074,
      "learning_rate": 2.1653743024856873e-05,
      "loss": 0.1397,
      "step": 12306
    },
    {
      "epoch": 0.8919085407834185,
      "grad_norm": 0.7690760493278503,
      "learning_rate": 2.163924922095804e-05,
      "loss": 0.0271,
      "step": 12307
    },
    {
      "epoch": 0.8919810124288872,
      "grad_norm": 0.3160521686077118,
      "learning_rate": 2.162475541705921e-05,
      "loss": 0.0148,
      "step": 12308
    },
    {
      "epoch": 0.8920534840743559,
      "grad_norm": 1.1351661682128906,
      "learning_rate": 2.1610261613160376e-05,
      "loss": 0.027,
      "step": 12309
    },
    {
      "epoch": 0.8921259557198247,
      "grad_norm": 0.10933378338813782,
      "learning_rate": 2.159576780926154e-05,
      "loss": 0.0032,
      "step": 12310
    },
    {
      "epoch": 0.8921984273652933,
      "grad_norm": 0.6079369783401489,
      "learning_rate": 2.158127400536271e-05,
      "loss": 0.0268,
      "step": 12311
    },
    {
      "epoch": 0.8922708990107621,
      "grad_norm": 1.0956251621246338,
      "learning_rate": 2.1566780201463876e-05,
      "loss": 0.0496,
      "step": 12312
    },
    {
      "epoch": 0.8923433706562307,
      "grad_norm": 0.35225874185562134,
      "learning_rate": 2.1552286397565043e-05,
      "loss": 0.0078,
      "step": 12313
    },
    {
      "epoch": 0.8924158423016995,
      "grad_norm": 0.7470009922981262,
      "learning_rate": 2.153779259366621e-05,
      "loss": 0.011,
      "step": 12314
    },
    {
      "epoch": 0.8924883139471682,
      "grad_norm": 1.0272693634033203,
      "learning_rate": 2.1523298789767376e-05,
      "loss": 0.0474,
      "step": 12315
    },
    {
      "epoch": 0.8925607855926369,
      "grad_norm": 0.8705468773841858,
      "learning_rate": 2.1508804985868543e-05,
      "loss": 0.0102,
      "step": 12316
    },
    {
      "epoch": 0.8926332572381056,
      "grad_norm": 1.7650549411773682,
      "learning_rate": 2.149431118196971e-05,
      "loss": 0.0339,
      "step": 12317
    },
    {
      "epoch": 0.8927057288835744,
      "grad_norm": 0.20002053678035736,
      "learning_rate": 2.1479817378070876e-05,
      "loss": 0.0014,
      "step": 12318
    },
    {
      "epoch": 0.892778200529043,
      "grad_norm": 1.4217866659164429,
      "learning_rate": 2.1465323574172043e-05,
      "loss": 0.0221,
      "step": 12319
    },
    {
      "epoch": 0.8928506721745118,
      "grad_norm": 0.09783835709095001,
      "learning_rate": 2.145082977027321e-05,
      "loss": 0.0026,
      "step": 12320
    },
    {
      "epoch": 0.8929231438199804,
      "grad_norm": 0.33534279465675354,
      "learning_rate": 2.1436335966374376e-05,
      "loss": 0.0065,
      "step": 12321
    },
    {
      "epoch": 0.8929956154654491,
      "grad_norm": 2.4103288650512695,
      "learning_rate": 2.1421842162475543e-05,
      "loss": 0.1282,
      "step": 12322
    },
    {
      "epoch": 0.8930680871109179,
      "grad_norm": 0.10662262886762619,
      "learning_rate": 2.140734835857671e-05,
      "loss": 0.0013,
      "step": 12323
    },
    {
      "epoch": 0.8931405587563865,
      "grad_norm": 2.5813889503479004,
      "learning_rate": 2.1392854554677876e-05,
      "loss": 0.1449,
      "step": 12324
    },
    {
      "epoch": 0.8932130304018553,
      "grad_norm": 1.8871312141418457,
      "learning_rate": 2.1378360750779043e-05,
      "loss": 0.0474,
      "step": 12325
    },
    {
      "epoch": 0.8932855020473239,
      "grad_norm": 0.08962763100862503,
      "learning_rate": 2.136386694688021e-05,
      "loss": 0.0028,
      "step": 12326
    },
    {
      "epoch": 0.8933579736927927,
      "grad_norm": 0.5617671608924866,
      "learning_rate": 2.1349373142981376e-05,
      "loss": 0.0095,
      "step": 12327
    },
    {
      "epoch": 0.8934304453382614,
      "grad_norm": 0.47594282031059265,
      "learning_rate": 2.1334879339082543e-05,
      "loss": 0.0175,
      "step": 12328
    },
    {
      "epoch": 0.8935029169837301,
      "grad_norm": 3.4982903003692627,
      "learning_rate": 2.132038553518371e-05,
      "loss": 0.0942,
      "step": 12329
    },
    {
      "epoch": 0.8935753886291988,
      "grad_norm": 5.305293560028076,
      "learning_rate": 2.1305891731284876e-05,
      "loss": 0.0576,
      "step": 12330
    },
    {
      "epoch": 0.8936478602746676,
      "grad_norm": 2.323793888092041,
      "learning_rate": 2.1291397927386046e-05,
      "loss": 0.0895,
      "step": 12331
    },
    {
      "epoch": 0.8937203319201362,
      "grad_norm": 1.8877756595611572,
      "learning_rate": 2.127690412348721e-05,
      "loss": 0.0917,
      "step": 12332
    },
    {
      "epoch": 0.893792803565605,
      "grad_norm": 3.2640838623046875,
      "learning_rate": 2.1262410319588376e-05,
      "loss": 0.067,
      "step": 12333
    },
    {
      "epoch": 0.8938652752110736,
      "grad_norm": 2.2126197814941406,
      "learning_rate": 2.1247916515689546e-05,
      "loss": 0.0515,
      "step": 12334
    },
    {
      "epoch": 0.8939377468565424,
      "grad_norm": 1.329654335975647,
      "learning_rate": 2.123342271179071e-05,
      "loss": 0.0235,
      "step": 12335
    },
    {
      "epoch": 0.8940102185020111,
      "grad_norm": 1.0885109901428223,
      "learning_rate": 2.1218928907891876e-05,
      "loss": 0.0397,
      "step": 12336
    },
    {
      "epoch": 0.8940826901474798,
      "grad_norm": 3.040358781814575,
      "learning_rate": 2.1204435103993046e-05,
      "loss": 0.05,
      "step": 12337
    },
    {
      "epoch": 0.8941551617929485,
      "grad_norm": 1.420206904411316,
      "learning_rate": 2.118994130009421e-05,
      "loss": 0.0239,
      "step": 12338
    },
    {
      "epoch": 0.8942276334384173,
      "grad_norm": 0.8419076204299927,
      "learning_rate": 2.1175447496195376e-05,
      "loss": 0.051,
      "step": 12339
    },
    {
      "epoch": 0.8943001050838859,
      "grad_norm": 0.2419150471687317,
      "learning_rate": 2.1160953692296546e-05,
      "loss": 0.0144,
      "step": 12340
    },
    {
      "epoch": 0.8943725767293547,
      "grad_norm": 0.2855452001094818,
      "learning_rate": 2.114645988839771e-05,
      "loss": 0.0079,
      "step": 12341
    },
    {
      "epoch": 0.8944450483748233,
      "grad_norm": 1.075753092765808,
      "learning_rate": 2.113196608449888e-05,
      "loss": 0.0309,
      "step": 12342
    },
    {
      "epoch": 0.8945175200202921,
      "grad_norm": 1.273627758026123,
      "learning_rate": 2.1117472280600046e-05,
      "loss": 0.0537,
      "step": 12343
    },
    {
      "epoch": 0.8945899916657608,
      "grad_norm": 0.5862631797790527,
      "learning_rate": 2.110297847670121e-05,
      "loss": 0.0116,
      "step": 12344
    },
    {
      "epoch": 0.8946624633112295,
      "grad_norm": 0.7034124135971069,
      "learning_rate": 2.108848467280238e-05,
      "loss": 0.0176,
      "step": 12345
    },
    {
      "epoch": 0.8947349349566982,
      "grad_norm": 2.807346820831299,
      "learning_rate": 2.1073990868903546e-05,
      "loss": 0.0468,
      "step": 12346
    },
    {
      "epoch": 0.894807406602167,
      "grad_norm": 3.7772276401519775,
      "learning_rate": 2.105949706500471e-05,
      "loss": 0.1179,
      "step": 12347
    },
    {
      "epoch": 0.8948798782476356,
      "grad_norm": 0.8245741724967957,
      "learning_rate": 2.104500326110588e-05,
      "loss": 0.0114,
      "step": 12348
    },
    {
      "epoch": 0.8949523498931043,
      "grad_norm": 0.065504290163517,
      "learning_rate": 2.1030509457207046e-05,
      "loss": 0.0008,
      "step": 12349
    },
    {
      "epoch": 0.895024821538573,
      "grad_norm": 0.8357803225517273,
      "learning_rate": 2.1016015653308212e-05,
      "loss": 0.0177,
      "step": 12350
    },
    {
      "epoch": 0.8950972931840417,
      "grad_norm": 4.174991130828857,
      "learning_rate": 2.100152184940938e-05,
      "loss": 0.0914,
      "step": 12351
    },
    {
      "epoch": 0.8951697648295105,
      "grad_norm": 1.980668544769287,
      "learning_rate": 2.0987028045510546e-05,
      "loss": 0.0568,
      "step": 12352
    },
    {
      "epoch": 0.8952422364749791,
      "grad_norm": 2.1479716300964355,
      "learning_rate": 2.0972534241611712e-05,
      "loss": 0.029,
      "step": 12353
    },
    {
      "epoch": 0.8953147081204479,
      "grad_norm": 3.912010908126831,
      "learning_rate": 2.095804043771288e-05,
      "loss": 0.0935,
      "step": 12354
    },
    {
      "epoch": 0.8953871797659165,
      "grad_norm": 2.034452199935913,
      "learning_rate": 2.0943546633814046e-05,
      "loss": 0.0465,
      "step": 12355
    },
    {
      "epoch": 0.8954596514113853,
      "grad_norm": 2.990699052810669,
      "learning_rate": 2.0929052829915212e-05,
      "loss": 0.0496,
      "step": 12356
    },
    {
      "epoch": 0.895532123056854,
      "grad_norm": 0.24048516154289246,
      "learning_rate": 2.091455902601638e-05,
      "loss": 0.01,
      "step": 12357
    },
    {
      "epoch": 0.8956045947023227,
      "grad_norm": 1.5690162181854248,
      "learning_rate": 2.0900065222117546e-05,
      "loss": 0.0495,
      "step": 12358
    },
    {
      "epoch": 0.8956770663477914,
      "grad_norm": 1.5979236364364624,
      "learning_rate": 2.0885571418218712e-05,
      "loss": 0.0416,
      "step": 12359
    },
    {
      "epoch": 0.8957495379932602,
      "grad_norm": 2.0919840335845947,
      "learning_rate": 2.087107761431988e-05,
      "loss": 0.0161,
      "step": 12360
    },
    {
      "epoch": 0.8958220096387288,
      "grad_norm": 0.7390806674957275,
      "learning_rate": 2.0856583810421046e-05,
      "loss": 0.0198,
      "step": 12361
    },
    {
      "epoch": 0.8958944812841976,
      "grad_norm": 0.8044977188110352,
      "learning_rate": 2.0842090006522212e-05,
      "loss": 0.0251,
      "step": 12362
    },
    {
      "epoch": 0.8959669529296662,
      "grad_norm": 0.9349339604377747,
      "learning_rate": 2.082759620262338e-05,
      "loss": 0.0163,
      "step": 12363
    },
    {
      "epoch": 0.896039424575135,
      "grad_norm": 0.48236584663391113,
      "learning_rate": 2.0813102398724545e-05,
      "loss": 0.017,
      "step": 12364
    },
    {
      "epoch": 0.8961118962206037,
      "grad_norm": 3.2363178730010986,
      "learning_rate": 2.0798608594825712e-05,
      "loss": 0.1668,
      "step": 12365
    },
    {
      "epoch": 0.8961843678660724,
      "grad_norm": 0.6237907409667969,
      "learning_rate": 2.078411479092688e-05,
      "loss": 0.0035,
      "step": 12366
    },
    {
      "epoch": 0.8962568395115411,
      "grad_norm": 0.7358400225639343,
      "learning_rate": 2.0769620987028045e-05,
      "loss": 0.0246,
      "step": 12367
    },
    {
      "epoch": 0.8963293111570099,
      "grad_norm": 1.555274248123169,
      "learning_rate": 2.0755127183129215e-05,
      "loss": 0.0419,
      "step": 12368
    },
    {
      "epoch": 0.8964017828024785,
      "grad_norm": 1.9344158172607422,
      "learning_rate": 2.074063337923038e-05,
      "loss": 0.0136,
      "step": 12369
    },
    {
      "epoch": 0.8964742544479473,
      "grad_norm": 2.6012251377105713,
      "learning_rate": 2.0726139575331545e-05,
      "loss": 0.02,
      "step": 12370
    },
    {
      "epoch": 0.8965467260934159,
      "grad_norm": 2.141099452972412,
      "learning_rate": 2.0711645771432715e-05,
      "loss": 0.0316,
      "step": 12371
    },
    {
      "epoch": 0.8966191977388847,
      "grad_norm": 1.1554723978042603,
      "learning_rate": 2.0697151967533882e-05,
      "loss": 0.0243,
      "step": 12372
    },
    {
      "epoch": 0.8966916693843534,
      "grad_norm": 0.500403106212616,
      "learning_rate": 2.0682658163635045e-05,
      "loss": 0.0137,
      "step": 12373
    },
    {
      "epoch": 0.896764141029822,
      "grad_norm": 1.9447565078735352,
      "learning_rate": 2.0668164359736215e-05,
      "loss": 0.0904,
      "step": 12374
    },
    {
      "epoch": 0.8968366126752908,
      "grad_norm": 1.383375883102417,
      "learning_rate": 2.0653670555837382e-05,
      "loss": 0.0411,
      "step": 12375
    },
    {
      "epoch": 0.8969090843207596,
      "grad_norm": 1.3382561206817627,
      "learning_rate": 2.0639176751938545e-05,
      "loss": 0.0196,
      "step": 12376
    },
    {
      "epoch": 0.8969815559662282,
      "grad_norm": 0.42900538444519043,
      "learning_rate": 2.0624682948039715e-05,
      "loss": 0.0115,
      "step": 12377
    },
    {
      "epoch": 0.897054027611697,
      "grad_norm": 0.9285848736763,
      "learning_rate": 2.0610189144140882e-05,
      "loss": 0.0077,
      "step": 12378
    },
    {
      "epoch": 0.8971264992571656,
      "grad_norm": 0.9847434759140015,
      "learning_rate": 2.0595695340242045e-05,
      "loss": 0.0405,
      "step": 12379
    },
    {
      "epoch": 0.8971989709026343,
      "grad_norm": 0.509356677532196,
      "learning_rate": 2.0581201536343215e-05,
      "loss": 0.0108,
      "step": 12380
    },
    {
      "epoch": 0.8972714425481031,
      "grad_norm": 0.8928585052490234,
      "learning_rate": 2.0566707732444382e-05,
      "loss": 0.0159,
      "step": 12381
    },
    {
      "epoch": 0.8973439141935717,
      "grad_norm": 0.4879201054573059,
      "learning_rate": 2.0552213928545545e-05,
      "loss": 0.0214,
      "step": 12382
    },
    {
      "epoch": 0.8974163858390405,
      "grad_norm": 2.1279568672180176,
      "learning_rate": 2.0537720124646715e-05,
      "loss": 0.0458,
      "step": 12383
    },
    {
      "epoch": 0.8974888574845092,
      "grad_norm": 2.224419593811035,
      "learning_rate": 2.0523226320747882e-05,
      "loss": 0.0626,
      "step": 12384
    },
    {
      "epoch": 0.8975613291299779,
      "grad_norm": 0.9130251407623291,
      "learning_rate": 2.050873251684905e-05,
      "loss": 0.0278,
      "step": 12385
    },
    {
      "epoch": 0.8976338007754466,
      "grad_norm": 0.431643009185791,
      "learning_rate": 2.0494238712950215e-05,
      "loss": 0.008,
      "step": 12386
    },
    {
      "epoch": 0.8977062724209153,
      "grad_norm": 2.2276556491851807,
      "learning_rate": 2.0479744909051382e-05,
      "loss": 0.0832,
      "step": 12387
    },
    {
      "epoch": 0.897778744066384,
      "grad_norm": 2.210872173309326,
      "learning_rate": 2.046525110515255e-05,
      "loss": 0.0417,
      "step": 12388
    },
    {
      "epoch": 0.8978512157118528,
      "grad_norm": 0.11149785667657852,
      "learning_rate": 2.0450757301253715e-05,
      "loss": 0.0008,
      "step": 12389
    },
    {
      "epoch": 0.8979236873573214,
      "grad_norm": 5.742473125457764,
      "learning_rate": 2.0436263497354882e-05,
      "loss": 0.064,
      "step": 12390
    },
    {
      "epoch": 0.8979961590027902,
      "grad_norm": 1.1862174272537231,
      "learning_rate": 2.042176969345605e-05,
      "loss": 0.0412,
      "step": 12391
    },
    {
      "epoch": 0.8980686306482588,
      "grad_norm": 2.891826629638672,
      "learning_rate": 2.0407275889557215e-05,
      "loss": 0.0588,
      "step": 12392
    },
    {
      "epoch": 0.8981411022937276,
      "grad_norm": 1.0151480436325073,
      "learning_rate": 2.0392782085658382e-05,
      "loss": 0.024,
      "step": 12393
    },
    {
      "epoch": 0.8982135739391963,
      "grad_norm": 1.3040814399719238,
      "learning_rate": 2.037828828175955e-05,
      "loss": 0.0216,
      "step": 12394
    },
    {
      "epoch": 0.898286045584665,
      "grad_norm": 2.5947744846343994,
      "learning_rate": 2.0363794477860715e-05,
      "loss": 0.0521,
      "step": 12395
    },
    {
      "epoch": 0.8983585172301337,
      "grad_norm": 1.7355152368545532,
      "learning_rate": 2.034930067396188e-05,
      "loss": 0.0165,
      "step": 12396
    },
    {
      "epoch": 0.8984309888756025,
      "grad_norm": 1.2712868452072144,
      "learning_rate": 2.033480687006305e-05,
      "loss": 0.0661,
      "step": 12397
    },
    {
      "epoch": 0.8985034605210711,
      "grad_norm": 2.9007985591888428,
      "learning_rate": 2.0320313066164215e-05,
      "loss": 0.0586,
      "step": 12398
    },
    {
      "epoch": 0.8985759321665399,
      "grad_norm": 0.42596128582954407,
      "learning_rate": 2.030581926226538e-05,
      "loss": 0.0061,
      "step": 12399
    },
    {
      "epoch": 0.8986484038120085,
      "grad_norm": 0.8594522476196289,
      "learning_rate": 2.029132545836655e-05,
      "loss": 0.0212,
      "step": 12400
    },
    {
      "epoch": 0.8987208754574773,
      "grad_norm": 0.8317380547523499,
      "learning_rate": 2.0276831654467715e-05,
      "loss": 0.0078,
      "step": 12401
    },
    {
      "epoch": 0.898793347102946,
      "grad_norm": 0.6346304416656494,
      "learning_rate": 2.026233785056888e-05,
      "loss": 0.0098,
      "step": 12402
    },
    {
      "epoch": 0.8988658187484146,
      "grad_norm": 0.04091998189687729,
      "learning_rate": 2.024784404667005e-05,
      "loss": 0.0008,
      "step": 12403
    },
    {
      "epoch": 0.8989382903938834,
      "grad_norm": 2.517333507537842,
      "learning_rate": 2.0233350242771215e-05,
      "loss": 0.1086,
      "step": 12404
    },
    {
      "epoch": 0.8990107620393522,
      "grad_norm": 4.551440715789795,
      "learning_rate": 2.021885643887238e-05,
      "loss": 0.1745,
      "step": 12405
    },
    {
      "epoch": 0.8990832336848208,
      "grad_norm": 0.5783262252807617,
      "learning_rate": 2.020436263497355e-05,
      "loss": 0.0057,
      "step": 12406
    },
    {
      "epoch": 0.8991557053302895,
      "grad_norm": 1.0435832738876343,
      "learning_rate": 2.0189868831074715e-05,
      "loss": 0.0087,
      "step": 12407
    },
    {
      "epoch": 0.8992281769757582,
      "grad_norm": 0.37115028500556946,
      "learning_rate": 2.017537502717588e-05,
      "loss": 0.0107,
      "step": 12408
    },
    {
      "epoch": 0.8993006486212269,
      "grad_norm": 0.4085163474082947,
      "learning_rate": 2.016088122327705e-05,
      "loss": 0.004,
      "step": 12409
    },
    {
      "epoch": 0.8993731202666957,
      "grad_norm": 1.9074230194091797,
      "learning_rate": 2.0146387419378218e-05,
      "loss": 0.0787,
      "step": 12410
    },
    {
      "epoch": 0.8994455919121643,
      "grad_norm": 2.449328899383545,
      "learning_rate": 2.013189361547938e-05,
      "loss": 0.0257,
      "step": 12411
    },
    {
      "epoch": 0.8995180635576331,
      "grad_norm": 0.8193678855895996,
      "learning_rate": 2.011739981158055e-05,
      "loss": 0.0297,
      "step": 12412
    },
    {
      "epoch": 0.8995905352031018,
      "grad_norm": 0.7330012917518616,
      "learning_rate": 2.0102906007681718e-05,
      "loss": 0.0134,
      "step": 12413
    },
    {
      "epoch": 0.8996630068485705,
      "grad_norm": 1.697603464126587,
      "learning_rate": 2.0088412203782885e-05,
      "loss": 0.0359,
      "step": 12414
    },
    {
      "epoch": 0.8997354784940392,
      "grad_norm": 1.7571861743927002,
      "learning_rate": 2.007391839988405e-05,
      "loss": 0.0209,
      "step": 12415
    },
    {
      "epoch": 0.8998079501395079,
      "grad_norm": 0.05023937672376633,
      "learning_rate": 2.0059424595985218e-05,
      "loss": 0.0004,
      "step": 12416
    },
    {
      "epoch": 0.8998804217849766,
      "grad_norm": 2.357877492904663,
      "learning_rate": 2.0044930792086385e-05,
      "loss": 0.0272,
      "step": 12417
    },
    {
      "epoch": 0.8999528934304454,
      "grad_norm": 0.015461663715541363,
      "learning_rate": 2.003043698818755e-05,
      "loss": 0.0003,
      "step": 12418
    },
    {
      "epoch": 0.900025365075914,
      "grad_norm": 0.1670900285243988,
      "learning_rate": 2.0015943184288718e-05,
      "loss": 0.0022,
      "step": 12419
    },
    {
      "epoch": 0.9000978367213828,
      "grad_norm": 1.1701891422271729,
      "learning_rate": 2.0001449380389885e-05,
      "loss": 0.0286,
      "step": 12420
    },
    {
      "epoch": 0.9001703083668515,
      "grad_norm": 0.3790043890476227,
      "learning_rate": 1.998695557649105e-05,
      "loss": 0.0122,
      "step": 12421
    },
    {
      "epoch": 0.9002427800123202,
      "grad_norm": 1.1745060682296753,
      "learning_rate": 1.9972461772592218e-05,
      "loss": 0.0272,
      "step": 12422
    },
    {
      "epoch": 0.9003152516577889,
      "grad_norm": 0.06091730296611786,
      "learning_rate": 1.9957967968693385e-05,
      "loss": 0.0012,
      "step": 12423
    },
    {
      "epoch": 0.9003877233032576,
      "grad_norm": 0.2813340425491333,
      "learning_rate": 1.994347416479455e-05,
      "loss": 0.0031,
      "step": 12424
    },
    {
      "epoch": 0.9004601949487263,
      "grad_norm": 0.060754574835300446,
      "learning_rate": 1.9928980360895718e-05,
      "loss": 0.001,
      "step": 12425
    },
    {
      "epoch": 0.9005326665941951,
      "grad_norm": 2.0477614402770996,
      "learning_rate": 1.9914486556996885e-05,
      "loss": 0.047,
      "step": 12426
    },
    {
      "epoch": 0.9006051382396637,
      "grad_norm": 0.2641407549381256,
      "learning_rate": 1.989999275309805e-05,
      "loss": 0.0052,
      "step": 12427
    },
    {
      "epoch": 0.9006776098851325,
      "grad_norm": 1.6105422973632812,
      "learning_rate": 1.9885498949199218e-05,
      "loss": 0.0324,
      "step": 12428
    },
    {
      "epoch": 0.9007500815306011,
      "grad_norm": 3.5161828994750977,
      "learning_rate": 1.9871005145300384e-05,
      "loss": 0.0623,
      "step": 12429
    },
    {
      "epoch": 0.9008225531760699,
      "grad_norm": 4.224288463592529,
      "learning_rate": 1.985651134140155e-05,
      "loss": 0.0266,
      "step": 12430
    },
    {
      "epoch": 0.9008950248215386,
      "grad_norm": 0.49692851305007935,
      "learning_rate": 1.9842017537502718e-05,
      "loss": 0.0074,
      "step": 12431
    },
    {
      "epoch": 0.9009674964670072,
      "grad_norm": 1.5014088153839111,
      "learning_rate": 1.9827523733603888e-05,
      "loss": 0.0475,
      "step": 12432
    },
    {
      "epoch": 0.901039968112476,
      "grad_norm": 0.05647897720336914,
      "learning_rate": 1.981302992970505e-05,
      "loss": 0.0009,
      "step": 12433
    },
    {
      "epoch": 0.9011124397579447,
      "grad_norm": 1.5418438911437988,
      "learning_rate": 1.9798536125806218e-05,
      "loss": 0.0135,
      "step": 12434
    },
    {
      "epoch": 0.9011849114034134,
      "grad_norm": 3.4327924251556396,
      "learning_rate": 1.9784042321907388e-05,
      "loss": 0.0875,
      "step": 12435
    },
    {
      "epoch": 0.9012573830488821,
      "grad_norm": 1.1857925653457642,
      "learning_rate": 1.976954851800855e-05,
      "loss": 0.0212,
      "step": 12436
    },
    {
      "epoch": 0.9013298546943508,
      "grad_norm": 2.3070788383483887,
      "learning_rate": 1.9755054714109718e-05,
      "loss": 0.0631,
      "step": 12437
    },
    {
      "epoch": 0.9014023263398195,
      "grad_norm": 0.12772570550441742,
      "learning_rate": 1.9740560910210888e-05,
      "loss": 0.0031,
      "step": 12438
    },
    {
      "epoch": 0.9014747979852883,
      "grad_norm": 1.20786714553833,
      "learning_rate": 1.972606710631205e-05,
      "loss": 0.018,
      "step": 12439
    },
    {
      "epoch": 0.9015472696307569,
      "grad_norm": 2.5747556686401367,
      "learning_rate": 1.9711573302413218e-05,
      "loss": 0.0937,
      "step": 12440
    },
    {
      "epoch": 0.9016197412762257,
      "grad_norm": 0.49565356969833374,
      "learning_rate": 1.9697079498514388e-05,
      "loss": 0.0113,
      "step": 12441
    },
    {
      "epoch": 0.9016922129216944,
      "grad_norm": 0.3470545709133148,
      "learning_rate": 1.968258569461555e-05,
      "loss": 0.006,
      "step": 12442
    },
    {
      "epoch": 0.9017646845671631,
      "grad_norm": 0.29909542202949524,
      "learning_rate": 1.966809189071672e-05,
      "loss": 0.0029,
      "step": 12443
    },
    {
      "epoch": 0.9018371562126318,
      "grad_norm": 1.648120641708374,
      "learning_rate": 1.9653598086817888e-05,
      "loss": 0.0249,
      "step": 12444
    },
    {
      "epoch": 0.9019096278581005,
      "grad_norm": 2.6343894004821777,
      "learning_rate": 1.963910428291905e-05,
      "loss": 0.0275,
      "step": 12445
    },
    {
      "epoch": 0.9019820995035692,
      "grad_norm": 0.45465409755706787,
      "learning_rate": 1.962461047902022e-05,
      "loss": 0.0226,
      "step": 12446
    },
    {
      "epoch": 0.902054571149038,
      "grad_norm": 0.12056729942560196,
      "learning_rate": 1.9610116675121388e-05,
      "loss": 0.0043,
      "step": 12447
    },
    {
      "epoch": 0.9021270427945066,
      "grad_norm": 1.1898417472839355,
      "learning_rate": 1.959562287122255e-05,
      "loss": 0.0205,
      "step": 12448
    },
    {
      "epoch": 0.9021995144399754,
      "grad_norm": 1.3004193305969238,
      "learning_rate": 1.958112906732372e-05,
      "loss": 0.0085,
      "step": 12449
    },
    {
      "epoch": 0.9022719860854441,
      "grad_norm": 0.9503577947616577,
      "learning_rate": 1.9566635263424888e-05,
      "loss": 0.0111,
      "step": 12450
    },
    {
      "epoch": 0.9023444577309128,
      "grad_norm": 0.22834758460521698,
      "learning_rate": 1.9552141459526054e-05,
      "loss": 0.0032,
      "step": 12451
    },
    {
      "epoch": 0.9024169293763815,
      "grad_norm": 1.353110909461975,
      "learning_rate": 1.953764765562722e-05,
      "loss": 0.0435,
      "step": 12452
    },
    {
      "epoch": 0.9024894010218502,
      "grad_norm": 0.556612491607666,
      "learning_rate": 1.9523153851728387e-05,
      "loss": 0.0081,
      "step": 12453
    },
    {
      "epoch": 0.9025618726673189,
      "grad_norm": 2.0730464458465576,
      "learning_rate": 1.9508660047829554e-05,
      "loss": 0.0714,
      "step": 12454
    },
    {
      "epoch": 0.9026343443127877,
      "grad_norm": 0.9986662268638611,
      "learning_rate": 1.949416624393072e-05,
      "loss": 0.0111,
      "step": 12455
    },
    {
      "epoch": 0.9027068159582563,
      "grad_norm": 3.085810899734497,
      "learning_rate": 1.9479672440031887e-05,
      "loss": 0.0584,
      "step": 12456
    },
    {
      "epoch": 0.9027792876037251,
      "grad_norm": 1.3391636610031128,
      "learning_rate": 1.9465178636133054e-05,
      "loss": 0.0325,
      "step": 12457
    },
    {
      "epoch": 0.9028517592491938,
      "grad_norm": 0.01216802466660738,
      "learning_rate": 1.945068483223422e-05,
      "loss": 0.0002,
      "step": 12458
    },
    {
      "epoch": 0.9029242308946624,
      "grad_norm": 0.7921408414840698,
      "learning_rate": 1.9436191028335387e-05,
      "loss": 0.01,
      "step": 12459
    },
    {
      "epoch": 0.9029967025401312,
      "grad_norm": 1.648209810256958,
      "learning_rate": 1.9421697224436554e-05,
      "loss": 0.0307,
      "step": 12460
    },
    {
      "epoch": 0.9030691741855998,
      "grad_norm": 1.7368539571762085,
      "learning_rate": 1.940720342053772e-05,
      "loss": 0.0601,
      "step": 12461
    },
    {
      "epoch": 0.9031416458310686,
      "grad_norm": 0.1321314126253128,
      "learning_rate": 1.9392709616638887e-05,
      "loss": 0.0032,
      "step": 12462
    },
    {
      "epoch": 0.9032141174765373,
      "grad_norm": 1.1690274477005005,
      "learning_rate": 1.9378215812740054e-05,
      "loss": 0.023,
      "step": 12463
    },
    {
      "epoch": 0.903286589122006,
      "grad_norm": 0.3636801838874817,
      "learning_rate": 1.936372200884122e-05,
      "loss": 0.006,
      "step": 12464
    },
    {
      "epoch": 0.9033590607674747,
      "grad_norm": 0.2722185552120209,
      "learning_rate": 1.9349228204942387e-05,
      "loss": 0.0111,
      "step": 12465
    },
    {
      "epoch": 0.9034315324129434,
      "grad_norm": 1.1666659116744995,
      "learning_rate": 1.9334734401043554e-05,
      "loss": 0.0324,
      "step": 12466
    },
    {
      "epoch": 0.9035040040584121,
      "grad_norm": 0.29324206709861755,
      "learning_rate": 1.932024059714472e-05,
      "loss": 0.0046,
      "step": 12467
    },
    {
      "epoch": 0.9035764757038809,
      "grad_norm": 1.034527063369751,
      "learning_rate": 1.9305746793245887e-05,
      "loss": 0.0304,
      "step": 12468
    },
    {
      "epoch": 0.9036489473493495,
      "grad_norm": 1.000395655632019,
      "learning_rate": 1.9291252989347057e-05,
      "loss": 0.0237,
      "step": 12469
    },
    {
      "epoch": 0.9037214189948183,
      "grad_norm": 0.26055777072906494,
      "learning_rate": 1.927675918544822e-05,
      "loss": 0.003,
      "step": 12470
    },
    {
      "epoch": 0.903793890640287,
      "grad_norm": 0.9169156551361084,
      "learning_rate": 1.9262265381549387e-05,
      "loss": 0.0229,
      "step": 12471
    },
    {
      "epoch": 0.9038663622857557,
      "grad_norm": 0.49209481477737427,
      "learning_rate": 1.9247771577650557e-05,
      "loss": 0.0058,
      "step": 12472
    },
    {
      "epoch": 0.9039388339312244,
      "grad_norm": 1.331834077835083,
      "learning_rate": 1.9233277773751724e-05,
      "loss": 0.0284,
      "step": 12473
    },
    {
      "epoch": 0.9040113055766931,
      "grad_norm": 2.56419038772583,
      "learning_rate": 1.9218783969852887e-05,
      "loss": 0.0587,
      "step": 12474
    },
    {
      "epoch": 0.9040837772221618,
      "grad_norm": 1.229230523109436,
      "learning_rate": 1.9204290165954057e-05,
      "loss": 0.0189,
      "step": 12475
    },
    {
      "epoch": 0.9041562488676306,
      "grad_norm": 0.4834904968738556,
      "learning_rate": 1.9189796362055224e-05,
      "loss": 0.008,
      "step": 12476
    },
    {
      "epoch": 0.9042287205130992,
      "grad_norm": 3.8081912994384766,
      "learning_rate": 1.9175302558156387e-05,
      "loss": 0.0886,
      "step": 12477
    },
    {
      "epoch": 0.904301192158568,
      "grad_norm": 3.7741453647613525,
      "learning_rate": 1.9160808754257557e-05,
      "loss": 0.0895,
      "step": 12478
    },
    {
      "epoch": 0.9043736638040367,
      "grad_norm": 1.669072151184082,
      "learning_rate": 1.9146314950358724e-05,
      "loss": 0.0234,
      "step": 12479
    },
    {
      "epoch": 0.9044461354495054,
      "grad_norm": 0.9454737305641174,
      "learning_rate": 1.9131821146459887e-05,
      "loss": 0.0194,
      "step": 12480
    },
    {
      "epoch": 0.9045186070949741,
      "grad_norm": 2.5193564891815186,
      "learning_rate": 1.9117327342561057e-05,
      "loss": 0.0386,
      "step": 12481
    },
    {
      "epoch": 0.9045910787404428,
      "grad_norm": 3.2416231632232666,
      "learning_rate": 1.9102833538662224e-05,
      "loss": 0.0615,
      "step": 12482
    },
    {
      "epoch": 0.9046635503859115,
      "grad_norm": 0.29776671528816223,
      "learning_rate": 1.9088339734763387e-05,
      "loss": 0.007,
      "step": 12483
    },
    {
      "epoch": 0.9047360220313803,
      "grad_norm": 0.5316492915153503,
      "learning_rate": 1.9073845930864557e-05,
      "loss": 0.0041,
      "step": 12484
    },
    {
      "epoch": 0.9048084936768489,
      "grad_norm": 5.0184125900268555,
      "learning_rate": 1.9059352126965724e-05,
      "loss": 0.0843,
      "step": 12485
    },
    {
      "epoch": 0.9048809653223177,
      "grad_norm": 2.0090792179107666,
      "learning_rate": 1.904485832306689e-05,
      "loss": 0.0306,
      "step": 12486
    },
    {
      "epoch": 0.9049534369677864,
      "grad_norm": 1.994299054145813,
      "learning_rate": 1.9030364519168057e-05,
      "loss": 0.0579,
      "step": 12487
    },
    {
      "epoch": 0.905025908613255,
      "grad_norm": 1.5577811002731323,
      "learning_rate": 1.9015870715269224e-05,
      "loss": 0.0376,
      "step": 12488
    },
    {
      "epoch": 0.9050983802587238,
      "grad_norm": 5.303974628448486,
      "learning_rate": 1.900137691137039e-05,
      "loss": 0.0443,
      "step": 12489
    },
    {
      "epoch": 0.9051708519041924,
      "grad_norm": 0.4632513225078583,
      "learning_rate": 1.8986883107471557e-05,
      "loss": 0.0058,
      "step": 12490
    },
    {
      "epoch": 0.9052433235496612,
      "grad_norm": 1.0391329526901245,
      "learning_rate": 1.8972389303572724e-05,
      "loss": 0.0306,
      "step": 12491
    },
    {
      "epoch": 0.90531579519513,
      "grad_norm": 0.6616337895393372,
      "learning_rate": 1.895789549967389e-05,
      "loss": 0.018,
      "step": 12492
    },
    {
      "epoch": 0.9053882668405986,
      "grad_norm": 2.3198370933532715,
      "learning_rate": 1.8943401695775057e-05,
      "loss": 0.0388,
      "step": 12493
    },
    {
      "epoch": 0.9054607384860673,
      "grad_norm": 2.369889736175537,
      "learning_rate": 1.8928907891876223e-05,
      "loss": 0.1723,
      "step": 12494
    },
    {
      "epoch": 0.905533210131536,
      "grad_norm": 0.5053259134292603,
      "learning_rate": 1.891441408797739e-05,
      "loss": 0.0067,
      "step": 12495
    },
    {
      "epoch": 0.9056056817770047,
      "grad_norm": 1.789944052696228,
      "learning_rate": 1.8899920284078557e-05,
      "loss": 0.0611,
      "step": 12496
    },
    {
      "epoch": 0.9056781534224735,
      "grad_norm": 2.868194818496704,
      "learning_rate": 1.8885426480179723e-05,
      "loss": 0.0751,
      "step": 12497
    },
    {
      "epoch": 0.9057506250679421,
      "grad_norm": 0.4275266230106354,
      "learning_rate": 1.8870932676280893e-05,
      "loss": 0.0073,
      "step": 12498
    },
    {
      "epoch": 0.9058230967134109,
      "grad_norm": 0.23031988739967346,
      "learning_rate": 1.8856438872382057e-05,
      "loss": 0.0032,
      "step": 12499
    },
    {
      "epoch": 0.9058955683588796,
      "grad_norm": 0.0176163949072361,
      "learning_rate": 1.8841945068483223e-05,
      "loss": 0.0003,
      "step": 12500
    },
    {
      "epoch": 0.9059680400043483,
      "grad_norm": 1.0251227617263794,
      "learning_rate": 1.8827451264584393e-05,
      "loss": 0.0172,
      "step": 12501
    },
    {
      "epoch": 0.906040511649817,
      "grad_norm": 2.7840077877044678,
      "learning_rate": 1.8812957460685557e-05,
      "loss": 0.0954,
      "step": 12502
    },
    {
      "epoch": 0.9061129832952857,
      "grad_norm": 2.282503128051758,
      "learning_rate": 1.8798463656786723e-05,
      "loss": 0.0577,
      "step": 12503
    },
    {
      "epoch": 0.9061854549407544,
      "grad_norm": 3.3747589588165283,
      "learning_rate": 1.8783969852887893e-05,
      "loss": 0.074,
      "step": 12504
    },
    {
      "epoch": 0.9062579265862232,
      "grad_norm": 1.8458524942398071,
      "learning_rate": 1.8769476048989057e-05,
      "loss": 0.0622,
      "step": 12505
    },
    {
      "epoch": 0.9063303982316918,
      "grad_norm": 5.991678714752197,
      "learning_rate": 1.8754982245090223e-05,
      "loss": 0.2017,
      "step": 12506
    },
    {
      "epoch": 0.9064028698771606,
      "grad_norm": 3.879591226577759,
      "learning_rate": 1.8740488441191393e-05,
      "loss": 0.1632,
      "step": 12507
    },
    {
      "epoch": 0.9064753415226293,
      "grad_norm": 3.129406213760376,
      "learning_rate": 1.8725994637292557e-05,
      "loss": 0.1179,
      "step": 12508
    },
    {
      "epoch": 0.906547813168098,
      "grad_norm": 1.6235520839691162,
      "learning_rate": 1.8711500833393723e-05,
      "loss": 0.0385,
      "step": 12509
    },
    {
      "epoch": 0.9066202848135667,
      "grad_norm": 4.653101921081543,
      "learning_rate": 1.8697007029494893e-05,
      "loss": 0.0729,
      "step": 12510
    },
    {
      "epoch": 0.9066927564590354,
      "grad_norm": 0.5365363955497742,
      "learning_rate": 1.8682513225596057e-05,
      "loss": 0.013,
      "step": 12511
    },
    {
      "epoch": 0.9067652281045041,
      "grad_norm": 0.327519953250885,
      "learning_rate": 1.8668019421697223e-05,
      "loss": 0.017,
      "step": 12512
    },
    {
      "epoch": 0.9068376997499729,
      "grad_norm": 2.0880072116851807,
      "learning_rate": 1.8653525617798393e-05,
      "loss": 0.0336,
      "step": 12513
    },
    {
      "epoch": 0.9069101713954415,
      "grad_norm": 0.39454999566078186,
      "learning_rate": 1.863903181389956e-05,
      "loss": 0.0099,
      "step": 12514
    },
    {
      "epoch": 0.9069826430409103,
      "grad_norm": 1.8487284183502197,
      "learning_rate": 1.8624538010000727e-05,
      "loss": 0.0515,
      "step": 12515
    },
    {
      "epoch": 0.907055114686379,
      "grad_norm": 2.018904685974121,
      "learning_rate": 1.8610044206101893e-05,
      "loss": 0.0236,
      "step": 12516
    },
    {
      "epoch": 0.9071275863318476,
      "grad_norm": 4.46037483215332,
      "learning_rate": 1.859555040220306e-05,
      "loss": 0.0471,
      "step": 12517
    },
    {
      "epoch": 0.9072000579773164,
      "grad_norm": 3.40631103515625,
      "learning_rate": 1.8581056598304226e-05,
      "loss": 0.0628,
      "step": 12518
    },
    {
      "epoch": 0.907272529622785,
      "grad_norm": 1.5057992935180664,
      "learning_rate": 1.8566562794405393e-05,
      "loss": 0.0632,
      "step": 12519
    },
    {
      "epoch": 0.9073450012682538,
      "grad_norm": 1.3279114961624146,
      "learning_rate": 1.855206899050656e-05,
      "loss": 0.1027,
      "step": 12520
    },
    {
      "epoch": 0.9074174729137225,
      "grad_norm": 0.5169605016708374,
      "learning_rate": 1.8537575186607726e-05,
      "loss": 0.0247,
      "step": 12521
    },
    {
      "epoch": 0.9074899445591912,
      "grad_norm": 0.25143054127693176,
      "learning_rate": 1.8523081382708893e-05,
      "loss": 0.0075,
      "step": 12522
    },
    {
      "epoch": 0.9075624162046599,
      "grad_norm": 0.059380121529102325,
      "learning_rate": 1.850858757881006e-05,
      "loss": 0.0007,
      "step": 12523
    },
    {
      "epoch": 0.9076348878501287,
      "grad_norm": 2.3347768783569336,
      "learning_rate": 1.8494093774911226e-05,
      "loss": 0.0801,
      "step": 12524
    },
    {
      "epoch": 0.9077073594955973,
      "grad_norm": 2.573580265045166,
      "learning_rate": 1.8479599971012393e-05,
      "loss": 0.0233,
      "step": 12525
    },
    {
      "epoch": 0.9077798311410661,
      "grad_norm": 2.241070508956909,
      "learning_rate": 1.846510616711356e-05,
      "loss": 0.0503,
      "step": 12526
    },
    {
      "epoch": 0.9078523027865347,
      "grad_norm": 1.305674433708191,
      "learning_rate": 1.8450612363214726e-05,
      "loss": 0.0324,
      "step": 12527
    },
    {
      "epoch": 0.9079247744320035,
      "grad_norm": 2.1567625999450684,
      "learning_rate": 1.8436118559315893e-05,
      "loss": 0.0853,
      "step": 12528
    },
    {
      "epoch": 0.9079972460774722,
      "grad_norm": 0.9432187080383301,
      "learning_rate": 1.842162475541706e-05,
      "loss": 0.0105,
      "step": 12529
    },
    {
      "epoch": 0.9080697177229409,
      "grad_norm": 1.8447929620742798,
      "learning_rate": 1.8407130951518226e-05,
      "loss": 0.0382,
      "step": 12530
    },
    {
      "epoch": 0.9081421893684096,
      "grad_norm": 0.3047541379928589,
      "learning_rate": 1.8392637147619393e-05,
      "loss": 0.0086,
      "step": 12531
    },
    {
      "epoch": 0.9082146610138783,
      "grad_norm": 0.03680063784122467,
      "learning_rate": 1.837814334372056e-05,
      "loss": 0.0004,
      "step": 12532
    },
    {
      "epoch": 0.908287132659347,
      "grad_norm": 0.5957773923873901,
      "learning_rate": 1.836364953982173e-05,
      "loss": 0.0096,
      "step": 12533
    },
    {
      "epoch": 0.9083596043048158,
      "grad_norm": 0.10402985662221909,
      "learning_rate": 1.8349155735922893e-05,
      "loss": 0.0019,
      "step": 12534
    },
    {
      "epoch": 0.9084320759502844,
      "grad_norm": 1.822891354560852,
      "learning_rate": 1.833466193202406e-05,
      "loss": 0.0235,
      "step": 12535
    },
    {
      "epoch": 0.9085045475957532,
      "grad_norm": 3.5815231800079346,
      "learning_rate": 1.832016812812523e-05,
      "loss": 0.0312,
      "step": 12536
    },
    {
      "epoch": 0.9085770192412219,
      "grad_norm": 2.398106575012207,
      "learning_rate": 1.8305674324226393e-05,
      "loss": 0.0427,
      "step": 12537
    },
    {
      "epoch": 0.9086494908866906,
      "grad_norm": 2.791433095932007,
      "learning_rate": 1.829118052032756e-05,
      "loss": 0.0772,
      "step": 12538
    },
    {
      "epoch": 0.9087219625321593,
      "grad_norm": 2.1553192138671875,
      "learning_rate": 1.827668671642873e-05,
      "loss": 0.0595,
      "step": 12539
    },
    {
      "epoch": 0.908794434177628,
      "grad_norm": 1.3615399599075317,
      "learning_rate": 1.8262192912529893e-05,
      "loss": 0.0203,
      "step": 12540
    },
    {
      "epoch": 0.9088669058230967,
      "grad_norm": 1.1945860385894775,
      "learning_rate": 1.8247699108631063e-05,
      "loss": 0.0242,
      "step": 12541
    },
    {
      "epoch": 0.9089393774685655,
      "grad_norm": 0.19492006301879883,
      "learning_rate": 1.823320530473223e-05,
      "loss": 0.0111,
      "step": 12542
    },
    {
      "epoch": 0.9090118491140341,
      "grad_norm": 0.7879277467727661,
      "learning_rate": 1.8218711500833393e-05,
      "loss": 0.0157,
      "step": 12543
    },
    {
      "epoch": 0.9090843207595029,
      "grad_norm": 1.3777483701705933,
      "learning_rate": 1.8204217696934563e-05,
      "loss": 0.0114,
      "step": 12544
    },
    {
      "epoch": 0.9091567924049716,
      "grad_norm": 0.9550960659980774,
      "learning_rate": 1.818972389303573e-05,
      "loss": 0.0358,
      "step": 12545
    },
    {
      "epoch": 0.9092292640504402,
      "grad_norm": 2.109170913696289,
      "learning_rate": 1.8175230089136893e-05,
      "loss": 0.0312,
      "step": 12546
    },
    {
      "epoch": 0.909301735695909,
      "grad_norm": 3.6630964279174805,
      "learning_rate": 1.8160736285238063e-05,
      "loss": 0.0484,
      "step": 12547
    },
    {
      "epoch": 0.9093742073413776,
      "grad_norm": 0.7434866428375244,
      "learning_rate": 1.814624248133923e-05,
      "loss": 0.0083,
      "step": 12548
    },
    {
      "epoch": 0.9094466789868464,
      "grad_norm": 0.8528991341590881,
      "learning_rate": 1.8131748677440393e-05,
      "loss": 0.0135,
      "step": 12549
    },
    {
      "epoch": 0.9095191506323151,
      "grad_norm": 0.07086041569709778,
      "learning_rate": 1.8117254873541563e-05,
      "loss": 0.0007,
      "step": 12550
    },
    {
      "epoch": 0.9095916222777838,
      "grad_norm": 1.9742218255996704,
      "learning_rate": 1.810276106964273e-05,
      "loss": 0.065,
      "step": 12551
    },
    {
      "epoch": 0.9096640939232525,
      "grad_norm": 1.8632469177246094,
      "learning_rate": 1.8088267265743893e-05,
      "loss": 0.0315,
      "step": 12552
    },
    {
      "epoch": 0.9097365655687213,
      "grad_norm": 0.5057851672172546,
      "learning_rate": 1.8073773461845063e-05,
      "loss": 0.0084,
      "step": 12553
    },
    {
      "epoch": 0.9098090372141899,
      "grad_norm": 0.12042342126369476,
      "learning_rate": 1.805927965794623e-05,
      "loss": 0.0023,
      "step": 12554
    },
    {
      "epoch": 0.9098815088596587,
      "grad_norm": 1.5235211849212646,
      "learning_rate": 1.8044785854047396e-05,
      "loss": 0.0366,
      "step": 12555
    },
    {
      "epoch": 0.9099539805051273,
      "grad_norm": 0.9503459930419922,
      "learning_rate": 1.8030292050148563e-05,
      "loss": 0.0497,
      "step": 12556
    },
    {
      "epoch": 0.9100264521505961,
      "grad_norm": 1.6733983755111694,
      "learning_rate": 1.801579824624973e-05,
      "loss": 0.0145,
      "step": 12557
    },
    {
      "epoch": 0.9100989237960648,
      "grad_norm": 2.9483914375305176,
      "learning_rate": 1.8001304442350896e-05,
      "loss": 0.0486,
      "step": 12558
    },
    {
      "epoch": 0.9101713954415335,
      "grad_norm": 2.0038671493530273,
      "learning_rate": 1.7986810638452062e-05,
      "loss": 0.0304,
      "step": 12559
    },
    {
      "epoch": 0.9102438670870022,
      "grad_norm": 0.17146073281764984,
      "learning_rate": 1.797231683455323e-05,
      "loss": 0.0015,
      "step": 12560
    },
    {
      "epoch": 0.910316338732471,
      "grad_norm": 0.3040667474269867,
      "learning_rate": 1.7957823030654396e-05,
      "loss": 0.0112,
      "step": 12561
    },
    {
      "epoch": 0.9103888103779396,
      "grad_norm": 0.7395126223564148,
      "learning_rate": 1.7943329226755562e-05,
      "loss": 0.0148,
      "step": 12562
    },
    {
      "epoch": 0.9104612820234084,
      "grad_norm": 2.9052894115448,
      "learning_rate": 1.792883542285673e-05,
      "loss": 0.1167,
      "step": 12563
    },
    {
      "epoch": 0.910533753668877,
      "grad_norm": 0.7197961211204529,
      "learning_rate": 1.7914341618957896e-05,
      "loss": 0.0163,
      "step": 12564
    },
    {
      "epoch": 0.9106062253143458,
      "grad_norm": 1.9524470567703247,
      "learning_rate": 1.7899847815059062e-05,
      "loss": 0.0275,
      "step": 12565
    },
    {
      "epoch": 0.9106786969598145,
      "grad_norm": 0.7285090088844299,
      "learning_rate": 1.788535401116023e-05,
      "loss": 0.0133,
      "step": 12566
    },
    {
      "epoch": 0.9107511686052832,
      "grad_norm": 3.3326518535614014,
      "learning_rate": 1.7870860207261396e-05,
      "loss": 0.1378,
      "step": 12567
    },
    {
      "epoch": 0.9108236402507519,
      "grad_norm": 1.2275546789169312,
      "learning_rate": 1.7856366403362562e-05,
      "loss": 0.0407,
      "step": 12568
    },
    {
      "epoch": 0.9108961118962206,
      "grad_norm": 4.532419204711914,
      "learning_rate": 1.784187259946373e-05,
      "loss": 0.146,
      "step": 12569
    },
    {
      "epoch": 0.9109685835416893,
      "grad_norm": 0.7895281314849854,
      "learning_rate": 1.78273787955649e-05,
      "loss": 0.0169,
      "step": 12570
    },
    {
      "epoch": 0.911041055187158,
      "grad_norm": 1.112552285194397,
      "learning_rate": 1.7812884991666062e-05,
      "loss": 0.0239,
      "step": 12571
    },
    {
      "epoch": 0.9111135268326267,
      "grad_norm": 4.548961162567139,
      "learning_rate": 1.779839118776723e-05,
      "loss": 0.0922,
      "step": 12572
    },
    {
      "epoch": 0.9111859984780954,
      "grad_norm": 2.031885862350464,
      "learning_rate": 1.77838973838684e-05,
      "loss": 0.0691,
      "step": 12573
    },
    {
      "epoch": 0.9112584701235642,
      "grad_norm": 0.031152814626693726,
      "learning_rate": 1.7769403579969566e-05,
      "loss": 0.0003,
      "step": 12574
    },
    {
      "epoch": 0.9113309417690328,
      "grad_norm": 2.0414280891418457,
      "learning_rate": 1.775490977607073e-05,
      "loss": 0.0087,
      "step": 12575
    },
    {
      "epoch": 0.9114034134145016,
      "grad_norm": 0.054839376360177994,
      "learning_rate": 1.77404159721719e-05,
      "loss": 0.0013,
      "step": 12576
    },
    {
      "epoch": 0.9114758850599702,
      "grad_norm": 1.1129708290100098,
      "learning_rate": 1.7725922168273066e-05,
      "loss": 0.0308,
      "step": 12577
    },
    {
      "epoch": 0.911548356705439,
      "grad_norm": 0.5706973075866699,
      "learning_rate": 1.771142836437423e-05,
      "loss": 0.0139,
      "step": 12578
    },
    {
      "epoch": 0.9116208283509077,
      "grad_norm": 2.419189691543579,
      "learning_rate": 1.76969345604754e-05,
      "loss": 0.0534,
      "step": 12579
    },
    {
      "epoch": 0.9116932999963764,
      "grad_norm": 0.1522338092327118,
      "learning_rate": 1.7682440756576566e-05,
      "loss": 0.0044,
      "step": 12580
    },
    {
      "epoch": 0.9117657716418451,
      "grad_norm": 0.5417461395263672,
      "learning_rate": 1.766794695267773e-05,
      "loss": 0.0268,
      "step": 12581
    },
    {
      "epoch": 0.9118382432873139,
      "grad_norm": 0.833378255367279,
      "learning_rate": 1.76534531487789e-05,
      "loss": 0.0167,
      "step": 12582
    },
    {
      "epoch": 0.9119107149327825,
      "grad_norm": 1.7616817951202393,
      "learning_rate": 1.7638959344880065e-05,
      "loss": 0.0153,
      "step": 12583
    },
    {
      "epoch": 0.9119831865782513,
      "grad_norm": 0.4628501534461975,
      "learning_rate": 1.762446554098123e-05,
      "loss": 0.01,
      "step": 12584
    },
    {
      "epoch": 0.9120556582237199,
      "grad_norm": 3.77862286567688,
      "learning_rate": 1.76099717370824e-05,
      "loss": 0.0823,
      "step": 12585
    },
    {
      "epoch": 0.9121281298691887,
      "grad_norm": 0.1560596376657486,
      "learning_rate": 1.7595477933183565e-05,
      "loss": 0.0023,
      "step": 12586
    },
    {
      "epoch": 0.9122006015146574,
      "grad_norm": 0.9654479622840881,
      "learning_rate": 1.7580984129284732e-05,
      "loss": 0.0257,
      "step": 12587
    },
    {
      "epoch": 0.9122730731601261,
      "grad_norm": 2.2630839347839355,
      "learning_rate": 1.75664903253859e-05,
      "loss": 0.0279,
      "step": 12588
    },
    {
      "epoch": 0.9123455448055948,
      "grad_norm": 2.684293508529663,
      "learning_rate": 1.7551996521487065e-05,
      "loss": 0.0286,
      "step": 12589
    },
    {
      "epoch": 0.9124180164510636,
      "grad_norm": 1.9809740781784058,
      "learning_rate": 1.7537502717588232e-05,
      "loss": 0.0531,
      "step": 12590
    },
    {
      "epoch": 0.9124904880965322,
      "grad_norm": 1.3739101886749268,
      "learning_rate": 1.75230089136894e-05,
      "loss": 0.0142,
      "step": 12591
    },
    {
      "epoch": 0.912562959742001,
      "grad_norm": 1.0999596118927002,
      "learning_rate": 1.7508515109790565e-05,
      "loss": 0.0163,
      "step": 12592
    },
    {
      "epoch": 0.9126354313874696,
      "grad_norm": 0.5521425008773804,
      "learning_rate": 1.7494021305891732e-05,
      "loss": 0.009,
      "step": 12593
    },
    {
      "epoch": 0.9127079030329384,
      "grad_norm": 1.1567332744598389,
      "learning_rate": 1.74795275019929e-05,
      "loss": 0.023,
      "step": 12594
    },
    {
      "epoch": 0.9127803746784071,
      "grad_norm": 2.0740227699279785,
      "learning_rate": 1.7465033698094065e-05,
      "loss": 0.039,
      "step": 12595
    },
    {
      "epoch": 0.9128528463238758,
      "grad_norm": 0.7075154781341553,
      "learning_rate": 1.7450539894195235e-05,
      "loss": 0.0071,
      "step": 12596
    },
    {
      "epoch": 0.9129253179693445,
      "grad_norm": 1.2054375410079956,
      "learning_rate": 1.74360460902964e-05,
      "loss": 0.0568,
      "step": 12597
    },
    {
      "epoch": 0.9129977896148131,
      "grad_norm": 1.9407521486282349,
      "learning_rate": 1.7421552286397565e-05,
      "loss": 0.0414,
      "step": 12598
    },
    {
      "epoch": 0.9130702612602819,
      "grad_norm": 0.6938148140907288,
      "learning_rate": 1.7407058482498735e-05,
      "loss": 0.0423,
      "step": 12599
    },
    {
      "epoch": 0.9131427329057507,
      "grad_norm": 2.0656802654266357,
      "learning_rate": 1.73925646785999e-05,
      "loss": 0.0309,
      "step": 12600
    },
    {
      "epoch": 0.9132152045512193,
      "grad_norm": 0.4359467625617981,
      "learning_rate": 1.7378070874701065e-05,
      "loss": 0.0037,
      "step": 12601
    },
    {
      "epoch": 0.913287676196688,
      "grad_norm": 1.697269320487976,
      "learning_rate": 1.7363577070802235e-05,
      "loss": 0.0663,
      "step": 12602
    },
    {
      "epoch": 0.9133601478421568,
      "grad_norm": 0.9331527352333069,
      "learning_rate": 1.73490832669034e-05,
      "loss": 0.0078,
      "step": 12603
    },
    {
      "epoch": 0.9134326194876254,
      "grad_norm": 1.24040687084198,
      "learning_rate": 1.7334589463004565e-05,
      "loss": 0.0173,
      "step": 12604
    },
    {
      "epoch": 0.9135050911330942,
      "grad_norm": 0.4123910367488861,
      "learning_rate": 1.7320095659105735e-05,
      "loss": 0.012,
      "step": 12605
    },
    {
      "epoch": 0.9135775627785628,
      "grad_norm": 2.1658384799957275,
      "learning_rate": 1.73056018552069e-05,
      "loss": 0.0373,
      "step": 12606
    },
    {
      "epoch": 0.9136500344240316,
      "grad_norm": 1.460757851600647,
      "learning_rate": 1.7291108051308065e-05,
      "loss": 0.0465,
      "step": 12607
    },
    {
      "epoch": 0.9137225060695003,
      "grad_norm": 2.208547592163086,
      "learning_rate": 1.7276614247409235e-05,
      "loss": 0.0392,
      "step": 12608
    },
    {
      "epoch": 0.913794977714969,
      "grad_norm": 4.1414408683776855,
      "learning_rate": 1.72621204435104e-05,
      "loss": 0.0157,
      "step": 12609
    },
    {
      "epoch": 0.9138674493604377,
      "grad_norm": 3.7148873805999756,
      "learning_rate": 1.7247626639611565e-05,
      "loss": 0.0614,
      "step": 12610
    },
    {
      "epoch": 0.9139399210059065,
      "grad_norm": 0.6309860944747925,
      "learning_rate": 1.7233132835712735e-05,
      "loss": 0.0301,
      "step": 12611
    },
    {
      "epoch": 0.9140123926513751,
      "grad_norm": 1.8966550827026367,
      "learning_rate": 1.7218639031813898e-05,
      "loss": 0.0154,
      "step": 12612
    },
    {
      "epoch": 0.9140848642968439,
      "grad_norm": 2.214031934738159,
      "learning_rate": 1.720414522791507e-05,
      "loss": 0.0713,
      "step": 12613
    },
    {
      "epoch": 0.9141573359423125,
      "grad_norm": 0.3994082808494568,
      "learning_rate": 1.7189651424016235e-05,
      "loss": 0.0077,
      "step": 12614
    },
    {
      "epoch": 0.9142298075877813,
      "grad_norm": 1.2106389999389648,
      "learning_rate": 1.71751576201174e-05,
      "loss": 0.0465,
      "step": 12615
    },
    {
      "epoch": 0.91430227923325,
      "grad_norm": 0.458842396736145,
      "learning_rate": 1.7160663816218568e-05,
      "loss": 0.0109,
      "step": 12616
    },
    {
      "epoch": 0.9143747508787187,
      "grad_norm": 2.956575393676758,
      "learning_rate": 1.7146170012319735e-05,
      "loss": 0.0817,
      "step": 12617
    },
    {
      "epoch": 0.9144472225241874,
      "grad_norm": 1.1995129585266113,
      "learning_rate": 1.71316762084209e-05,
      "loss": 0.0132,
      "step": 12618
    },
    {
      "epoch": 0.9145196941696562,
      "grad_norm": 1.5947182178497314,
      "learning_rate": 1.7117182404522068e-05,
      "loss": 0.0193,
      "step": 12619
    },
    {
      "epoch": 0.9145921658151248,
      "grad_norm": 1.7624543905258179,
      "learning_rate": 1.7102688600623235e-05,
      "loss": 0.0596,
      "step": 12620
    },
    {
      "epoch": 0.9146646374605936,
      "grad_norm": 4.191086292266846,
      "learning_rate": 1.70881947967244e-05,
      "loss": 0.0425,
      "step": 12621
    },
    {
      "epoch": 0.9147371091060622,
      "grad_norm": 0.4164702296257019,
      "learning_rate": 1.7073700992825568e-05,
      "loss": 0.0105,
      "step": 12622
    },
    {
      "epoch": 0.914809580751531,
      "grad_norm": 1.3354613780975342,
      "learning_rate": 1.7059207188926735e-05,
      "loss": 0.0353,
      "step": 12623
    },
    {
      "epoch": 0.9148820523969997,
      "grad_norm": 6.799964904785156,
      "learning_rate": 1.70447133850279e-05,
      "loss": 0.0711,
      "step": 12624
    },
    {
      "epoch": 0.9149545240424684,
      "grad_norm": 0.7411142587661743,
      "learning_rate": 1.7030219581129068e-05,
      "loss": 0.0146,
      "step": 12625
    },
    {
      "epoch": 0.9150269956879371,
      "grad_norm": 0.8044623732566833,
      "learning_rate": 1.7015725777230235e-05,
      "loss": 0.0212,
      "step": 12626
    },
    {
      "epoch": 0.9150994673334059,
      "grad_norm": 3.915851593017578,
      "learning_rate": 1.70012319733314e-05,
      "loss": 0.086,
      "step": 12627
    },
    {
      "epoch": 0.9151719389788745,
      "grad_norm": 0.3331393897533417,
      "learning_rate": 1.6986738169432568e-05,
      "loss": 0.0083,
      "step": 12628
    },
    {
      "epoch": 0.9152444106243433,
      "grad_norm": 2.8738768100738525,
      "learning_rate": 1.6972244365533735e-05,
      "loss": 0.0376,
      "step": 12629
    },
    {
      "epoch": 0.9153168822698119,
      "grad_norm": 2.7549867630004883,
      "learning_rate": 1.69577505616349e-05,
      "loss": 0.0613,
      "step": 12630
    },
    {
      "epoch": 0.9153893539152806,
      "grad_norm": 0.5438866019248962,
      "learning_rate": 1.6943256757736068e-05,
      "loss": 0.0253,
      "step": 12631
    },
    {
      "epoch": 0.9154618255607494,
      "grad_norm": 0.5335959792137146,
      "learning_rate": 1.6928762953837235e-05,
      "loss": 0.0161,
      "step": 12632
    },
    {
      "epoch": 0.915534297206218,
      "grad_norm": 1.7589377164840698,
      "learning_rate": 1.69142691499384e-05,
      "loss": 0.0203,
      "step": 12633
    },
    {
      "epoch": 0.9156067688516868,
      "grad_norm": 0.7968162298202515,
      "learning_rate": 1.689977534603957e-05,
      "loss": 0.0516,
      "step": 12634
    },
    {
      "epoch": 0.9156792404971554,
      "grad_norm": 1.0514506101608276,
      "learning_rate": 1.6885281542140735e-05,
      "loss": 0.0136,
      "step": 12635
    },
    {
      "epoch": 0.9157517121426242,
      "grad_norm": 1.9617806673049927,
      "learning_rate": 1.68707877382419e-05,
      "loss": 0.0398,
      "step": 12636
    },
    {
      "epoch": 0.9158241837880929,
      "grad_norm": 0.6526801586151123,
      "learning_rate": 1.685629393434307e-05,
      "loss": 0.0077,
      "step": 12637
    },
    {
      "epoch": 0.9158966554335616,
      "grad_norm": 2.280665397644043,
      "learning_rate": 1.6841800130444235e-05,
      "loss": 0.0912,
      "step": 12638
    },
    {
      "epoch": 0.9159691270790303,
      "grad_norm": 0.8958588242530823,
      "learning_rate": 1.68273063265454e-05,
      "loss": 0.0296,
      "step": 12639
    },
    {
      "epoch": 0.9160415987244991,
      "grad_norm": 3.5131478309631348,
      "learning_rate": 1.681281252264657e-05,
      "loss": 0.0251,
      "step": 12640
    },
    {
      "epoch": 0.9161140703699677,
      "grad_norm": 1.2654478549957275,
      "learning_rate": 1.6798318718747735e-05,
      "loss": 0.0455,
      "step": 12641
    },
    {
      "epoch": 0.9161865420154365,
      "grad_norm": 0.8599966168403625,
      "learning_rate": 1.6783824914848905e-05,
      "loss": 0.0148,
      "step": 12642
    },
    {
      "epoch": 0.9162590136609051,
      "grad_norm": 3.198859930038452,
      "learning_rate": 1.676933111095007e-05,
      "loss": 0.0137,
      "step": 12643
    },
    {
      "epoch": 0.9163314853063739,
      "grad_norm": 1.132739543914795,
      "learning_rate": 1.6754837307051234e-05,
      "loss": 0.0274,
      "step": 12644
    },
    {
      "epoch": 0.9164039569518426,
      "grad_norm": 2.0885722637176514,
      "learning_rate": 1.6740343503152405e-05,
      "loss": 0.0642,
      "step": 12645
    },
    {
      "epoch": 0.9164764285973113,
      "grad_norm": 2.3402371406555176,
      "learning_rate": 1.672584969925357e-05,
      "loss": 0.0607,
      "step": 12646
    },
    {
      "epoch": 0.91654890024278,
      "grad_norm": 3.0245985984802246,
      "learning_rate": 1.6711355895354734e-05,
      "loss": 0.0361,
      "step": 12647
    },
    {
      "epoch": 0.9166213718882488,
      "grad_norm": 1.151056170463562,
      "learning_rate": 1.6696862091455904e-05,
      "loss": 0.0313,
      "step": 12648
    },
    {
      "epoch": 0.9166938435337174,
      "grad_norm": 0.16500195860862732,
      "learning_rate": 1.668236828755707e-05,
      "loss": 0.0041,
      "step": 12649
    },
    {
      "epoch": 0.9167663151791862,
      "grad_norm": 0.6346978545188904,
      "learning_rate": 1.6667874483658234e-05,
      "loss": 0.0246,
      "step": 12650
    },
    {
      "epoch": 0.9168387868246548,
      "grad_norm": 0.39298152923583984,
      "learning_rate": 1.6653380679759404e-05,
      "loss": 0.0264,
      "step": 12651
    },
    {
      "epoch": 0.9169112584701236,
      "grad_norm": 1.6003888845443726,
      "learning_rate": 1.663888687586057e-05,
      "loss": 0.0227,
      "step": 12652
    },
    {
      "epoch": 0.9169837301155923,
      "grad_norm": 0.30080780386924744,
      "learning_rate": 1.6624393071961734e-05,
      "loss": 0.0041,
      "step": 12653
    },
    {
      "epoch": 0.917056201761061,
      "grad_norm": 1.9257441759109497,
      "learning_rate": 1.6609899268062904e-05,
      "loss": 0.057,
      "step": 12654
    },
    {
      "epoch": 0.9171286734065297,
      "grad_norm": 0.8072280883789062,
      "learning_rate": 1.659540546416407e-05,
      "loss": 0.0252,
      "step": 12655
    },
    {
      "epoch": 0.9172011450519985,
      "grad_norm": 1.7639714479446411,
      "learning_rate": 1.6580911660265238e-05,
      "loss": 0.0856,
      "step": 12656
    },
    {
      "epoch": 0.9172736166974671,
      "grad_norm": 1.9845761060714722,
      "learning_rate": 1.6566417856366404e-05,
      "loss": 0.0415,
      "step": 12657
    },
    {
      "epoch": 0.9173460883429359,
      "grad_norm": 2.049365758895874,
      "learning_rate": 1.655192405246757e-05,
      "loss": 0.0278,
      "step": 12658
    },
    {
      "epoch": 0.9174185599884045,
      "grad_norm": 2.6944527626037598,
      "learning_rate": 1.6537430248568738e-05,
      "loss": 0.0604,
      "step": 12659
    },
    {
      "epoch": 0.9174910316338732,
      "grad_norm": 1.408411979675293,
      "learning_rate": 1.6522936444669904e-05,
      "loss": 0.0225,
      "step": 12660
    },
    {
      "epoch": 0.917563503279342,
      "grad_norm": 2.2972962856292725,
      "learning_rate": 1.650844264077107e-05,
      "loss": 0.0991,
      "step": 12661
    },
    {
      "epoch": 0.9176359749248106,
      "grad_norm": 2.723924398422241,
      "learning_rate": 1.6493948836872238e-05,
      "loss": 0.0943,
      "step": 12662
    },
    {
      "epoch": 0.9177084465702794,
      "grad_norm": 2.0385379791259766,
      "learning_rate": 1.6479455032973404e-05,
      "loss": 0.0622,
      "step": 12663
    },
    {
      "epoch": 0.9177809182157481,
      "grad_norm": 2.7432541847229004,
      "learning_rate": 1.646496122907457e-05,
      "loss": 0.0502,
      "step": 12664
    },
    {
      "epoch": 0.9178533898612168,
      "grad_norm": 2.342737913131714,
      "learning_rate": 1.6450467425175738e-05,
      "loss": 0.0784,
      "step": 12665
    },
    {
      "epoch": 0.9179258615066855,
      "grad_norm": 0.8461135029792786,
      "learning_rate": 1.6435973621276904e-05,
      "loss": 0.0047,
      "step": 12666
    },
    {
      "epoch": 0.9179983331521542,
      "grad_norm": 0.5248706936836243,
      "learning_rate": 1.642147981737807e-05,
      "loss": 0.0036,
      "step": 12667
    },
    {
      "epoch": 0.9180708047976229,
      "grad_norm": 2.3627262115478516,
      "learning_rate": 1.6406986013479237e-05,
      "loss": 0.1074,
      "step": 12668
    },
    {
      "epoch": 0.9181432764430917,
      "grad_norm": 2.961549997329712,
      "learning_rate": 1.6392492209580404e-05,
      "loss": 0.0306,
      "step": 12669
    },
    {
      "epoch": 0.9182157480885603,
      "grad_norm": 3.702493190765381,
      "learning_rate": 1.637799840568157e-05,
      "loss": 0.0975,
      "step": 12670
    },
    {
      "epoch": 0.9182882197340291,
      "grad_norm": 2.9814412593841553,
      "learning_rate": 1.636350460178274e-05,
      "loss": 0.0729,
      "step": 12671
    },
    {
      "epoch": 0.9183606913794977,
      "grad_norm": 3.4157142639160156,
      "learning_rate": 1.6349010797883904e-05,
      "loss": 0.0364,
      "step": 12672
    },
    {
      "epoch": 0.9184331630249665,
      "grad_norm": 0.6575042605400085,
      "learning_rate": 1.633451699398507e-05,
      "loss": 0.0146,
      "step": 12673
    },
    {
      "epoch": 0.9185056346704352,
      "grad_norm": 0.014908277429640293,
      "learning_rate": 1.632002319008624e-05,
      "loss": 0.0002,
      "step": 12674
    },
    {
      "epoch": 0.9185781063159039,
      "grad_norm": 1.4709526300430298,
      "learning_rate": 1.6305529386187407e-05,
      "loss": 0.0387,
      "step": 12675
    },
    {
      "epoch": 0.9186505779613726,
      "grad_norm": 1.6050506830215454,
      "learning_rate": 1.629103558228857e-05,
      "loss": 0.04,
      "step": 12676
    },
    {
      "epoch": 0.9187230496068414,
      "grad_norm": 2.19238018989563,
      "learning_rate": 1.627654177838974e-05,
      "loss": 0.0185,
      "step": 12677
    },
    {
      "epoch": 0.91879552125231,
      "grad_norm": 0.2470901906490326,
      "learning_rate": 1.6262047974490907e-05,
      "loss": 0.003,
      "step": 12678
    },
    {
      "epoch": 0.9188679928977788,
      "grad_norm": 1.1405872106552124,
      "learning_rate": 1.624755417059207e-05,
      "loss": 0.0219,
      "step": 12679
    },
    {
      "epoch": 0.9189404645432474,
      "grad_norm": 2.0305047035217285,
      "learning_rate": 1.623306036669324e-05,
      "loss": 0.017,
      "step": 12680
    },
    {
      "epoch": 0.9190129361887162,
      "grad_norm": 2.4500598907470703,
      "learning_rate": 1.6218566562794407e-05,
      "loss": 0.0497,
      "step": 12681
    },
    {
      "epoch": 0.9190854078341849,
      "grad_norm": 0.5981422066688538,
      "learning_rate": 1.620407275889557e-05,
      "loss": 0.0245,
      "step": 12682
    },
    {
      "epoch": 0.9191578794796536,
      "grad_norm": 2.1265084743499756,
      "learning_rate": 1.618957895499674e-05,
      "loss": 0.1903,
      "step": 12683
    },
    {
      "epoch": 0.9192303511251223,
      "grad_norm": 1.1159967184066772,
      "learning_rate": 1.6175085151097907e-05,
      "loss": 0.0193,
      "step": 12684
    },
    {
      "epoch": 0.919302822770591,
      "grad_norm": 0.8978855013847351,
      "learning_rate": 1.6160591347199074e-05,
      "loss": 0.0076,
      "step": 12685
    },
    {
      "epoch": 0.9193752944160597,
      "grad_norm": 0.6048303246498108,
      "learning_rate": 1.614609754330024e-05,
      "loss": 0.009,
      "step": 12686
    },
    {
      "epoch": 0.9194477660615284,
      "grad_norm": 0.6281078457832336,
      "learning_rate": 1.6131603739401407e-05,
      "loss": 0.0067,
      "step": 12687
    },
    {
      "epoch": 0.9195202377069971,
      "grad_norm": 0.4923352897167206,
      "learning_rate": 1.6117109935502574e-05,
      "loss": 0.0078,
      "step": 12688
    },
    {
      "epoch": 0.9195927093524658,
      "grad_norm": 2.051604747772217,
      "learning_rate": 1.610261613160374e-05,
      "loss": 0.0324,
      "step": 12689
    },
    {
      "epoch": 0.9196651809979346,
      "grad_norm": 3.3927314281463623,
      "learning_rate": 1.6088122327704907e-05,
      "loss": 0.0528,
      "step": 12690
    },
    {
      "epoch": 0.9197376526434032,
      "grad_norm": 0.9607492685317993,
      "learning_rate": 1.6073628523806074e-05,
      "loss": 0.018,
      "step": 12691
    },
    {
      "epoch": 0.919810124288872,
      "grad_norm": 1.8612686395645142,
      "learning_rate": 1.605913471990724e-05,
      "loss": 0.0863,
      "step": 12692
    },
    {
      "epoch": 0.9198825959343407,
      "grad_norm": 0.9077534079551697,
      "learning_rate": 1.6044640916008407e-05,
      "loss": 0.0145,
      "step": 12693
    },
    {
      "epoch": 0.9199550675798094,
      "grad_norm": 1.1829036474227905,
      "learning_rate": 1.6030147112109574e-05,
      "loss": 0.0165,
      "step": 12694
    },
    {
      "epoch": 0.9200275392252781,
      "grad_norm": 0.282378613948822,
      "learning_rate": 1.601565330821074e-05,
      "loss": 0.0141,
      "step": 12695
    },
    {
      "epoch": 0.9201000108707468,
      "grad_norm": 2.957242250442505,
      "learning_rate": 1.6001159504311907e-05,
      "loss": 0.1097,
      "step": 12696
    },
    {
      "epoch": 0.9201724825162155,
      "grad_norm": 0.3006511330604553,
      "learning_rate": 1.5986665700413077e-05,
      "loss": 0.0118,
      "step": 12697
    },
    {
      "epoch": 0.9202449541616843,
      "grad_norm": 0.7550025582313538,
      "learning_rate": 1.597217189651424e-05,
      "loss": 0.0328,
      "step": 12698
    },
    {
      "epoch": 0.9203174258071529,
      "grad_norm": 0.7126439213752747,
      "learning_rate": 1.5957678092615407e-05,
      "loss": 0.0138,
      "step": 12699
    },
    {
      "epoch": 0.9203898974526217,
      "grad_norm": 0.43793198466300964,
      "learning_rate": 1.5943184288716577e-05,
      "loss": 0.0027,
      "step": 12700
    },
    {
      "epoch": 0.9204623690980904,
      "grad_norm": 2.3482778072357178,
      "learning_rate": 1.592869048481774e-05,
      "loss": 0.0747,
      "step": 12701
    },
    {
      "epoch": 0.9205348407435591,
      "grad_norm": 1.2376816272735596,
      "learning_rate": 1.5914196680918907e-05,
      "loss": 0.0454,
      "step": 12702
    },
    {
      "epoch": 0.9206073123890278,
      "grad_norm": 0.909877359867096,
      "learning_rate": 1.5899702877020077e-05,
      "loss": 0.0287,
      "step": 12703
    },
    {
      "epoch": 0.9206797840344965,
      "grad_norm": 4.159369945526123,
      "learning_rate": 1.588520907312124e-05,
      "loss": 0.0415,
      "step": 12704
    },
    {
      "epoch": 0.9207522556799652,
      "grad_norm": 0.0681234821677208,
      "learning_rate": 1.5870715269222407e-05,
      "loss": 0.0006,
      "step": 12705
    },
    {
      "epoch": 0.920824727325434,
      "grad_norm": 3.999953031539917,
      "learning_rate": 1.5856221465323577e-05,
      "loss": 0.0417,
      "step": 12706
    },
    {
      "epoch": 0.9208971989709026,
      "grad_norm": 1.3747546672821045,
      "learning_rate": 1.584172766142474e-05,
      "loss": 0.0918,
      "step": 12707
    },
    {
      "epoch": 0.9209696706163714,
      "grad_norm": 0.9816184043884277,
      "learning_rate": 1.5827233857525907e-05,
      "loss": 0.0291,
      "step": 12708
    },
    {
      "epoch": 0.92104214226184,
      "grad_norm": 0.1853940784931183,
      "learning_rate": 1.5812740053627077e-05,
      "loss": 0.0014,
      "step": 12709
    },
    {
      "epoch": 0.9211146139073088,
      "grad_norm": 0.11475808918476105,
      "learning_rate": 1.579824624972824e-05,
      "loss": 0.0028,
      "step": 12710
    },
    {
      "epoch": 0.9211870855527775,
      "grad_norm": 0.8577539324760437,
      "learning_rate": 1.5783752445829407e-05,
      "loss": 0.0123,
      "step": 12711
    },
    {
      "epoch": 0.9212595571982461,
      "grad_norm": 3.329159736633301,
      "learning_rate": 1.5769258641930577e-05,
      "loss": 0.0337,
      "step": 12712
    },
    {
      "epoch": 0.9213320288437149,
      "grad_norm": 3.183807849884033,
      "learning_rate": 1.575476483803174e-05,
      "loss": 0.0512,
      "step": 12713
    },
    {
      "epoch": 0.9214045004891837,
      "grad_norm": 0.3335278630256653,
      "learning_rate": 1.574027103413291e-05,
      "loss": 0.0053,
      "step": 12714
    },
    {
      "epoch": 0.9214769721346523,
      "grad_norm": 1.8559845685958862,
      "learning_rate": 1.5725777230234077e-05,
      "loss": 0.1442,
      "step": 12715
    },
    {
      "epoch": 0.921549443780121,
      "grad_norm": 3.6243345737457275,
      "learning_rate": 1.5711283426335243e-05,
      "loss": 0.0727,
      "step": 12716
    },
    {
      "epoch": 0.9216219154255897,
      "grad_norm": 0.26988908648490906,
      "learning_rate": 1.569678962243641e-05,
      "loss": 0.0078,
      "step": 12717
    },
    {
      "epoch": 0.9216943870710584,
      "grad_norm": 2.13470721244812,
      "learning_rate": 1.5682295818537577e-05,
      "loss": 0.0484,
      "step": 12718
    },
    {
      "epoch": 0.9217668587165272,
      "grad_norm": 0.2582727074623108,
      "learning_rate": 1.5667802014638743e-05,
      "loss": 0.0016,
      "step": 12719
    },
    {
      "epoch": 0.9218393303619958,
      "grad_norm": 0.5002905130386353,
      "learning_rate": 1.565330821073991e-05,
      "loss": 0.0156,
      "step": 12720
    },
    {
      "epoch": 0.9219118020074646,
      "grad_norm": 1.5823572874069214,
      "learning_rate": 1.5638814406841077e-05,
      "loss": 0.0237,
      "step": 12721
    },
    {
      "epoch": 0.9219842736529333,
      "grad_norm": 1.3633880615234375,
      "learning_rate": 1.5624320602942243e-05,
      "loss": 0.0263,
      "step": 12722
    },
    {
      "epoch": 0.922056745298402,
      "grad_norm": 4.163415908813477,
      "learning_rate": 1.560982679904341e-05,
      "loss": 0.085,
      "step": 12723
    },
    {
      "epoch": 0.9221292169438707,
      "grad_norm": 1.5197378396987915,
      "learning_rate": 1.5595332995144577e-05,
      "loss": 0.0313,
      "step": 12724
    },
    {
      "epoch": 0.9222016885893394,
      "grad_norm": 0.7425042390823364,
      "learning_rate": 1.5580839191245743e-05,
      "loss": 0.0056,
      "step": 12725
    },
    {
      "epoch": 0.9222741602348081,
      "grad_norm": 0.40152469277381897,
      "learning_rate": 1.556634538734691e-05,
      "loss": 0.0228,
      "step": 12726
    },
    {
      "epoch": 0.9223466318802769,
      "grad_norm": 2.2882893085479736,
      "learning_rate": 1.5551851583448077e-05,
      "loss": 0.0867,
      "step": 12727
    },
    {
      "epoch": 0.9224191035257455,
      "grad_norm": 0.6274210810661316,
      "learning_rate": 1.5537357779549243e-05,
      "loss": 0.0174,
      "step": 12728
    },
    {
      "epoch": 0.9224915751712143,
      "grad_norm": 1.245552897453308,
      "learning_rate": 1.552286397565041e-05,
      "loss": 0.0374,
      "step": 12729
    },
    {
      "epoch": 0.922564046816683,
      "grad_norm": 1.2098246812820435,
      "learning_rate": 1.5508370171751577e-05,
      "loss": 0.0249,
      "step": 12730
    },
    {
      "epoch": 0.9226365184621517,
      "grad_norm": 3.1925277709960938,
      "learning_rate": 1.5493876367852743e-05,
      "loss": 0.0639,
      "step": 12731
    },
    {
      "epoch": 0.9227089901076204,
      "grad_norm": 0.4470279812812805,
      "learning_rate": 1.547938256395391e-05,
      "loss": 0.007,
      "step": 12732
    },
    {
      "epoch": 0.9227814617530891,
      "grad_norm": 1.0740618705749512,
      "learning_rate": 1.5464888760055076e-05,
      "loss": 0.0348,
      "step": 12733
    },
    {
      "epoch": 0.9228539333985578,
      "grad_norm": 1.5689082145690918,
      "learning_rate": 1.5450394956156243e-05,
      "loss": 0.0666,
      "step": 12734
    },
    {
      "epoch": 0.9229264050440266,
      "grad_norm": 2.132909059524536,
      "learning_rate": 1.5435901152257413e-05,
      "loss": 0.1043,
      "step": 12735
    },
    {
      "epoch": 0.9229988766894952,
      "grad_norm": 0.7025383114814758,
      "learning_rate": 1.5421407348358576e-05,
      "loss": 0.0235,
      "step": 12736
    },
    {
      "epoch": 0.923071348334964,
      "grad_norm": 0.7151424288749695,
      "learning_rate": 1.5406913544459743e-05,
      "loss": 0.0239,
      "step": 12737
    },
    {
      "epoch": 0.9231438199804326,
      "grad_norm": 3.638288974761963,
      "learning_rate": 1.5392419740560913e-05,
      "loss": 0.0308,
      "step": 12738
    },
    {
      "epoch": 0.9232162916259014,
      "grad_norm": 1.5145055055618286,
      "learning_rate": 1.5377925936662076e-05,
      "loss": 0.0521,
      "step": 12739
    },
    {
      "epoch": 0.9232887632713701,
      "grad_norm": 1.8861576318740845,
      "learning_rate": 1.5363432132763243e-05,
      "loss": 0.0253,
      "step": 12740
    },
    {
      "epoch": 0.9233612349168387,
      "grad_norm": 1.3524246215820312,
      "learning_rate": 1.5348938328864413e-05,
      "loss": 0.0501,
      "step": 12741
    },
    {
      "epoch": 0.9234337065623075,
      "grad_norm": 2.3193931579589844,
      "learning_rate": 1.5334444524965576e-05,
      "loss": 0.0461,
      "step": 12742
    },
    {
      "epoch": 0.9235061782077763,
      "grad_norm": 2.502092123031616,
      "learning_rate": 1.5319950721066746e-05,
      "loss": 0.0874,
      "step": 12743
    },
    {
      "epoch": 0.9235786498532449,
      "grad_norm": 0.9442602396011353,
      "learning_rate": 1.5305456917167913e-05,
      "loss": 0.0212,
      "step": 12744
    },
    {
      "epoch": 0.9236511214987136,
      "grad_norm": 0.16693124175071716,
      "learning_rate": 1.5290963113269076e-05,
      "loss": 0.0039,
      "step": 12745
    },
    {
      "epoch": 0.9237235931441823,
      "grad_norm": 1.8580187559127808,
      "learning_rate": 1.5276469309370246e-05,
      "loss": 0.0871,
      "step": 12746
    },
    {
      "epoch": 0.923796064789651,
      "grad_norm": 1.6090081930160522,
      "learning_rate": 1.5261975505471413e-05,
      "loss": 0.0182,
      "step": 12747
    },
    {
      "epoch": 0.9238685364351198,
      "grad_norm": 1.0790178775787354,
      "learning_rate": 1.5247481701572578e-05,
      "loss": 0.0363,
      "step": 12748
    },
    {
      "epoch": 0.9239410080805884,
      "grad_norm": 2.157599925994873,
      "learning_rate": 1.5232987897673745e-05,
      "loss": 0.0441,
      "step": 12749
    },
    {
      "epoch": 0.9240134797260572,
      "grad_norm": 0.5717813968658447,
      "learning_rate": 1.5218494093774913e-05,
      "loss": 0.0231,
      "step": 12750
    },
    {
      "epoch": 0.9240859513715259,
      "grad_norm": 0.8146968483924866,
      "learning_rate": 1.5204000289876078e-05,
      "loss": 0.0201,
      "step": 12751
    },
    {
      "epoch": 0.9241584230169946,
      "grad_norm": 0.6386505961418152,
      "learning_rate": 1.5189506485977244e-05,
      "loss": 0.0162,
      "step": 12752
    },
    {
      "epoch": 0.9242308946624633,
      "grad_norm": 3.445272445678711,
      "learning_rate": 1.5175012682078413e-05,
      "loss": 0.0283,
      "step": 12753
    },
    {
      "epoch": 0.924303366307932,
      "grad_norm": 0.6674537062644958,
      "learning_rate": 1.5160518878179578e-05,
      "loss": 0.0237,
      "step": 12754
    },
    {
      "epoch": 0.9243758379534007,
      "grad_norm": 2.9719600677490234,
      "learning_rate": 1.5146025074280744e-05,
      "loss": 0.0595,
      "step": 12755
    },
    {
      "epoch": 0.9244483095988695,
      "grad_norm": 0.6006317138671875,
      "learning_rate": 1.5131531270381913e-05,
      "loss": 0.0139,
      "step": 12756
    },
    {
      "epoch": 0.9245207812443381,
      "grad_norm": 1.2565538883209229,
      "learning_rate": 1.5117037466483081e-05,
      "loss": 0.0454,
      "step": 12757
    },
    {
      "epoch": 0.9245932528898069,
      "grad_norm": 0.546654462814331,
      "learning_rate": 1.5102543662584246e-05,
      "loss": 0.0238,
      "step": 12758
    },
    {
      "epoch": 0.9246657245352756,
      "grad_norm": 1.2202109098434448,
      "learning_rate": 1.5088049858685413e-05,
      "loss": 0.0213,
      "step": 12759
    },
    {
      "epoch": 0.9247381961807443,
      "grad_norm": 1.4673727750778198,
      "learning_rate": 1.5073556054786581e-05,
      "loss": 0.0461,
      "step": 12760
    },
    {
      "epoch": 0.924810667826213,
      "grad_norm": 0.9335973858833313,
      "learning_rate": 1.5059062250887746e-05,
      "loss": 0.0395,
      "step": 12761
    },
    {
      "epoch": 0.9248831394716817,
      "grad_norm": 0.6246106624603271,
      "learning_rate": 1.5044568446988913e-05,
      "loss": 0.0181,
      "step": 12762
    },
    {
      "epoch": 0.9249556111171504,
      "grad_norm": 0.18853577971458435,
      "learning_rate": 1.5030074643090081e-05,
      "loss": 0.0044,
      "step": 12763
    },
    {
      "epoch": 0.9250280827626192,
      "grad_norm": 0.01695588231086731,
      "learning_rate": 1.5015580839191246e-05,
      "loss": 0.0002,
      "step": 12764
    },
    {
      "epoch": 0.9251005544080878,
      "grad_norm": 2.6870920658111572,
      "learning_rate": 1.5001087035292413e-05,
      "loss": 0.0535,
      "step": 12765
    },
    {
      "epoch": 0.9251730260535566,
      "grad_norm": 1.360952377319336,
      "learning_rate": 1.4986593231393581e-05,
      "loss": 0.051,
      "step": 12766
    },
    {
      "epoch": 0.9252454976990253,
      "grad_norm": 1.1638771295547485,
      "learning_rate": 1.4972099427494746e-05,
      "loss": 0.017,
      "step": 12767
    },
    {
      "epoch": 0.925317969344494,
      "grad_norm": 1.9116005897521973,
      "learning_rate": 1.4957605623595913e-05,
      "loss": 0.0111,
      "step": 12768
    },
    {
      "epoch": 0.9253904409899627,
      "grad_norm": 1.2634772062301636,
      "learning_rate": 1.4943111819697081e-05,
      "loss": 0.0177,
      "step": 12769
    },
    {
      "epoch": 0.9254629126354313,
      "grad_norm": 0.4074767827987671,
      "learning_rate": 1.4928618015798246e-05,
      "loss": 0.0044,
      "step": 12770
    },
    {
      "epoch": 0.9255353842809001,
      "grad_norm": 3.4836738109588623,
      "learning_rate": 1.4914124211899414e-05,
      "loss": 0.1324,
      "step": 12771
    },
    {
      "epoch": 0.9256078559263688,
      "grad_norm": 1.2673215866088867,
      "learning_rate": 1.4899630408000581e-05,
      "loss": 0.0189,
      "step": 12772
    },
    {
      "epoch": 0.9256803275718375,
      "grad_norm": 3.9716298580169678,
      "learning_rate": 1.4885136604101746e-05,
      "loss": 0.0905,
      "step": 12773
    },
    {
      "epoch": 0.9257527992173062,
      "grad_norm": 0.3352798521518707,
      "learning_rate": 1.4870642800202914e-05,
      "loss": 0.0066,
      "step": 12774
    },
    {
      "epoch": 0.9258252708627749,
      "grad_norm": 1.6520302295684814,
      "learning_rate": 1.485614899630408e-05,
      "loss": 0.0506,
      "step": 12775
    },
    {
      "epoch": 0.9258977425082436,
      "grad_norm": 0.5031557083129883,
      "learning_rate": 1.484165519240525e-05,
      "loss": 0.0149,
      "step": 12776
    },
    {
      "epoch": 0.9259702141537124,
      "grad_norm": 0.2324964702129364,
      "learning_rate": 1.4827161388506414e-05,
      "loss": 0.0018,
      "step": 12777
    },
    {
      "epoch": 0.926042685799181,
      "grad_norm": 1.2145469188690186,
      "learning_rate": 1.481266758460758e-05,
      "loss": 0.0398,
      "step": 12778
    },
    {
      "epoch": 0.9261151574446498,
      "grad_norm": 1.2419462203979492,
      "learning_rate": 1.4798173780708749e-05,
      "loss": 0.0265,
      "step": 12779
    },
    {
      "epoch": 0.9261876290901185,
      "grad_norm": 1.5811353921890259,
      "learning_rate": 1.4783679976809914e-05,
      "loss": 0.0294,
      "step": 12780
    },
    {
      "epoch": 0.9262601007355872,
      "grad_norm": 1.2536108493804932,
      "learning_rate": 1.476918617291108e-05,
      "loss": 0.0352,
      "step": 12781
    },
    {
      "epoch": 0.9263325723810559,
      "grad_norm": 1.9355347156524658,
      "learning_rate": 1.4754692369012249e-05,
      "loss": 0.0847,
      "step": 12782
    },
    {
      "epoch": 0.9264050440265246,
      "grad_norm": 0.982225239276886,
      "learning_rate": 1.4740198565113414e-05,
      "loss": 0.0487,
      "step": 12783
    },
    {
      "epoch": 0.9264775156719933,
      "grad_norm": 1.0561552047729492,
      "learning_rate": 1.4725704761214582e-05,
      "loss": 0.0219,
      "step": 12784
    },
    {
      "epoch": 0.9265499873174621,
      "grad_norm": 1.4722028970718384,
      "learning_rate": 1.4711210957315749e-05,
      "loss": 0.0268,
      "step": 12785
    },
    {
      "epoch": 0.9266224589629307,
      "grad_norm": 2.627789258956909,
      "learning_rate": 1.4696717153416914e-05,
      "loss": 0.0328,
      "step": 12786
    },
    {
      "epoch": 0.9266949306083995,
      "grad_norm": 3.027597665786743,
      "learning_rate": 1.4682223349518082e-05,
      "loss": 0.1466,
      "step": 12787
    },
    {
      "epoch": 0.9267674022538682,
      "grad_norm": 2.1693670749664307,
      "learning_rate": 1.4667729545619249e-05,
      "loss": 0.1012,
      "step": 12788
    },
    {
      "epoch": 0.9268398738993369,
      "grad_norm": 0.3516659438610077,
      "learning_rate": 1.4653235741720414e-05,
      "loss": 0.0046,
      "step": 12789
    },
    {
      "epoch": 0.9269123455448056,
      "grad_norm": 1.8571475744247437,
      "learning_rate": 1.4638741937821582e-05,
      "loss": 0.0543,
      "step": 12790
    },
    {
      "epoch": 0.9269848171902743,
      "grad_norm": 2.7123289108276367,
      "learning_rate": 1.4624248133922749e-05,
      "loss": 0.0643,
      "step": 12791
    },
    {
      "epoch": 0.927057288835743,
      "grad_norm": 1.3839070796966553,
      "learning_rate": 1.4609754330023914e-05,
      "loss": 0.0101,
      "step": 12792
    },
    {
      "epoch": 0.9271297604812118,
      "grad_norm": 1.3917373418807983,
      "learning_rate": 1.4595260526125082e-05,
      "loss": 0.0429,
      "step": 12793
    },
    {
      "epoch": 0.9272022321266804,
      "grad_norm": 1.5095221996307373,
      "learning_rate": 1.4580766722226249e-05,
      "loss": 0.057,
      "step": 12794
    },
    {
      "epoch": 0.9272747037721492,
      "grad_norm": 1.367358684539795,
      "learning_rate": 1.4566272918327414e-05,
      "loss": 0.0105,
      "step": 12795
    },
    {
      "epoch": 0.9273471754176179,
      "grad_norm": 2.7656195163726807,
      "learning_rate": 1.4551779114428582e-05,
      "loss": 0.0677,
      "step": 12796
    },
    {
      "epoch": 0.9274196470630865,
      "grad_norm": 1.2950083017349243,
      "learning_rate": 1.4537285310529749e-05,
      "loss": 0.0783,
      "step": 12797
    },
    {
      "epoch": 0.9274921187085553,
      "grad_norm": 3.2914679050445557,
      "learning_rate": 1.4522791506630917e-05,
      "loss": 0.076,
      "step": 12798
    },
    {
      "epoch": 0.9275645903540239,
      "grad_norm": 0.4967838525772095,
      "learning_rate": 1.4508297702732082e-05,
      "loss": 0.0156,
      "step": 12799
    },
    {
      "epoch": 0.9276370619994927,
      "grad_norm": 1.0905077457427979,
      "learning_rate": 1.449380389883325e-05,
      "loss": 0.0207,
      "step": 12800
    },
    {
      "epoch": 0.9277095336449614,
      "grad_norm": 2.152987480163574,
      "learning_rate": 1.4479310094934417e-05,
      "loss": 0.0644,
      "step": 12801
    },
    {
      "epoch": 0.9277820052904301,
      "grad_norm": 0.9582083821296692,
      "learning_rate": 1.4464816291035582e-05,
      "loss": 0.0183,
      "step": 12802
    },
    {
      "epoch": 0.9278544769358988,
      "grad_norm": 1.1717766523361206,
      "learning_rate": 1.445032248713675e-05,
      "loss": 0.0186,
      "step": 12803
    },
    {
      "epoch": 0.9279269485813676,
      "grad_norm": 0.47237348556518555,
      "learning_rate": 1.4435828683237917e-05,
      "loss": 0.0137,
      "step": 12804
    },
    {
      "epoch": 0.9279994202268362,
      "grad_norm": 2.7678887844085693,
      "learning_rate": 1.4421334879339082e-05,
      "loss": 0.0201,
      "step": 12805
    },
    {
      "epoch": 0.928071891872305,
      "grad_norm": 3.4334604740142822,
      "learning_rate": 1.440684107544025e-05,
      "loss": 0.1016,
      "step": 12806
    },
    {
      "epoch": 0.9281443635177736,
      "grad_norm": 2.557856321334839,
      "learning_rate": 1.4392347271541417e-05,
      "loss": 0.0931,
      "step": 12807
    },
    {
      "epoch": 0.9282168351632424,
      "grad_norm": 1.3394732475280762,
      "learning_rate": 1.4377853467642582e-05,
      "loss": 0.0526,
      "step": 12808
    },
    {
      "epoch": 0.9282893068087111,
      "grad_norm": 0.6831542253494263,
      "learning_rate": 1.436335966374375e-05,
      "loss": 0.0259,
      "step": 12809
    },
    {
      "epoch": 0.9283617784541798,
      "grad_norm": 3.202322006225586,
      "learning_rate": 1.4348865859844917e-05,
      "loss": 0.0648,
      "step": 12810
    },
    {
      "epoch": 0.9284342500996485,
      "grad_norm": 0.7951467633247375,
      "learning_rate": 1.4334372055946082e-05,
      "loss": 0.0189,
      "step": 12811
    },
    {
      "epoch": 0.9285067217451172,
      "grad_norm": 0.35448211431503296,
      "learning_rate": 1.431987825204725e-05,
      "loss": 0.0053,
      "step": 12812
    },
    {
      "epoch": 0.9285791933905859,
      "grad_norm": 2.294992208480835,
      "learning_rate": 1.4305384448148419e-05,
      "loss": 0.0561,
      "step": 12813
    },
    {
      "epoch": 0.9286516650360547,
      "grad_norm": 0.3689807653427124,
      "learning_rate": 1.4290890644249582e-05,
      "loss": 0.0071,
      "step": 12814
    },
    {
      "epoch": 0.9287241366815233,
      "grad_norm": 0.31523653864860535,
      "learning_rate": 1.427639684035075e-05,
      "loss": 0.0058,
      "step": 12815
    },
    {
      "epoch": 0.9287966083269921,
      "grad_norm": 4.398899555206299,
      "learning_rate": 1.4261903036451919e-05,
      "loss": 0.0453,
      "step": 12816
    },
    {
      "epoch": 0.9288690799724608,
      "grad_norm": 3.1128246784210205,
      "learning_rate": 1.4247409232553085e-05,
      "loss": 0.0398,
      "step": 12817
    },
    {
      "epoch": 0.9289415516179295,
      "grad_norm": 0.9214898347854614,
      "learning_rate": 1.423291542865425e-05,
      "loss": 0.0214,
      "step": 12818
    },
    {
      "epoch": 0.9290140232633982,
      "grad_norm": 0.9985571503639221,
      "learning_rate": 1.4218421624755418e-05,
      "loss": 0.0246,
      "step": 12819
    },
    {
      "epoch": 0.9290864949088669,
      "grad_norm": 1.8624756336212158,
      "learning_rate": 1.4203927820856585e-05,
      "loss": 0.0609,
      "step": 12820
    },
    {
      "epoch": 0.9291589665543356,
      "grad_norm": 0.13922272622585297,
      "learning_rate": 1.418943401695775e-05,
      "loss": 0.0049,
      "step": 12821
    },
    {
      "epoch": 0.9292314381998044,
      "grad_norm": 0.3917846381664276,
      "learning_rate": 1.4174940213058918e-05,
      "loss": 0.0071,
      "step": 12822
    },
    {
      "epoch": 0.929303909845273,
      "grad_norm": 0.5765989422798157,
      "learning_rate": 1.4160446409160085e-05,
      "loss": 0.0147,
      "step": 12823
    },
    {
      "epoch": 0.9293763814907418,
      "grad_norm": 3.3989615440368652,
      "learning_rate": 1.414595260526125e-05,
      "loss": 0.2581,
      "step": 12824
    },
    {
      "epoch": 0.9294488531362105,
      "grad_norm": 1.399476170539856,
      "learning_rate": 1.4131458801362418e-05,
      "loss": 0.0385,
      "step": 12825
    },
    {
      "epoch": 0.9295213247816791,
      "grad_norm": 0.8326790928840637,
      "learning_rate": 1.4116964997463587e-05,
      "loss": 0.0244,
      "step": 12826
    },
    {
      "epoch": 0.9295937964271479,
      "grad_norm": 0.026498358696699142,
      "learning_rate": 1.410247119356475e-05,
      "loss": 0.0006,
      "step": 12827
    },
    {
      "epoch": 0.9296662680726165,
      "grad_norm": 1.2206687927246094,
      "learning_rate": 1.4087977389665918e-05,
      "loss": 0.0171,
      "step": 12828
    },
    {
      "epoch": 0.9297387397180853,
      "grad_norm": 2.5668082237243652,
      "learning_rate": 1.4073483585767087e-05,
      "loss": 0.1021,
      "step": 12829
    },
    {
      "epoch": 0.929811211363554,
      "grad_norm": 1.255031704902649,
      "learning_rate": 1.4058989781868252e-05,
      "loss": 0.0208,
      "step": 12830
    },
    {
      "epoch": 0.9298836830090227,
      "grad_norm": 0.1916903555393219,
      "learning_rate": 1.4044495977969418e-05,
      "loss": 0.0011,
      "step": 12831
    },
    {
      "epoch": 0.9299561546544914,
      "grad_norm": 0.04775965213775635,
      "learning_rate": 1.4030002174070587e-05,
      "loss": 0.0005,
      "step": 12832
    },
    {
      "epoch": 0.9300286262999602,
      "grad_norm": 0.8523584604263306,
      "learning_rate": 1.4015508370171752e-05,
      "loss": 0.0394,
      "step": 12833
    },
    {
      "epoch": 0.9301010979454288,
      "grad_norm": 1.9251993894577026,
      "learning_rate": 1.4001014566272918e-05,
      "loss": 0.0398,
      "step": 12834
    },
    {
      "epoch": 0.9301735695908976,
      "grad_norm": 0.11230800300836563,
      "learning_rate": 1.3986520762374087e-05,
      "loss": 0.0012,
      "step": 12835
    },
    {
      "epoch": 0.9302460412363662,
      "grad_norm": 4.132810592651367,
      "learning_rate": 1.3972026958475252e-05,
      "loss": 0.0132,
      "step": 12836
    },
    {
      "epoch": 0.930318512881835,
      "grad_norm": 2.1010172367095947,
      "learning_rate": 1.3957533154576418e-05,
      "loss": 0.0494,
      "step": 12837
    },
    {
      "epoch": 0.9303909845273037,
      "grad_norm": 4.042247772216797,
      "learning_rate": 1.3943039350677587e-05,
      "loss": 0.092,
      "step": 12838
    },
    {
      "epoch": 0.9304634561727724,
      "grad_norm": 1.1751612424850464,
      "learning_rate": 1.3928545546778753e-05,
      "loss": 0.0265,
      "step": 12839
    },
    {
      "epoch": 0.9305359278182411,
      "grad_norm": 2.912785768508911,
      "learning_rate": 1.3914051742879918e-05,
      "loss": 0.0446,
      "step": 12840
    },
    {
      "epoch": 0.9306083994637099,
      "grad_norm": 0.48295050859451294,
      "learning_rate": 1.3899557938981086e-05,
      "loss": 0.0131,
      "step": 12841
    },
    {
      "epoch": 0.9306808711091785,
      "grad_norm": 1.4430361986160278,
      "learning_rate": 1.3885064135082255e-05,
      "loss": 0.0553,
      "step": 12842
    },
    {
      "epoch": 0.9307533427546473,
      "grad_norm": 2.1544079780578613,
      "learning_rate": 1.387057033118342e-05,
      "loss": 0.0322,
      "step": 12843
    },
    {
      "epoch": 0.9308258144001159,
      "grad_norm": 1.3597424030303955,
      "learning_rate": 1.3856076527284586e-05,
      "loss": 0.057,
      "step": 12844
    },
    {
      "epoch": 0.9308982860455847,
      "grad_norm": 0.10621292889118195,
      "learning_rate": 1.3841582723385755e-05,
      "loss": 0.0022,
      "step": 12845
    },
    {
      "epoch": 0.9309707576910534,
      "grad_norm": 0.7215245366096497,
      "learning_rate": 1.382708891948692e-05,
      "loss": 0.0129,
      "step": 12846
    },
    {
      "epoch": 0.9310432293365221,
      "grad_norm": 0.5116671323776245,
      "learning_rate": 1.3812595115588086e-05,
      "loss": 0.0132,
      "step": 12847
    },
    {
      "epoch": 0.9311157009819908,
      "grad_norm": 1.097483515739441,
      "learning_rate": 1.3798101311689255e-05,
      "loss": 0.0358,
      "step": 12848
    },
    {
      "epoch": 0.9311881726274595,
      "grad_norm": 1.777357816696167,
      "learning_rate": 1.378360750779042e-05,
      "loss": 0.0987,
      "step": 12849
    },
    {
      "epoch": 0.9312606442729282,
      "grad_norm": 0.6303967237472534,
      "learning_rate": 1.3769113703891586e-05,
      "loss": 0.0099,
      "step": 12850
    },
    {
      "epoch": 0.931333115918397,
      "grad_norm": 1.9174892902374268,
      "learning_rate": 1.3754619899992755e-05,
      "loss": 0.0312,
      "step": 12851
    },
    {
      "epoch": 0.9314055875638656,
      "grad_norm": 3.9032206535339355,
      "learning_rate": 1.374012609609392e-05,
      "loss": 0.1056,
      "step": 12852
    },
    {
      "epoch": 0.9314780592093344,
      "grad_norm": 2.376396417617798,
      "learning_rate": 1.3725632292195086e-05,
      "loss": 0.055,
      "step": 12853
    },
    {
      "epoch": 0.9315505308548031,
      "grad_norm": 0.15551935136318207,
      "learning_rate": 1.3711138488296255e-05,
      "loss": 0.0042,
      "step": 12854
    },
    {
      "epoch": 0.9316230025002717,
      "grad_norm": 1.5979527235031128,
      "learning_rate": 1.369664468439742e-05,
      "loss": 0.0373,
      "step": 12855
    },
    {
      "epoch": 0.9316954741457405,
      "grad_norm": 0.055730849504470825,
      "learning_rate": 1.3682150880498588e-05,
      "loss": 0.0007,
      "step": 12856
    },
    {
      "epoch": 0.9317679457912091,
      "grad_norm": 0.578870415687561,
      "learning_rate": 1.3667657076599755e-05,
      "loss": 0.011,
      "step": 12857
    },
    {
      "epoch": 0.9318404174366779,
      "grad_norm": 0.8842908143997192,
      "learning_rate": 1.3653163272700923e-05,
      "loss": 0.0264,
      "step": 12858
    },
    {
      "epoch": 0.9319128890821466,
      "grad_norm": 0.6508140563964844,
      "learning_rate": 1.3638669468802088e-05,
      "loss": 0.0148,
      "step": 12859
    },
    {
      "epoch": 0.9319853607276153,
      "grad_norm": 1.0078083276748657,
      "learning_rate": 1.3624175664903255e-05,
      "loss": 0.0213,
      "step": 12860
    },
    {
      "epoch": 0.932057832373084,
      "grad_norm": 0.3567950427532196,
      "learning_rate": 1.3609681861004423e-05,
      "loss": 0.0052,
      "step": 12861
    },
    {
      "epoch": 0.9321303040185528,
      "grad_norm": 1.3135616779327393,
      "learning_rate": 1.3595188057105588e-05,
      "loss": 0.02,
      "step": 12862
    },
    {
      "epoch": 0.9322027756640214,
      "grad_norm": 0.7563162446022034,
      "learning_rate": 1.3580694253206754e-05,
      "loss": 0.0163,
      "step": 12863
    },
    {
      "epoch": 0.9322752473094902,
      "grad_norm": 1.4587366580963135,
      "learning_rate": 1.3566200449307923e-05,
      "loss": 0.0433,
      "step": 12864
    },
    {
      "epoch": 0.9323477189549588,
      "grad_norm": 1.6855981349945068,
      "learning_rate": 1.3551706645409088e-05,
      "loss": 0.0416,
      "step": 12865
    },
    {
      "epoch": 0.9324201906004276,
      "grad_norm": 1.5782619714736938,
      "learning_rate": 1.3537212841510254e-05,
      "loss": 0.0353,
      "step": 12866
    },
    {
      "epoch": 0.9324926622458963,
      "grad_norm": 0.5043997168540955,
      "learning_rate": 1.3522719037611423e-05,
      "loss": 0.0126,
      "step": 12867
    },
    {
      "epoch": 0.932565133891365,
      "grad_norm": 0.24627378582954407,
      "learning_rate": 1.3508225233712588e-05,
      "loss": 0.0085,
      "step": 12868
    },
    {
      "epoch": 0.9326376055368337,
      "grad_norm": 0.7458317279815674,
      "learning_rate": 1.3493731429813754e-05,
      "loss": 0.0185,
      "step": 12869
    },
    {
      "epoch": 0.9327100771823025,
      "grad_norm": 3.3617122173309326,
      "learning_rate": 1.3479237625914923e-05,
      "loss": 0.0825,
      "step": 12870
    },
    {
      "epoch": 0.9327825488277711,
      "grad_norm": 0.25208181142807007,
      "learning_rate": 1.3464743822016088e-05,
      "loss": 0.0084,
      "step": 12871
    },
    {
      "epoch": 0.9328550204732399,
      "grad_norm": 4.392868995666504,
      "learning_rate": 1.3450250018117256e-05,
      "loss": 0.0617,
      "step": 12872
    },
    {
      "epoch": 0.9329274921187085,
      "grad_norm": 0.946379542350769,
      "learning_rate": 1.3435756214218423e-05,
      "loss": 0.0239,
      "step": 12873
    },
    {
      "epoch": 0.9329999637641773,
      "grad_norm": 2.5547142028808594,
      "learning_rate": 1.3421262410319588e-05,
      "loss": 0.0773,
      "step": 12874
    },
    {
      "epoch": 0.933072435409646,
      "grad_norm": 0.8933200836181641,
      "learning_rate": 1.3406768606420756e-05,
      "loss": 0.0101,
      "step": 12875
    },
    {
      "epoch": 0.9331449070551147,
      "grad_norm": 1.9507135152816772,
      "learning_rate": 1.3392274802521923e-05,
      "loss": 0.031,
      "step": 12876
    },
    {
      "epoch": 0.9332173787005834,
      "grad_norm": 1.3764406442642212,
      "learning_rate": 1.3377780998623091e-05,
      "loss": 0.045,
      "step": 12877
    },
    {
      "epoch": 0.933289850346052,
      "grad_norm": 3.2544121742248535,
      "learning_rate": 1.3363287194724256e-05,
      "loss": 0.0807,
      "step": 12878
    },
    {
      "epoch": 0.9333623219915208,
      "grad_norm": 3.302168607711792,
      "learning_rate": 1.3348793390825423e-05,
      "loss": 0.0759,
      "step": 12879
    },
    {
      "epoch": 0.9334347936369896,
      "grad_norm": 1.3180885314941406,
      "learning_rate": 1.3334299586926591e-05,
      "loss": 0.0414,
      "step": 12880
    },
    {
      "epoch": 0.9335072652824582,
      "grad_norm": 2.515618324279785,
      "learning_rate": 1.3319805783027756e-05,
      "loss": 0.0116,
      "step": 12881
    },
    {
      "epoch": 0.933579736927927,
      "grad_norm": 0.02978873997926712,
      "learning_rate": 1.3305311979128922e-05,
      "loss": 0.0005,
      "step": 12882
    },
    {
      "epoch": 0.9336522085733957,
      "grad_norm": 2.751383066177368,
      "learning_rate": 1.329081817523009e-05,
      "loss": 0.0879,
      "step": 12883
    },
    {
      "epoch": 0.9337246802188643,
      "grad_norm": 3.1283915042877197,
      "learning_rate": 1.3276324371331256e-05,
      "loss": 0.0533,
      "step": 12884
    },
    {
      "epoch": 0.9337971518643331,
      "grad_norm": 0.4798659086227417,
      "learning_rate": 1.3261830567432424e-05,
      "loss": 0.013,
      "step": 12885
    },
    {
      "epoch": 0.9338696235098017,
      "grad_norm": 0.576542854309082,
      "learning_rate": 1.324733676353359e-05,
      "loss": 0.0123,
      "step": 12886
    },
    {
      "epoch": 0.9339420951552705,
      "grad_norm": 2.447798490524292,
      "learning_rate": 1.3232842959634756e-05,
      "loss": 0.0689,
      "step": 12887
    },
    {
      "epoch": 0.9340145668007392,
      "grad_norm": 1.1338117122650146,
      "learning_rate": 1.3218349155735924e-05,
      "loss": 0.0157,
      "step": 12888
    },
    {
      "epoch": 0.9340870384462079,
      "grad_norm": 1.0640625953674316,
      "learning_rate": 1.320385535183709e-05,
      "loss": 0.0452,
      "step": 12889
    },
    {
      "epoch": 0.9341595100916766,
      "grad_norm": 0.452507346868515,
      "learning_rate": 1.3189361547938256e-05,
      "loss": 0.0126,
      "step": 12890
    },
    {
      "epoch": 0.9342319817371454,
      "grad_norm": 1.5098737478256226,
      "learning_rate": 1.3174867744039424e-05,
      "loss": 0.0373,
      "step": 12891
    },
    {
      "epoch": 0.934304453382614,
      "grad_norm": 2.459355354309082,
      "learning_rate": 1.316037394014059e-05,
      "loss": 0.0485,
      "step": 12892
    },
    {
      "epoch": 0.9343769250280828,
      "grad_norm": 1.5349633693695068,
      "learning_rate": 1.3145880136241756e-05,
      "loss": 0.0468,
      "step": 12893
    },
    {
      "epoch": 0.9344493966735514,
      "grad_norm": 1.296886920928955,
      "learning_rate": 1.3131386332342924e-05,
      "loss": 0.0196,
      "step": 12894
    },
    {
      "epoch": 0.9345218683190202,
      "grad_norm": 0.3806478977203369,
      "learning_rate": 1.311689252844409e-05,
      "loss": 0.0044,
      "step": 12895
    },
    {
      "epoch": 0.9345943399644889,
      "grad_norm": 1.0210466384887695,
      "learning_rate": 1.3102398724545256e-05,
      "loss": 0.0349,
      "step": 12896
    },
    {
      "epoch": 0.9346668116099576,
      "grad_norm": 0.0438593253493309,
      "learning_rate": 1.3087904920646424e-05,
      "loss": 0.001,
      "step": 12897
    },
    {
      "epoch": 0.9347392832554263,
      "grad_norm": 0.9371264576911926,
      "learning_rate": 1.3073411116747592e-05,
      "loss": 0.0334,
      "step": 12898
    },
    {
      "epoch": 0.9348117549008951,
      "grad_norm": 0.20727244019508362,
      "learning_rate": 1.3058917312848759e-05,
      "loss": 0.0055,
      "step": 12899
    },
    {
      "epoch": 0.9348842265463637,
      "grad_norm": 2.0344109535217285,
      "learning_rate": 1.3044423508949924e-05,
      "loss": 0.0242,
      "step": 12900
    },
    {
      "epoch": 0.9349566981918325,
      "grad_norm": 0.08638867735862732,
      "learning_rate": 1.3029929705051092e-05,
      "loss": 0.0018,
      "step": 12901
    },
    {
      "epoch": 0.9350291698373011,
      "grad_norm": 1.4975371360778809,
      "learning_rate": 1.3015435901152259e-05,
      "loss": 0.0291,
      "step": 12902
    },
    {
      "epoch": 0.9351016414827699,
      "grad_norm": 1.003607988357544,
      "learning_rate": 1.3000942097253424e-05,
      "loss": 0.0166,
      "step": 12903
    },
    {
      "epoch": 0.9351741131282386,
      "grad_norm": 1.737375259399414,
      "learning_rate": 1.2986448293354592e-05,
      "loss": 0.0319,
      "step": 12904
    },
    {
      "epoch": 0.9352465847737073,
      "grad_norm": 0.4569447338581085,
      "learning_rate": 1.2971954489455759e-05,
      "loss": 0.0057,
      "step": 12905
    },
    {
      "epoch": 0.935319056419176,
      "grad_norm": 0.5966549515724182,
      "learning_rate": 1.2957460685556924e-05,
      "loss": 0.0316,
      "step": 12906
    },
    {
      "epoch": 0.9353915280646448,
      "grad_norm": 0.7072498798370361,
      "learning_rate": 1.2942966881658092e-05,
      "loss": 0.0198,
      "step": 12907
    },
    {
      "epoch": 0.9354639997101134,
      "grad_norm": 0.10277802497148514,
      "learning_rate": 1.2928473077759259e-05,
      "loss": 0.0015,
      "step": 12908
    },
    {
      "epoch": 0.9355364713555822,
      "grad_norm": 1.3003959655761719,
      "learning_rate": 1.2913979273860424e-05,
      "loss": 0.0394,
      "step": 12909
    },
    {
      "epoch": 0.9356089430010508,
      "grad_norm": 0.49426233768463135,
      "learning_rate": 1.2899485469961592e-05,
      "loss": 0.0172,
      "step": 12910
    },
    {
      "epoch": 0.9356814146465195,
      "grad_norm": 1.0559496879577637,
      "learning_rate": 1.2884991666062759e-05,
      "loss": 0.0353,
      "step": 12911
    },
    {
      "epoch": 0.9357538862919883,
      "grad_norm": 0.2065814733505249,
      "learning_rate": 1.2870497862163924e-05,
      "loss": 0.0029,
      "step": 12912
    },
    {
      "epoch": 0.9358263579374569,
      "grad_norm": 4.380279064178467,
      "learning_rate": 1.2856004058265092e-05,
      "loss": 0.0326,
      "step": 12913
    },
    {
      "epoch": 0.9358988295829257,
      "grad_norm": 0.34957101941108704,
      "learning_rate": 1.284151025436626e-05,
      "loss": 0.0093,
      "step": 12914
    },
    {
      "epoch": 0.9359713012283943,
      "grad_norm": 3.9694674015045166,
      "learning_rate": 1.2827016450467425e-05,
      "loss": 0.1316,
      "step": 12915
    },
    {
      "epoch": 0.9360437728738631,
      "grad_norm": 3.7089760303497314,
      "learning_rate": 1.2812522646568592e-05,
      "loss": 0.0681,
      "step": 12916
    },
    {
      "epoch": 0.9361162445193318,
      "grad_norm": 1.1784610748291016,
      "learning_rate": 1.279802884266976e-05,
      "loss": 0.0164,
      "step": 12917
    },
    {
      "epoch": 0.9361887161648005,
      "grad_norm": 0.8885805606842041,
      "learning_rate": 1.2783535038770927e-05,
      "loss": 0.015,
      "step": 12918
    },
    {
      "epoch": 0.9362611878102692,
      "grad_norm": 0.9725868701934814,
      "learning_rate": 1.2769041234872092e-05,
      "loss": 0.0187,
      "step": 12919
    },
    {
      "epoch": 0.936333659455738,
      "grad_norm": 0.3798610270023346,
      "learning_rate": 1.275454743097326e-05,
      "loss": 0.0037,
      "step": 12920
    },
    {
      "epoch": 0.9364061311012066,
      "grad_norm": 0.2385118454694748,
      "learning_rate": 1.2740053627074427e-05,
      "loss": 0.0058,
      "step": 12921
    },
    {
      "epoch": 0.9364786027466754,
      "grad_norm": 1.7304599285125732,
      "learning_rate": 1.2725559823175592e-05,
      "loss": 0.0296,
      "step": 12922
    },
    {
      "epoch": 0.936551074392144,
      "grad_norm": 0.1805761158466339,
      "learning_rate": 1.271106601927676e-05,
      "loss": 0.0032,
      "step": 12923
    },
    {
      "epoch": 0.9366235460376128,
      "grad_norm": 0.7831036448478699,
      "learning_rate": 1.2696572215377927e-05,
      "loss": 0.0201,
      "step": 12924
    },
    {
      "epoch": 0.9366960176830815,
      "grad_norm": 0.951619565486908,
      "learning_rate": 1.2682078411479092e-05,
      "loss": 0.0514,
      "step": 12925
    },
    {
      "epoch": 0.9367684893285502,
      "grad_norm": 0.8928751349449158,
      "learning_rate": 1.266758460758026e-05,
      "loss": 0.0149,
      "step": 12926
    },
    {
      "epoch": 0.9368409609740189,
      "grad_norm": 2.2116024494171143,
      "learning_rate": 1.2653090803681428e-05,
      "loss": 0.054,
      "step": 12927
    },
    {
      "epoch": 0.9369134326194877,
      "grad_norm": 0.5153486728668213,
      "learning_rate": 1.2638596999782592e-05,
      "loss": 0.0125,
      "step": 12928
    },
    {
      "epoch": 0.9369859042649563,
      "grad_norm": 2.208739757537842,
      "learning_rate": 1.262410319588376e-05,
      "loss": 0.0539,
      "step": 12929
    },
    {
      "epoch": 0.9370583759104251,
      "grad_norm": 5.558896064758301,
      "learning_rate": 1.2609609391984928e-05,
      "loss": 0.0811,
      "step": 12930
    },
    {
      "epoch": 0.9371308475558937,
      "grad_norm": 2.2343103885650635,
      "learning_rate": 1.2595115588086093e-05,
      "loss": 0.0566,
      "step": 12931
    },
    {
      "epoch": 0.9372033192013625,
      "grad_norm": 2.347123146057129,
      "learning_rate": 1.258062178418726e-05,
      "loss": 0.1192,
      "step": 12932
    },
    {
      "epoch": 0.9372757908468312,
      "grad_norm": 0.16303324699401855,
      "learning_rate": 1.2566127980288428e-05,
      "loss": 0.0032,
      "step": 12933
    },
    {
      "epoch": 0.9373482624922999,
      "grad_norm": 2.9455573558807373,
      "learning_rate": 1.2551634176389593e-05,
      "loss": 0.047,
      "step": 12934
    },
    {
      "epoch": 0.9374207341377686,
      "grad_norm": 1.8607829809188843,
      "learning_rate": 1.253714037249076e-05,
      "loss": 0.0243,
      "step": 12935
    },
    {
      "epoch": 0.9374932057832374,
      "grad_norm": 2.476634979248047,
      "learning_rate": 1.2522646568591928e-05,
      "loss": 0.1016,
      "step": 12936
    },
    {
      "epoch": 0.937565677428706,
      "grad_norm": 4.860779285430908,
      "learning_rate": 1.2508152764693093e-05,
      "loss": 0.0773,
      "step": 12937
    },
    {
      "epoch": 0.9376381490741748,
      "grad_norm": 2.039860248565674,
      "learning_rate": 1.249365896079426e-05,
      "loss": 0.0095,
      "step": 12938
    },
    {
      "epoch": 0.9377106207196434,
      "grad_norm": 1.3871216773986816,
      "learning_rate": 1.2479165156895428e-05,
      "loss": 0.0426,
      "step": 12939
    },
    {
      "epoch": 0.9377830923651121,
      "grad_norm": 0.34668222069740295,
      "learning_rate": 1.2464671352996595e-05,
      "loss": 0.0061,
      "step": 12940
    },
    {
      "epoch": 0.9378555640105809,
      "grad_norm": 0.9226264953613281,
      "learning_rate": 1.245017754909776e-05,
      "loss": 0.0211,
      "step": 12941
    },
    {
      "epoch": 0.9379280356560495,
      "grad_norm": 0.12404254078865051,
      "learning_rate": 1.2435683745198928e-05,
      "loss": 0.0013,
      "step": 12942
    },
    {
      "epoch": 0.9380005073015183,
      "grad_norm": 0.8587836027145386,
      "learning_rate": 1.2421189941300095e-05,
      "loss": 0.0092,
      "step": 12943
    },
    {
      "epoch": 0.938072978946987,
      "grad_norm": 0.0380728617310524,
      "learning_rate": 1.2406696137401262e-05,
      "loss": 0.0006,
      "step": 12944
    },
    {
      "epoch": 0.9381454505924557,
      "grad_norm": 1.456139087677002,
      "learning_rate": 1.2392202333502428e-05,
      "loss": 0.048,
      "step": 12945
    },
    {
      "epoch": 0.9382179222379244,
      "grad_norm": 0.8921008110046387,
      "learning_rate": 1.2377708529603595e-05,
      "loss": 0.0349,
      "step": 12946
    },
    {
      "epoch": 0.9382903938833931,
      "grad_norm": 3.269451141357422,
      "learning_rate": 1.2363214725704761e-05,
      "loss": 0.0185,
      "step": 12947
    },
    {
      "epoch": 0.9383628655288618,
      "grad_norm": 1.9587717056274414,
      "learning_rate": 1.2348720921805928e-05,
      "loss": 0.0232,
      "step": 12948
    },
    {
      "epoch": 0.9384353371743306,
      "grad_norm": 3.9689877033233643,
      "learning_rate": 1.2334227117907095e-05,
      "loss": 0.0268,
      "step": 12949
    },
    {
      "epoch": 0.9385078088197992,
      "grad_norm": 0.3055420517921448,
      "learning_rate": 1.2319733314008263e-05,
      "loss": 0.0032,
      "step": 12950
    },
    {
      "epoch": 0.938580280465268,
      "grad_norm": 1.3242716789245605,
      "learning_rate": 1.2305239510109428e-05,
      "loss": 0.0184,
      "step": 12951
    },
    {
      "epoch": 0.9386527521107366,
      "grad_norm": 0.9265196919441223,
      "learning_rate": 1.2290745706210595e-05,
      "loss": 0.0231,
      "step": 12952
    },
    {
      "epoch": 0.9387252237562054,
      "grad_norm": 1.1886366605758667,
      "learning_rate": 1.2276251902311763e-05,
      "loss": 0.0211,
      "step": 12953
    },
    {
      "epoch": 0.9387976954016741,
      "grad_norm": 3.120098352432251,
      "learning_rate": 1.2261758098412928e-05,
      "loss": 0.0621,
      "step": 12954
    },
    {
      "epoch": 0.9388701670471428,
      "grad_norm": 0.20250661671161652,
      "learning_rate": 1.2247264294514096e-05,
      "loss": 0.0048,
      "step": 12955
    },
    {
      "epoch": 0.9389426386926115,
      "grad_norm": 0.2203095704317093,
      "learning_rate": 1.2232770490615263e-05,
      "loss": 0.0021,
      "step": 12956
    },
    {
      "epoch": 0.9390151103380803,
      "grad_norm": 0.22372834384441376,
      "learning_rate": 1.221827668671643e-05,
      "loss": 0.0031,
      "step": 12957
    },
    {
      "epoch": 0.9390875819835489,
      "grad_norm": 0.9820267558097839,
      "learning_rate": 1.2203782882817596e-05,
      "loss": 0.0332,
      "step": 12958
    },
    {
      "epoch": 0.9391600536290177,
      "grad_norm": 0.18809007108211517,
      "learning_rate": 1.2189289078918763e-05,
      "loss": 0.0062,
      "step": 12959
    },
    {
      "epoch": 0.9392325252744863,
      "grad_norm": 1.3528985977172852,
      "learning_rate": 1.217479527501993e-05,
      "loss": 0.0439,
      "step": 12960
    },
    {
      "epoch": 0.9393049969199551,
      "grad_norm": 0.3612203299999237,
      "learning_rate": 1.2160301471121096e-05,
      "loss": 0.0079,
      "step": 12961
    },
    {
      "epoch": 0.9393774685654238,
      "grad_norm": 0.2604074478149414,
      "learning_rate": 1.2145807667222263e-05,
      "loss": 0.0029,
      "step": 12962
    },
    {
      "epoch": 0.9394499402108925,
      "grad_norm": 1.5606791973114014,
      "learning_rate": 1.2131313863323431e-05,
      "loss": 0.0151,
      "step": 12963
    },
    {
      "epoch": 0.9395224118563612,
      "grad_norm": 2.7139267921447754,
      "learning_rate": 1.2116820059424596e-05,
      "loss": 0.0274,
      "step": 12964
    },
    {
      "epoch": 0.93959488350183,
      "grad_norm": 0.9166891574859619,
      "learning_rate": 1.2102326255525763e-05,
      "loss": 0.044,
      "step": 12965
    },
    {
      "epoch": 0.9396673551472986,
      "grad_norm": 0.34486696124076843,
      "learning_rate": 1.2087832451626931e-05,
      "loss": 0.0101,
      "step": 12966
    },
    {
      "epoch": 0.9397398267927674,
      "grad_norm": 0.5742774605751038,
      "learning_rate": 1.2073338647728096e-05,
      "loss": 0.0212,
      "step": 12967
    },
    {
      "epoch": 0.939812298438236,
      "grad_norm": 0.003776024328544736,
      "learning_rate": 1.2058844843829263e-05,
      "loss": 0.0001,
      "step": 12968
    },
    {
      "epoch": 0.9398847700837047,
      "grad_norm": 1.6793769598007202,
      "learning_rate": 1.2044351039930431e-05,
      "loss": 0.0238,
      "step": 12969
    },
    {
      "epoch": 0.9399572417291735,
      "grad_norm": 0.40511295199394226,
      "learning_rate": 1.2029857236031598e-05,
      "loss": 0.0066,
      "step": 12970
    },
    {
      "epoch": 0.9400297133746421,
      "grad_norm": 0.39819806814193726,
      "learning_rate": 1.2015363432132763e-05,
      "loss": 0.0036,
      "step": 12971
    },
    {
      "epoch": 0.9401021850201109,
      "grad_norm": 2.6754696369171143,
      "learning_rate": 1.2000869628233931e-05,
      "loss": 0.0943,
      "step": 12972
    },
    {
      "epoch": 0.9401746566655796,
      "grad_norm": 1.7430925369262695,
      "learning_rate": 1.1986375824335098e-05,
      "loss": 0.0219,
      "step": 12973
    },
    {
      "epoch": 0.9402471283110483,
      "grad_norm": 1.1843667030334473,
      "learning_rate": 1.1971882020436264e-05,
      "loss": 0.0287,
      "step": 12974
    },
    {
      "epoch": 0.940319599956517,
      "grad_norm": 0.6455367803573608,
      "learning_rate": 1.1957388216537431e-05,
      "loss": 0.0134,
      "step": 12975
    },
    {
      "epoch": 0.9403920716019857,
      "grad_norm": 2.042227029800415,
      "learning_rate": 1.1942894412638598e-05,
      "loss": 0.0458,
      "step": 12976
    },
    {
      "epoch": 0.9404645432474544,
      "grad_norm": 2.576493263244629,
      "learning_rate": 1.1928400608739764e-05,
      "loss": 0.0585,
      "step": 12977
    },
    {
      "epoch": 0.9405370148929232,
      "grad_norm": 7.117792129516602,
      "learning_rate": 1.1913906804840931e-05,
      "loss": 0.1847,
      "step": 12978
    },
    {
      "epoch": 0.9406094865383918,
      "grad_norm": 2.3461761474609375,
      "learning_rate": 1.1899413000942098e-05,
      "loss": 0.0117,
      "step": 12979
    },
    {
      "epoch": 0.9406819581838606,
      "grad_norm": 0.9225341081619263,
      "learning_rate": 1.1884919197043264e-05,
      "loss": 0.0371,
      "step": 12980
    },
    {
      "epoch": 0.9407544298293292,
      "grad_norm": 1.2146787643432617,
      "learning_rate": 1.1870425393144431e-05,
      "loss": 0.0448,
      "step": 12981
    },
    {
      "epoch": 0.940826901474798,
      "grad_norm": 7.351628303527832,
      "learning_rate": 1.1855931589245598e-05,
      "loss": 0.0395,
      "step": 12982
    },
    {
      "epoch": 0.9408993731202667,
      "grad_norm": 3.7088875770568848,
      "learning_rate": 1.1841437785346764e-05,
      "loss": 0.1456,
      "step": 12983
    },
    {
      "epoch": 0.9409718447657354,
      "grad_norm": 1.3634637594223022,
      "learning_rate": 1.1826943981447931e-05,
      "loss": 0.0547,
      "step": 12984
    },
    {
      "epoch": 0.9410443164112041,
      "grad_norm": 2.1305603981018066,
      "learning_rate": 1.18124501775491e-05,
      "loss": 0.0863,
      "step": 12985
    },
    {
      "epoch": 0.9411167880566729,
      "grad_norm": 0.6066052317619324,
      "learning_rate": 1.1797956373650266e-05,
      "loss": 0.0146,
      "step": 12986
    },
    {
      "epoch": 0.9411892597021415,
      "grad_norm": 1.6405751705169678,
      "learning_rate": 1.1783462569751431e-05,
      "loss": 0.1285,
      "step": 12987
    },
    {
      "epoch": 0.9412617313476103,
      "grad_norm": 0.925703227519989,
      "learning_rate": 1.17689687658526e-05,
      "loss": 0.0096,
      "step": 12988
    },
    {
      "epoch": 0.9413342029930789,
      "grad_norm": 5.331142902374268,
      "learning_rate": 1.1754474961953766e-05,
      "loss": 0.1414,
      "step": 12989
    },
    {
      "epoch": 0.9414066746385477,
      "grad_norm": 1.132985234260559,
      "learning_rate": 1.173998115805493e-05,
      "loss": 0.0197,
      "step": 12990
    },
    {
      "epoch": 0.9414791462840164,
      "grad_norm": 2.130516767501831,
      "learning_rate": 1.17254873541561e-05,
      "loss": 0.1119,
      "step": 12991
    },
    {
      "epoch": 0.941551617929485,
      "grad_norm": 0.696875810623169,
      "learning_rate": 1.1710993550257266e-05,
      "loss": 0.0268,
      "step": 12992
    },
    {
      "epoch": 0.9416240895749538,
      "grad_norm": 2.1389265060424805,
      "learning_rate": 1.1696499746358432e-05,
      "loss": 0.0424,
      "step": 12993
    },
    {
      "epoch": 0.9416965612204226,
      "grad_norm": 1.9600905179977417,
      "learning_rate": 1.1682005942459599e-05,
      "loss": 0.0427,
      "step": 12994
    },
    {
      "epoch": 0.9417690328658912,
      "grad_norm": 1.6961376667022705,
      "learning_rate": 1.1667512138560766e-05,
      "loss": 0.0341,
      "step": 12995
    },
    {
      "epoch": 0.94184150451136,
      "grad_norm": 0.033737797290086746,
      "learning_rate": 1.1653018334661932e-05,
      "loss": 0.0006,
      "step": 12996
    },
    {
      "epoch": 0.9419139761568286,
      "grad_norm": 0.8196145296096802,
      "learning_rate": 1.1638524530763099e-05,
      "loss": 0.0379,
      "step": 12997
    },
    {
      "epoch": 0.9419864478022973,
      "grad_norm": 0.6561852097511292,
      "learning_rate": 1.1624030726864266e-05,
      "loss": 0.0072,
      "step": 12998
    },
    {
      "epoch": 0.9420589194477661,
      "grad_norm": 0.04534691199660301,
      "learning_rate": 1.1609536922965434e-05,
      "loss": 0.0006,
      "step": 12999
    },
    {
      "epoch": 0.9421313910932347,
      "grad_norm": 2.6512184143066406,
      "learning_rate": 1.1595043119066599e-05,
      "loss": 0.0846,
      "step": 13000
    },
    {
      "epoch": 0.9422038627387035,
      "grad_norm": 0.020799340680241585,
      "learning_rate": 1.1580549315167766e-05,
      "loss": 0.0003,
      "step": 13001
    },
    {
      "epoch": 0.9422763343841722,
      "grad_norm": 1.2587701082229614,
      "learning_rate": 1.1566055511268934e-05,
      "loss": 0.0252,
      "step": 13002
    },
    {
      "epoch": 0.9423488060296409,
      "grad_norm": 0.19872011244297028,
      "learning_rate": 1.1551561707370099e-05,
      "loss": 0.0082,
      "step": 13003
    },
    {
      "epoch": 0.9424212776751096,
      "grad_norm": 0.3726951479911804,
      "learning_rate": 1.1537067903471267e-05,
      "loss": 0.0074,
      "step": 13004
    },
    {
      "epoch": 0.9424937493205783,
      "grad_norm": 4.234302520751953,
      "learning_rate": 1.1522574099572434e-05,
      "loss": 0.1126,
      "step": 13005
    },
    {
      "epoch": 0.942566220966047,
      "grad_norm": 0.5177207589149475,
      "learning_rate": 1.1508080295673599e-05,
      "loss": 0.0135,
      "step": 13006
    },
    {
      "epoch": 0.9426386926115158,
      "grad_norm": 0.6479345560073853,
      "learning_rate": 1.1493586491774767e-05,
      "loss": 0.0063,
      "step": 13007
    },
    {
      "epoch": 0.9427111642569844,
      "grad_norm": 1.5254343748092651,
      "learning_rate": 1.1479092687875934e-05,
      "loss": 0.0495,
      "step": 13008
    },
    {
      "epoch": 0.9427836359024532,
      "grad_norm": 1.4849673509597778,
      "learning_rate": 1.14645988839771e-05,
      "loss": 0.0524,
      "step": 13009
    },
    {
      "epoch": 0.9428561075479219,
      "grad_norm": 1.3195207118988037,
      "learning_rate": 1.1450105080078267e-05,
      "loss": 0.0123,
      "step": 13010
    },
    {
      "epoch": 0.9429285791933906,
      "grad_norm": 0.4302533268928528,
      "learning_rate": 1.1435611276179434e-05,
      "loss": 0.0111,
      "step": 13011
    },
    {
      "epoch": 0.9430010508388593,
      "grad_norm": 0.4082416296005249,
      "learning_rate": 1.14211174722806e-05,
      "loss": 0.0035,
      "step": 13012
    },
    {
      "epoch": 0.943073522484328,
      "grad_norm": 1.6315765380859375,
      "learning_rate": 1.1406623668381767e-05,
      "loss": 0.0223,
      "step": 13013
    },
    {
      "epoch": 0.9431459941297967,
      "grad_norm": 0.5661409497261047,
      "learning_rate": 1.1392129864482934e-05,
      "loss": 0.0091,
      "step": 13014
    },
    {
      "epoch": 0.9432184657752655,
      "grad_norm": 1.320359706878662,
      "learning_rate": 1.1377636060584102e-05,
      "loss": 0.0537,
      "step": 13015
    },
    {
      "epoch": 0.9432909374207341,
      "grad_norm": 0.8699925541877747,
      "learning_rate": 1.1363142256685267e-05,
      "loss": 0.0255,
      "step": 13016
    },
    {
      "epoch": 0.9433634090662029,
      "grad_norm": 2.012646436691284,
      "learning_rate": 1.1348648452786434e-05,
      "loss": 0.0379,
      "step": 13017
    },
    {
      "epoch": 0.9434358807116715,
      "grad_norm": 1.6694456338882446,
      "learning_rate": 1.1334154648887602e-05,
      "loss": 0.0539,
      "step": 13018
    },
    {
      "epoch": 0.9435083523571403,
      "grad_norm": 1.0270153284072876,
      "learning_rate": 1.1319660844988767e-05,
      "loss": 0.013,
      "step": 13019
    },
    {
      "epoch": 0.943580824002609,
      "grad_norm": 1.4092892408370972,
      "learning_rate": 1.1305167041089934e-05,
      "loss": 0.012,
      "step": 13020
    },
    {
      "epoch": 0.9436532956480777,
      "grad_norm": 2.5922348499298096,
      "learning_rate": 1.1290673237191102e-05,
      "loss": 0.0285,
      "step": 13021
    },
    {
      "epoch": 0.9437257672935464,
      "grad_norm": 1.2098175287246704,
      "learning_rate": 1.1276179433292269e-05,
      "loss": 0.0344,
      "step": 13022
    },
    {
      "epoch": 0.9437982389390152,
      "grad_norm": 2.39977765083313,
      "learning_rate": 1.1261685629393434e-05,
      "loss": 0.0803,
      "step": 13023
    },
    {
      "epoch": 0.9438707105844838,
      "grad_norm": 0.7950701117515564,
      "learning_rate": 1.1247191825494602e-05,
      "loss": 0.0079,
      "step": 13024
    },
    {
      "epoch": 0.9439431822299525,
      "grad_norm": 3.509446144104004,
      "learning_rate": 1.1232698021595769e-05,
      "loss": 0.0742,
      "step": 13025
    },
    {
      "epoch": 0.9440156538754212,
      "grad_norm": 1.1680335998535156,
      "learning_rate": 1.1218204217696935e-05,
      "loss": 0.0063,
      "step": 13026
    },
    {
      "epoch": 0.9440881255208899,
      "grad_norm": 0.6221490502357483,
      "learning_rate": 1.1203710413798102e-05,
      "loss": 0.0179,
      "step": 13027
    },
    {
      "epoch": 0.9441605971663587,
      "grad_norm": 0.53913414478302,
      "learning_rate": 1.1189216609899269e-05,
      "loss": 0.0055,
      "step": 13028
    },
    {
      "epoch": 0.9442330688118273,
      "grad_norm": 0.43137598037719727,
      "learning_rate": 1.1174722806000435e-05,
      "loss": 0.0155,
      "step": 13029
    },
    {
      "epoch": 0.9443055404572961,
      "grad_norm": 1.4125399589538574,
      "learning_rate": 1.1160229002101602e-05,
      "loss": 0.051,
      "step": 13030
    },
    {
      "epoch": 0.9443780121027648,
      "grad_norm": 1.25899076461792,
      "learning_rate": 1.1145735198202769e-05,
      "loss": 0.0212,
      "step": 13031
    },
    {
      "epoch": 0.9444504837482335,
      "grad_norm": 0.1833118498325348,
      "learning_rate": 1.1131241394303935e-05,
      "loss": 0.0032,
      "step": 13032
    },
    {
      "epoch": 0.9445229553937022,
      "grad_norm": 0.5739273428916931,
      "learning_rate": 1.1116747590405102e-05,
      "loss": 0.0227,
      "step": 13033
    },
    {
      "epoch": 0.9445954270391709,
      "grad_norm": 1.2013931274414062,
      "learning_rate": 1.110225378650627e-05,
      "loss": 0.0437,
      "step": 13034
    },
    {
      "epoch": 0.9446678986846396,
      "grad_norm": 1.4489153623580933,
      "learning_rate": 1.1087759982607437e-05,
      "loss": 0.1036,
      "step": 13035
    },
    {
      "epoch": 0.9447403703301084,
      "grad_norm": 0.5338056087493896,
      "learning_rate": 1.1073266178708602e-05,
      "loss": 0.0121,
      "step": 13036
    },
    {
      "epoch": 0.944812841975577,
      "grad_norm": 0.5116883516311646,
      "learning_rate": 1.105877237480977e-05,
      "loss": 0.0072,
      "step": 13037
    },
    {
      "epoch": 0.9448853136210458,
      "grad_norm": 1.1773775815963745,
      "learning_rate": 1.1044278570910937e-05,
      "loss": 0.0509,
      "step": 13038
    },
    {
      "epoch": 0.9449577852665145,
      "grad_norm": 1.774622917175293,
      "learning_rate": 1.1029784767012102e-05,
      "loss": 0.0533,
      "step": 13039
    },
    {
      "epoch": 0.9450302569119832,
      "grad_norm": 1.1482255458831787,
      "learning_rate": 1.101529096311327e-05,
      "loss": 0.0458,
      "step": 13040
    },
    {
      "epoch": 0.9451027285574519,
      "grad_norm": 1.5217945575714111,
      "learning_rate": 1.1000797159214437e-05,
      "loss": 0.0537,
      "step": 13041
    },
    {
      "epoch": 0.9451752002029206,
      "grad_norm": 0.2790469229221344,
      "learning_rate": 1.0986303355315602e-05,
      "loss": 0.0043,
      "step": 13042
    },
    {
      "epoch": 0.9452476718483893,
      "grad_norm": 2.129101037979126,
      "learning_rate": 1.097180955141677e-05,
      "loss": 0.0353,
      "step": 13043
    },
    {
      "epoch": 0.9453201434938581,
      "grad_norm": 2.1902880668640137,
      "learning_rate": 1.0957315747517937e-05,
      "loss": 0.0395,
      "step": 13044
    },
    {
      "epoch": 0.9453926151393267,
      "grad_norm": 1.5545567274093628,
      "learning_rate": 1.0942821943619103e-05,
      "loss": 0.0262,
      "step": 13045
    },
    {
      "epoch": 0.9454650867847955,
      "grad_norm": 0.5748170018196106,
      "learning_rate": 1.092832813972027e-05,
      "loss": 0.0135,
      "step": 13046
    },
    {
      "epoch": 0.9455375584302642,
      "grad_norm": 2.8023128509521484,
      "learning_rate": 1.0913834335821437e-05,
      "loss": 0.0227,
      "step": 13047
    },
    {
      "epoch": 0.9456100300757329,
      "grad_norm": 1.1079754829406738,
      "learning_rate": 1.0899340531922605e-05,
      "loss": 0.0355,
      "step": 13048
    },
    {
      "epoch": 0.9456825017212016,
      "grad_norm": 1.0003491640090942,
      "learning_rate": 1.088484672802377e-05,
      "loss": 0.0171,
      "step": 13049
    },
    {
      "epoch": 0.9457549733666702,
      "grad_norm": 0.009484449401497841,
      "learning_rate": 1.0870352924124937e-05,
      "loss": 0.0001,
      "step": 13050
    },
    {
      "epoch": 0.945827445012139,
      "grad_norm": 3.472020387649536,
      "learning_rate": 1.0855859120226105e-05,
      "loss": 0.1232,
      "step": 13051
    },
    {
      "epoch": 0.9458999166576078,
      "grad_norm": 1.8588311672210693,
      "learning_rate": 1.084136531632727e-05,
      "loss": 0.0506,
      "step": 13052
    },
    {
      "epoch": 0.9459723883030764,
      "grad_norm": 0.09963373094797134,
      "learning_rate": 1.0826871512428437e-05,
      "loss": 0.0019,
      "step": 13053
    },
    {
      "epoch": 0.9460448599485451,
      "grad_norm": 4.450676441192627,
      "learning_rate": 1.0812377708529605e-05,
      "loss": 0.0708,
      "step": 13054
    },
    {
      "epoch": 0.9461173315940138,
      "grad_norm": 1.8866630792617798,
      "learning_rate": 1.079788390463077e-05,
      "loss": 0.0142,
      "step": 13055
    },
    {
      "epoch": 0.9461898032394825,
      "grad_norm": 1.4508997201919556,
      "learning_rate": 1.0783390100731938e-05,
      "loss": 0.0326,
      "step": 13056
    },
    {
      "epoch": 0.9462622748849513,
      "grad_norm": 1.5178331136703491,
      "learning_rate": 1.0768896296833105e-05,
      "loss": 0.0315,
      "step": 13057
    },
    {
      "epoch": 0.9463347465304199,
      "grad_norm": 1.5688856840133667,
      "learning_rate": 1.0754402492934271e-05,
      "loss": 0.0471,
      "step": 13058
    },
    {
      "epoch": 0.9464072181758887,
      "grad_norm": 0.4870243966579437,
      "learning_rate": 1.0739908689035438e-05,
      "loss": 0.0223,
      "step": 13059
    },
    {
      "epoch": 0.9464796898213574,
      "grad_norm": 2.6126530170440674,
      "learning_rate": 1.0725414885136605e-05,
      "loss": 0.0637,
      "step": 13060
    },
    {
      "epoch": 0.9465521614668261,
      "grad_norm": 3.768584966659546,
      "learning_rate": 1.0710921081237771e-05,
      "loss": 0.0516,
      "step": 13061
    },
    {
      "epoch": 0.9466246331122948,
      "grad_norm": 2.0429439544677734,
      "learning_rate": 1.0696427277338938e-05,
      "loss": 0.0553,
      "step": 13062
    },
    {
      "epoch": 0.9466971047577635,
      "grad_norm": 0.6111277937889099,
      "learning_rate": 1.0681933473440105e-05,
      "loss": 0.0132,
      "step": 13063
    },
    {
      "epoch": 0.9467695764032322,
      "grad_norm": 0.5438873171806335,
      "learning_rate": 1.0667439669541271e-05,
      "loss": 0.0066,
      "step": 13064
    },
    {
      "epoch": 0.946842048048701,
      "grad_norm": 6.968235969543457,
      "learning_rate": 1.0652945865642438e-05,
      "loss": 0.1408,
      "step": 13065
    },
    {
      "epoch": 0.9469145196941696,
      "grad_norm": 0.8708813190460205,
      "learning_rate": 1.0638452061743605e-05,
      "loss": 0.0219,
      "step": 13066
    },
    {
      "epoch": 0.9469869913396384,
      "grad_norm": 0.69610995054245,
      "learning_rate": 1.0623958257844773e-05,
      "loss": 0.0086,
      "step": 13067
    },
    {
      "epoch": 0.9470594629851071,
      "grad_norm": 0.08079928904771805,
      "learning_rate": 1.0609464453945938e-05,
      "loss": 0.0008,
      "step": 13068
    },
    {
      "epoch": 0.9471319346305758,
      "grad_norm": 0.1140316054224968,
      "learning_rate": 1.0594970650047105e-05,
      "loss": 0.0009,
      "step": 13069
    },
    {
      "epoch": 0.9472044062760445,
      "grad_norm": 0.3633109927177429,
      "learning_rate": 1.0580476846148273e-05,
      "loss": 0.0069,
      "step": 13070
    },
    {
      "epoch": 0.9472768779215132,
      "grad_norm": 0.9503248929977417,
      "learning_rate": 1.056598304224944e-05,
      "loss": 0.0255,
      "step": 13071
    },
    {
      "epoch": 0.9473493495669819,
      "grad_norm": 3.6273598670959473,
      "learning_rate": 1.0551489238350605e-05,
      "loss": 0.0807,
      "step": 13072
    },
    {
      "epoch": 0.9474218212124507,
      "grad_norm": 0.42711296677589417,
      "learning_rate": 1.0536995434451773e-05,
      "loss": 0.0096,
      "step": 13073
    },
    {
      "epoch": 0.9474942928579193,
      "grad_norm": 0.9943612217903137,
      "learning_rate": 1.052250163055294e-05,
      "loss": 0.0294,
      "step": 13074
    },
    {
      "epoch": 0.9475667645033881,
      "grad_norm": 3.0106258392333984,
      "learning_rate": 1.0508007826654106e-05,
      "loss": 0.0266,
      "step": 13075
    },
    {
      "epoch": 0.9476392361488568,
      "grad_norm": 0.2904684841632843,
      "learning_rate": 1.0493514022755273e-05,
      "loss": 0.008,
      "step": 13076
    },
    {
      "epoch": 0.9477117077943255,
      "grad_norm": 0.34273529052734375,
      "learning_rate": 1.047902021885644e-05,
      "loss": 0.0061,
      "step": 13077
    },
    {
      "epoch": 0.9477841794397942,
      "grad_norm": 0.1397751271724701,
      "learning_rate": 1.0464526414957606e-05,
      "loss": 0.0013,
      "step": 13078
    },
    {
      "epoch": 0.9478566510852628,
      "grad_norm": 3.2582905292510986,
      "learning_rate": 1.0450032611058773e-05,
      "loss": 0.104,
      "step": 13079
    },
    {
      "epoch": 0.9479291227307316,
      "grad_norm": 0.5650836229324341,
      "learning_rate": 1.043553880715994e-05,
      "loss": 0.0178,
      "step": 13080
    },
    {
      "epoch": 0.9480015943762004,
      "grad_norm": 1.1532071828842163,
      "learning_rate": 1.0421045003261106e-05,
      "loss": 0.0463,
      "step": 13081
    },
    {
      "epoch": 0.948074066021669,
      "grad_norm": 1.6186556816101074,
      "learning_rate": 1.0406551199362273e-05,
      "loss": 0.0723,
      "step": 13082
    },
    {
      "epoch": 0.9481465376671377,
      "grad_norm": 2.7643346786499023,
      "learning_rate": 1.039205739546344e-05,
      "loss": 0.0435,
      "step": 13083
    },
    {
      "epoch": 0.9482190093126065,
      "grad_norm": 0.8003517389297485,
      "learning_rate": 1.0377563591564608e-05,
      "loss": 0.0222,
      "step": 13084
    },
    {
      "epoch": 0.9482914809580751,
      "grad_norm": 0.19041380286216736,
      "learning_rate": 1.0363069787665773e-05,
      "loss": 0.0127,
      "step": 13085
    },
    {
      "epoch": 0.9483639526035439,
      "grad_norm": 0.29621773958206177,
      "learning_rate": 1.0348575983766941e-05,
      "loss": 0.0036,
      "step": 13086
    },
    {
      "epoch": 0.9484364242490125,
      "grad_norm": 1.0150703191757202,
      "learning_rate": 1.0334082179868108e-05,
      "loss": 0.0475,
      "step": 13087
    },
    {
      "epoch": 0.9485088958944813,
      "grad_norm": 2.9950110912323,
      "learning_rate": 1.0319588375969273e-05,
      "loss": 0.0563,
      "step": 13088
    },
    {
      "epoch": 0.94858136753995,
      "grad_norm": 0.785862922668457,
      "learning_rate": 1.0305094572070441e-05,
      "loss": 0.0054,
      "step": 13089
    },
    {
      "epoch": 0.9486538391854187,
      "grad_norm": 1.605981469154358,
      "learning_rate": 1.0290600768171608e-05,
      "loss": 0.045,
      "step": 13090
    },
    {
      "epoch": 0.9487263108308874,
      "grad_norm": 1.5923902988433838,
      "learning_rate": 1.0276106964272773e-05,
      "loss": 0.0285,
      "step": 13091
    },
    {
      "epoch": 0.9487987824763561,
      "grad_norm": 0.0308228749781847,
      "learning_rate": 1.0261613160373941e-05,
      "loss": 0.0006,
      "step": 13092
    },
    {
      "epoch": 0.9488712541218248,
      "grad_norm": 0.5234987139701843,
      "learning_rate": 1.0247119356475108e-05,
      "loss": 0.0042,
      "step": 13093
    },
    {
      "epoch": 0.9489437257672936,
      "grad_norm": 2.7351861000061035,
      "learning_rate": 1.0232625552576274e-05,
      "loss": 0.0395,
      "step": 13094
    },
    {
      "epoch": 0.9490161974127622,
      "grad_norm": 0.011236769147217274,
      "learning_rate": 1.0218131748677441e-05,
      "loss": 0.0002,
      "step": 13095
    },
    {
      "epoch": 0.949088669058231,
      "grad_norm": 2.407529592514038,
      "learning_rate": 1.0203637944778608e-05,
      "loss": 0.07,
      "step": 13096
    },
    {
      "epoch": 0.9491611407036997,
      "grad_norm": 0.0606575571000576,
      "learning_rate": 1.0189144140879774e-05,
      "loss": 0.001,
      "step": 13097
    },
    {
      "epoch": 0.9492336123491684,
      "grad_norm": 0.04825000837445259,
      "learning_rate": 1.017465033698094e-05,
      "loss": 0.0007,
      "step": 13098
    },
    {
      "epoch": 0.9493060839946371,
      "grad_norm": 1.1478888988494873,
      "learning_rate": 1.0160156533082107e-05,
      "loss": 0.0125,
      "step": 13099
    },
    {
      "epoch": 0.9493785556401058,
      "grad_norm": 2.4410486221313477,
      "learning_rate": 1.0145662729183276e-05,
      "loss": 0.061,
      "step": 13100
    },
    {
      "epoch": 0.9494510272855745,
      "grad_norm": 0.10924571007490158,
      "learning_rate": 1.013116892528444e-05,
      "loss": 0.0014,
      "step": 13101
    },
    {
      "epoch": 0.9495234989310433,
      "grad_norm": 2.123046875,
      "learning_rate": 1.0116675121385607e-05,
      "loss": 0.0419,
      "step": 13102
    },
    {
      "epoch": 0.9495959705765119,
      "grad_norm": 0.13665735721588135,
      "learning_rate": 1.0102181317486776e-05,
      "loss": 0.0015,
      "step": 13103
    },
    {
      "epoch": 0.9496684422219807,
      "grad_norm": 0.5342973470687866,
      "learning_rate": 1.008768751358794e-05,
      "loss": 0.0067,
      "step": 13104
    },
    {
      "epoch": 0.9497409138674494,
      "grad_norm": 3.3632452487945557,
      "learning_rate": 1.0073193709689109e-05,
      "loss": 0.0409,
      "step": 13105
    },
    {
      "epoch": 0.949813385512918,
      "grad_norm": 2.095717668533325,
      "learning_rate": 1.0058699905790276e-05,
      "loss": 0.0592,
      "step": 13106
    },
    {
      "epoch": 0.9498858571583868,
      "grad_norm": 0.2867357134819031,
      "learning_rate": 1.0044206101891442e-05,
      "loss": 0.0036,
      "step": 13107
    },
    {
      "epoch": 0.9499583288038554,
      "grad_norm": 2.201007604598999,
      "learning_rate": 1.0029712297992609e-05,
      "loss": 0.0494,
      "step": 13108
    },
    {
      "epoch": 0.9500308004493242,
      "grad_norm": 1.1920082569122314,
      "learning_rate": 1.0015218494093776e-05,
      "loss": 0.0735,
      "step": 13109
    },
    {
      "epoch": 0.950103272094793,
      "grad_norm": 0.10819123685359955,
      "learning_rate": 1.0000724690194942e-05,
      "loss": 0.0027,
      "step": 13110
    },
    {
      "epoch": 0.9501757437402616,
      "grad_norm": 2.1998603343963623,
      "learning_rate": 9.986230886296109e-06,
      "loss": 0.0732,
      "step": 13111
    },
    {
      "epoch": 0.9502482153857303,
      "grad_norm": 1.2590172290802002,
      "learning_rate": 9.971737082397276e-06,
      "loss": 0.0331,
      "step": 13112
    },
    {
      "epoch": 0.9503206870311991,
      "grad_norm": 2.552450656890869,
      "learning_rate": 9.957243278498442e-06,
      "loss": 0.1392,
      "step": 13113
    },
    {
      "epoch": 0.9503931586766677,
      "grad_norm": 1.3742579221725464,
      "learning_rate": 9.942749474599609e-06,
      "loss": 0.0247,
      "step": 13114
    },
    {
      "epoch": 0.9504656303221365,
      "grad_norm": 1.691919207572937,
      "learning_rate": 9.928255670700776e-06,
      "loss": 0.0322,
      "step": 13115
    },
    {
      "epoch": 0.9505381019676051,
      "grad_norm": 1.5660581588745117,
      "learning_rate": 9.913761866801944e-06,
      "loss": 0.0609,
      "step": 13116
    },
    {
      "epoch": 0.9506105736130739,
      "grad_norm": 1.6159955263137817,
      "learning_rate": 9.899268062903109e-06,
      "loss": 0.0998,
      "step": 13117
    },
    {
      "epoch": 0.9506830452585426,
      "grad_norm": 2.1536917686462402,
      "learning_rate": 9.884774259004276e-06,
      "loss": 0.0349,
      "step": 13118
    },
    {
      "epoch": 0.9507555169040113,
      "grad_norm": 2.218318223953247,
      "learning_rate": 9.870280455105444e-06,
      "loss": 0.0429,
      "step": 13119
    },
    {
      "epoch": 0.95082798854948,
      "grad_norm": 1.873384714126587,
      "learning_rate": 9.855786651206609e-06,
      "loss": 0.0185,
      "step": 13120
    },
    {
      "epoch": 0.9509004601949487,
      "grad_norm": 0.21323268115520477,
      "learning_rate": 9.841292847307775e-06,
      "loss": 0.0068,
      "step": 13121
    },
    {
      "epoch": 0.9509729318404174,
      "grad_norm": 0.040204375982284546,
      "learning_rate": 9.826799043408944e-06,
      "loss": 0.0003,
      "step": 13122
    },
    {
      "epoch": 0.9510454034858862,
      "grad_norm": 0.28355202078819275,
      "learning_rate": 9.81230523951011e-06,
      "loss": 0.0036,
      "step": 13123
    },
    {
      "epoch": 0.9511178751313548,
      "grad_norm": 0.40808016061782837,
      "learning_rate": 9.797811435611275e-06,
      "loss": 0.0223,
      "step": 13124
    },
    {
      "epoch": 0.9511903467768236,
      "grad_norm": 1.611832857131958,
      "learning_rate": 9.783317631712444e-06,
      "loss": 0.0638,
      "step": 13125
    },
    {
      "epoch": 0.9512628184222923,
      "grad_norm": 3.9795031547546387,
      "learning_rate": 9.76882382781361e-06,
      "loss": 0.1296,
      "step": 13126
    },
    {
      "epoch": 0.951335290067761,
      "grad_norm": 0.9337447285652161,
      "learning_rate": 9.754330023914777e-06,
      "loss": 0.0189,
      "step": 13127
    },
    {
      "epoch": 0.9514077617132297,
      "grad_norm": 1.4190367460250854,
      "learning_rate": 9.739836220015944e-06,
      "loss": 0.0152,
      "step": 13128
    },
    {
      "epoch": 0.9514802333586984,
      "grad_norm": 0.15358199179172516,
      "learning_rate": 9.72534241611711e-06,
      "loss": 0.0015,
      "step": 13129
    },
    {
      "epoch": 0.9515527050041671,
      "grad_norm": 1.8498274087905884,
      "learning_rate": 9.710848612218277e-06,
      "loss": 0.0365,
      "step": 13130
    },
    {
      "epoch": 0.9516251766496359,
      "grad_norm": 3.9709129333496094,
      "learning_rate": 9.696354808319444e-06,
      "loss": 0.1024,
      "step": 13131
    },
    {
      "epoch": 0.9516976482951045,
      "grad_norm": 0.404520720243454,
      "learning_rate": 9.68186100442061e-06,
      "loss": 0.022,
      "step": 13132
    },
    {
      "epoch": 0.9517701199405733,
      "grad_norm": 0.06988655030727386,
      "learning_rate": 9.667367200521777e-06,
      "loss": 0.0012,
      "step": 13133
    },
    {
      "epoch": 0.951842591586042,
      "grad_norm": 6.0572309494018555,
      "learning_rate": 9.652873396622944e-06,
      "loss": 0.1052,
      "step": 13134
    },
    {
      "epoch": 0.9519150632315106,
      "grad_norm": 2.9287776947021484,
      "learning_rate": 9.63837959272411e-06,
      "loss": 0.0586,
      "step": 13135
    },
    {
      "epoch": 0.9519875348769794,
      "grad_norm": 0.38613513112068176,
      "learning_rate": 9.623885788825279e-06,
      "loss": 0.0073,
      "step": 13136
    },
    {
      "epoch": 0.952060006522448,
      "grad_norm": 3.104036808013916,
      "learning_rate": 9.609391984926444e-06,
      "loss": 0.0861,
      "step": 13137
    },
    {
      "epoch": 0.9521324781679168,
      "grad_norm": 2.6467795372009277,
      "learning_rate": 9.594898181027612e-06,
      "loss": 0.0732,
      "step": 13138
    },
    {
      "epoch": 0.9522049498133855,
      "grad_norm": 1.1573474407196045,
      "learning_rate": 9.580404377128779e-06,
      "loss": 0.0459,
      "step": 13139
    },
    {
      "epoch": 0.9522774214588542,
      "grad_norm": 3.3254313468933105,
      "learning_rate": 9.565910573229943e-06,
      "loss": 0.0396,
      "step": 13140
    },
    {
      "epoch": 0.9523498931043229,
      "grad_norm": 1.428666353225708,
      "learning_rate": 9.551416769331112e-06,
      "loss": 0.0311,
      "step": 13141
    },
    {
      "epoch": 0.9524223647497917,
      "grad_norm": 0.16910259425640106,
      "learning_rate": 9.536922965432278e-06,
      "loss": 0.0007,
      "step": 13142
    },
    {
      "epoch": 0.9524948363952603,
      "grad_norm": 2.4657726287841797,
      "learning_rate": 9.522429161533445e-06,
      "loss": 0.0948,
      "step": 13143
    },
    {
      "epoch": 0.9525673080407291,
      "grad_norm": 0.02052166685461998,
      "learning_rate": 9.507935357634612e-06,
      "loss": 0.0003,
      "step": 13144
    },
    {
      "epoch": 0.9526397796861977,
      "grad_norm": 0.251544713973999,
      "learning_rate": 9.493441553735778e-06,
      "loss": 0.0028,
      "step": 13145
    },
    {
      "epoch": 0.9527122513316665,
      "grad_norm": 0.7027682065963745,
      "learning_rate": 9.478947749836945e-06,
      "loss": 0.0187,
      "step": 13146
    },
    {
      "epoch": 0.9527847229771352,
      "grad_norm": 0.7232324481010437,
      "learning_rate": 9.464453945938112e-06,
      "loss": 0.0219,
      "step": 13147
    },
    {
      "epoch": 0.9528571946226039,
      "grad_norm": 0.49500563740730286,
      "learning_rate": 9.449960142039278e-06,
      "loss": 0.0092,
      "step": 13148
    },
    {
      "epoch": 0.9529296662680726,
      "grad_norm": 1.5701738595962524,
      "learning_rate": 9.435466338140447e-06,
      "loss": 0.0082,
      "step": 13149
    },
    {
      "epoch": 0.9530021379135414,
      "grad_norm": 1.3296462297439575,
      "learning_rate": 9.420972534241612e-06,
      "loss": 0.0345,
      "step": 13150
    },
    {
      "epoch": 0.95307460955901,
      "grad_norm": 0.4677453339099884,
      "learning_rate": 9.406478730342778e-06,
      "loss": 0.013,
      "step": 13151
    },
    {
      "epoch": 0.9531470812044788,
      "grad_norm": 0.0981181412935257,
      "learning_rate": 9.391984926443947e-06,
      "loss": 0.0007,
      "step": 13152
    },
    {
      "epoch": 0.9532195528499474,
      "grad_norm": 1.6854337453842163,
      "learning_rate": 9.377491122545112e-06,
      "loss": 0.0189,
      "step": 13153
    },
    {
      "epoch": 0.9532920244954162,
      "grad_norm": 2.3025143146514893,
      "learning_rate": 9.362997318646278e-06,
      "loss": 0.0375,
      "step": 13154
    },
    {
      "epoch": 0.9533644961408849,
      "grad_norm": 2.3946149349212646,
      "learning_rate": 9.348503514747447e-06,
      "loss": 0.0473,
      "step": 13155
    },
    {
      "epoch": 0.9534369677863536,
      "grad_norm": 0.3682039976119995,
      "learning_rate": 9.334009710848612e-06,
      "loss": 0.0025,
      "step": 13156
    },
    {
      "epoch": 0.9535094394318223,
      "grad_norm": 0.3859807252883911,
      "learning_rate": 9.31951590694978e-06,
      "loss": 0.0079,
      "step": 13157
    },
    {
      "epoch": 0.953581911077291,
      "grad_norm": 0.37408313155174255,
      "learning_rate": 9.305022103050947e-06,
      "loss": 0.0113,
      "step": 13158
    },
    {
      "epoch": 0.9536543827227597,
      "grad_norm": 2.2662062644958496,
      "learning_rate": 9.290528299152113e-06,
      "loss": 0.1207,
      "step": 13159
    },
    {
      "epoch": 0.9537268543682285,
      "grad_norm": 1.267815113067627,
      "learning_rate": 9.27603449525328e-06,
      "loss": 0.025,
      "step": 13160
    },
    {
      "epoch": 0.9537993260136971,
      "grad_norm": 0.2834939956665039,
      "learning_rate": 9.261540691354447e-06,
      "loss": 0.0068,
      "step": 13161
    },
    {
      "epoch": 0.9538717976591659,
      "grad_norm": 2.63498854637146,
      "learning_rate": 9.247046887455613e-06,
      "loss": 0.0663,
      "step": 13162
    },
    {
      "epoch": 0.9539442693046346,
      "grad_norm": 1.9966355562210083,
      "learning_rate": 9.23255308355678e-06,
      "loss": 0.0453,
      "step": 13163
    },
    {
      "epoch": 0.9540167409501032,
      "grad_norm": 0.31722915172576904,
      "learning_rate": 9.218059279657946e-06,
      "loss": 0.007,
      "step": 13164
    },
    {
      "epoch": 0.954089212595572,
      "grad_norm": 0.6560682654380798,
      "learning_rate": 9.203565475759113e-06,
      "loss": 0.0173,
      "step": 13165
    },
    {
      "epoch": 0.9541616842410406,
      "grad_norm": 1.4382139444351196,
      "learning_rate": 9.18907167186028e-06,
      "loss": 0.0188,
      "step": 13166
    },
    {
      "epoch": 0.9542341558865094,
      "grad_norm": 1.2661255598068237,
      "learning_rate": 9.174577867961446e-06,
      "loss": 0.0244,
      "step": 13167
    },
    {
      "epoch": 0.9543066275319781,
      "grad_norm": 1.8295892477035522,
      "learning_rate": 9.160084064062615e-06,
      "loss": 0.0426,
      "step": 13168
    },
    {
      "epoch": 0.9543790991774468,
      "grad_norm": 1.0161992311477661,
      "learning_rate": 9.14559026016378e-06,
      "loss": 0.0291,
      "step": 13169
    },
    {
      "epoch": 0.9544515708229155,
      "grad_norm": 1.4913520812988281,
      "learning_rate": 9.131096456264946e-06,
      "loss": 0.0269,
      "step": 13170
    },
    {
      "epoch": 0.9545240424683843,
      "grad_norm": 0.04893013462424278,
      "learning_rate": 9.116602652366115e-06,
      "loss": 0.0009,
      "step": 13171
    },
    {
      "epoch": 0.9545965141138529,
      "grad_norm": 1.0827488899230957,
      "learning_rate": 9.102108848467281e-06,
      "loss": 0.027,
      "step": 13172
    },
    {
      "epoch": 0.9546689857593217,
      "grad_norm": 1.3823442459106445,
      "learning_rate": 9.087615044568446e-06,
      "loss": 0.0299,
      "step": 13173
    },
    {
      "epoch": 0.9547414574047903,
      "grad_norm": 0.5694605708122253,
      "learning_rate": 9.073121240669615e-06,
      "loss": 0.0165,
      "step": 13174
    },
    {
      "epoch": 0.9548139290502591,
      "grad_norm": 0.8341436386108398,
      "learning_rate": 9.058627436770781e-06,
      "loss": 0.024,
      "step": 13175
    },
    {
      "epoch": 0.9548864006957278,
      "grad_norm": 0.6103323101997375,
      "learning_rate": 9.044133632871946e-06,
      "loss": 0.0049,
      "step": 13176
    },
    {
      "epoch": 0.9549588723411965,
      "grad_norm": 1.3022053241729736,
      "learning_rate": 9.029639828973115e-06,
      "loss": 0.0268,
      "step": 13177
    },
    {
      "epoch": 0.9550313439866652,
      "grad_norm": 1.8354965448379517,
      "learning_rate": 9.015146025074281e-06,
      "loss": 0.0473,
      "step": 13178
    },
    {
      "epoch": 0.955103815632134,
      "grad_norm": 0.8951438665390015,
      "learning_rate": 9.000652221175448e-06,
      "loss": 0.0182,
      "step": 13179
    },
    {
      "epoch": 0.9551762872776026,
      "grad_norm": 1.0619490146636963,
      "learning_rate": 8.986158417276615e-06,
      "loss": 0.0272,
      "step": 13180
    },
    {
      "epoch": 0.9552487589230714,
      "grad_norm": 1.196411371231079,
      "learning_rate": 8.971664613377781e-06,
      "loss": 0.0238,
      "step": 13181
    },
    {
      "epoch": 0.95532123056854,
      "grad_norm": 1.0044840574264526,
      "learning_rate": 8.957170809478948e-06,
      "loss": 0.0168,
      "step": 13182
    },
    {
      "epoch": 0.9553937022140088,
      "grad_norm": 1.2156829833984375,
      "learning_rate": 8.942677005580115e-06,
      "loss": 0.0161,
      "step": 13183
    },
    {
      "epoch": 0.9554661738594775,
      "grad_norm": 0.1948920041322708,
      "learning_rate": 8.928183201681281e-06,
      "loss": 0.0024,
      "step": 13184
    },
    {
      "epoch": 0.9555386455049462,
      "grad_norm": 0.21077245473861694,
      "learning_rate": 8.91368939778245e-06,
      "loss": 0.0029,
      "step": 13185
    },
    {
      "epoch": 0.9556111171504149,
      "grad_norm": 3.693044424057007,
      "learning_rate": 8.899195593883614e-06,
      "loss": 0.0549,
      "step": 13186
    },
    {
      "epoch": 0.9556835887958837,
      "grad_norm": 1.1916511058807373,
      "learning_rate": 8.884701789984783e-06,
      "loss": 0.0483,
      "step": 13187
    },
    {
      "epoch": 0.9557560604413523,
      "grad_norm": 0.5874040722846985,
      "learning_rate": 8.87020798608595e-06,
      "loss": 0.0059,
      "step": 13188
    },
    {
      "epoch": 0.9558285320868211,
      "grad_norm": 4.341233730316162,
      "learning_rate": 8.855714182187114e-06,
      "loss": 0.0718,
      "step": 13189
    },
    {
      "epoch": 0.9559010037322897,
      "grad_norm": 0.475376158952713,
      "learning_rate": 8.841220378288283e-06,
      "loss": 0.0045,
      "step": 13190
    },
    {
      "epoch": 0.9559734753777585,
      "grad_norm": 1.438144564628601,
      "learning_rate": 8.82672657438945e-06,
      "loss": 0.0273,
      "step": 13191
    },
    {
      "epoch": 0.9560459470232272,
      "grad_norm": 1.0322691202163696,
      "learning_rate": 8.812232770490614e-06,
      "loss": 0.016,
      "step": 13192
    },
    {
      "epoch": 0.9561184186686958,
      "grad_norm": 1.2858024835586548,
      "learning_rate": 8.797738966591783e-06,
      "loss": 0.0182,
      "step": 13193
    },
    {
      "epoch": 0.9561908903141646,
      "grad_norm": 11.504060745239258,
      "learning_rate": 8.78324516269295e-06,
      "loss": 0.0212,
      "step": 13194
    },
    {
      "epoch": 0.9562633619596332,
      "grad_norm": 5.141534328460693,
      "learning_rate": 8.768751358794116e-06,
      "loss": 0.0606,
      "step": 13195
    },
    {
      "epoch": 0.956335833605102,
      "grad_norm": 0.6207303404808044,
      "learning_rate": 8.754257554895283e-06,
      "loss": 0.0041,
      "step": 13196
    },
    {
      "epoch": 0.9564083052505707,
      "grad_norm": 1.8554556369781494,
      "learning_rate": 8.73976375099645e-06,
      "loss": 0.0408,
      "step": 13197
    },
    {
      "epoch": 0.9564807768960394,
      "grad_norm": 1.2669347524642944,
      "learning_rate": 8.725269947097618e-06,
      "loss": 0.0165,
      "step": 13198
    },
    {
      "epoch": 0.9565532485415081,
      "grad_norm": 0.24929383397102356,
      "learning_rate": 8.710776143198783e-06,
      "loss": 0.005,
      "step": 13199
    },
    {
      "epoch": 0.9566257201869769,
      "grad_norm": 0.521994411945343,
      "learning_rate": 8.69628233929995e-06,
      "loss": 0.0076,
      "step": 13200
    },
    {
      "epoch": 0.9566981918324455,
      "grad_norm": 3.386255979537964,
      "learning_rate": 8.681788535401118e-06,
      "loss": 0.0983,
      "step": 13201
    },
    {
      "epoch": 0.9567706634779143,
      "grad_norm": 0.429403692483902,
      "learning_rate": 8.667294731502283e-06,
      "loss": 0.0111,
      "step": 13202
    },
    {
      "epoch": 0.9568431351233829,
      "grad_norm": 1.1148167848587036,
      "learning_rate": 8.65280092760345e-06,
      "loss": 0.0622,
      "step": 13203
    },
    {
      "epoch": 0.9569156067688517,
      "grad_norm": 1.3358503580093384,
      "learning_rate": 8.638307123704618e-06,
      "loss": 0.0774,
      "step": 13204
    },
    {
      "epoch": 0.9569880784143204,
      "grad_norm": 0.7837008237838745,
      "learning_rate": 8.623813319805782e-06,
      "loss": 0.0424,
      "step": 13205
    },
    {
      "epoch": 0.9570605500597891,
      "grad_norm": 0.030074233189225197,
      "learning_rate": 8.609319515906949e-06,
      "loss": 0.0003,
      "step": 13206
    },
    {
      "epoch": 0.9571330217052578,
      "grad_norm": 0.13971006870269775,
      "learning_rate": 8.594825712008117e-06,
      "loss": 0.0026,
      "step": 13207
    },
    {
      "epoch": 0.9572054933507266,
      "grad_norm": 3.4113924503326416,
      "learning_rate": 8.580331908109284e-06,
      "loss": 0.0748,
      "step": 13208
    },
    {
      "epoch": 0.9572779649961952,
      "grad_norm": 0.08424337953329086,
      "learning_rate": 8.56583810421045e-06,
      "loss": 0.0023,
      "step": 13209
    },
    {
      "epoch": 0.957350436641664,
      "grad_norm": 5.513779640197754,
      "learning_rate": 8.551344300311617e-06,
      "loss": 0.0939,
      "step": 13210
    },
    {
      "epoch": 0.9574229082871326,
      "grad_norm": 2.3668053150177,
      "learning_rate": 8.536850496412784e-06,
      "loss": 0.0724,
      "step": 13211
    },
    {
      "epoch": 0.9574953799326014,
      "grad_norm": 3.9602856636047363,
      "learning_rate": 8.52235669251395e-06,
      "loss": 0.1321,
      "step": 13212
    },
    {
      "epoch": 0.9575678515780701,
      "grad_norm": 2.3617937564849854,
      "learning_rate": 8.507862888615117e-06,
      "loss": 0.0746,
      "step": 13213
    },
    {
      "epoch": 0.9576403232235388,
      "grad_norm": 1.0540810823440552,
      "learning_rate": 8.493369084716284e-06,
      "loss": 0.0254,
      "step": 13214
    },
    {
      "epoch": 0.9577127948690075,
      "grad_norm": 0.6223084330558777,
      "learning_rate": 8.47887528081745e-06,
      "loss": 0.0333,
      "step": 13215
    },
    {
      "epoch": 0.9577852665144763,
      "grad_norm": 0.3278059959411621,
      "learning_rate": 8.464381476918617e-06,
      "loss": 0.0044,
      "step": 13216
    },
    {
      "epoch": 0.9578577381599449,
      "grad_norm": 0.25324469804763794,
      "learning_rate": 8.449887673019786e-06,
      "loss": 0.0172,
      "step": 13217
    },
    {
      "epoch": 0.9579302098054137,
      "grad_norm": 0.908900260925293,
      "learning_rate": 8.43539386912095e-06,
      "loss": 0.019,
      "step": 13218
    },
    {
      "epoch": 0.9580026814508823,
      "grad_norm": 0.9276711940765381,
      "learning_rate": 8.420900065222117e-06,
      "loss": 0.0159,
      "step": 13219
    },
    {
      "epoch": 0.958075153096351,
      "grad_norm": 0.19568262994289398,
      "learning_rate": 8.406406261323286e-06,
      "loss": 0.0016,
      "step": 13220
    },
    {
      "epoch": 0.9581476247418198,
      "grad_norm": 0.8754799962043762,
      "learning_rate": 8.391912457424452e-06,
      "loss": 0.0118,
      "step": 13221
    },
    {
      "epoch": 0.9582200963872884,
      "grad_norm": 2.2301812171936035,
      "learning_rate": 8.377418653525617e-06,
      "loss": 0.0267,
      "step": 13222
    },
    {
      "epoch": 0.9582925680327572,
      "grad_norm": 1.7672289609909058,
      "learning_rate": 8.362924849626786e-06,
      "loss": 0.01,
      "step": 13223
    },
    {
      "epoch": 0.958365039678226,
      "grad_norm": 0.8330383896827698,
      "learning_rate": 8.348431045727952e-06,
      "loss": 0.0351,
      "step": 13224
    },
    {
      "epoch": 0.9584375113236946,
      "grad_norm": 1.6280336380004883,
      "learning_rate": 8.333937241829117e-06,
      "loss": 0.0689,
      "step": 13225
    },
    {
      "epoch": 0.9585099829691633,
      "grad_norm": 0.22872623801231384,
      "learning_rate": 8.319443437930286e-06,
      "loss": 0.0071,
      "step": 13226
    },
    {
      "epoch": 0.958582454614632,
      "grad_norm": 1.608901858329773,
      "learning_rate": 8.304949634031452e-06,
      "loss": 0.0325,
      "step": 13227
    },
    {
      "epoch": 0.9586549262601007,
      "grad_norm": 2.4521450996398926,
      "learning_rate": 8.290455830132619e-06,
      "loss": 0.0849,
      "step": 13228
    },
    {
      "epoch": 0.9587273979055695,
      "grad_norm": 0.5555078387260437,
      "learning_rate": 8.275962026233785e-06,
      "loss": 0.01,
      "step": 13229
    },
    {
      "epoch": 0.9587998695510381,
      "grad_norm": 0.5634582042694092,
      "learning_rate": 8.261468222334952e-06,
      "loss": 0.0123,
      "step": 13230
    },
    {
      "epoch": 0.9588723411965069,
      "grad_norm": 1.5264376401901245,
      "learning_rate": 8.246974418436119e-06,
      "loss": 0.0828,
      "step": 13231
    },
    {
      "epoch": 0.9589448128419755,
      "grad_norm": 1.35745108127594,
      "learning_rate": 8.232480614537285e-06,
      "loss": 0.0121,
      "step": 13232
    },
    {
      "epoch": 0.9590172844874443,
      "grad_norm": 1.6860713958740234,
      "learning_rate": 8.217986810638452e-06,
      "loss": 0.0365,
      "step": 13233
    },
    {
      "epoch": 0.959089756132913,
      "grad_norm": 1.0401880741119385,
      "learning_rate": 8.203493006739619e-06,
      "loss": 0.0304,
      "step": 13234
    },
    {
      "epoch": 0.9591622277783817,
      "grad_norm": 2.997627019882202,
      "learning_rate": 8.188999202840785e-06,
      "loss": 0.079,
      "step": 13235
    },
    {
      "epoch": 0.9592346994238504,
      "grad_norm": 0.6745529174804688,
      "learning_rate": 8.174505398941952e-06,
      "loss": 0.0204,
      "step": 13236
    },
    {
      "epoch": 0.9593071710693192,
      "grad_norm": 1.2259151935577393,
      "learning_rate": 8.16001159504312e-06,
      "loss": 0.0085,
      "step": 13237
    },
    {
      "epoch": 0.9593796427147878,
      "grad_norm": 0.4481206238269806,
      "learning_rate": 8.145517791144285e-06,
      "loss": 0.0088,
      "step": 13238
    },
    {
      "epoch": 0.9594521143602566,
      "grad_norm": 0.14481885731220245,
      "learning_rate": 8.131023987245454e-06,
      "loss": 0.003,
      "step": 13239
    },
    {
      "epoch": 0.9595245860057252,
      "grad_norm": 1.0080188512802124,
      "learning_rate": 8.11653018334662e-06,
      "loss": 0.0282,
      "step": 13240
    },
    {
      "epoch": 0.959597057651194,
      "grad_norm": 1.924636960029602,
      "learning_rate": 8.102036379447785e-06,
      "loss": 0.0519,
      "step": 13241
    },
    {
      "epoch": 0.9596695292966627,
      "grad_norm": 1.1025068759918213,
      "learning_rate": 8.087542575548954e-06,
      "loss": 0.0111,
      "step": 13242
    },
    {
      "epoch": 0.9597420009421314,
      "grad_norm": 0.31397247314453125,
      "learning_rate": 8.07304877165012e-06,
      "loss": 0.0072,
      "step": 13243
    },
    {
      "epoch": 0.9598144725876001,
      "grad_norm": 1.0288143157958984,
      "learning_rate": 8.058554967751287e-06,
      "loss": 0.0126,
      "step": 13244
    },
    {
      "epoch": 0.9598869442330689,
      "grad_norm": 1.1553246974945068,
      "learning_rate": 8.044061163852454e-06,
      "loss": 0.0084,
      "step": 13245
    },
    {
      "epoch": 0.9599594158785375,
      "grad_norm": 0.6988893747329712,
      "learning_rate": 8.02956735995362e-06,
      "loss": 0.0288,
      "step": 13246
    },
    {
      "epoch": 0.9600318875240063,
      "grad_norm": 0.3430953621864319,
      "learning_rate": 8.015073556054787e-06,
      "loss": 0.0096,
      "step": 13247
    },
    {
      "epoch": 0.9601043591694749,
      "grad_norm": 0.32497942447662354,
      "learning_rate": 8.000579752155954e-06,
      "loss": 0.0071,
      "step": 13248
    },
    {
      "epoch": 0.9601768308149436,
      "grad_norm": 0.36940181255340576,
      "learning_rate": 7.98608594825712e-06,
      "loss": 0.009,
      "step": 13249
    },
    {
      "epoch": 0.9602493024604124,
      "grad_norm": 1.8485372066497803,
      "learning_rate": 7.971592144358289e-06,
      "loss": 0.0537,
      "step": 13250
    },
    {
      "epoch": 0.960321774105881,
      "grad_norm": 1.1752804517745972,
      "learning_rate": 7.957098340459453e-06,
      "loss": 0.027,
      "step": 13251
    },
    {
      "epoch": 0.9603942457513498,
      "grad_norm": 1.7975661754608154,
      "learning_rate": 7.94260453656062e-06,
      "loss": 0.0202,
      "step": 13252
    },
    {
      "epoch": 0.9604667173968185,
      "grad_norm": 1.5860645771026611,
      "learning_rate": 7.928110732661788e-06,
      "loss": 0.0613,
      "step": 13253
    },
    {
      "epoch": 0.9605391890422872,
      "grad_norm": 0.4036494195461273,
      "learning_rate": 7.913616928762953e-06,
      "loss": 0.0086,
      "step": 13254
    },
    {
      "epoch": 0.9606116606877559,
      "grad_norm": 0.4121558964252472,
      "learning_rate": 7.89912312486412e-06,
      "loss": 0.0118,
      "step": 13255
    },
    {
      "epoch": 0.9606841323332246,
      "grad_norm": 0.057644523680210114,
      "learning_rate": 7.884629320965288e-06,
      "loss": 0.0012,
      "step": 13256
    },
    {
      "epoch": 0.9607566039786933,
      "grad_norm": 1.771816611289978,
      "learning_rate": 7.870135517066455e-06,
      "loss": 0.018,
      "step": 13257
    },
    {
      "epoch": 0.9608290756241621,
      "grad_norm": 1.8819714784622192,
      "learning_rate": 7.855641713167622e-06,
      "loss": 0.0251,
      "step": 13258
    },
    {
      "epoch": 0.9609015472696307,
      "grad_norm": 3.4260220527648926,
      "learning_rate": 7.841147909268788e-06,
      "loss": 0.053,
      "step": 13259
    },
    {
      "epoch": 0.9609740189150995,
      "grad_norm": 1.5326318740844727,
      "learning_rate": 7.826654105369955e-06,
      "loss": 0.0366,
      "step": 13260
    },
    {
      "epoch": 0.9610464905605681,
      "grad_norm": 0.19252729415893555,
      "learning_rate": 7.812160301471122e-06,
      "loss": 0.004,
      "step": 13261
    },
    {
      "epoch": 0.9611189622060369,
      "grad_norm": 1.8562629222869873,
      "learning_rate": 7.797666497572288e-06,
      "loss": 0.0264,
      "step": 13262
    },
    {
      "epoch": 0.9611914338515056,
      "grad_norm": 1.3286980390548706,
      "learning_rate": 7.783172693673455e-06,
      "loss": 0.0655,
      "step": 13263
    },
    {
      "epoch": 0.9612639054969743,
      "grad_norm": 0.13700872659683228,
      "learning_rate": 7.768678889774622e-06,
      "loss": 0.0035,
      "step": 13264
    },
    {
      "epoch": 0.961336377142443,
      "grad_norm": 0.16474227607250214,
      "learning_rate": 7.754185085875788e-06,
      "loss": 0.0032,
      "step": 13265
    },
    {
      "epoch": 0.9614088487879118,
      "grad_norm": 2.494067668914795,
      "learning_rate": 7.739691281976955e-06,
      "loss": 0.0757,
      "step": 13266
    },
    {
      "epoch": 0.9614813204333804,
      "grad_norm": 1.2789160013198853,
      "learning_rate": 7.725197478078122e-06,
      "loss": 0.0407,
      "step": 13267
    },
    {
      "epoch": 0.9615537920788492,
      "grad_norm": 0.35042622685432434,
      "learning_rate": 7.710703674179288e-06,
      "loss": 0.0044,
      "step": 13268
    },
    {
      "epoch": 0.9616262637243178,
      "grad_norm": 0.8187811970710754,
      "learning_rate": 7.696209870280457e-06,
      "loss": 0.0227,
      "step": 13269
    },
    {
      "epoch": 0.9616987353697866,
      "grad_norm": 1.0823453664779663,
      "learning_rate": 7.681716066381621e-06,
      "loss": 0.0256,
      "step": 13270
    },
    {
      "epoch": 0.9617712070152553,
      "grad_norm": 1.045114517211914,
      "learning_rate": 7.667222262482788e-06,
      "loss": 0.0197,
      "step": 13271
    },
    {
      "epoch": 0.961843678660724,
      "grad_norm": 0.6667250394821167,
      "learning_rate": 7.652728458583956e-06,
      "loss": 0.0149,
      "step": 13272
    },
    {
      "epoch": 0.9619161503061927,
      "grad_norm": 0.9525195360183716,
      "learning_rate": 7.638234654685123e-06,
      "loss": 0.0407,
      "step": 13273
    },
    {
      "epoch": 0.9619886219516615,
      "grad_norm": 1.414994716644287,
      "learning_rate": 7.623740850786289e-06,
      "loss": 0.0214,
      "step": 13274
    },
    {
      "epoch": 0.9620610935971301,
      "grad_norm": 2.8163411617279053,
      "learning_rate": 7.6092470468874564e-06,
      "loss": 0.1145,
      "step": 13275
    },
    {
      "epoch": 0.9621335652425989,
      "grad_norm": 4.079729080200195,
      "learning_rate": 7.594753242988622e-06,
      "loss": 0.0561,
      "step": 13276
    },
    {
      "epoch": 0.9622060368880675,
      "grad_norm": 0.23381024599075317,
      "learning_rate": 7.580259439089789e-06,
      "loss": 0.003,
      "step": 13277
    },
    {
      "epoch": 0.9622785085335362,
      "grad_norm": 0.9145431518554688,
      "learning_rate": 7.565765635190956e-06,
      "loss": 0.0208,
      "step": 13278
    },
    {
      "epoch": 0.962350980179005,
      "grad_norm": 0.6092469692230225,
      "learning_rate": 7.551271831292123e-06,
      "loss": 0.0125,
      "step": 13279
    },
    {
      "epoch": 0.9624234518244736,
      "grad_norm": 0.3248407542705536,
      "learning_rate": 7.5367780273932905e-06,
      "loss": 0.0062,
      "step": 13280
    },
    {
      "epoch": 0.9624959234699424,
      "grad_norm": 2.4892160892486572,
      "learning_rate": 7.522284223494456e-06,
      "loss": 0.0267,
      "step": 13281
    },
    {
      "epoch": 0.9625683951154111,
      "grad_norm": 1.1794085502624512,
      "learning_rate": 7.507790419595623e-06,
      "loss": 0.0376,
      "step": 13282
    },
    {
      "epoch": 0.9626408667608798,
      "grad_norm": 0.7287716865539551,
      "learning_rate": 7.4932966156967905e-06,
      "loss": 0.0064,
      "step": 13283
    },
    {
      "epoch": 0.9627133384063485,
      "grad_norm": 3.347385883331299,
      "learning_rate": 7.478802811797956e-06,
      "loss": 0.0537,
      "step": 13284
    },
    {
      "epoch": 0.9627858100518172,
      "grad_norm": 4.541815280914307,
      "learning_rate": 7.464309007899123e-06,
      "loss": 0.0628,
      "step": 13285
    },
    {
      "epoch": 0.9628582816972859,
      "grad_norm": 2.7375681400299072,
      "learning_rate": 7.4498152040002904e-06,
      "loss": 0.0863,
      "step": 13286
    },
    {
      "epoch": 0.9629307533427547,
      "grad_norm": 1.2396355867385864,
      "learning_rate": 7.435321400101457e-06,
      "loss": 0.0197,
      "step": 13287
    },
    {
      "epoch": 0.9630032249882233,
      "grad_norm": 2.2856228351593018,
      "learning_rate": 7.420827596202625e-06,
      "loss": 0.1108,
      "step": 13288
    },
    {
      "epoch": 0.9630756966336921,
      "grad_norm": 1.6327170133590698,
      "learning_rate": 7.40633379230379e-06,
      "loss": 0.0611,
      "step": 13289
    },
    {
      "epoch": 0.9631481682791608,
      "grad_norm": 3.0740227699279785,
      "learning_rate": 7.391839988404957e-06,
      "loss": 0.0585,
      "step": 13290
    },
    {
      "epoch": 0.9632206399246295,
      "grad_norm": 1.6709829568862915,
      "learning_rate": 7.3773461845061245e-06,
      "loss": 0.0684,
      "step": 13291
    },
    {
      "epoch": 0.9632931115700982,
      "grad_norm": 1.0615288019180298,
      "learning_rate": 7.362852380607291e-06,
      "loss": 0.0497,
      "step": 13292
    },
    {
      "epoch": 0.9633655832155669,
      "grad_norm": 0.8279449939727783,
      "learning_rate": 7.348358576708457e-06,
      "loss": 0.0152,
      "step": 13293
    },
    {
      "epoch": 0.9634380548610356,
      "grad_norm": 1.9716185331344604,
      "learning_rate": 7.3338647728096245e-06,
      "loss": 0.0489,
      "step": 13294
    },
    {
      "epoch": 0.9635105265065044,
      "grad_norm": 2.137965202331543,
      "learning_rate": 7.319370968910791e-06,
      "loss": 0.0436,
      "step": 13295
    },
    {
      "epoch": 0.963582998151973,
      "grad_norm": 1.942082166671753,
      "learning_rate": 7.304877165011957e-06,
      "loss": 0.0386,
      "step": 13296
    },
    {
      "epoch": 0.9636554697974418,
      "grad_norm": 1.1982382535934448,
      "learning_rate": 7.2903833611131244e-06,
      "loss": 0.0168,
      "step": 13297
    },
    {
      "epoch": 0.9637279414429104,
      "grad_norm": 0.2947942018508911,
      "learning_rate": 7.275889557214291e-06,
      "loss": 0.0044,
      "step": 13298
    },
    {
      "epoch": 0.9638004130883792,
      "grad_norm": 0.550650417804718,
      "learning_rate": 7.2613957533154586e-06,
      "loss": 0.0087,
      "step": 13299
    },
    {
      "epoch": 0.9638728847338479,
      "grad_norm": 0.8400381207466125,
      "learning_rate": 7.246901949416625e-06,
      "loss": 0.014,
      "step": 13300
    },
    {
      "epoch": 0.9639453563793166,
      "grad_norm": 1.9247102737426758,
      "learning_rate": 7.232408145517791e-06,
      "loss": 0.045,
      "step": 13301
    },
    {
      "epoch": 0.9640178280247853,
      "grad_norm": 2.4255638122558594,
      "learning_rate": 7.2179143416189585e-06,
      "loss": 0.1031,
      "step": 13302
    },
    {
      "epoch": 0.9640902996702541,
      "grad_norm": 1.9520580768585205,
      "learning_rate": 7.203420537720125e-06,
      "loss": 0.0564,
      "step": 13303
    },
    {
      "epoch": 0.9641627713157227,
      "grad_norm": 0.5056267976760864,
      "learning_rate": 7.188926733821291e-06,
      "loss": 0.0126,
      "step": 13304
    },
    {
      "epoch": 0.9642352429611915,
      "grad_norm": 3.213960647583008,
      "learning_rate": 7.1744329299224585e-06,
      "loss": 0.0607,
      "step": 13305
    },
    {
      "epoch": 0.9643077146066601,
      "grad_norm": 0.8410089015960693,
      "learning_rate": 7.159939126023625e-06,
      "loss": 0.0225,
      "step": 13306
    },
    {
      "epoch": 0.9643801862521288,
      "grad_norm": 1.190496802330017,
      "learning_rate": 7.145445322124791e-06,
      "loss": 0.0448,
      "step": 13307
    },
    {
      "epoch": 0.9644526578975976,
      "grad_norm": 2.327521562576294,
      "learning_rate": 7.130951518225959e-06,
      "loss": 0.0712,
      "step": 13308
    },
    {
      "epoch": 0.9645251295430662,
      "grad_norm": 1.1354374885559082,
      "learning_rate": 7.116457714327125e-06,
      "loss": 0.0414,
      "step": 13309
    },
    {
      "epoch": 0.964597601188535,
      "grad_norm": 3.0642287731170654,
      "learning_rate": 7.1019639104282926e-06,
      "loss": 0.0882,
      "step": 13310
    },
    {
      "epoch": 0.9646700728340037,
      "grad_norm": 0.8376458287239075,
      "learning_rate": 7.087470106529459e-06,
      "loss": 0.0101,
      "step": 13311
    },
    {
      "epoch": 0.9647425444794724,
      "grad_norm": 2.777010202407837,
      "learning_rate": 7.072976302630625e-06,
      "loss": 0.116,
      "step": 13312
    },
    {
      "epoch": 0.9648150161249411,
      "grad_norm": 0.44097745418548584,
      "learning_rate": 7.058482498731793e-06,
      "loss": 0.0062,
      "step": 13313
    },
    {
      "epoch": 0.9648874877704098,
      "grad_norm": 0.9596553444862366,
      "learning_rate": 7.043988694832959e-06,
      "loss": 0.0354,
      "step": 13314
    },
    {
      "epoch": 0.9649599594158785,
      "grad_norm": 2.130220890045166,
      "learning_rate": 7.029494890934126e-06,
      "loss": 0.064,
      "step": 13315
    },
    {
      "epoch": 0.9650324310613473,
      "grad_norm": 0.9498418569564819,
      "learning_rate": 7.015001087035293e-06,
      "loss": 0.0194,
      "step": 13316
    },
    {
      "epoch": 0.9651049027068159,
      "grad_norm": 1.7437068223953247,
      "learning_rate": 7.000507283136459e-06,
      "loss": 0.1029,
      "step": 13317
    },
    {
      "epoch": 0.9651773743522847,
      "grad_norm": 0.898999810218811,
      "learning_rate": 6.986013479237626e-06,
      "loss": 0.0377,
      "step": 13318
    },
    {
      "epoch": 0.9652498459977534,
      "grad_norm": 1.1934316158294678,
      "learning_rate": 6.971519675338793e-06,
      "loss": 0.0484,
      "step": 13319
    },
    {
      "epoch": 0.9653223176432221,
      "grad_norm": 0.40082794427871704,
      "learning_rate": 6.957025871439959e-06,
      "loss": 0.0069,
      "step": 13320
    },
    {
      "epoch": 0.9653947892886908,
      "grad_norm": 1.6621006727218628,
      "learning_rate": 6.942532067541127e-06,
      "loss": 0.04,
      "step": 13321
    },
    {
      "epoch": 0.9654672609341595,
      "grad_norm": 2.4086496829986572,
      "learning_rate": 6.928038263642293e-06,
      "loss": 0.0579,
      "step": 13322
    },
    {
      "epoch": 0.9655397325796282,
      "grad_norm": 0.3316197097301483,
      "learning_rate": 6.91354445974346e-06,
      "loss": 0.0037,
      "step": 13323
    },
    {
      "epoch": 0.965612204225097,
      "grad_norm": 0.3555968403816223,
      "learning_rate": 6.899050655844627e-06,
      "loss": 0.0069,
      "step": 13324
    },
    {
      "epoch": 0.9656846758705656,
      "grad_norm": 5.532389163970947,
      "learning_rate": 6.884556851945793e-06,
      "loss": 0.2128,
      "step": 13325
    },
    {
      "epoch": 0.9657571475160344,
      "grad_norm": 3.9896364212036133,
      "learning_rate": 6.87006304804696e-06,
      "loss": 0.0471,
      "step": 13326
    },
    {
      "epoch": 0.9658296191615031,
      "grad_norm": 2.162533760070801,
      "learning_rate": 6.855569244148127e-06,
      "loss": 0.0404,
      "step": 13327
    },
    {
      "epoch": 0.9659020908069718,
      "grad_norm": 0.8135578632354736,
      "learning_rate": 6.841075440249294e-06,
      "loss": 0.0101,
      "step": 13328
    },
    {
      "epoch": 0.9659745624524405,
      "grad_norm": 2.8352015018463135,
      "learning_rate": 6.8265816363504614e-06,
      "loss": 0.0985,
      "step": 13329
    },
    {
      "epoch": 0.9660470340979092,
      "grad_norm": 3.326406717300415,
      "learning_rate": 6.812087832451627e-06,
      "loss": 0.0666,
      "step": 13330
    },
    {
      "epoch": 0.9661195057433779,
      "grad_norm": 1.5792325735092163,
      "learning_rate": 6.797594028552794e-06,
      "loss": 0.0172,
      "step": 13331
    },
    {
      "epoch": 0.9661919773888467,
      "grad_norm": 2.8312325477600098,
      "learning_rate": 6.783100224653961e-06,
      "loss": 0.0601,
      "step": 13332
    },
    {
      "epoch": 0.9662644490343153,
      "grad_norm": 0.48694169521331787,
      "learning_rate": 6.768606420755127e-06,
      "loss": 0.0072,
      "step": 13333
    },
    {
      "epoch": 0.966336920679784,
      "grad_norm": 1.712609052658081,
      "learning_rate": 6.754112616856294e-06,
      "loss": 0.032,
      "step": 13334
    },
    {
      "epoch": 0.9664093923252527,
      "grad_norm": 1.1731353998184204,
      "learning_rate": 6.739618812957461e-06,
      "loss": 0.039,
      "step": 13335
    },
    {
      "epoch": 0.9664818639707214,
      "grad_norm": 2.56472110748291,
      "learning_rate": 6.725125009058628e-06,
      "loss": 0.0445,
      "step": 13336
    },
    {
      "epoch": 0.9665543356161902,
      "grad_norm": 2.049546957015991,
      "learning_rate": 6.710631205159794e-06,
      "loss": 0.0455,
      "step": 13337
    },
    {
      "epoch": 0.9666268072616588,
      "grad_norm": 4.844642639160156,
      "learning_rate": 6.696137401260961e-06,
      "loss": 0.0718,
      "step": 13338
    },
    {
      "epoch": 0.9666992789071276,
      "grad_norm": 2.590013027191162,
      "learning_rate": 6.681643597362128e-06,
      "loss": 0.0821,
      "step": 13339
    },
    {
      "epoch": 0.9667717505525963,
      "grad_norm": 0.905640184879303,
      "learning_rate": 6.6671497934632954e-06,
      "loss": 0.0076,
      "step": 13340
    },
    {
      "epoch": 0.966844222198065,
      "grad_norm": 0.6996926665306091,
      "learning_rate": 6.652655989564461e-06,
      "loss": 0.0234,
      "step": 13341
    },
    {
      "epoch": 0.9669166938435337,
      "grad_norm": 0.19293399155139923,
      "learning_rate": 6.638162185665628e-06,
      "loss": 0.0041,
      "step": 13342
    },
    {
      "epoch": 0.9669891654890024,
      "grad_norm": 0.07427690178155899,
      "learning_rate": 6.623668381766795e-06,
      "loss": 0.0015,
      "step": 13343
    },
    {
      "epoch": 0.9670616371344711,
      "grad_norm": 2.4730539321899414,
      "learning_rate": 6.609174577867962e-06,
      "loss": 0.0433,
      "step": 13344
    },
    {
      "epoch": 0.9671341087799399,
      "grad_norm": 2.1436707973480225,
      "learning_rate": 6.594680773969128e-06,
      "loss": 0.0885,
      "step": 13345
    },
    {
      "epoch": 0.9672065804254085,
      "grad_norm": 2.192385196685791,
      "learning_rate": 6.580186970070295e-06,
      "loss": 0.0532,
      "step": 13346
    },
    {
      "epoch": 0.9672790520708773,
      "grad_norm": 1.666648507118225,
      "learning_rate": 6.565693166171462e-06,
      "loss": 0.0426,
      "step": 13347
    },
    {
      "epoch": 0.967351523716346,
      "grad_norm": 1.7840592861175537,
      "learning_rate": 6.551199362272628e-06,
      "loss": 0.1151,
      "step": 13348
    },
    {
      "epoch": 0.9674239953618147,
      "grad_norm": 3.215395927429199,
      "learning_rate": 6.536705558373796e-06,
      "loss": 0.1205,
      "step": 13349
    },
    {
      "epoch": 0.9674964670072834,
      "grad_norm": 0.8638963103294373,
      "learning_rate": 6.522211754474962e-06,
      "loss": 0.0144,
      "step": 13350
    },
    {
      "epoch": 0.9675689386527521,
      "grad_norm": 0.3890111446380615,
      "learning_rate": 6.5077179505761294e-06,
      "loss": 0.0044,
      "step": 13351
    },
    {
      "epoch": 0.9676414102982208,
      "grad_norm": 3.4028542041778564,
      "learning_rate": 6.493224146677296e-06,
      "loss": 0.0659,
      "step": 13352
    },
    {
      "epoch": 0.9677138819436896,
      "grad_norm": 0.0642719715833664,
      "learning_rate": 6.478730342778462e-06,
      "loss": 0.0009,
      "step": 13353
    },
    {
      "epoch": 0.9677863535891582,
      "grad_norm": 1.6217522621154785,
      "learning_rate": 6.464236538879629e-06,
      "loss": 0.0651,
      "step": 13354
    },
    {
      "epoch": 0.967858825234627,
      "grad_norm": 2.367117404937744,
      "learning_rate": 6.449742734980796e-06,
      "loss": 0.1929,
      "step": 13355
    },
    {
      "epoch": 0.9679312968800957,
      "grad_norm": 3.235401153564453,
      "learning_rate": 6.435248931081962e-06,
      "loss": 0.1028,
      "step": 13356
    },
    {
      "epoch": 0.9680037685255644,
      "grad_norm": 1.6901183128356934,
      "learning_rate": 6.42075512718313e-06,
      "loss": 0.0306,
      "step": 13357
    },
    {
      "epoch": 0.9680762401710331,
      "grad_norm": 0.8198022246360779,
      "learning_rate": 6.406261323284296e-06,
      "loss": 0.0201,
      "step": 13358
    },
    {
      "epoch": 0.9681487118165018,
      "grad_norm": 1.8660955429077148,
      "learning_rate": 6.3917675193854635e-06,
      "loss": 0.0087,
      "step": 13359
    },
    {
      "epoch": 0.9682211834619705,
      "grad_norm": 0.9780928492546082,
      "learning_rate": 6.37727371548663e-06,
      "loss": 0.0301,
      "step": 13360
    },
    {
      "epoch": 0.9682936551074393,
      "grad_norm": 2.03625750541687,
      "learning_rate": 6.362779911587796e-06,
      "loss": 0.0538,
      "step": 13361
    },
    {
      "epoch": 0.9683661267529079,
      "grad_norm": 1.017183542251587,
      "learning_rate": 6.3482861076889634e-06,
      "loss": 0.0302,
      "step": 13362
    },
    {
      "epoch": 0.9684385983983766,
      "grad_norm": 0.46661341190338135,
      "learning_rate": 6.33379230379013e-06,
      "loss": 0.0048,
      "step": 13363
    },
    {
      "epoch": 0.9685110700438453,
      "grad_norm": 1.7526005506515503,
      "learning_rate": 6.319298499891296e-06,
      "loss": 0.0199,
      "step": 13364
    },
    {
      "epoch": 0.968583541689314,
      "grad_norm": 1.344062328338623,
      "learning_rate": 6.304804695992464e-06,
      "loss": 0.0062,
      "step": 13365
    },
    {
      "epoch": 0.9686560133347828,
      "grad_norm": 5.656440734863281,
      "learning_rate": 6.29031089209363e-06,
      "loss": 0.0278,
      "step": 13366
    },
    {
      "epoch": 0.9687284849802514,
      "grad_norm": 2.8674609661102295,
      "learning_rate": 6.275817088194797e-06,
      "loss": 0.0738,
      "step": 13367
    },
    {
      "epoch": 0.9688009566257202,
      "grad_norm": 0.247012659907341,
      "learning_rate": 6.261323284295964e-06,
      "loss": 0.0106,
      "step": 13368
    },
    {
      "epoch": 0.9688734282711889,
      "grad_norm": 1.3029221296310425,
      "learning_rate": 6.24682948039713e-06,
      "loss": 0.0325,
      "step": 13369
    },
    {
      "epoch": 0.9689458999166576,
      "grad_norm": 0.0979190319776535,
      "learning_rate": 6.2323356764982975e-06,
      "loss": 0.0011,
      "step": 13370
    },
    {
      "epoch": 0.9690183715621263,
      "grad_norm": 1.5333689451217651,
      "learning_rate": 6.217841872599464e-06,
      "loss": 0.0484,
      "step": 13371
    },
    {
      "epoch": 0.969090843207595,
      "grad_norm": 0.5887529253959656,
      "learning_rate": 6.203348068700631e-06,
      "loss": 0.01,
      "step": 13372
    },
    {
      "epoch": 0.9691633148530637,
      "grad_norm": 1.9468432664871216,
      "learning_rate": 6.188854264801797e-06,
      "loss": 0.0431,
      "step": 13373
    },
    {
      "epoch": 0.9692357864985325,
      "grad_norm": 1.1055673360824585,
      "learning_rate": 6.174360460902964e-06,
      "loss": 0.0107,
      "step": 13374
    },
    {
      "epoch": 0.9693082581440011,
      "grad_norm": 3.343411684036255,
      "learning_rate": 6.1598666570041316e-06,
      "loss": 0.0232,
      "step": 13375
    },
    {
      "epoch": 0.9693807297894699,
      "grad_norm": 1.913800597190857,
      "learning_rate": 6.145372853105297e-06,
      "loss": 0.0456,
      "step": 13376
    },
    {
      "epoch": 0.9694532014349386,
      "grad_norm": 1.1945725679397583,
      "learning_rate": 6.130879049206464e-06,
      "loss": 0.0335,
      "step": 13377
    },
    {
      "epoch": 0.9695256730804073,
      "grad_norm": 3.58451509475708,
      "learning_rate": 6.1163852453076315e-06,
      "loss": 0.0809,
      "step": 13378
    },
    {
      "epoch": 0.969598144725876,
      "grad_norm": 0.6970460414886475,
      "learning_rate": 6.101891441408798e-06,
      "loss": 0.0071,
      "step": 13379
    },
    {
      "epoch": 0.9696706163713447,
      "grad_norm": 0.7940216660499573,
      "learning_rate": 6.087397637509965e-06,
      "loss": 0.0128,
      "step": 13380
    },
    {
      "epoch": 0.9697430880168134,
      "grad_norm": 1.8041296005249023,
      "learning_rate": 6.0729038336111315e-06,
      "loss": 0.0844,
      "step": 13381
    },
    {
      "epoch": 0.9698155596622822,
      "grad_norm": 0.08075346797704697,
      "learning_rate": 6.058410029712298e-06,
      "loss": 0.0014,
      "step": 13382
    },
    {
      "epoch": 0.9698880313077508,
      "grad_norm": 0.611187756061554,
      "learning_rate": 6.043916225813466e-06,
      "loss": 0.0049,
      "step": 13383
    },
    {
      "epoch": 0.9699605029532196,
      "grad_norm": 0.7036164999008179,
      "learning_rate": 6.029422421914631e-06,
      "loss": 0.0277,
      "step": 13384
    },
    {
      "epoch": 0.9700329745986883,
      "grad_norm": 1.8544890880584717,
      "learning_rate": 6.014928618015799e-06,
      "loss": 0.0372,
      "step": 13385
    },
    {
      "epoch": 0.970105446244157,
      "grad_norm": 2.047683000564575,
      "learning_rate": 6.0004348141169656e-06,
      "loss": 0.048,
      "step": 13386
    },
    {
      "epoch": 0.9701779178896257,
      "grad_norm": 0.4670863151550293,
      "learning_rate": 5.985941010218132e-06,
      "loss": 0.0094,
      "step": 13387
    },
    {
      "epoch": 0.9702503895350943,
      "grad_norm": 0.5096782445907593,
      "learning_rate": 5.971447206319299e-06,
      "loss": 0.0111,
      "step": 13388
    },
    {
      "epoch": 0.9703228611805631,
      "grad_norm": 2.031250476837158,
      "learning_rate": 5.9569534024204655e-06,
      "loss": 0.1188,
      "step": 13389
    },
    {
      "epoch": 0.9703953328260319,
      "grad_norm": 3.385477304458618,
      "learning_rate": 5.942459598521632e-06,
      "loss": 0.0356,
      "step": 13390
    },
    {
      "epoch": 0.9704678044715005,
      "grad_norm": 0.21915094554424286,
      "learning_rate": 5.927965794622799e-06,
      "loss": 0.0072,
      "step": 13391
    },
    {
      "epoch": 0.9705402761169692,
      "grad_norm": 1.9330308437347412,
      "learning_rate": 5.9134719907239655e-06,
      "loss": 0.0342,
      "step": 13392
    },
    {
      "epoch": 0.970612747762438,
      "grad_norm": 3.6312055587768555,
      "learning_rate": 5.898978186825133e-06,
      "loss": 0.1129,
      "step": 13393
    },
    {
      "epoch": 0.9706852194079066,
      "grad_norm": 0.20745781064033508,
      "learning_rate": 5.8844843829263e-06,
      "loss": 0.0051,
      "step": 13394
    },
    {
      "epoch": 0.9707576910533754,
      "grad_norm": 0.8901762366294861,
      "learning_rate": 5.869990579027465e-06,
      "loss": 0.0117,
      "step": 13395
    },
    {
      "epoch": 0.970830162698844,
      "grad_norm": 1.5981887578964233,
      "learning_rate": 5.855496775128633e-06,
      "loss": 0.0347,
      "step": 13396
    },
    {
      "epoch": 0.9709026343443128,
      "grad_norm": 1.813011646270752,
      "learning_rate": 5.8410029712297996e-06,
      "loss": 0.0549,
      "step": 13397
    },
    {
      "epoch": 0.9709751059897815,
      "grad_norm": 1.9718255996704102,
      "learning_rate": 5.826509167330966e-06,
      "loss": 0.0497,
      "step": 13398
    },
    {
      "epoch": 0.9710475776352502,
      "grad_norm": 0.5521492958068848,
      "learning_rate": 5.812015363432133e-06,
      "loss": 0.0028,
      "step": 13399
    },
    {
      "epoch": 0.9711200492807189,
      "grad_norm": 2.6100902557373047,
      "learning_rate": 5.7975215595332995e-06,
      "loss": 0.0684,
      "step": 13400
    },
    {
      "epoch": 0.9711925209261876,
      "grad_norm": 0.47341740131378174,
      "learning_rate": 5.783027755634467e-06,
      "loss": 0.0097,
      "step": 13401
    },
    {
      "epoch": 0.9712649925716563,
      "grad_norm": 2.1927363872528076,
      "learning_rate": 5.768533951735634e-06,
      "loss": 0.0128,
      "step": 13402
    },
    {
      "epoch": 0.9713374642171251,
      "grad_norm": 1.7401349544525146,
      "learning_rate": 5.7540401478367994e-06,
      "loss": 0.0358,
      "step": 13403
    },
    {
      "epoch": 0.9714099358625937,
      "grad_norm": 0.037999559193849564,
      "learning_rate": 5.739546343937967e-06,
      "loss": 0.0004,
      "step": 13404
    },
    {
      "epoch": 0.9714824075080625,
      "grad_norm": 1.012107491493225,
      "learning_rate": 5.725052540039134e-06,
      "loss": 0.0157,
      "step": 13405
    },
    {
      "epoch": 0.9715548791535312,
      "grad_norm": 0.9111817479133606,
      "learning_rate": 5.7105587361403e-06,
      "loss": 0.0197,
      "step": 13406
    },
    {
      "epoch": 0.9716273507989999,
      "grad_norm": 2.326197385787964,
      "learning_rate": 5.696064932241467e-06,
      "loss": 0.0571,
      "step": 13407
    },
    {
      "epoch": 0.9716998224444686,
      "grad_norm": 2.718961477279663,
      "learning_rate": 5.6815711283426335e-06,
      "loss": 0.1176,
      "step": 13408
    },
    {
      "epoch": 0.9717722940899373,
      "grad_norm": 0.715143084526062,
      "learning_rate": 5.667077324443801e-06,
      "loss": 0.0336,
      "step": 13409
    },
    {
      "epoch": 0.971844765735406,
      "grad_norm": 4.508316516876221,
      "learning_rate": 5.652583520544967e-06,
      "loss": 0.0452,
      "step": 13410
    },
    {
      "epoch": 0.9719172373808748,
      "grad_norm": 0.24192911386489868,
      "learning_rate": 5.638089716646134e-06,
      "loss": 0.0021,
      "step": 13411
    },
    {
      "epoch": 0.9719897090263434,
      "grad_norm": 1.5600931644439697,
      "learning_rate": 5.623595912747301e-06,
      "loss": 0.0418,
      "step": 13412
    },
    {
      "epoch": 0.9720621806718122,
      "grad_norm": 1.9409197568893433,
      "learning_rate": 5.609102108848468e-06,
      "loss": 0.0516,
      "step": 13413
    },
    {
      "epoch": 0.9721346523172809,
      "grad_norm": 3.1352531909942627,
      "learning_rate": 5.594608304949634e-06,
      "loss": 0.0662,
      "step": 13414
    },
    {
      "epoch": 0.9722071239627496,
      "grad_norm": 4.6276116371154785,
      "learning_rate": 5.580114501050801e-06,
      "loss": 0.1669,
      "step": 13415
    },
    {
      "epoch": 0.9722795956082183,
      "grad_norm": 1.6096967458724976,
      "learning_rate": 5.565620697151968e-06,
      "loss": 0.0355,
      "step": 13416
    },
    {
      "epoch": 0.972352067253687,
      "grad_norm": 1.7508268356323242,
      "learning_rate": 5.551126893253135e-06,
      "loss": 0.0531,
      "step": 13417
    },
    {
      "epoch": 0.9724245388991557,
      "grad_norm": 1.4108024835586548,
      "learning_rate": 5.536633089354301e-06,
      "loss": 0.0107,
      "step": 13418
    },
    {
      "epoch": 0.9724970105446245,
      "grad_norm": 0.12259098142385483,
      "learning_rate": 5.522139285455468e-06,
      "loss": 0.0044,
      "step": 13419
    },
    {
      "epoch": 0.9725694821900931,
      "grad_norm": 0.7508619427680969,
      "learning_rate": 5.507645481556635e-06,
      "loss": 0.0184,
      "step": 13420
    },
    {
      "epoch": 0.9726419538355618,
      "grad_norm": 0.5850512385368347,
      "learning_rate": 5.493151677657801e-06,
      "loss": 0.0208,
      "step": 13421
    },
    {
      "epoch": 0.9727144254810306,
      "grad_norm": 4.34072208404541,
      "learning_rate": 5.478657873758968e-06,
      "loss": 0.1981,
      "step": 13422
    },
    {
      "epoch": 0.9727868971264992,
      "grad_norm": 0.9332804679870605,
      "learning_rate": 5.464164069860135e-06,
      "loss": 0.0207,
      "step": 13423
    },
    {
      "epoch": 0.972859368771968,
      "grad_norm": 1.5449280738830566,
      "learning_rate": 5.4496702659613025e-06,
      "loss": 0.0088,
      "step": 13424
    },
    {
      "epoch": 0.9729318404174366,
      "grad_norm": 1.1017602682113647,
      "learning_rate": 5.435176462062468e-06,
      "loss": 0.0181,
      "step": 13425
    },
    {
      "epoch": 0.9730043120629054,
      "grad_norm": 1.8099013566970825,
      "learning_rate": 5.420682658163635e-06,
      "loss": 0.0268,
      "step": 13426
    },
    {
      "epoch": 0.9730767837083741,
      "grad_norm": 1.1336829662322998,
      "learning_rate": 5.4061888542648024e-06,
      "loss": 0.0325,
      "step": 13427
    },
    {
      "epoch": 0.9731492553538428,
      "grad_norm": 0.6970285773277283,
      "learning_rate": 5.391695050365969e-06,
      "loss": 0.0081,
      "step": 13428
    },
    {
      "epoch": 0.9732217269993115,
      "grad_norm": 1.8082672357559204,
      "learning_rate": 5.377201246467136e-06,
      "loss": 0.0587,
      "step": 13429
    },
    {
      "epoch": 0.9732941986447803,
      "grad_norm": 0.9776617884635925,
      "learning_rate": 5.362707442568302e-06,
      "loss": 0.029,
      "step": 13430
    },
    {
      "epoch": 0.9733666702902489,
      "grad_norm": 1.7897422313690186,
      "learning_rate": 5.348213638669469e-06,
      "loss": 0.067,
      "step": 13431
    },
    {
      "epoch": 0.9734391419357177,
      "grad_norm": 2.485074043273926,
      "learning_rate": 5.333719834770636e-06,
      "loss": 0.0611,
      "step": 13432
    },
    {
      "epoch": 0.9735116135811863,
      "grad_norm": 1.758596420288086,
      "learning_rate": 5.319226030871802e-06,
      "loss": 0.0593,
      "step": 13433
    },
    {
      "epoch": 0.9735840852266551,
      "grad_norm": 0.2700311243534088,
      "learning_rate": 5.304732226972969e-06,
      "loss": 0.0031,
      "step": 13434
    },
    {
      "epoch": 0.9736565568721238,
      "grad_norm": 0.2274034321308136,
      "learning_rate": 5.2902384230741365e-06,
      "loss": 0.0038,
      "step": 13435
    },
    {
      "epoch": 0.9737290285175925,
      "grad_norm": 0.3295271694660187,
      "learning_rate": 5.275744619175302e-06,
      "loss": 0.0088,
      "step": 13436
    },
    {
      "epoch": 0.9738015001630612,
      "grad_norm": 1.5267590284347534,
      "learning_rate": 5.26125081527647e-06,
      "loss": 0.0277,
      "step": 13437
    },
    {
      "epoch": 0.9738739718085299,
      "grad_norm": 4.414227485656738,
      "learning_rate": 5.246757011377636e-06,
      "loss": 0.0976,
      "step": 13438
    },
    {
      "epoch": 0.9739464434539986,
      "grad_norm": 5.801494598388672,
      "learning_rate": 5.232263207478803e-06,
      "loss": 0.0345,
      "step": 13439
    },
    {
      "epoch": 0.9740189150994674,
      "grad_norm": 0.6056329607963562,
      "learning_rate": 5.21776940357997e-06,
      "loss": 0.0073,
      "step": 13440
    },
    {
      "epoch": 0.974091386744936,
      "grad_norm": 0.9495973587036133,
      "learning_rate": 5.203275599681136e-06,
      "loss": 0.0449,
      "step": 13441
    },
    {
      "epoch": 0.9741638583904048,
      "grad_norm": 3.96661376953125,
      "learning_rate": 5.188781795782304e-06,
      "loss": 0.1168,
      "step": 13442
    },
    {
      "epoch": 0.9742363300358735,
      "grad_norm": 1.5347633361816406,
      "learning_rate": 5.1742879918834705e-06,
      "loss": 0.0418,
      "step": 13443
    },
    {
      "epoch": 0.9743088016813422,
      "grad_norm": 3.2108116149902344,
      "learning_rate": 5.159794187984636e-06,
      "loss": 0.0876,
      "step": 13444
    },
    {
      "epoch": 0.9743812733268109,
      "grad_norm": 0.2887265980243683,
      "learning_rate": 5.145300384085804e-06,
      "loss": 0.0095,
      "step": 13445
    },
    {
      "epoch": 0.9744537449722795,
      "grad_norm": 0.5603501200675964,
      "learning_rate": 5.1308065801869705e-06,
      "loss": 0.0096,
      "step": 13446
    },
    {
      "epoch": 0.9745262166177483,
      "grad_norm": 1.2681108713150024,
      "learning_rate": 5.116312776288137e-06,
      "loss": 0.0297,
      "step": 13447
    },
    {
      "epoch": 0.974598688263217,
      "grad_norm": 5.431885719299316,
      "learning_rate": 5.101818972389304e-06,
      "loss": 0.135,
      "step": 13448
    },
    {
      "epoch": 0.9746711599086857,
      "grad_norm": 2.4627323150634766,
      "learning_rate": 5.08732516849047e-06,
      "loss": 0.051,
      "step": 13449
    },
    {
      "epoch": 0.9747436315541544,
      "grad_norm": 1.491464614868164,
      "learning_rate": 5.072831364591638e-06,
      "loss": 0.048,
      "step": 13450
    },
    {
      "epoch": 0.9748161031996232,
      "grad_norm": 1.914293885231018,
      "learning_rate": 5.058337560692804e-06,
      "loss": 0.0437,
      "step": 13451
    },
    {
      "epoch": 0.9748885748450918,
      "grad_norm": 0.007525664754211903,
      "learning_rate": 5.04384375679397e-06,
      "loss": 0.0001,
      "step": 13452
    },
    {
      "epoch": 0.9749610464905606,
      "grad_norm": 1.6374419927597046,
      "learning_rate": 5.029349952895138e-06,
      "loss": 0.0333,
      "step": 13453
    },
    {
      "epoch": 0.9750335181360292,
      "grad_norm": 0.8755534887313843,
      "learning_rate": 5.0148561489963045e-06,
      "loss": 0.015,
      "step": 13454
    },
    {
      "epoch": 0.975105989781498,
      "grad_norm": 2.0285909175872803,
      "learning_rate": 5.000362345097471e-06,
      "loss": 0.0608,
      "step": 13455
    },
    {
      "epoch": 0.9751784614269667,
      "grad_norm": 0.19913220405578613,
      "learning_rate": 4.985868541198638e-06,
      "loss": 0.0061,
      "step": 13456
    },
    {
      "epoch": 0.9752509330724354,
      "grad_norm": 0.6733423471450806,
      "learning_rate": 4.9713747372998045e-06,
      "loss": 0.0159,
      "step": 13457
    },
    {
      "epoch": 0.9753234047179041,
      "grad_norm": 0.353641539812088,
      "learning_rate": 4.956880933400972e-06,
      "loss": 0.0083,
      "step": 13458
    },
    {
      "epoch": 0.9753958763633729,
      "grad_norm": 0.545933187007904,
      "learning_rate": 4.942387129502138e-06,
      "loss": 0.0077,
      "step": 13459
    },
    {
      "epoch": 0.9754683480088415,
      "grad_norm": 1.4297572374343872,
      "learning_rate": 4.927893325603304e-06,
      "loss": 0.028,
      "step": 13460
    },
    {
      "epoch": 0.9755408196543103,
      "grad_norm": 4.869977951049805,
      "learning_rate": 4.913399521704472e-06,
      "loss": 0.1642,
      "step": 13461
    },
    {
      "epoch": 0.9756132912997789,
      "grad_norm": 0.4808480739593506,
      "learning_rate": 4.898905717805638e-06,
      "loss": 0.0093,
      "step": 13462
    },
    {
      "epoch": 0.9756857629452477,
      "grad_norm": 3.4784164428710938,
      "learning_rate": 4.884411913906805e-06,
      "loss": 0.082,
      "step": 13463
    },
    {
      "epoch": 0.9757582345907164,
      "grad_norm": 1.8615654706954956,
      "learning_rate": 4.869918110007972e-06,
      "loss": 0.0339,
      "step": 13464
    },
    {
      "epoch": 0.9758307062361851,
      "grad_norm": 0.9204291701316833,
      "learning_rate": 4.8554243061091385e-06,
      "loss": 0.0502,
      "step": 13465
    },
    {
      "epoch": 0.9759031778816538,
      "grad_norm": 0.6139678955078125,
      "learning_rate": 4.840930502210305e-06,
      "loss": 0.0092,
      "step": 13466
    },
    {
      "epoch": 0.9759756495271226,
      "grad_norm": 2.083380937576294,
      "learning_rate": 4.826436698311472e-06,
      "loss": 0.0502,
      "step": 13467
    },
    {
      "epoch": 0.9760481211725912,
      "grad_norm": 3.3647091388702393,
      "learning_rate": 4.811942894412639e-06,
      "loss": 0.0932,
      "step": 13468
    },
    {
      "epoch": 0.97612059281806,
      "grad_norm": 0.6244469285011292,
      "learning_rate": 4.797449090513806e-06,
      "loss": 0.0095,
      "step": 13469
    },
    {
      "epoch": 0.9761930644635286,
      "grad_norm": 0.878004252910614,
      "learning_rate": 4.782955286614972e-06,
      "loss": 0.0133,
      "step": 13470
    },
    {
      "epoch": 0.9762655361089974,
      "grad_norm": 1.6022546291351318,
      "learning_rate": 4.768461482716139e-06,
      "loss": 0.0416,
      "step": 13471
    },
    {
      "epoch": 0.9763380077544661,
      "grad_norm": 0.9073346257209778,
      "learning_rate": 4.753967678817306e-06,
      "loss": 0.015,
      "step": 13472
    },
    {
      "epoch": 0.9764104793999347,
      "grad_norm": 0.712614893913269,
      "learning_rate": 4.7394738749184725e-06,
      "loss": 0.0183,
      "step": 13473
    },
    {
      "epoch": 0.9764829510454035,
      "grad_norm": 0.9681289196014404,
      "learning_rate": 4.724980071019639e-06,
      "loss": 0.015,
      "step": 13474
    },
    {
      "epoch": 0.9765554226908721,
      "grad_norm": 1.0101159811019897,
      "learning_rate": 4.710486267120806e-06,
      "loss": 0.0134,
      "step": 13475
    },
    {
      "epoch": 0.9766278943363409,
      "grad_norm": 0.6981558203697205,
      "learning_rate": 4.695992463221973e-06,
      "loss": 0.0257,
      "step": 13476
    },
    {
      "epoch": 0.9767003659818096,
      "grad_norm": 0.8364242315292358,
      "learning_rate": 4.681498659323139e-06,
      "loss": 0.0332,
      "step": 13477
    },
    {
      "epoch": 0.9767728376272783,
      "grad_norm": 1.809649109840393,
      "learning_rate": 4.667004855424306e-06,
      "loss": 0.0468,
      "step": 13478
    },
    {
      "epoch": 0.976845309272747,
      "grad_norm": 0.436798632144928,
      "learning_rate": 4.652511051525473e-06,
      "loss": 0.0132,
      "step": 13479
    },
    {
      "epoch": 0.9769177809182158,
      "grad_norm": 3.5576841831207275,
      "learning_rate": 4.63801724762664e-06,
      "loss": 0.0876,
      "step": 13480
    },
    {
      "epoch": 0.9769902525636844,
      "grad_norm": 2.3948988914489746,
      "learning_rate": 4.623523443727807e-06,
      "loss": 0.0436,
      "step": 13481
    },
    {
      "epoch": 0.9770627242091532,
      "grad_norm": 0.21888329088687897,
      "learning_rate": 4.609029639828973e-06,
      "loss": 0.0031,
      "step": 13482
    },
    {
      "epoch": 0.9771351958546218,
      "grad_norm": 2.235020875930786,
      "learning_rate": 4.59453583593014e-06,
      "loss": 0.0466,
      "step": 13483
    },
    {
      "epoch": 0.9772076675000906,
      "grad_norm": 0.07169904559850693,
      "learning_rate": 4.580042032031307e-06,
      "loss": 0.0014,
      "step": 13484
    },
    {
      "epoch": 0.9772801391455593,
      "grad_norm": 2.1709420680999756,
      "learning_rate": 4.565548228132473e-06,
      "loss": 0.0424,
      "step": 13485
    },
    {
      "epoch": 0.977352610791028,
      "grad_norm": 1.0995808839797974,
      "learning_rate": 4.551054424233641e-06,
      "loss": 0.0139,
      "step": 13486
    },
    {
      "epoch": 0.9774250824364967,
      "grad_norm": 1.0256643295288086,
      "learning_rate": 4.536560620334807e-06,
      "loss": 0.0187,
      "step": 13487
    },
    {
      "epoch": 0.9774975540819655,
      "grad_norm": 1.1785143613815308,
      "learning_rate": 4.522066816435973e-06,
      "loss": 0.0203,
      "step": 13488
    },
    {
      "epoch": 0.9775700257274341,
      "grad_norm": 0.49933508038520813,
      "learning_rate": 4.507573012537141e-06,
      "loss": 0.0119,
      "step": 13489
    },
    {
      "epoch": 0.9776424973729029,
      "grad_norm": 0.7386811375617981,
      "learning_rate": 4.493079208638307e-06,
      "loss": 0.0036,
      "step": 13490
    },
    {
      "epoch": 0.9777149690183715,
      "grad_norm": 0.7156702280044556,
      "learning_rate": 4.478585404739474e-06,
      "loss": 0.0148,
      "step": 13491
    },
    {
      "epoch": 0.9777874406638403,
      "grad_norm": 0.5497732162475586,
      "learning_rate": 4.464091600840641e-06,
      "loss": 0.009,
      "step": 13492
    },
    {
      "epoch": 0.977859912309309,
      "grad_norm": 0.09313149750232697,
      "learning_rate": 4.449597796941807e-06,
      "loss": 0.0018,
      "step": 13493
    },
    {
      "epoch": 0.9779323839547777,
      "grad_norm": 0.7294859886169434,
      "learning_rate": 4.435103993042975e-06,
      "loss": 0.01,
      "step": 13494
    },
    {
      "epoch": 0.9780048556002464,
      "grad_norm": 1.2910425662994385,
      "learning_rate": 4.420610189144141e-06,
      "loss": 0.0483,
      "step": 13495
    },
    {
      "epoch": 0.9780773272457152,
      "grad_norm": 0.13245101273059845,
      "learning_rate": 4.406116385245307e-06,
      "loss": 0.0038,
      "step": 13496
    },
    {
      "epoch": 0.9781497988911838,
      "grad_norm": 1.4370797872543335,
      "learning_rate": 4.391622581346475e-06,
      "loss": 0.0155,
      "step": 13497
    },
    {
      "epoch": 0.9782222705366526,
      "grad_norm": 0.7755146622657776,
      "learning_rate": 4.377128777447641e-06,
      "loss": 0.0593,
      "step": 13498
    },
    {
      "epoch": 0.9782947421821212,
      "grad_norm": 2.542854070663452,
      "learning_rate": 4.362634973548809e-06,
      "loss": 0.0783,
      "step": 13499
    },
    {
      "epoch": 0.97836721382759,
      "grad_norm": 0.7290658950805664,
      "learning_rate": 4.348141169649975e-06,
      "loss": 0.0048,
      "step": 13500
    },
    {
      "epoch": 0.9784396854730587,
      "grad_norm": 0.48582297563552856,
      "learning_rate": 4.333647365751141e-06,
      "loss": 0.0113,
      "step": 13501
    },
    {
      "epoch": 0.9785121571185273,
      "grad_norm": 0.5578449964523315,
      "learning_rate": 4.319153561852309e-06,
      "loss": 0.0055,
      "step": 13502
    },
    {
      "epoch": 0.9785846287639961,
      "grad_norm": 1.8845937252044678,
      "learning_rate": 4.3046597579534746e-06,
      "loss": 0.0365,
      "step": 13503
    },
    {
      "epoch": 0.9786571004094647,
      "grad_norm": 0.9496443271636963,
      "learning_rate": 4.290165954054642e-06,
      "loss": 0.0253,
      "step": 13504
    },
    {
      "epoch": 0.9787295720549335,
      "grad_norm": 1.3833184242248535,
      "learning_rate": 4.275672150155809e-06,
      "loss": 0.0539,
      "step": 13505
    },
    {
      "epoch": 0.9788020437004022,
      "grad_norm": 0.07330099493265152,
      "learning_rate": 4.261178346256975e-06,
      "loss": 0.0008,
      "step": 13506
    },
    {
      "epoch": 0.9788745153458709,
      "grad_norm": 2.092195987701416,
      "learning_rate": 4.246684542358142e-06,
      "loss": 0.1211,
      "step": 13507
    },
    {
      "epoch": 0.9789469869913396,
      "grad_norm": 0.14691680669784546,
      "learning_rate": 4.232190738459309e-06,
      "loss": 0.0021,
      "step": 13508
    },
    {
      "epoch": 0.9790194586368084,
      "grad_norm": 1.9501746892929077,
      "learning_rate": 4.217696934560475e-06,
      "loss": 0.0411,
      "step": 13509
    },
    {
      "epoch": 0.979091930282277,
      "grad_norm": 1.3809318542480469,
      "learning_rate": 4.203203130661643e-06,
      "loss": 0.039,
      "step": 13510
    },
    {
      "epoch": 0.9791644019277458,
      "grad_norm": 0.1334690898656845,
      "learning_rate": 4.188709326762809e-06,
      "loss": 0.0023,
      "step": 13511
    },
    {
      "epoch": 0.9792368735732144,
      "grad_norm": 0.2695837914943695,
      "learning_rate": 4.174215522863976e-06,
      "loss": 0.0059,
      "step": 13512
    },
    {
      "epoch": 0.9793093452186832,
      "grad_norm": 4.737565040588379,
      "learning_rate": 4.159721718965143e-06,
      "loss": 0.028,
      "step": 13513
    },
    {
      "epoch": 0.9793818168641519,
      "grad_norm": 1.4443717002868652,
      "learning_rate": 4.145227915066309e-06,
      "loss": 0.0832,
      "step": 13514
    },
    {
      "epoch": 0.9794542885096206,
      "grad_norm": 1.4024823904037476,
      "learning_rate": 4.130734111167476e-06,
      "loss": 0.0139,
      "step": 13515
    },
    {
      "epoch": 0.9795267601550893,
      "grad_norm": 0.14217785000801086,
      "learning_rate": 4.116240307268643e-06,
      "loss": 0.0031,
      "step": 13516
    },
    {
      "epoch": 0.9795992318005581,
      "grad_norm": 1.393904209136963,
      "learning_rate": 4.101746503369809e-06,
      "loss": 0.0086,
      "step": 13517
    },
    {
      "epoch": 0.9796717034460267,
      "grad_norm": 0.7400557994842529,
      "learning_rate": 4.087252699470976e-06,
      "loss": 0.011,
      "step": 13518
    },
    {
      "epoch": 0.9797441750914955,
      "grad_norm": 1.2367326021194458,
      "learning_rate": 4.072758895572143e-06,
      "loss": 0.0416,
      "step": 13519
    },
    {
      "epoch": 0.9798166467369641,
      "grad_norm": 1.3065614700317383,
      "learning_rate": 4.05826509167331e-06,
      "loss": 0.0291,
      "step": 13520
    },
    {
      "epoch": 0.9798891183824329,
      "grad_norm": 2.116804361343384,
      "learning_rate": 4.043771287774477e-06,
      "loss": 0.0756,
      "step": 13521
    },
    {
      "epoch": 0.9799615900279016,
      "grad_norm": 1.4447195529937744,
      "learning_rate": 4.0292774838756435e-06,
      "loss": 0.0617,
      "step": 13522
    },
    {
      "epoch": 0.9800340616733703,
      "grad_norm": 2.8501694202423096,
      "learning_rate": 4.01478367997681e-06,
      "loss": 0.0658,
      "step": 13523
    },
    {
      "epoch": 0.980106533318839,
      "grad_norm": 1.2172621488571167,
      "learning_rate": 4.000289876077977e-06,
      "loss": 0.0304,
      "step": 13524
    },
    {
      "epoch": 0.9801790049643078,
      "grad_norm": 1.5511163473129272,
      "learning_rate": 3.985796072179144e-06,
      "loss": 0.0248,
      "step": 13525
    },
    {
      "epoch": 0.9802514766097764,
      "grad_norm": 0.9531528353691101,
      "learning_rate": 3.97130226828031e-06,
      "loss": 0.017,
      "step": 13526
    },
    {
      "epoch": 0.9803239482552452,
      "grad_norm": 1.26407790184021,
      "learning_rate": 3.956808464381477e-06,
      "loss": 0.0423,
      "step": 13527
    },
    {
      "epoch": 0.9803964199007138,
      "grad_norm": 1.8137974739074707,
      "learning_rate": 3.942314660482644e-06,
      "loss": 0.0798,
      "step": 13528
    },
    {
      "epoch": 0.9804688915461826,
      "grad_norm": 0.5403521060943604,
      "learning_rate": 3.927820856583811e-06,
      "loss": 0.0112,
      "step": 13529
    },
    {
      "epoch": 0.9805413631916513,
      "grad_norm": 5.202516555786133,
      "learning_rate": 3.9133270526849775e-06,
      "loss": 0.0186,
      "step": 13530
    },
    {
      "epoch": 0.98061383483712,
      "grad_norm": 0.6496152877807617,
      "learning_rate": 3.898833248786144e-06,
      "loss": 0.0151,
      "step": 13531
    },
    {
      "epoch": 0.9806863064825887,
      "grad_norm": 2.183605194091797,
      "learning_rate": 3.884339444887311e-06,
      "loss": 0.0632,
      "step": 13532
    },
    {
      "epoch": 0.9807587781280575,
      "grad_norm": 0.7271907925605774,
      "learning_rate": 3.8698456409884775e-06,
      "loss": 0.0228,
      "step": 13533
    },
    {
      "epoch": 0.9808312497735261,
      "grad_norm": 2.558701515197754,
      "learning_rate": 3.855351837089644e-06,
      "loss": 0.0501,
      "step": 13534
    },
    {
      "epoch": 0.9809037214189948,
      "grad_norm": 0.4686581492424011,
      "learning_rate": 3.840858033190811e-06,
      "loss": 0.0052,
      "step": 13535
    },
    {
      "epoch": 0.9809761930644635,
      "grad_norm": 0.09904936701059341,
      "learning_rate": 3.826364229291978e-06,
      "loss": 0.0034,
      "step": 13536
    },
    {
      "epoch": 0.9810486647099322,
      "grad_norm": 0.802508533000946,
      "learning_rate": 3.8118704253931445e-06,
      "loss": 0.0136,
      "step": 13537
    },
    {
      "epoch": 0.981121136355401,
      "grad_norm": 1.8893868923187256,
      "learning_rate": 3.797376621494311e-06,
      "loss": 0.0338,
      "step": 13538
    },
    {
      "epoch": 0.9811936080008696,
      "grad_norm": 2.30663800239563,
      "learning_rate": 3.782882817595478e-06,
      "loss": 0.0428,
      "step": 13539
    },
    {
      "epoch": 0.9812660796463384,
      "grad_norm": 1.347709059715271,
      "learning_rate": 3.7683890136966453e-06,
      "loss": 0.0246,
      "step": 13540
    },
    {
      "epoch": 0.981338551291807,
      "grad_norm": 3.7416932582855225,
      "learning_rate": 3.7538952097978115e-06,
      "loss": 0.1136,
      "step": 13541
    },
    {
      "epoch": 0.9814110229372758,
      "grad_norm": 0.27481430768966675,
      "learning_rate": 3.739401405898978e-06,
      "loss": 0.0077,
      "step": 13542
    },
    {
      "epoch": 0.9814834945827445,
      "grad_norm": 2.3520259857177734,
      "learning_rate": 3.7249076020001452e-06,
      "loss": 0.0794,
      "step": 13543
    },
    {
      "epoch": 0.9815559662282132,
      "grad_norm": 1.5248725414276123,
      "learning_rate": 3.7104137981013123e-06,
      "loss": 0.0241,
      "step": 13544
    },
    {
      "epoch": 0.9816284378736819,
      "grad_norm": 1.2958186864852905,
      "learning_rate": 3.6959199942024785e-06,
      "loss": 0.0722,
      "step": 13545
    },
    {
      "epoch": 0.9817009095191507,
      "grad_norm": 1.119275450706482,
      "learning_rate": 3.6814261903036456e-06,
      "loss": 0.0629,
      "step": 13546
    },
    {
      "epoch": 0.9817733811646193,
      "grad_norm": 2.082392692565918,
      "learning_rate": 3.6669323864048122e-06,
      "loss": 0.047,
      "step": 13547
    },
    {
      "epoch": 0.9818458528100881,
      "grad_norm": 0.13818201422691345,
      "learning_rate": 3.6524385825059785e-06,
      "loss": 0.0016,
      "step": 13548
    },
    {
      "epoch": 0.9819183244555567,
      "grad_norm": 0.6164674162864685,
      "learning_rate": 3.6379447786071455e-06,
      "loss": 0.0161,
      "step": 13549
    },
    {
      "epoch": 0.9819907961010255,
      "grad_norm": 3.28074312210083,
      "learning_rate": 3.6234509747083126e-06,
      "loss": 0.066,
      "step": 13550
    },
    {
      "epoch": 0.9820632677464942,
      "grad_norm": 2.5279130935668945,
      "learning_rate": 3.6089571708094793e-06,
      "loss": 0.1547,
      "step": 13551
    },
    {
      "epoch": 0.9821357393919629,
      "grad_norm": 0.536601185798645,
      "learning_rate": 3.5944633669106455e-06,
      "loss": 0.0108,
      "step": 13552
    },
    {
      "epoch": 0.9822082110374316,
      "grad_norm": 1.069395899772644,
      "learning_rate": 3.5799695630118126e-06,
      "loss": 0.0494,
      "step": 13553
    },
    {
      "epoch": 0.9822806826829004,
      "grad_norm": 0.24654164910316467,
      "learning_rate": 3.5654757591129796e-06,
      "loss": 0.0038,
      "step": 13554
    },
    {
      "epoch": 0.982353154328369,
      "grad_norm": 0.6355592012405396,
      "learning_rate": 3.5509819552141463e-06,
      "loss": 0.0148,
      "step": 13555
    },
    {
      "epoch": 0.9824256259738378,
      "grad_norm": 0.47173547744750977,
      "learning_rate": 3.5364881513153125e-06,
      "loss": 0.0036,
      "step": 13556
    },
    {
      "epoch": 0.9824980976193064,
      "grad_norm": 0.68928062915802,
      "learning_rate": 3.5219943474164796e-06,
      "loss": 0.0164,
      "step": 13557
    },
    {
      "epoch": 0.9825705692647752,
      "grad_norm": 2.6108951568603516,
      "learning_rate": 3.5075005435176467e-06,
      "loss": 0.0319,
      "step": 13558
    },
    {
      "epoch": 0.9826430409102439,
      "grad_norm": 0.9248443245887756,
      "learning_rate": 3.493006739618813e-06,
      "loss": 0.0337,
      "step": 13559
    },
    {
      "epoch": 0.9827155125557125,
      "grad_norm": 1.4401217699050903,
      "learning_rate": 3.4785129357199795e-06,
      "loss": 0.0515,
      "step": 13560
    },
    {
      "epoch": 0.9827879842011813,
      "grad_norm": 2.102142095565796,
      "learning_rate": 3.4640191318211466e-06,
      "loss": 0.0351,
      "step": 13561
    },
    {
      "epoch": 0.98286045584665,
      "grad_norm": 0.09394540637731552,
      "learning_rate": 3.4495253279223137e-06,
      "loss": 0.002,
      "step": 13562
    },
    {
      "epoch": 0.9829329274921187,
      "grad_norm": 4.693490982055664,
      "learning_rate": 3.43503152402348e-06,
      "loss": 0.1778,
      "step": 13563
    },
    {
      "epoch": 0.9830053991375874,
      "grad_norm": 1.9515914916992188,
      "learning_rate": 3.420537720124647e-06,
      "loss": 0.0261,
      "step": 13564
    },
    {
      "epoch": 0.9830778707830561,
      "grad_norm": 3.1137824058532715,
      "learning_rate": 3.4060439162258136e-06,
      "loss": 0.0265,
      "step": 13565
    },
    {
      "epoch": 0.9831503424285248,
      "grad_norm": 0.6920412182807922,
      "learning_rate": 3.3915501123269807e-06,
      "loss": 0.0126,
      "step": 13566
    },
    {
      "epoch": 0.9832228140739936,
      "grad_norm": 1.1306337118148804,
      "learning_rate": 3.377056308428147e-06,
      "loss": 0.021,
      "step": 13567
    },
    {
      "epoch": 0.9832952857194622,
      "grad_norm": 1.1626390218734741,
      "learning_rate": 3.362562504529314e-06,
      "loss": 0.021,
      "step": 13568
    },
    {
      "epoch": 0.983367757364931,
      "grad_norm": 0.7187998294830322,
      "learning_rate": 3.3480687006304806e-06,
      "loss": 0.0105,
      "step": 13569
    },
    {
      "epoch": 0.9834402290103997,
      "grad_norm": 2.6396329402923584,
      "learning_rate": 3.3335748967316477e-06,
      "loss": 0.035,
      "step": 13570
    },
    {
      "epoch": 0.9835127006558684,
      "grad_norm": 9.508614540100098,
      "learning_rate": 3.319081092832814e-06,
      "loss": 0.0958,
      "step": 13571
    },
    {
      "epoch": 0.9835851723013371,
      "grad_norm": 1.7722411155700684,
      "learning_rate": 3.304587288933981e-06,
      "loss": 0.016,
      "step": 13572
    },
    {
      "epoch": 0.9836576439468058,
      "grad_norm": 5.380974769592285,
      "learning_rate": 3.2900934850351477e-06,
      "loss": 0.0697,
      "step": 13573
    },
    {
      "epoch": 0.9837301155922745,
      "grad_norm": 2.690973997116089,
      "learning_rate": 3.275599681136314e-06,
      "loss": 0.0379,
      "step": 13574
    },
    {
      "epoch": 0.9838025872377433,
      "grad_norm": 0.5261292457580566,
      "learning_rate": 3.261105877237481e-06,
      "loss": 0.0058,
      "step": 13575
    },
    {
      "epoch": 0.9838750588832119,
      "grad_norm": 1.305583119392395,
      "learning_rate": 3.246612073338648e-06,
      "loss": 0.0211,
      "step": 13576
    },
    {
      "epoch": 0.9839475305286807,
      "grad_norm": 0.2803054749965668,
      "learning_rate": 3.2321182694398147e-06,
      "loss": 0.0049,
      "step": 13577
    },
    {
      "epoch": 0.9840200021741493,
      "grad_norm": 2.8301191329956055,
      "learning_rate": 3.217624465540981e-06,
      "loss": 0.0523,
      "step": 13578
    },
    {
      "epoch": 0.9840924738196181,
      "grad_norm": 0.013429655693471432,
      "learning_rate": 3.203130661642148e-06,
      "loss": 0.0004,
      "step": 13579
    },
    {
      "epoch": 0.9841649454650868,
      "grad_norm": 0.6499060392379761,
      "learning_rate": 3.188636857743315e-06,
      "loss": 0.0217,
      "step": 13580
    },
    {
      "epoch": 0.9842374171105555,
      "grad_norm": 0.8289687037467957,
      "learning_rate": 3.1741430538444817e-06,
      "loss": 0.0141,
      "step": 13581
    },
    {
      "epoch": 0.9843098887560242,
      "grad_norm": 0.3700855076313019,
      "learning_rate": 3.159649249945648e-06,
      "loss": 0.0032,
      "step": 13582
    },
    {
      "epoch": 0.984382360401493,
      "grad_norm": 0.8290637731552124,
      "learning_rate": 3.145155446046815e-06,
      "loss": 0.0281,
      "step": 13583
    },
    {
      "epoch": 0.9844548320469616,
      "grad_norm": 2.9846553802490234,
      "learning_rate": 3.130661642147982e-06,
      "loss": 0.0734,
      "step": 13584
    },
    {
      "epoch": 0.9845273036924304,
      "grad_norm": 5.1410627365112305,
      "learning_rate": 3.1161678382491487e-06,
      "loss": 0.1944,
      "step": 13585
    },
    {
      "epoch": 0.984599775337899,
      "grad_norm": 1.6484774351119995,
      "learning_rate": 3.1016740343503154e-06,
      "loss": 0.0108,
      "step": 13586
    },
    {
      "epoch": 0.9846722469833677,
      "grad_norm": 0.9216833114624023,
      "learning_rate": 3.087180230451482e-06,
      "loss": 0.0374,
      "step": 13587
    },
    {
      "epoch": 0.9847447186288365,
      "grad_norm": 0.6383336782455444,
      "learning_rate": 3.0726864265526487e-06,
      "loss": 0.0124,
      "step": 13588
    },
    {
      "epoch": 0.9848171902743051,
      "grad_norm": 0.649222195148468,
      "learning_rate": 3.0581926226538158e-06,
      "loss": 0.005,
      "step": 13589
    },
    {
      "epoch": 0.9848896619197739,
      "grad_norm": 2.8873727321624756,
      "learning_rate": 3.0436988187549824e-06,
      "loss": 0.0687,
      "step": 13590
    },
    {
      "epoch": 0.9849621335652426,
      "grad_norm": 0.846558690071106,
      "learning_rate": 3.029205014856149e-06,
      "loss": 0.03,
      "step": 13591
    },
    {
      "epoch": 0.9850346052107113,
      "grad_norm": 4.534696102142334,
      "learning_rate": 3.0147112109573157e-06,
      "loss": 0.1,
      "step": 13592
    },
    {
      "epoch": 0.98510707685618,
      "grad_norm": 0.844617486000061,
      "learning_rate": 3.0002174070584828e-06,
      "loss": 0.0141,
      "step": 13593
    },
    {
      "epoch": 0.9851795485016487,
      "grad_norm": 0.2476188987493515,
      "learning_rate": 2.9857236031596494e-06,
      "loss": 0.0032,
      "step": 13594
    },
    {
      "epoch": 0.9852520201471174,
      "grad_norm": 1.1173861026763916,
      "learning_rate": 2.971229799260816e-06,
      "loss": 0.0124,
      "step": 13595
    },
    {
      "epoch": 0.9853244917925862,
      "grad_norm": 1.1964565515518188,
      "learning_rate": 2.9567359953619827e-06,
      "loss": 0.036,
      "step": 13596
    },
    {
      "epoch": 0.9853969634380548,
      "grad_norm": 0.18075256049633026,
      "learning_rate": 2.94224219146315e-06,
      "loss": 0.0037,
      "step": 13597
    },
    {
      "epoch": 0.9854694350835236,
      "grad_norm": 1.1744346618652344,
      "learning_rate": 2.9277483875643165e-06,
      "loss": 0.052,
      "step": 13598
    },
    {
      "epoch": 0.9855419067289923,
      "grad_norm": 2.350844383239746,
      "learning_rate": 2.913254583665483e-06,
      "loss": 0.1309,
      "step": 13599
    },
    {
      "epoch": 0.985614378374461,
      "grad_norm": 1.6990504264831543,
      "learning_rate": 2.8987607797666498e-06,
      "loss": 0.0429,
      "step": 13600
    },
    {
      "epoch": 0.9856868500199297,
      "grad_norm": 1.5623691082000732,
      "learning_rate": 2.884266975867817e-06,
      "loss": 0.0365,
      "step": 13601
    },
    {
      "epoch": 0.9857593216653984,
      "grad_norm": 1.7413227558135986,
      "learning_rate": 2.8697731719689835e-06,
      "loss": 0.0085,
      "step": 13602
    },
    {
      "epoch": 0.9858317933108671,
      "grad_norm": 3.9102416038513184,
      "learning_rate": 2.85527936807015e-06,
      "loss": 0.0443,
      "step": 13603
    },
    {
      "epoch": 0.9859042649563359,
      "grad_norm": 0.9333986639976501,
      "learning_rate": 2.8407855641713168e-06,
      "loss": 0.0343,
      "step": 13604
    },
    {
      "epoch": 0.9859767366018045,
      "grad_norm": 2.059554100036621,
      "learning_rate": 2.8262917602724834e-06,
      "loss": 0.0284,
      "step": 13605
    },
    {
      "epoch": 0.9860492082472733,
      "grad_norm": 0.13397850096225739,
      "learning_rate": 2.8117979563736505e-06,
      "loss": 0.0023,
      "step": 13606
    },
    {
      "epoch": 0.986121679892742,
      "grad_norm": 0.6296877264976501,
      "learning_rate": 2.797304152474817e-06,
      "loss": 0.013,
      "step": 13607
    },
    {
      "epoch": 0.9861941515382107,
      "grad_norm": 1.2520878314971924,
      "learning_rate": 2.782810348575984e-06,
      "loss": 0.0424,
      "step": 13608
    },
    {
      "epoch": 0.9862666231836794,
      "grad_norm": 8.675861358642578,
      "learning_rate": 2.7683165446771504e-06,
      "loss": 0.0754,
      "step": 13609
    },
    {
      "epoch": 0.986339094829148,
      "grad_norm": 2.3575375080108643,
      "learning_rate": 2.7538227407783175e-06,
      "loss": 0.0494,
      "step": 13610
    },
    {
      "epoch": 0.9864115664746168,
      "grad_norm": 1.1436262130737305,
      "learning_rate": 2.739328936879484e-06,
      "loss": 0.032,
      "step": 13611
    },
    {
      "epoch": 0.9864840381200856,
      "grad_norm": 0.37782299518585205,
      "learning_rate": 2.7248351329806512e-06,
      "loss": 0.0069,
      "step": 13612
    },
    {
      "epoch": 0.9865565097655542,
      "grad_norm": 1.3429994583129883,
      "learning_rate": 2.7103413290818175e-06,
      "loss": 0.0293,
      "step": 13613
    },
    {
      "epoch": 0.986628981411023,
      "grad_norm": 3.400960922241211,
      "learning_rate": 2.6958475251829845e-06,
      "loss": 0.1117,
      "step": 13614
    },
    {
      "epoch": 0.9867014530564916,
      "grad_norm": 0.9152405261993408,
      "learning_rate": 2.681353721284151e-06,
      "loss": 0.0346,
      "step": 13615
    },
    {
      "epoch": 0.9867739247019603,
      "grad_norm": 1.2393453121185303,
      "learning_rate": 2.666859917385318e-06,
      "loss": 0.0299,
      "step": 13616
    },
    {
      "epoch": 0.9868463963474291,
      "grad_norm": 1.8021174669265747,
      "learning_rate": 2.6523661134864845e-06,
      "loss": 0.0559,
      "step": 13617
    },
    {
      "epoch": 0.9869188679928977,
      "grad_norm": 0.14017868041992188,
      "learning_rate": 2.637872309587651e-06,
      "loss": 0.0027,
      "step": 13618
    },
    {
      "epoch": 0.9869913396383665,
      "grad_norm": 0.514818012714386,
      "learning_rate": 2.623378505688818e-06,
      "loss": 0.0086,
      "step": 13619
    },
    {
      "epoch": 0.9870638112838352,
      "grad_norm": 3.990342378616333,
      "learning_rate": 2.608884701789985e-06,
      "loss": 0.0645,
      "step": 13620
    },
    {
      "epoch": 0.9871362829293039,
      "grad_norm": 3.5287835597991943,
      "learning_rate": 2.594390897891152e-06,
      "loss": 0.0559,
      "step": 13621
    },
    {
      "epoch": 0.9872087545747726,
      "grad_norm": 1.3648282289505005,
      "learning_rate": 2.579897093992318e-06,
      "loss": 0.012,
      "step": 13622
    },
    {
      "epoch": 0.9872812262202413,
      "grad_norm": 0.19494763016700745,
      "learning_rate": 2.5654032900934852e-06,
      "loss": 0.0019,
      "step": 13623
    },
    {
      "epoch": 0.98735369786571,
      "grad_norm": 1.877892255783081,
      "learning_rate": 2.550909486194652e-06,
      "loss": 0.0526,
      "step": 13624
    },
    {
      "epoch": 0.9874261695111788,
      "grad_norm": 1.1264595985412598,
      "learning_rate": 2.536415682295819e-06,
      "loss": 0.0348,
      "step": 13625
    },
    {
      "epoch": 0.9874986411566474,
      "grad_norm": 2.229905605316162,
      "learning_rate": 2.521921878396985e-06,
      "loss": 0.0424,
      "step": 13626
    },
    {
      "epoch": 0.9875711128021162,
      "grad_norm": 2.063663959503174,
      "learning_rate": 2.5074280744981523e-06,
      "loss": 0.0519,
      "step": 13627
    },
    {
      "epoch": 0.9876435844475849,
      "grad_norm": 0.09332576394081116,
      "learning_rate": 2.492934270599319e-06,
      "loss": 0.0015,
      "step": 13628
    },
    {
      "epoch": 0.9877160560930536,
      "grad_norm": 0.32949578762054443,
      "learning_rate": 2.478440466700486e-06,
      "loss": 0.0057,
      "step": 13629
    },
    {
      "epoch": 0.9877885277385223,
      "grad_norm": 3.9011595249176025,
      "learning_rate": 2.463946662801652e-06,
      "loss": 0.1621,
      "step": 13630
    },
    {
      "epoch": 0.987860999383991,
      "grad_norm": 1.0356783866882324,
      "learning_rate": 2.449452858902819e-06,
      "loss": 0.0171,
      "step": 13631
    },
    {
      "epoch": 0.9879334710294597,
      "grad_norm": 1.1318758726119995,
      "learning_rate": 2.434959055003986e-06,
      "loss": 0.0436,
      "step": 13632
    },
    {
      "epoch": 0.9880059426749285,
      "grad_norm": 0.9847438931465149,
      "learning_rate": 2.4204652511051526e-06,
      "loss": 0.0109,
      "step": 13633
    },
    {
      "epoch": 0.9880784143203971,
      "grad_norm": 3.497824192047119,
      "learning_rate": 2.4059714472063196e-06,
      "loss": 0.0383,
      "step": 13634
    },
    {
      "epoch": 0.9881508859658659,
      "grad_norm": 1.6733006238937378,
      "learning_rate": 2.391477643307486e-06,
      "loss": 0.0464,
      "step": 13635
    },
    {
      "epoch": 0.9882233576113346,
      "grad_norm": 0.24148355424404144,
      "learning_rate": 2.376983839408653e-06,
      "loss": 0.0132,
      "step": 13636
    },
    {
      "epoch": 0.9882958292568033,
      "grad_norm": 0.6596778631210327,
      "learning_rate": 2.3624900355098196e-06,
      "loss": 0.0057,
      "step": 13637
    },
    {
      "epoch": 0.988368300902272,
      "grad_norm": 1.4428799152374268,
      "learning_rate": 2.3479962316109867e-06,
      "loss": 0.0167,
      "step": 13638
    },
    {
      "epoch": 0.9884407725477407,
      "grad_norm": 2.7519543170928955,
      "learning_rate": 2.333502427712153e-06,
      "loss": 0.0603,
      "step": 13639
    },
    {
      "epoch": 0.9885132441932094,
      "grad_norm": 1.173214316368103,
      "learning_rate": 2.31900862381332e-06,
      "loss": 0.0127,
      "step": 13640
    },
    {
      "epoch": 0.9885857158386782,
      "grad_norm": 2.2654097080230713,
      "learning_rate": 2.3045148199144866e-06,
      "loss": 0.1027,
      "step": 13641
    },
    {
      "epoch": 0.9886581874841468,
      "grad_norm": 0.9325925707817078,
      "learning_rate": 2.2900210160156537e-06,
      "loss": 0.0392,
      "step": 13642
    },
    {
      "epoch": 0.9887306591296156,
      "grad_norm": 0.56986004114151,
      "learning_rate": 2.2755272121168203e-06,
      "loss": 0.0205,
      "step": 13643
    },
    {
      "epoch": 0.9888031307750842,
      "grad_norm": 2.2598211765289307,
      "learning_rate": 2.2610334082179866e-06,
      "loss": 0.0915,
      "step": 13644
    },
    {
      "epoch": 0.988875602420553,
      "grad_norm": 0.030966799706220627,
      "learning_rate": 2.2465396043191536e-06,
      "loss": 0.0006,
      "step": 13645
    },
    {
      "epoch": 0.9889480740660217,
      "grad_norm": 0.489035427570343,
      "learning_rate": 2.2320458004203203e-06,
      "loss": 0.0076,
      "step": 13646
    },
    {
      "epoch": 0.9890205457114903,
      "grad_norm": 1.3772144317626953,
      "learning_rate": 2.2175519965214874e-06,
      "loss": 0.0062,
      "step": 13647
    },
    {
      "epoch": 0.9890930173569591,
      "grad_norm": 1.120323657989502,
      "learning_rate": 2.2030581926226536e-06,
      "loss": 0.0249,
      "step": 13648
    },
    {
      "epoch": 0.9891654890024278,
      "grad_norm": 1.0251764059066772,
      "learning_rate": 2.1885643887238207e-06,
      "loss": 0.0408,
      "step": 13649
    },
    {
      "epoch": 0.9892379606478965,
      "grad_norm": 1.1662359237670898,
      "learning_rate": 2.1740705848249873e-06,
      "loss": 0.0587,
      "step": 13650
    },
    {
      "epoch": 0.9893104322933652,
      "grad_norm": 1.2608816623687744,
      "learning_rate": 2.1595767809261544e-06,
      "loss": 0.056,
      "step": 13651
    },
    {
      "epoch": 0.9893829039388339,
      "grad_norm": 0.47250524163246155,
      "learning_rate": 2.145082977027321e-06,
      "loss": 0.0127,
      "step": 13652
    },
    {
      "epoch": 0.9894553755843026,
      "grad_norm": 1.5221118927001953,
      "learning_rate": 2.1305891731284877e-06,
      "loss": 0.0933,
      "step": 13653
    },
    {
      "epoch": 0.9895278472297714,
      "grad_norm": 0.9178197979927063,
      "learning_rate": 2.1160953692296543e-06,
      "loss": 0.0164,
      "step": 13654
    },
    {
      "epoch": 0.98960031887524,
      "grad_norm": 1.2280712127685547,
      "learning_rate": 2.1016015653308214e-06,
      "loss": 0.0137,
      "step": 13655
    },
    {
      "epoch": 0.9896727905207088,
      "grad_norm": 1.0662727355957031,
      "learning_rate": 2.087107761431988e-06,
      "loss": 0.0428,
      "step": 13656
    },
    {
      "epoch": 0.9897452621661775,
      "grad_norm": 1.384588599205017,
      "learning_rate": 2.0726139575331547e-06,
      "loss": 0.036,
      "step": 13657
    },
    {
      "epoch": 0.9898177338116462,
      "grad_norm": 1.8892221450805664,
      "learning_rate": 2.0581201536343214e-06,
      "loss": 0.0361,
      "step": 13658
    },
    {
      "epoch": 0.9898902054571149,
      "grad_norm": 1.2046221494674683,
      "learning_rate": 2.043626349735488e-06,
      "loss": 0.0214,
      "step": 13659
    },
    {
      "epoch": 0.9899626771025836,
      "grad_norm": 1.8476784229278564,
      "learning_rate": 2.029132545836655e-06,
      "loss": 0.0536,
      "step": 13660
    },
    {
      "epoch": 0.9900351487480523,
      "grad_norm": 0.1442163735628128,
      "learning_rate": 2.0146387419378217e-06,
      "loss": 0.0015,
      "step": 13661
    },
    {
      "epoch": 0.9901076203935211,
      "grad_norm": 4.143214225769043,
      "learning_rate": 2.0001449380389884e-06,
      "loss": 0.0457,
      "step": 13662
    },
    {
      "epoch": 0.9901800920389897,
      "grad_norm": 0.014539330266416073,
      "learning_rate": 1.985651134140155e-06,
      "loss": 0.0002,
      "step": 13663
    },
    {
      "epoch": 0.9902525636844585,
      "grad_norm": 3.4688165187835693,
      "learning_rate": 1.971157330241322e-06,
      "loss": 0.0754,
      "step": 13664
    },
    {
      "epoch": 0.9903250353299272,
      "grad_norm": 0.842206597328186,
      "learning_rate": 1.9566635263424888e-06,
      "loss": 0.0247,
      "step": 13665
    },
    {
      "epoch": 0.9903975069753959,
      "grad_norm": 0.9439096450805664,
      "learning_rate": 1.9421697224436554e-06,
      "loss": 0.0499,
      "step": 13666
    },
    {
      "epoch": 0.9904699786208646,
      "grad_norm": 0.46570372581481934,
      "learning_rate": 1.927675918544822e-06,
      "loss": 0.0107,
      "step": 13667
    },
    {
      "epoch": 0.9905424502663333,
      "grad_norm": 1.5590444803237915,
      "learning_rate": 1.913182114645989e-06,
      "loss": 0.0416,
      "step": 13668
    },
    {
      "epoch": 0.990614921911802,
      "grad_norm": 0.13534942269325256,
      "learning_rate": 1.8986883107471556e-06,
      "loss": 0.0016,
      "step": 13669
    },
    {
      "epoch": 0.9906873935572708,
      "grad_norm": 0.2517061233520508,
      "learning_rate": 1.8841945068483226e-06,
      "loss": 0.0043,
      "step": 13670
    },
    {
      "epoch": 0.9907598652027394,
      "grad_norm": 1.132817268371582,
      "learning_rate": 1.869700702949489e-06,
      "loss": 0.0162,
      "step": 13671
    },
    {
      "epoch": 0.9908323368482082,
      "grad_norm": 0.490793913602829,
      "learning_rate": 1.8552068990506561e-06,
      "loss": 0.0135,
      "step": 13672
    },
    {
      "epoch": 0.9909048084936769,
      "grad_norm": 0.575029730796814,
      "learning_rate": 1.8407130951518228e-06,
      "loss": 0.0092,
      "step": 13673
    },
    {
      "epoch": 0.9909772801391455,
      "grad_norm": 1.5885409116744995,
      "learning_rate": 1.8262192912529892e-06,
      "loss": 0.0121,
      "step": 13674
    },
    {
      "epoch": 0.9910497517846143,
      "grad_norm": 0.9821670055389404,
      "learning_rate": 1.8117254873541563e-06,
      "loss": 0.0286,
      "step": 13675
    },
    {
      "epoch": 0.9911222234300829,
      "grad_norm": 1.2353920936584473,
      "learning_rate": 1.7972316834553227e-06,
      "loss": 0.0556,
      "step": 13676
    },
    {
      "epoch": 0.9911946950755517,
      "grad_norm": 0.770347535610199,
      "learning_rate": 1.7827378795564898e-06,
      "loss": 0.0169,
      "step": 13677
    },
    {
      "epoch": 0.9912671667210204,
      "grad_norm": 1.054818034172058,
      "learning_rate": 1.7682440756576563e-06,
      "loss": 0.0294,
      "step": 13678
    },
    {
      "epoch": 0.9913396383664891,
      "grad_norm": 0.9377509951591492,
      "learning_rate": 1.7537502717588233e-06,
      "loss": 0.0236,
      "step": 13679
    },
    {
      "epoch": 0.9914121100119578,
      "grad_norm": 0.16092196106910706,
      "learning_rate": 1.7392564678599898e-06,
      "loss": 0.0076,
      "step": 13680
    },
    {
      "epoch": 0.9914845816574265,
      "grad_norm": 1.70367431640625,
      "learning_rate": 1.7247626639611568e-06,
      "loss": 0.0624,
      "step": 13681
    },
    {
      "epoch": 0.9915570533028952,
      "grad_norm": 0.2726994454860687,
      "learning_rate": 1.7102688600623235e-06,
      "loss": 0.0069,
      "step": 13682
    },
    {
      "epoch": 0.991629524948364,
      "grad_norm": 0.7008410096168518,
      "learning_rate": 1.6957750561634903e-06,
      "loss": 0.0081,
      "step": 13683
    },
    {
      "epoch": 0.9917019965938326,
      "grad_norm": 3.590703010559082,
      "learning_rate": 1.681281252264657e-06,
      "loss": 0.0858,
      "step": 13684
    },
    {
      "epoch": 0.9917744682393014,
      "grad_norm": 0.9129967093467712,
      "learning_rate": 1.6667874483658239e-06,
      "loss": 0.0283,
      "step": 13685
    },
    {
      "epoch": 0.9918469398847701,
      "grad_norm": 0.30039602518081665,
      "learning_rate": 1.6522936444669905e-06,
      "loss": 0.0031,
      "step": 13686
    },
    {
      "epoch": 0.9919194115302388,
      "grad_norm": 3.448209762573242,
      "learning_rate": 1.637799840568157e-06,
      "loss": 0.0762,
      "step": 13687
    },
    {
      "epoch": 0.9919918831757075,
      "grad_norm": 0.8277954459190369,
      "learning_rate": 1.623306036669324e-06,
      "loss": 0.0235,
      "step": 13688
    },
    {
      "epoch": 0.9920643548211762,
      "grad_norm": 1.207698941230774,
      "learning_rate": 1.6088122327704905e-06,
      "loss": 0.0651,
      "step": 13689
    },
    {
      "epoch": 0.9921368264666449,
      "grad_norm": 2.3345701694488525,
      "learning_rate": 1.5943184288716575e-06,
      "loss": 0.0718,
      "step": 13690
    },
    {
      "epoch": 0.9922092981121137,
      "grad_norm": 0.2306225746870041,
      "learning_rate": 1.579824624972824e-06,
      "loss": 0.0119,
      "step": 13691
    },
    {
      "epoch": 0.9922817697575823,
      "grad_norm": 1.5716780424118042,
      "learning_rate": 1.565330821073991e-06,
      "loss": 0.0619,
      "step": 13692
    },
    {
      "epoch": 0.9923542414030511,
      "grad_norm": 0.9558203816413879,
      "learning_rate": 1.5508370171751577e-06,
      "loss": 0.0216,
      "step": 13693
    },
    {
      "epoch": 0.9924267130485198,
      "grad_norm": 3.6329638957977295,
      "learning_rate": 1.5363432132763243e-06,
      "loss": 0.0598,
      "step": 13694
    },
    {
      "epoch": 0.9924991846939885,
      "grad_norm": 3.2707409858703613,
      "learning_rate": 1.5218494093774912e-06,
      "loss": 0.0595,
      "step": 13695
    },
    {
      "epoch": 0.9925716563394572,
      "grad_norm": 1.1375727653503418,
      "learning_rate": 1.5073556054786579e-06,
      "loss": 0.0256,
      "step": 13696
    },
    {
      "epoch": 0.9926441279849259,
      "grad_norm": 0.26409387588500977,
      "learning_rate": 1.4928618015798247e-06,
      "loss": 0.003,
      "step": 13697
    },
    {
      "epoch": 0.9927165996303946,
      "grad_norm": 1.5349847078323364,
      "learning_rate": 1.4783679976809914e-06,
      "loss": 0.0315,
      "step": 13698
    },
    {
      "epoch": 0.9927890712758634,
      "grad_norm": 1.6543632745742798,
      "learning_rate": 1.4638741937821582e-06,
      "loss": 0.0285,
      "step": 13699
    },
    {
      "epoch": 0.992861542921332,
      "grad_norm": 0.951783299446106,
      "learning_rate": 1.4493803898833249e-06,
      "loss": 0.0085,
      "step": 13700
    },
    {
      "epoch": 0.9929340145668007,
      "grad_norm": 2.8101749420166016,
      "learning_rate": 1.4348865859844917e-06,
      "loss": 0.0042,
      "step": 13701
    },
    {
      "epoch": 0.9930064862122695,
      "grad_norm": 1.3649053573608398,
      "learning_rate": 1.4203927820856584e-06,
      "loss": 0.0216,
      "step": 13702
    },
    {
      "epoch": 0.9930789578577381,
      "grad_norm": 0.7415483593940735,
      "learning_rate": 1.4058989781868252e-06,
      "loss": 0.0096,
      "step": 13703
    },
    {
      "epoch": 0.9931514295032069,
      "grad_norm": 2.8783416748046875,
      "learning_rate": 1.391405174287992e-06,
      "loss": 0.0468,
      "step": 13704
    },
    {
      "epoch": 0.9932239011486755,
      "grad_norm": 2.3071510791778564,
      "learning_rate": 1.3769113703891588e-06,
      "loss": 0.0564,
      "step": 13705
    },
    {
      "epoch": 0.9932963727941443,
      "grad_norm": 0.8127375841140747,
      "learning_rate": 1.3624175664903256e-06,
      "loss": 0.0166,
      "step": 13706
    },
    {
      "epoch": 0.993368844439613,
      "grad_norm": 0.021612871438264847,
      "learning_rate": 1.3479237625914923e-06,
      "loss": 0.0003,
      "step": 13707
    },
    {
      "epoch": 0.9934413160850817,
      "grad_norm": 0.8127423524856567,
      "learning_rate": 1.333429958692659e-06,
      "loss": 0.0228,
      "step": 13708
    },
    {
      "epoch": 0.9935137877305504,
      "grad_norm": 0.521925151348114,
      "learning_rate": 1.3189361547938256e-06,
      "loss": 0.0079,
      "step": 13709
    },
    {
      "epoch": 0.9935862593760192,
      "grad_norm": 1.534120798110962,
      "learning_rate": 1.3044423508949924e-06,
      "loss": 0.0341,
      "step": 13710
    },
    {
      "epoch": 0.9936587310214878,
      "grad_norm": 1.4442028999328613,
      "learning_rate": 1.289948546996159e-06,
      "loss": 0.0124,
      "step": 13711
    },
    {
      "epoch": 0.9937312026669566,
      "grad_norm": 1.2105451822280884,
      "learning_rate": 1.275454743097326e-06,
      "loss": 0.0298,
      "step": 13712
    },
    {
      "epoch": 0.9938036743124252,
      "grad_norm": 0.5366602540016174,
      "learning_rate": 1.2609609391984926e-06,
      "loss": 0.0121,
      "step": 13713
    },
    {
      "epoch": 0.993876145957894,
      "grad_norm": 0.15490558743476868,
      "learning_rate": 1.2464671352996595e-06,
      "loss": 0.0042,
      "step": 13714
    },
    {
      "epoch": 0.9939486176033627,
      "grad_norm": 0.8986142873764038,
      "learning_rate": 1.231973331400826e-06,
      "loss": 0.0232,
      "step": 13715
    },
    {
      "epoch": 0.9940210892488314,
      "grad_norm": 1.856746792793274,
      "learning_rate": 1.217479527501993e-06,
      "loss": 0.0537,
      "step": 13716
    },
    {
      "epoch": 0.9940935608943001,
      "grad_norm": 2.0094408988952637,
      "learning_rate": 1.2029857236031598e-06,
      "loss": 0.0332,
      "step": 13717
    },
    {
      "epoch": 0.9941660325397688,
      "grad_norm": 1.0197949409484863,
      "learning_rate": 1.1884919197043265e-06,
      "loss": 0.0281,
      "step": 13718
    },
    {
      "epoch": 0.9942385041852375,
      "grad_norm": 0.009693197906017303,
      "learning_rate": 1.1739981158054933e-06,
      "loss": 0.0002,
      "step": 13719
    },
    {
      "epoch": 0.9943109758307063,
      "grad_norm": 4.611328125,
      "learning_rate": 1.15950431190666e-06,
      "loss": 0.1167,
      "step": 13720
    },
    {
      "epoch": 0.9943834474761749,
      "grad_norm": 1.5916380882263184,
      "learning_rate": 1.1450105080078268e-06,
      "loss": 0.0493,
      "step": 13721
    },
    {
      "epoch": 0.9944559191216437,
      "grad_norm": 0.5046820044517517,
      "learning_rate": 1.1305167041089933e-06,
      "loss": 0.0045,
      "step": 13722
    },
    {
      "epoch": 0.9945283907671124,
      "grad_norm": 0.7989785671234131,
      "learning_rate": 1.1160229002101601e-06,
      "loss": 0.0471,
      "step": 13723
    },
    {
      "epoch": 0.994600862412581,
      "grad_norm": 1.989624261856079,
      "learning_rate": 1.1015290963113268e-06,
      "loss": 0.0443,
      "step": 13724
    },
    {
      "epoch": 0.9946733340580498,
      "grad_norm": 0.8653028607368469,
      "learning_rate": 1.0870352924124937e-06,
      "loss": 0.0063,
      "step": 13725
    },
    {
      "epoch": 0.9947458057035184,
      "grad_norm": 0.6829378604888916,
      "learning_rate": 1.0725414885136605e-06,
      "loss": 0.0069,
      "step": 13726
    },
    {
      "epoch": 0.9948182773489872,
      "grad_norm": 0.32275110483169556,
      "learning_rate": 1.0580476846148272e-06,
      "loss": 0.0125,
      "step": 13727
    },
    {
      "epoch": 0.994890748994456,
      "grad_norm": 0.21785780787467957,
      "learning_rate": 1.043553880715994e-06,
      "loss": 0.003,
      "step": 13728
    },
    {
      "epoch": 0.9949632206399246,
      "grad_norm": 1.6498377323150635,
      "learning_rate": 1.0290600768171607e-06,
      "loss": 0.0548,
      "step": 13729
    },
    {
      "epoch": 0.9950356922853933,
      "grad_norm": 0.8663520812988281,
      "learning_rate": 1.0145662729183275e-06,
      "loss": 0.0346,
      "step": 13730
    },
    {
      "epoch": 0.9951081639308621,
      "grad_norm": 1.3167610168457031,
      "learning_rate": 1.0000724690194942e-06,
      "loss": 0.0204,
      "step": 13731
    },
    {
      "epoch": 0.9951806355763307,
      "grad_norm": 1.9308725595474243,
      "learning_rate": 9.85578665120661e-07,
      "loss": 0.0496,
      "step": 13732
    },
    {
      "epoch": 0.9952531072217995,
      "grad_norm": 0.5804911851882935,
      "learning_rate": 9.710848612218277e-07,
      "loss": 0.0053,
      "step": 13733
    },
    {
      "epoch": 0.9953255788672681,
      "grad_norm": 2.0216317176818848,
      "learning_rate": 9.565910573229946e-07,
      "loss": 0.0606,
      "step": 13734
    },
    {
      "epoch": 0.9953980505127369,
      "grad_norm": 1.8771700859069824,
      "learning_rate": 9.420972534241613e-07,
      "loss": 0.0214,
      "step": 13735
    },
    {
      "epoch": 0.9954705221582056,
      "grad_norm": 1.9499436616897583,
      "learning_rate": 9.276034495253281e-07,
      "loss": 0.0541,
      "step": 13736
    },
    {
      "epoch": 0.9955429938036743,
      "grad_norm": 0.32200372219085693,
      "learning_rate": 9.131096456264946e-07,
      "loss": 0.0145,
      "step": 13737
    },
    {
      "epoch": 0.995615465449143,
      "grad_norm": 1.3922754526138306,
      "learning_rate": 8.986158417276614e-07,
      "loss": 0.0226,
      "step": 13738
    },
    {
      "epoch": 0.9956879370946118,
      "grad_norm": 5.412158012390137,
      "learning_rate": 8.841220378288281e-07,
      "loss": 0.0597,
      "step": 13739
    },
    {
      "epoch": 0.9957604087400804,
      "grad_norm": 1.7216686010360718,
      "learning_rate": 8.696282339299949e-07,
      "loss": 0.017,
      "step": 13740
    },
    {
      "epoch": 0.9958328803855492,
      "grad_norm": 1.0072245597839355,
      "learning_rate": 8.551344300311617e-07,
      "loss": 0.0307,
      "step": 13741
    },
    {
      "epoch": 0.9959053520310178,
      "grad_norm": 1.6944713592529297,
      "learning_rate": 8.406406261323285e-07,
      "loss": 0.0107,
      "step": 13742
    },
    {
      "epoch": 0.9959778236764866,
      "grad_norm": 1.1408268213272095,
      "learning_rate": 8.261468222334953e-07,
      "loss": 0.022,
      "step": 13743
    },
    {
      "epoch": 0.9960502953219553,
      "grad_norm": 0.7455407381057739,
      "learning_rate": 8.11653018334662e-07,
      "loss": 0.0129,
      "step": 13744
    },
    {
      "epoch": 0.996122766967424,
      "grad_norm": 0.23746374249458313,
      "learning_rate": 7.971592144358288e-07,
      "loss": 0.0017,
      "step": 13745
    },
    {
      "epoch": 0.9961952386128927,
      "grad_norm": 2.6356616020202637,
      "learning_rate": 7.826654105369955e-07,
      "loss": 0.0745,
      "step": 13746
    },
    {
      "epoch": 0.9962677102583614,
      "grad_norm": 8.313435554504395,
      "learning_rate": 7.681716066381622e-07,
      "loss": 0.0486,
      "step": 13747
    },
    {
      "epoch": 0.9963401819038301,
      "grad_norm": 1.0237122774124146,
      "learning_rate": 7.536778027393289e-07,
      "loss": 0.0336,
      "step": 13748
    },
    {
      "epoch": 0.9964126535492989,
      "grad_norm": 1.2059701681137085,
      "learning_rate": 7.391839988404957e-07,
      "loss": 0.0248,
      "step": 13749
    },
    {
      "epoch": 0.9964851251947675,
      "grad_norm": 1.4033392667770386,
      "learning_rate": 7.246901949416624e-07,
      "loss": 0.0293,
      "step": 13750
    },
    {
      "epoch": 0.9965575968402363,
      "grad_norm": 1.4191476106643677,
      "learning_rate": 7.101963910428292e-07,
      "loss": 0.0384,
      "step": 13751
    },
    {
      "epoch": 0.996630068485705,
      "grad_norm": 1.3433746099472046,
      "learning_rate": 6.95702587143996e-07,
      "loss": 0.0413,
      "step": 13752
    },
    {
      "epoch": 0.9967025401311737,
      "grad_norm": 1.1279785633087158,
      "learning_rate": 6.812087832451628e-07,
      "loss": 0.037,
      "step": 13753
    },
    {
      "epoch": 0.9967750117766424,
      "grad_norm": 2.1378960609436035,
      "learning_rate": 6.667149793463295e-07,
      "loss": 0.0149,
      "step": 13754
    },
    {
      "epoch": 0.996847483422111,
      "grad_norm": 0.3973820209503174,
      "learning_rate": 6.522211754474962e-07,
      "loss": 0.0071,
      "step": 13755
    },
    {
      "epoch": 0.9969199550675798,
      "grad_norm": 3.345301389694214,
      "learning_rate": 6.37727371548663e-07,
      "loss": 0.0287,
      "step": 13756
    },
    {
      "epoch": 0.9969924267130486,
      "grad_norm": 0.44115352630615234,
      "learning_rate": 6.232335676498297e-07,
      "loss": 0.0098,
      "step": 13757
    },
    {
      "epoch": 0.9970648983585172,
      "grad_norm": 4.522690773010254,
      "learning_rate": 6.087397637509965e-07,
      "loss": 0.1249,
      "step": 13758
    },
    {
      "epoch": 0.997137370003986,
      "grad_norm": 2.7306926250457764,
      "learning_rate": 5.942459598521632e-07,
      "loss": 0.0813,
      "step": 13759
    },
    {
      "epoch": 0.9972098416494547,
      "grad_norm": 3.8523218631744385,
      "learning_rate": 5.7975215595333e-07,
      "loss": 0.0247,
      "step": 13760
    },
    {
      "epoch": 0.9972823132949233,
      "grad_norm": 0.6470256447792053,
      "learning_rate": 5.652583520544966e-07,
      "loss": 0.0117,
      "step": 13761
    },
    {
      "epoch": 0.9973547849403921,
      "grad_norm": 3.0897979736328125,
      "learning_rate": 5.507645481556634e-07,
      "loss": 0.1133,
      "step": 13762
    },
    {
      "epoch": 0.9974272565858607,
      "grad_norm": 0.9011849164962769,
      "learning_rate": 5.362707442568303e-07,
      "loss": 0.0219,
      "step": 13763
    },
    {
      "epoch": 0.9974997282313295,
      "grad_norm": 0.3285793960094452,
      "learning_rate": 5.21776940357997e-07,
      "loss": 0.0066,
      "step": 13764
    },
    {
      "epoch": 0.9975721998767982,
      "grad_norm": 1.5177747011184692,
      "learning_rate": 5.072831364591638e-07,
      "loss": 0.1052,
      "step": 13765
    },
    {
      "epoch": 0.9976446715222669,
      "grad_norm": 2.976787805557251,
      "learning_rate": 4.927893325603305e-07,
      "loss": 0.0346,
      "step": 13766
    },
    {
      "epoch": 0.9977171431677356,
      "grad_norm": 2.0931687355041504,
      "learning_rate": 4.782955286614973e-07,
      "loss": 0.041,
      "step": 13767
    },
    {
      "epoch": 0.9977896148132044,
      "grad_norm": 0.9097402095794678,
      "learning_rate": 4.6380172476266404e-07,
      "loss": 0.0083,
      "step": 13768
    },
    {
      "epoch": 0.997862086458673,
      "grad_norm": 0.9670326709747314,
      "learning_rate": 4.493079208638307e-07,
      "loss": 0.0155,
      "step": 13769
    },
    {
      "epoch": 0.9979345581041418,
      "grad_norm": 0.45562297105789185,
      "learning_rate": 4.3481411696499744e-07,
      "loss": 0.0114,
      "step": 13770
    },
    {
      "epoch": 0.9980070297496104,
      "grad_norm": 1.559219479560852,
      "learning_rate": 4.2032031306616425e-07,
      "loss": 0.0503,
      "step": 13771
    },
    {
      "epoch": 0.9980795013950792,
      "grad_norm": 1.841080665588379,
      "learning_rate": 4.05826509167331e-07,
      "loss": 0.0285,
      "step": 13772
    },
    {
      "epoch": 0.9981519730405479,
      "grad_norm": 0.398136168718338,
      "learning_rate": 3.9133270526849776e-07,
      "loss": 0.0083,
      "step": 13773
    },
    {
      "epoch": 0.9982244446860166,
      "grad_norm": 0.2797843813896179,
      "learning_rate": 3.7683890136966446e-07,
      "loss": 0.0076,
      "step": 13774
    },
    {
      "epoch": 0.9982969163314853,
      "grad_norm": 1.6457473039627075,
      "learning_rate": 3.623450974708312e-07,
      "loss": 0.0355,
      "step": 13775
    },
    {
      "epoch": 0.9983693879769541,
      "grad_norm": 0.18075211346149445,
      "learning_rate": 3.47851293571998e-07,
      "loss": 0.0032,
      "step": 13776
    },
    {
      "epoch": 0.9984418596224227,
      "grad_norm": 3.1670925617218018,
      "learning_rate": 3.3335748967316473e-07,
      "loss": 0.0558,
      "step": 13777
    },
    {
      "epoch": 0.9985143312678915,
      "grad_norm": 1.0587505102157593,
      "learning_rate": 3.188636857743315e-07,
      "loss": 0.0195,
      "step": 13778
    },
    {
      "epoch": 0.9985868029133601,
      "grad_norm": 2.5782623291015625,
      "learning_rate": 3.0436988187549824e-07,
      "loss": 0.0412,
      "step": 13779
    },
    {
      "epoch": 0.9986592745588289,
      "grad_norm": 1.4289571046829224,
      "learning_rate": 2.89876077976665e-07,
      "loss": 0.0212,
      "step": 13780
    },
    {
      "epoch": 0.9987317462042976,
      "grad_norm": 0.11009921133518219,
      "learning_rate": 2.753822740778317e-07,
      "loss": 0.0014,
      "step": 13781
    },
    {
      "epoch": 0.9988042178497663,
      "grad_norm": 2.536698341369629,
      "learning_rate": 2.608884701789985e-07,
      "loss": 0.0637,
      "step": 13782
    },
    {
      "epoch": 0.998876689495235,
      "grad_norm": 1.2437576055526733,
      "learning_rate": 2.4639466628016526e-07,
      "loss": 0.0448,
      "step": 13783
    },
    {
      "epoch": 0.9989491611407036,
      "grad_norm": 1.1155438423156738,
      "learning_rate": 2.3190086238133202e-07,
      "loss": 0.0466,
      "step": 13784
    },
    {
      "epoch": 0.9990216327861724,
      "grad_norm": 1.5115658044815063,
      "learning_rate": 2.1740705848249872e-07,
      "loss": 0.0387,
      "step": 13785
    },
    {
      "epoch": 0.9990941044316412,
      "grad_norm": 1.5271819829940796,
      "learning_rate": 2.029132545836655e-07,
      "loss": 0.0411,
      "step": 13786
    },
    {
      "epoch": 0.9991665760771098,
      "grad_norm": 0.5298146605491638,
      "learning_rate": 1.8841945068483223e-07,
      "loss": 0.0097,
      "step": 13787
    },
    {
      "epoch": 0.9992390477225785,
      "grad_norm": 2.239424228668213,
      "learning_rate": 1.73925646785999e-07,
      "loss": 0.0592,
      "step": 13788
    },
    {
      "epoch": 0.9993115193680473,
      "grad_norm": 3.4149303436279297,
      "learning_rate": 1.5943184288716574e-07,
      "loss": 0.117,
      "step": 13789
    },
    {
      "epoch": 0.9993839910135159,
      "grad_norm": 0.10884895920753479,
      "learning_rate": 1.449380389883325e-07,
      "loss": 0.0011,
      "step": 13790
    },
    {
      "epoch": 0.9994564626589847,
      "grad_norm": 1.4629464149475098,
      "learning_rate": 1.3044423508949925e-07,
      "loss": 0.0463,
      "step": 13791
    },
    {
      "epoch": 0.9995289343044533,
      "grad_norm": 1.7548692226409912,
      "learning_rate": 1.1595043119066601e-07,
      "loss": 0.0275,
      "step": 13792
    },
    {
      "epoch": 0.9996014059499221,
      "grad_norm": 0.6592771410942078,
      "learning_rate": 1.0145662729183275e-07,
      "loss": 0.0154,
      "step": 13793
    },
    {
      "epoch": 0.9996738775953908,
      "grad_norm": 3.426571846008301,
      "learning_rate": 8.69628233929995e-08,
      "loss": 0.0568,
      "step": 13794
    },
    {
      "epoch": 0.9997463492408595,
      "grad_norm": 3.949258804321289,
      "learning_rate": 7.246901949416625e-08,
      "loss": 0.1008,
      "step": 13795
    },
    {
      "epoch": 0.9998188208863282,
      "grad_norm": 0.33086928725242615,
      "learning_rate": 5.7975215595333005e-08,
      "loss": 0.0032,
      "step": 13796
    },
    {
      "epoch": 0.999891292531797,
      "grad_norm": 2.425854444503784,
      "learning_rate": 4.348141169649975e-08,
      "loss": 0.1139,
      "step": 13797
    },
    {
      "epoch": 0.9999637641772656,
      "grad_norm": 3.2061517238616943,
      "learning_rate": 2.8987607797666502e-08,
      "loss": 0.0758,
      "step": 13798
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.0185684934258461,
      "learning_rate": 1.4493803898833251e-08,
      "loss": 0.0003,
      "step": 13799
    }
  ],
  "logging_steps": 1,
  "max_steps": 13799,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.69333952943511e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
